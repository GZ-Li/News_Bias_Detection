{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EuP_7ksfag6h"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "import torch.utils.data as Data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from math import log"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')\n",
        "#改变当前工作目录到谷歌云盘的路径\n",
        "path=\"/content/drive/My Drive/Colab Notebooks/Bias Detection/\"\n",
        "os.chdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGSzrj5G_X_h",
        "outputId": "adf63db7-0930-4b9b-9fe3-9e81aae1e4d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_process = np.load(\"X_train_glove_title.npy\")\n",
        "X_test_process = np.load(\"X_test_glove_title.npy\")\n",
        "X_valid_process = np.load(\"X_valid_glove_title.npy\")\n",
        "y_train_process = np.load(\"y_train_glove.npy\")\n",
        "y_test_process = np.load(\"y_test_glove.npy\")\n",
        "y_valid_process = np.load(\"y_valid_glove.npy\")\n",
        "H_train_process = np.load(\"X_train_glove_headline.npy\")\n",
        "H_test_process = np.load(\"X_test_glove_headline.npy\")\n",
        "H_valid_process = np.load(\"X_valid_glove_headline.npy\")"
      ],
      "metadata": {
        "id": "HeWMyPW6_aj2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate([X_train_process, H_train_process], axis = 1)\n",
        "X_test = np.concatenate([X_test_process, H_test_process], axis = 1)\n",
        "X_valid = np.concatenate([X_valid_process, H_valid_process], axis = 1)"
      ],
      "metadata": {
        "id": "O4mHBv4L_cdP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = Data.DataLoader(\n",
        "    dataset=Data.TensorDataset(torch.Tensor(X_train),torch.LongTensor(y_train_process)),      \n",
        "    batch_size=128,      \n",
        "    shuffle=True,               \n",
        "    num_workers=2, \n",
        "    drop_last=True\n",
        ")\n",
        "test_loader = Data.DataLoader(\n",
        "    dataset=Data.TensorDataset(torch.Tensor(X_test),torch.LongTensor(y_test_process)),      \n",
        "    batch_size=128,      \n",
        "    shuffle=True,               \n",
        "    num_workers=2,  \n",
        "    drop_last=True\n",
        ")\n",
        "val_loader = Data.DataLoader(\n",
        "    dataset=Data.TensorDataset(torch.Tensor(X_valid),torch.LongTensor(y_valid_process)),      \n",
        "    batch_size=128,      \n",
        "    shuffle=True,               \n",
        "    num_workers=2,\n",
        "    drop_last=True\n",
        ")"
      ],
      "metadata": {
        "id": "b4NoDLYu_eo8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ECA(x,gamma=2,b=1):\n",
        "    N,C,H,W=x.size()\n",
        "    t=int(abs((log(C,2)+b)/gamma))\n",
        "    k=t if t%2 else t+1\n",
        "    \n",
        "    avg_pool=nn.AdaptiveAvgPool2d(1).cuda()\n",
        "    conv=nn.Conv1d(1,1,kernel_size=k,padding=int(k/2),bias=False).cuda()\n",
        "    sigmoid=nn.Sigmoid().cuda()\n",
        "    \n",
        "    y=avg_pool(x)\n",
        "    y=conv(y.squeeze(-1).transpose(-1,-2))\n",
        "    y=y.transpose(-1,-2).unsqueeze(-1)\n",
        "    y=sigmoid(y)\n",
        "    return y"
      ],
      "metadata": {
        "id": "ykYf4NIN_g2W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextRCNN(nn.Module):\n",
        "    def __init__(self,vocab_size,embedding_dim,hidden_size,num_labels=5):\n",
        "        super(TextRCNN,self).__init__()\n",
        "        self.GRU = nn.GRU(input_size=embedding_dim,hidden_size=hidden_size,\n",
        "                            batch_first=True,bidirectional=True)\n",
        "        self.dropout = nn.Dropout(.3)\n",
        "        self.linear1 = nn.Linear(embedding_dim+2*hidden_size, 128)\n",
        "        self.linear2 = nn.Linear(600, 128)\n",
        "        self.linear3 = nn.Linear(128, num_labels)\n",
        "        self.conv1 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=6)#通过out_channel改变文中的feature map，且out_channel∈[10,50,100,200,400,600,800,1000]\n",
        "        self.conv2 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=7)\n",
        "        self.conv3 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=8)\n",
        "        self.conv4 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=9)\n",
        "        #self.w_omiga = torch.randn(128,hidden_size*2,1,requires_grad=True).cuda()\n",
        "\n",
        "    def forward(self, x):#x: [batch,L]\n",
        "        #x_embed = x.cuda()\n",
        "        headline = x[:, 500:, :].cuda()\n",
        "        head_hidden_state, (h_c, h_h) = self.GRU(headline)\n",
        "        U = head_hidden_state[:, -1, :].unsqueeze(1)\n",
        "        U = U.permute(0,2,1)\n",
        "        x_embed = x[:, :500, :].cuda()\n",
        "        last_hidden_state,(c,h) = self.GRU(x_embed) #last_hidden_state: [batch,L,hidden_size * num_bidirectional]\n",
        "        H = torch.nn.Tanh()(last_hidden_state)\n",
        "        weights=torch.nn.Softmax(dim=-1)(torch.bmm(H, U).squeeze(-1)).unsqueeze(dim=-1).repeat(1,1,2*12)  # LSTM+ATTN-Weight\n",
        "        last_hidden_state=torch.mul(last_hidden_state,weights)\n",
        "        out = torch.cat((last_hidden_state[:,:,:12],x_embed,last_hidden_state[:,:,12:]),2).cuda()#out: [batch,L,embedding_size + hidden_size * num_bidirectional]  \n",
        "        out = F.tanh(self.linear1(out))\n",
        "        out = out.permute(dims=[0,2,1]).cuda() #out: [batch,embedding_size + hidden_size * num_bidirectional,L]\n",
        "        out_1 = self.conv1(out)\n",
        "        out_1 = nn.ReLU()(out_1)\n",
        "        out_1 = nn.MaxPool1d(kernel_size=495)(out_1)\n",
        "        out_2 = self.conv1(out)\n",
        "        out_2 = nn.ReLU()(out_2)\n",
        "        out_2 = nn.MaxPool1d(kernel_size=494)(out_2)\n",
        "        out_3 = self.conv1(out)\n",
        "        out_3 = nn.ReLU()(out_3)\n",
        "        out_3 = nn.MaxPool1d(kernel_size=493)(out_3)\n",
        "        out_4 = self.conv1(out)\n",
        "        out_4 = nn.ReLU()(out_4)\n",
        "        out_4 = nn.MaxPool1d(kernel_size=492)(out_4)\n",
        "        out_1 = out_1.unsqueeze(1).cuda()\n",
        "        out_2 = out_2.unsqueeze(1).cuda()\n",
        "        out_3 = out_3.unsqueeze(1).cuda()\n",
        "        out_4 = out_4.unsqueeze(1).cuda()\n",
        "        out = torch.cat([out_1, out_2, out_3, out_4],dim=1).cuda()\n",
        "        channel_weights = F.softmax(ECA(out).squeeze().squeeze(),dim=1).unsqueeze(-1).unsqueeze(-1).expand_as(out)\n",
        "        out = torch.mul(channel_weights,out).cuda()\n",
        "        out = torch.sum(out, dim = 1)\n",
        "        out = self.linear2(out.squeeze()) #out: [batch,num_labels]\n",
        "        out = self.linear3(F.tanh(out))\n",
        "        out = F.softmax(out,dim=1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "oKYRlBYG_xbj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextRCNN(5302,200,12).cuda()"
      ],
      "metadata": {
        "id": "61ZEtZue_z6V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list, counter =[], []\n",
        "count = 0\n",
        "running_loss=0\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0)\n",
        "total_train = 0\n",
        "correct_train = 0\n",
        "train_epoch, train_loss = [], []\n",
        "train_acc, val_acc = [], []\n",
        "avg_epoch, avg_train_loss, avg_val_acc = [], [], []\n",
        "epoch_time=[]\n",
        "\n",
        "model.train()\n",
        "for epoch in range(128): \n",
        "    running_loss = 0\n",
        "    total_train = 0\n",
        "    correct_train = 0\n",
        "    total_accuracy = 0\n",
        "    total_val_accuracy = 0\n",
        "    correct_val = 0\n",
        "    total_val = 0   \n",
        "    start1 = time.time()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        start = time.time()\n",
        "        t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
        "        t_image=t_image.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(t_image) # forward\n",
        "        ###########################################################################\n",
        "        outputs=outputs.cuda()\n",
        "        mask=mask.cuda()\n",
        "        loss = criterion(outputs, mask.long()) # calculate the loss\n",
        "        loss.backward() # back propagation\n",
        "        optimizer.step() # update gradients\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += mask.nelement()\n",
        "        correct_train += predicted.eq(mask.data).sum().item()\n",
        "        train_accuracy = 100 * correct_train / total_train\n",
        "        total_accuracy += train_accuracy\n",
        "        if i % 5 == 0:\n",
        "            end = time.time()\n",
        "            print('Epoch {}:[{}/{}], Current Loss: {}, Current Training Accuracy: {}, Time: {} ms'.format(epoch+1, i, len(train_loader), loss.item(), train_accuracy, end - start))      \n",
        "            train_acc.append(train_accuracy)\n",
        "            train_loss.append(loss.item())\n",
        "            train_epoch.append(str(epoch+1) + '/' + str(i))\n",
        "\n",
        "            for j, data1 in enumerate(val_loader, 0):\n",
        "                t_image1, mask1 = data1[0],data1[1].long()\n",
        "                outputs1 = model(t_image1)\n",
        "                mask1_temp=torch.max(mask1.data,1)\n",
        "                mask1_temp1=mask1_temp[1].cuda()\n",
        "                _, predicted1 = torch.max(outputs1.data, 1)\n",
        "                total_val += mask1.nelement()\n",
        "                correct_val += predicted1.eq(mask1_temp1).sum().item()\n",
        "                val_accuracy= 100 * correct_val / total_val\n",
        "                total_val_accuracy += val_accuracy\n",
        "            val_acc.append(val_accuracy)\n",
        "    end1 = time.time()\n",
        "    print('Epoch {}, train Loss: {:.3f} '.format(epoch+1, running_loss/len(train_loader)), \"Avg Training Accuracy: {%d %%}\" % (total_accuracy/len(train_loader)), \"Avg Validation Accuracy: %d %%\" % (total_val_accuracy/len(val_loader)), \"Epoch Time: {} ms\".format(end1 - start1))\n",
        "    epoch_time.append(end1-start1)\n",
        "    avg_epoch.append(epoch+1)\n",
        "    avg_train_loss.append(running_loss/len(train_loader))\n",
        "    avg_val_acc.append(total_val_accuracy/len(val_loader))\n",
        "    #print(avg_epoch)\n",
        "    #print(avg_train_loss)\n",
        "    #print(avg_val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mpiuzXV_14J",
        "outputId": "7b53d6c9-74cb-49cc-a12f-24b6faf40df8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:[0/16], Current Loss: 1.6120760440826416, Current Training Accuracy: 10.15625, Time: 4.839828729629517 ms\n",
            "Epoch 1:[5/16], Current Loss: 1.4962838888168335, Current Training Accuracy: 29.296875, Time: 0.2452700138092041 ms\n",
            "Epoch 1:[10/16], Current Loss: 1.5095211267471313, Current Training Accuracy: 31.74715909090909, Time: 0.24591898918151855 ms\n",
            "Epoch 1:[15/16], Current Loss: 1.4342546463012695, Current Training Accuracy: 37.451171875, Time: 0.23952794075012207 ms\n",
            "Epoch 1, train Loss: 1.517  Avg Training Accuracy: {30 %} Avg Validation Accuracy: 31 % Epoch Time: 11.983918190002441 ms\n",
            "Epoch 2:[0/16], Current Loss: 1.4047307968139648, Current Training Accuracy: 57.8125, Time: 0.26941514015197754 ms\n",
            "Epoch 2:[5/16], Current Loss: 1.3179470300674438, Current Training Accuracy: 55.338541666666664, Time: 0.2495572566986084 ms\n",
            "Epoch 2:[10/16], Current Loss: 1.2961660623550415, Current Training Accuracy: 56.32102272727273, Time: 0.25290536880493164 ms\n",
            "Epoch 2:[15/16], Current Loss: 1.3285237550735474, Current Training Accuracy: 56.0546875, Time: 0.24210906028747559 ms\n",
            "Epoch 2, train Loss: 1.354  Avg Training Accuracy: {55 %} Avg Validation Accuracy: 43 % Epoch Time: 7.233402252197266 ms\n",
            "Epoch 3:[0/16], Current Loss: 1.343432903289795, Current Training Accuracy: 54.6875, Time: 0.267744779586792 ms\n",
            "Epoch 3:[5/16], Current Loss: 1.298354148864746, Current Training Accuracy: 57.291666666666664, Time: 0.25551700592041016 ms\n",
            "Epoch 3:[10/16], Current Loss: 1.2493829727172852, Current Training Accuracy: 63.21022727272727, Time: 0.24837875366210938 ms\n",
            "Epoch 3:[15/16], Current Loss: 1.2893671989440918, Current Training Accuracy: 64.306640625, Time: 0.2418808937072754 ms\n",
            "Epoch 3, train Loss: 1.276  Avg Training Accuracy: {59 %} Avg Validation Accuracy: 47 % Epoch Time: 7.276503324508667 ms\n",
            "Epoch 4:[0/16], Current Loss: 1.248348593711853, Current Training Accuracy: 67.1875, Time: 0.26514124870300293 ms\n",
            "Epoch 4:[5/16], Current Loss: 1.2214505672454834, Current Training Accuracy: 70.57291666666667, Time: 0.2521355152130127 ms\n",
            "Epoch 4:[10/16], Current Loss: 1.247652292251587, Current Training Accuracy: 69.0340909090909, Time: 0.25957417488098145 ms\n",
            "Epoch 4:[15/16], Current Loss: 1.156115174293518, Current Training Accuracy: 70.166015625, Time: 0.24284577369689941 ms\n",
            "Epoch 4, train Loss: 1.215  Avg Training Accuracy: {69 %} Avg Validation Accuracy: 52 % Epoch Time: 7.257136106491089 ms\n",
            "Epoch 5:[0/16], Current Loss: 1.1908234357833862, Current Training Accuracy: 73.4375, Time: 0.2676112651824951 ms\n",
            "Epoch 5:[5/16], Current Loss: 1.166463017463684, Current Training Accuracy: 71.484375, Time: 0.2458667755126953 ms\n",
            "Epoch 5:[10/16], Current Loss: 1.140139102935791, Current Training Accuracy: 72.86931818181819, Time: 0.24892425537109375 ms\n",
            "Epoch 5:[15/16], Current Loss: 1.1638679504394531, Current Training Accuracy: 73.193359375, Time: 0.24437999725341797 ms\n",
            "Epoch 5, train Loss: 1.180  Avg Training Accuracy: {72 %} Avg Validation Accuracy: 53 % Epoch Time: 7.295395851135254 ms\n",
            "Epoch 6:[0/16], Current Loss: 1.1894636154174805, Current Training Accuracy: 71.09375, Time: 0.2797846794128418 ms\n",
            "Epoch 6:[5/16], Current Loss: 1.185288667678833, Current Training Accuracy: 73.95833333333333, Time: 0.25125694274902344 ms\n",
            "Epoch 6:[10/16], Current Loss: 1.145353078842163, Current Training Accuracy: 75.78125, Time: 0.24971771240234375 ms\n",
            "Epoch 6:[15/16], Current Loss: 1.1303575038909912, Current Training Accuracy: 75.927734375, Time: 0.2469484806060791 ms\n",
            "Epoch 6, train Loss: 1.149  Avg Training Accuracy: {74 %} Avg Validation Accuracy: 55 % Epoch Time: 7.294396162033081 ms\n",
            "Epoch 7:[0/16], Current Loss: 1.1293787956237793, Current Training Accuracy: 78.90625, Time: 0.27135133743286133 ms\n",
            "Epoch 7:[5/16], Current Loss: 1.1073622703552246, Current Training Accuracy: 76.69270833333333, Time: 0.24904751777648926 ms\n",
            "Epoch 7:[10/16], Current Loss: 1.1453779935836792, Current Training Accuracy: 77.20170454545455, Time: 0.24964332580566406 ms\n",
            "Epoch 7:[15/16], Current Loss: 1.126269817352295, Current Training Accuracy: 77.734375, Time: 0.24849677085876465 ms\n",
            "Epoch 7, train Loss: 1.133  Avg Training Accuracy: {77 %} Avg Validation Accuracy: 53 % Epoch Time: 7.333968162536621 ms\n",
            "Epoch 8:[0/16], Current Loss: 1.1466310024261475, Current Training Accuracy: 76.5625, Time: 0.2680356502532959 ms\n",
            "Epoch 8:[5/16], Current Loss: 1.1180819272994995, Current Training Accuracy: 79.16666666666667, Time: 0.24985718727111816 ms\n",
            "Epoch 8:[10/16], Current Loss: 1.1623680591583252, Current Training Accuracy: 78.19602272727273, Time: 0.2514960765838623 ms\n",
            "Epoch 8:[15/16], Current Loss: 1.1587165594100952, Current Training Accuracy: 78.271484375, Time: 0.24956607818603516 ms\n",
            "Epoch 8, train Loss: 1.122  Avg Training Accuracy: {78 %} Avg Validation Accuracy: 55 % Epoch Time: 7.366880178451538 ms\n",
            "Epoch 9:[0/16], Current Loss: 1.133109211921692, Current Training Accuracy: 77.34375, Time: 0.2760148048400879 ms\n",
            "Epoch 9:[5/16], Current Loss: 1.1382153034210205, Current Training Accuracy: 77.34375, Time: 0.25235414505004883 ms\n",
            "Epoch 9:[10/16], Current Loss: 1.1036778688430786, Current Training Accuracy: 79.04829545454545, Time: 0.25455641746520996 ms\n",
            "Epoch 9:[15/16], Current Loss: 1.1499813795089722, Current Training Accuracy: 78.857421875, Time: 0.25005364418029785 ms\n",
            "Epoch 9, train Loss: 1.116  Avg Training Accuracy: {78 %} Avg Validation Accuracy: 54 % Epoch Time: 7.44053840637207 ms\n",
            "Epoch 10:[0/16], Current Loss: 1.0792042016983032, Current Training Accuracy: 82.03125, Time: 0.28104662895202637 ms\n",
            "Epoch 10:[5/16], Current Loss: 1.071022629737854, Current Training Accuracy: 79.55729166666667, Time: 0.2589375972747803 ms\n",
            "Epoch 10:[10/16], Current Loss: 1.0739017724990845, Current Training Accuracy: 79.61647727272727, Time: 0.25501132011413574 ms\n",
            "Epoch 10:[15/16], Current Loss: 1.0667414665222168, Current Training Accuracy: 81.005859375, Time: 0.25013256072998047 ms\n",
            "Epoch 10, train Loss: 1.095  Avg Training Accuracy: {79 %} Avg Validation Accuracy: 56 % Epoch Time: 7.403374433517456 ms\n",
            "Epoch 11:[0/16], Current Loss: 1.0587910413742065, Current Training Accuracy: 88.28125, Time: 0.28335142135620117 ms\n",
            "Epoch 11:[5/16], Current Loss: 1.0664142370224, Current Training Accuracy: 84.11458333333333, Time: 0.2545135021209717 ms\n",
            "Epoch 11:[10/16], Current Loss: 1.0862656831741333, Current Training Accuracy: 84.6590909090909, Time: 0.25943756103515625 ms\n",
            "Epoch 11:[15/16], Current Loss: 1.0628650188446045, Current Training Accuracy: 85.693359375, Time: 0.25185728073120117 ms\n",
            "Epoch 11, train Loss: 1.053  Avg Training Accuracy: {85 %} Avg Validation Accuracy: 61 % Epoch Time: 7.424889802932739 ms\n",
            "Epoch 12:[0/16], Current Loss: 1.049102544784546, Current Training Accuracy: 85.9375, Time: 0.2749161720275879 ms\n",
            "Epoch 12:[5/16], Current Loss: 1.0676071643829346, Current Training Accuracy: 85.9375, Time: 0.2551841735839844 ms\n",
            "Epoch 12:[10/16], Current Loss: 1.037710189819336, Current Training Accuracy: 86.29261363636364, Time: 0.2558426856994629 ms\n",
            "Epoch 12:[15/16], Current Loss: 1.0217028856277466, Current Training Accuracy: 86.962890625, Time: 0.2583327293395996 ms\n",
            "Epoch 12, train Loss: 1.038  Avg Training Accuracy: {86 %} Avg Validation Accuracy: 62 % Epoch Time: 7.4562928676605225 ms\n",
            "Epoch 13:[0/16], Current Loss: 1.0642198324203491, Current Training Accuracy: 83.59375, Time: 0.27703428268432617 ms\n",
            "Epoch 13:[5/16], Current Loss: 1.0371971130371094, Current Training Accuracy: 86.71875, Time: 0.2601780891418457 ms\n",
            "Epoch 13:[10/16], Current Loss: 0.99017733335495, Current Training Accuracy: 87.35795454545455, Time: 0.25600290298461914 ms\n",
            "Epoch 13:[15/16], Current Loss: 1.1065750122070312, Current Training Accuracy: 87.451171875, Time: 0.2552378177642822 ms\n",
            "Epoch 13, train Loss: 1.029  Avg Training Accuracy: {86 %} Avg Validation Accuracy: 61 % Epoch Time: 7.465485572814941 ms\n",
            "Epoch 14:[0/16], Current Loss: 1.0636261701583862, Current Training Accuracy: 83.59375, Time: 0.28346967697143555 ms\n",
            "Epoch 14:[5/16], Current Loss: 1.0415784120559692, Current Training Accuracy: 87.36979166666667, Time: 0.26070737838745117 ms\n",
            "Epoch 14:[10/16], Current Loss: 1.0149297714233398, Current Training Accuracy: 87.28693181818181, Time: 0.2557084560394287 ms\n",
            "Epoch 14:[15/16], Current Loss: 1.0228208303451538, Current Training Accuracy: 88.0859375, Time: 0.2530827522277832 ms\n",
            "Epoch 14, train Loss: 1.024  Avg Training Accuracy: {87 %} Avg Validation Accuracy: 62 % Epoch Time: 7.466389894485474 ms\n",
            "Epoch 15:[0/16], Current Loss: 1.058579921722412, Current Training Accuracy: 84.375, Time: 0.2842276096343994 ms\n",
            "Epoch 15:[5/16], Current Loss: 1.0202072858810425, Current Training Accuracy: 88.54166666666667, Time: 0.2573115825653076 ms\n",
            "Epoch 15:[10/16], Current Loss: 1.0709697008132935, Current Training Accuracy: 87.92613636363636, Time: 0.2622184753417969 ms\n",
            "Epoch 15:[15/16], Current Loss: 1.0331932306289673, Current Training Accuracy: 88.427734375, Time: 0.25718045234680176 ms\n",
            "Epoch 15, train Loss: 1.019  Avg Training Accuracy: {87 %} Avg Validation Accuracy: 61 % Epoch Time: 7.5589070320129395 ms\n",
            "Epoch 16:[0/16], Current Loss: 0.991998553276062, Current Training Accuracy: 90.625, Time: 0.2750580310821533 ms\n",
            "Epoch 16:[5/16], Current Loss: 1.0493191480636597, Current Training Accuracy: 88.54166666666667, Time: 0.2606363296508789 ms\n",
            "Epoch 16:[10/16], Current Loss: 1.0150058269500732, Current Training Accuracy: 88.21022727272727, Time: 0.261310338973999 ms\n",
            "Epoch 16:[15/16], Current Loss: 1.030817985534668, Current Training Accuracy: 88.37890625, Time: 0.25292539596557617 ms\n",
            "Epoch 16, train Loss: 1.017  Avg Training Accuracy: {88 %} Avg Validation Accuracy: 60 % Epoch Time: 7.488457918167114 ms\n",
            "Epoch 17:[0/16], Current Loss: 1.0087956190109253, Current Training Accuracy: 89.0625, Time: 0.2798035144805908 ms\n",
            "Epoch 17:[5/16], Current Loss: 1.0392987728118896, Current Training Accuracy: 88.671875, Time: 0.2593362331390381 ms\n",
            "Epoch 17:[10/16], Current Loss: 0.9944680333137512, Current Training Accuracy: 88.7784090909091, Time: 0.2549002170562744 ms\n",
            "Epoch 17:[15/16], Current Loss: 0.9771736860275269, Current Training Accuracy: 88.818359375, Time: 0.25545310974121094 ms\n",
            "Epoch 17, train Loss: 1.010  Avg Training Accuracy: {88 %} Avg Validation Accuracy: 62 % Epoch Time: 7.491493225097656 ms\n",
            "Epoch 18:[0/16], Current Loss: 0.975543737411499, Current Training Accuracy: 96.875, Time: 0.2768585681915283 ms\n",
            "Epoch 18:[5/16], Current Loss: 0.9807263016700745, Current Training Accuracy: 95.57291666666667, Time: 0.2552459239959717 ms\n",
            "Epoch 18:[10/16], Current Loss: 0.9632888436317444, Current Training Accuracy: 96.3778409090909, Time: 0.2687687873840332 ms\n",
            "Epoch 18:[15/16], Current Loss: 0.952016294002533, Current Training Accuracy: 96.09375, Time: 0.2541689872741699 ms\n",
            "Epoch 18, train Loss: 0.975  Avg Training Accuracy: {95 %} Avg Validation Accuracy: 62 % Epoch Time: 7.506800889968872 ms\n",
            "Epoch 19:[0/16], Current Loss: 0.9429049491882324, Current Training Accuracy: 98.4375, Time: 0.27692532539367676 ms\n",
            "Epoch 19:[5/16], Current Loss: 0.9537365436553955, Current Training Accuracy: 97.00520833333333, Time: 0.2573697566986084 ms\n",
            "Epoch 19:[10/16], Current Loss: 0.9481622576713562, Current Training Accuracy: 96.44886363636364, Time: 0.25629472732543945 ms\n",
            "Epoch 19:[15/16], Current Loss: 0.934484601020813, Current Training Accuracy: 96.6796875, Time: 0.2501673698425293 ms\n",
            "Epoch 19, train Loss: 0.952  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 63 % Epoch Time: 7.421940565109253 ms\n",
            "Epoch 20:[0/16], Current Loss: 0.9366021156311035, Current Training Accuracy: 98.4375, Time: 0.2724785804748535 ms\n",
            "Epoch 20:[5/16], Current Loss: 0.9417717456817627, Current Training Accuracy: 97.39583333333333, Time: 0.254443883895874 ms\n",
            "Epoch 20:[10/16], Current Loss: 0.9498830437660217, Current Training Accuracy: 97.08806818181819, Time: 0.25448036193847656 ms\n",
            "Epoch 20:[15/16], Current Loss: 0.9387291669845581, Current Training Accuracy: 97.0703125, Time: 0.25343918800354004 ms\n",
            "Epoch 20, train Loss: 0.944  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 62 % Epoch Time: 7.502656936645508 ms\n",
            "Epoch 21:[0/16], Current Loss: 0.9234628677368164, Current Training Accuracy: 99.21875, Time: 0.27782416343688965 ms\n",
            "Epoch 21:[5/16], Current Loss: 0.9301847815513611, Current Training Accuracy: 96.74479166666667, Time: 0.2567477226257324 ms\n",
            "Epoch 21:[10/16], Current Loss: 0.9450790286064148, Current Training Accuracy: 97.08806818181819, Time: 0.25702691078186035 ms\n",
            "Epoch 21:[15/16], Current Loss: 0.9310847520828247, Current Training Accuracy: 97.265625, Time: 0.25012922286987305 ms\n",
            "Epoch 21, train Loss: 0.936  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 62 % Epoch Time: 7.401914358139038 ms\n",
            "Epoch 22:[0/16], Current Loss: 0.9232585430145264, Current Training Accuracy: 98.4375, Time: 0.2845571041107178 ms\n",
            "Epoch 22:[5/16], Current Loss: 0.9153333902359009, Current Training Accuracy: 97.91666666666667, Time: 0.25485992431640625 ms\n",
            "Epoch 22:[10/16], Current Loss: 0.9226254224777222, Current Training Accuracy: 97.65625, Time: 0.25768136978149414 ms\n",
            "Epoch 22:[15/16], Current Loss: 0.9304099082946777, Current Training Accuracy: 97.412109375, Time: 0.2521681785583496 ms\n",
            "Epoch 22, train Loss: 0.933  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.457718372344971 ms\n",
            "Epoch 23:[0/16], Current Loss: 0.9067656993865967, Current Training Accuracy: 100.0, Time: 0.2779734134674072 ms\n",
            "Epoch 23:[5/16], Current Loss: 0.9296556711196899, Current Training Accuracy: 97.52604166666667, Time: 0.2566535472869873 ms\n",
            "Epoch 23:[10/16], Current Loss: 0.929509699344635, Current Training Accuracy: 97.23011363636364, Time: 0.2597315311431885 ms\n",
            "Epoch 23:[15/16], Current Loss: 0.9527646899223328, Current Training Accuracy: 97.36328125, Time: 0.2536661624908447 ms\n",
            "Epoch 23, train Loss: 0.932  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 7.464742183685303 ms\n",
            "Epoch 24:[0/16], Current Loss: 0.9214565753936768, Current Training Accuracy: 98.4375, Time: 0.2853739261627197 ms\n",
            "Epoch 24:[5/16], Current Loss: 0.906352162361145, Current Training Accuracy: 97.39583333333333, Time: 0.25745439529418945 ms\n",
            "Epoch 24:[10/16], Current Loss: 0.936856210231781, Current Training Accuracy: 97.3721590909091, Time: 0.26099085807800293 ms\n",
            "Epoch 24:[15/16], Current Loss: 0.9216552376747131, Current Training Accuracy: 97.36328125, Time: 0.2528109550476074 ms\n",
            "Epoch 24, train Loss: 0.932  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.500285863876343 ms\n",
            "Epoch 25:[0/16], Current Loss: 0.9359418153762817, Current Training Accuracy: 96.875, Time: 0.28471851348876953 ms\n",
            "Epoch 25:[5/16], Current Loss: 0.921001136302948, Current Training Accuracy: 98.046875, Time: 0.260225772857666 ms\n",
            "Epoch 25:[10/16], Current Loss: 0.9275691509246826, Current Training Accuracy: 98.08238636363636, Time: 0.25799012184143066 ms\n",
            "Epoch 25:[15/16], Current Loss: 0.9671262502670288, Current Training Accuracy: 97.4609375, Time: 0.2558014392852783 ms\n",
            "Epoch 25, train Loss: 0.930  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.4693052768707275 ms\n",
            "Epoch 26:[0/16], Current Loss: 0.9207974672317505, Current Training Accuracy: 98.4375, Time: 0.27481746673583984 ms\n",
            "Epoch 26:[5/16], Current Loss: 0.9506287574768066, Current Training Accuracy: 97.00520833333333, Time: 0.25505542755126953 ms\n",
            "Epoch 26:[10/16], Current Loss: 0.9199562668800354, Current Training Accuracy: 97.30113636363636, Time: 0.26143670082092285 ms\n",
            "Epoch 26:[15/16], Current Loss: 0.9208429455757141, Current Training Accuracy: 97.4609375, Time: 0.25221920013427734 ms\n",
            "Epoch 26, train Loss: 0.930  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.430843830108643 ms\n",
            "Epoch 27:[0/16], Current Loss: 0.9357361197471619, Current Training Accuracy: 96.875, Time: 0.27776575088500977 ms\n",
            "Epoch 27:[5/16], Current Loss: 0.9291252493858337, Current Training Accuracy: 97.00520833333333, Time: 0.2595534324645996 ms\n",
            "Epoch 27:[10/16], Current Loss: 0.9187949299812317, Current Training Accuracy: 97.3721590909091, Time: 0.257443904876709 ms\n",
            "Epoch 27:[15/16], Current Loss: 0.9357418417930603, Current Training Accuracy: 97.412109375, Time: 0.25665283203125 ms\n",
            "Epoch 27, train Loss: 0.931  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.908100128173828 ms\n",
            "Epoch 28:[0/16], Current Loss: 0.9355935454368591, Current Training Accuracy: 96.875, Time: 0.280745267868042 ms\n",
            "Epoch 28:[5/16], Current Loss: 0.9446155428886414, Current Training Accuracy: 97.39583333333333, Time: 0.26513004302978516 ms\n",
            "Epoch 28:[10/16], Current Loss: 0.9279994964599609, Current Training Accuracy: 97.65625, Time: 0.2535836696624756 ms\n",
            "Epoch 28:[15/16], Current Loss: 0.9354124069213867, Current Training Accuracy: 97.4609375, Time: 0.25603222846984863 ms\n",
            "Epoch 28, train Loss: 0.930  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 8.139427661895752 ms\n",
            "Epoch 29:[0/16], Current Loss: 0.9283861517906189, Current Training Accuracy: 97.65625, Time: 0.28277587890625 ms\n",
            "Epoch 29:[5/16], Current Loss: 0.9212155938148499, Current Training Accuracy: 97.78645833333333, Time: 0.2557556629180908 ms\n",
            "Epoch 29:[10/16], Current Loss: 0.9572330117225647, Current Training Accuracy: 97.72727272727273, Time: 0.2575347423553467 ms\n",
            "Epoch 29:[15/16], Current Loss: 0.9436292052268982, Current Training Accuracy: 97.4609375, Time: 0.2526893615722656 ms\n",
            "Epoch 29, train Loss: 0.930  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.8041040897369385 ms\n",
            "Epoch 30:[0/16], Current Loss: 0.9134508967399597, Current Training Accuracy: 99.21875, Time: 0.2752950191497803 ms\n",
            "Epoch 30:[5/16], Current Loss: 0.9289646148681641, Current Training Accuracy: 97.13541666666667, Time: 0.25749826431274414 ms\n",
            "Epoch 30:[10/16], Current Loss: 0.9288797974586487, Current Training Accuracy: 97.51420454545455, Time: 0.26257967948913574 ms\n",
            "Epoch 30:[15/16], Current Loss: 0.9276183843612671, Current Training Accuracy: 97.509765625, Time: 0.25150489807128906 ms\n",
            "Epoch 30, train Loss: 0.930  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.499046564102173 ms\n",
            "Epoch 31:[0/16], Current Loss: 0.9205405116081238, Current Training Accuracy: 98.4375, Time: 0.2753117084503174 ms\n",
            "Epoch 31:[5/16], Current Loss: 0.9440584778785706, Current Training Accuracy: 97.39583333333333, Time: 0.2553446292877197 ms\n",
            "Epoch 31:[10/16], Current Loss: 0.9200913310050964, Current Training Accuracy: 97.51420454545455, Time: 0.2526099681854248 ms\n",
            "Epoch 31:[15/16], Current Loss: 0.92081218957901, Current Training Accuracy: 97.55859375, Time: 0.2518939971923828 ms\n",
            "Epoch 31, train Loss: 0.929  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.433235168457031 ms\n",
            "Epoch 32:[0/16], Current Loss: 0.9132262468338013, Current Training Accuracy: 99.21875, Time: 0.27779483795166016 ms\n",
            "Epoch 32:[5/16], Current Loss: 0.9282081127166748, Current Training Accuracy: 97.39583333333333, Time: 0.2585916519165039 ms\n",
            "Epoch 32:[10/16], Current Loss: 0.9280904531478882, Current Training Accuracy: 97.3721590909091, Time: 0.2574880123138428 ms\n",
            "Epoch 32:[15/16], Current Loss: 0.9366285800933838, Current Training Accuracy: 97.55859375, Time: 0.25461888313293457 ms\n",
            "Epoch 32, train Loss: 0.929  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.502267599105835 ms\n",
            "Epoch 33:[0/16], Current Loss: 0.9349899888038635, Current Training Accuracy: 96.875, Time: 0.2716183662414551 ms\n",
            "Epoch 33:[5/16], Current Loss: 0.9359670877456665, Current Training Accuracy: 97.39583333333333, Time: 0.25766706466674805 ms\n",
            "Epoch 33:[10/16], Current Loss: 0.9275661110877991, Current Training Accuracy: 97.58522727272727, Time: 0.2591104507446289 ms\n",
            "Epoch 33:[15/16], Current Loss: 0.913093090057373, Current Training Accuracy: 97.55859375, Time: 0.2531893253326416 ms\n",
            "Epoch 33, train Loss: 0.929  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 7.473849058151245 ms\n",
            "Epoch 34:[0/16], Current Loss: 0.9208643436431885, Current Training Accuracy: 98.4375, Time: 0.2848813533782959 ms\n",
            "Epoch 34:[5/16], Current Loss: 0.9359006881713867, Current Training Accuracy: 97.78645833333333, Time: 0.25525474548339844 ms\n",
            "Epoch 34:[10/16], Current Loss: 0.9053287506103516, Current Training Accuracy: 97.9403409090909, Time: 0.25980520248413086 ms\n",
            "Epoch 34:[15/16], Current Loss: 0.9581689238548279, Current Training Accuracy: 97.55859375, Time: 0.25192832946777344 ms\n",
            "Epoch 34, train Loss: 0.929  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 7.4737982749938965 ms\n",
            "Epoch 35:[0/16], Current Loss: 0.9349499940872192, Current Training Accuracy: 96.875, Time: 0.2829556465148926 ms\n",
            "Epoch 35:[5/16], Current Loss: 0.9594054818153381, Current Training Accuracy: 96.35416666666667, Time: 0.2554488182067871 ms\n",
            "Epoch 35:[10/16], Current Loss: 0.9354559779167175, Current Training Accuracy: 97.1590909090909, Time: 0.25608301162719727 ms\n",
            "Epoch 35:[15/16], Current Loss: 0.9203824400901794, Current Training Accuracy: 97.65625, Time: 0.25362110137939453 ms\n",
            "Epoch 35, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 7.49117636680603 ms\n",
            "Epoch 36:[0/16], Current Loss: 0.920272171497345, Current Training Accuracy: 98.4375, Time: 0.28067946434020996 ms\n",
            "Epoch 36:[5/16], Current Loss: 0.949682891368866, Current Training Accuracy: 97.65625, Time: 0.2598705291748047 ms\n",
            "Epoch 36:[10/16], Current Loss: 0.928635835647583, Current Training Accuracy: 97.51420454545455, Time: 0.2557046413421631 ms\n",
            "Epoch 36:[15/16], Current Loss: 0.9210178256034851, Current Training Accuracy: 97.705078125, Time: 0.2524294853210449 ms\n",
            "Epoch 36, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.466193675994873 ms\n",
            "Epoch 37:[0/16], Current Loss: 0.9361370801925659, Current Training Accuracy: 96.875, Time: 0.280012845993042 ms\n",
            "Epoch 37:[5/16], Current Loss: 0.9052155017852783, Current Training Accuracy: 97.52604166666667, Time: 0.2578310966491699 ms\n",
            "Epoch 37:[10/16], Current Loss: 0.9052913188934326, Current Training Accuracy: 97.65625, Time: 0.2564268112182617 ms\n",
            "Epoch 37:[15/16], Current Loss: 0.9283688068389893, Current Training Accuracy: 97.705078125, Time: 0.2553703784942627 ms\n",
            "Epoch 37, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 7.4742209911346436 ms\n",
            "Epoch 38:[0/16], Current Loss: 0.9131457805633545, Current Training Accuracy: 99.21875, Time: 0.2806861400604248 ms\n",
            "Epoch 38:[5/16], Current Loss: 0.9281257390975952, Current Training Accuracy: 97.91666666666667, Time: 0.2577240467071533 ms\n",
            "Epoch 38:[10/16], Current Loss: 0.9355230331420898, Current Training Accuracy: 97.58522727272727, Time: 0.2604026794433594 ms\n",
            "Epoch 38:[15/16], Current Loss: 0.9286106824874878, Current Training Accuracy: 97.802734375, Time: 0.2556488513946533 ms\n",
            "Epoch 38, train Loss: 0.927  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 7.47288966178894 ms\n",
            "Epoch 39:[0/16], Current Loss: 0.9359940886497498, Current Training Accuracy: 96.875, Time: 0.2796790599822998 ms\n",
            "Epoch 39:[5/16], Current Loss: 0.9348503947257996, Current Training Accuracy: 97.65625, Time: 0.25573301315307617 ms\n",
            "Epoch 39:[10/16], Current Loss: 0.9131661057472229, Current Training Accuracy: 98.08238636363636, Time: 0.2592909336090088 ms\n",
            "Epoch 39:[15/16], Current Loss: 0.9352648258209229, Current Training Accuracy: 97.75390625, Time: 0.2541382312774658 ms\n",
            "Epoch 39, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.48148250579834 ms\n",
            "Epoch 40:[0/16], Current Loss: 0.9206926822662354, Current Training Accuracy: 98.4375, Time: 0.27684617042541504 ms\n",
            "Epoch 40:[5/16], Current Loss: 0.9430479407310486, Current Training Accuracy: 97.52604166666667, Time: 0.25420427322387695 ms\n",
            "Epoch 40:[10/16], Current Loss: 0.9509871006011963, Current Training Accuracy: 97.51420454545455, Time: 0.2595643997192383 ms\n",
            "Epoch 40:[15/16], Current Loss: 0.9129217863082886, Current Training Accuracy: 97.75390625, Time: 0.25321245193481445 ms\n",
            "Epoch 40, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.473186254501343 ms\n",
            "Epoch 41:[0/16], Current Loss: 0.92019122838974, Current Training Accuracy: 98.4375, Time: 0.2825653553009033 ms\n",
            "Epoch 41:[5/16], Current Loss: 0.9283614754676819, Current Training Accuracy: 97.65625, Time: 0.2541344165802002 ms\n",
            "Epoch 41:[10/16], Current Loss: 0.9127360582351685, Current Training Accuracy: 98.22443181818181, Time: 0.2593803405761719 ms\n",
            "Epoch 41:[15/16], Current Loss: 0.9358512163162231, Current Training Accuracy: 97.75390625, Time: 0.25167346000671387 ms\n",
            "Epoch 41, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.477449893951416 ms\n",
            "Epoch 42:[0/16], Current Loss: 0.9427407383918762, Current Training Accuracy: 96.09375, Time: 0.27858686447143555 ms\n",
            "Epoch 42:[5/16], Current Loss: 0.9358185529708862, Current Training Accuracy: 96.875, Time: 0.260988712310791 ms\n",
            "Epoch 42:[10/16], Current Loss: 0.9204696416854858, Current Training Accuracy: 97.58522727272727, Time: 0.2592329978942871 ms\n",
            "Epoch 42:[15/16], Current Loss: 0.9357092976570129, Current Training Accuracy: 97.75390625, Time: 0.25374484062194824 ms\n",
            "Epoch 42, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.441894292831421 ms\n",
            "Epoch 43:[0/16], Current Loss: 0.9207025766372681, Current Training Accuracy: 98.4375, Time: 0.28060293197631836 ms\n",
            "Epoch 43:[5/16], Current Loss: 0.9285829067230225, Current Training Accuracy: 97.65625, Time: 0.25507330894470215 ms\n",
            "Epoch 43:[10/16], Current Loss: 0.9354547262191772, Current Training Accuracy: 97.65625, Time: 0.2666802406311035 ms\n",
            "Epoch 43:[15/16], Current Loss: 0.9358265399932861, Current Training Accuracy: 97.802734375, Time: 0.2554008960723877 ms\n",
            "Epoch 43, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.508105516433716 ms\n",
            "Epoch 44:[0/16], Current Loss: 0.9282531142234802, Current Training Accuracy: 97.65625, Time: 0.27549099922180176 ms\n",
            "Epoch 44:[5/16], Current Loss: 0.9126599431037903, Current Training Accuracy: 98.046875, Time: 0.25880932807922363 ms\n",
            "Epoch 44:[10/16], Current Loss: 0.935592770576477, Current Training Accuracy: 97.79829545454545, Time: 0.2586948871612549 ms\n",
            "Epoch 44:[15/16], Current Loss: 0.9363415837287903, Current Training Accuracy: 97.75390625, Time: 0.252117395401001 ms\n",
            "Epoch 44, train Loss: 0.927  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.427143335342407 ms\n",
            "Epoch 45:[0/16], Current Loss: 0.9201667308807373, Current Training Accuracy: 98.4375, Time: 0.2822456359863281 ms\n",
            "Epoch 45:[5/16], Current Loss: 0.9353363513946533, Current Training Accuracy: 97.65625, Time: 0.2554774284362793 ms\n",
            "Epoch 45:[10/16], Current Loss: 0.912912130355835, Current Training Accuracy: 97.72727272727273, Time: 0.26064324378967285 ms\n",
            "Epoch 45:[15/16], Current Loss: 0.9201259613037109, Current Training Accuracy: 97.802734375, Time: 0.2533233165740967 ms\n",
            "Epoch 45, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.51880407333374 ms\n",
            "Epoch 46:[0/16], Current Loss: 0.9351017475128174, Current Training Accuracy: 96.875, Time: 0.2750222682952881 ms\n",
            "Epoch 46:[5/16], Current Loss: 0.9285544753074646, Current Training Accuracy: 97.78645833333333, Time: 0.25908851623535156 ms\n",
            "Epoch 46:[10/16], Current Loss: 0.9207128882408142, Current Training Accuracy: 97.58522727272727, Time: 0.2563509941101074 ms\n",
            "Epoch 46:[15/16], Current Loss: 0.9206478595733643, Current Training Accuracy: 97.75390625, Time: 0.2547929286956787 ms\n",
            "Epoch 46, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.485456228256226 ms\n",
            "Epoch 47:[0/16], Current Loss: 0.9196022748947144, Current Training Accuracy: 98.4375, Time: 0.2785615921020508 ms\n",
            "Epoch 47:[5/16], Current Loss: 0.912868320941925, Current Training Accuracy: 97.91666666666667, Time: 0.2551758289337158 ms\n",
            "Epoch 47:[10/16], Current Loss: 0.92023766040802, Current Training Accuracy: 97.72727272727273, Time: 0.25440120697021484 ms\n",
            "Epoch 47:[15/16], Current Loss: 0.9195420145988464, Current Training Accuracy: 97.75390625, Time: 0.2522776126861572 ms\n",
            "Epoch 47, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 7.472030878067017 ms\n",
            "Epoch 48:[0/16], Current Loss: 0.9207051396369934, Current Training Accuracy: 98.4375, Time: 0.28501009941101074 ms\n",
            "Epoch 48:[5/16], Current Loss: 0.9206836819648743, Current Training Accuracy: 97.65625, Time: 0.2540726661682129 ms\n",
            "Epoch 48:[10/16], Current Loss: 0.9206384420394897, Current Training Accuracy: 97.58522727272727, Time: 0.25635480880737305 ms\n",
            "Epoch 48:[15/16], Current Loss: 0.9122687578201294, Current Training Accuracy: 97.75390625, Time: 0.2544260025024414 ms\n",
            "Epoch 48, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.4951112270355225 ms\n",
            "Epoch 49:[0/16], Current Loss: 0.9200236201286316, Current Training Accuracy: 98.4375, Time: 0.27637195587158203 ms\n",
            "Epoch 49:[5/16], Current Loss: 0.9200202822685242, Current Training Accuracy: 98.17708333333333, Time: 0.25677013397216797 ms\n",
            "Epoch 49:[10/16], Current Loss: 0.9279484748840332, Current Training Accuracy: 98.01136363636364, Time: 0.2545337677001953 ms\n",
            "Epoch 49:[15/16], Current Loss: 0.9122685194015503, Current Training Accuracy: 97.75390625, Time: 0.25323963165283203 ms\n",
            "Epoch 49, train Loss: 0.927  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.473313808441162 ms\n",
            "Epoch 50:[0/16], Current Loss: 0.9124236106872559, Current Training Accuracy: 99.21875, Time: 0.28137850761413574 ms\n",
            "Epoch 50:[5/16], Current Loss: 0.9206846952438354, Current Training Accuracy: 98.4375, Time: 0.25585246086120605 ms\n",
            "Epoch 50:[10/16], Current Loss: 0.9428107738494873, Current Training Accuracy: 98.1534090909091, Time: 0.2672116756439209 ms\n",
            "Epoch 50:[15/16], Current Loss: 0.9279443025588989, Current Training Accuracy: 97.75390625, Time: 0.25240397453308105 ms\n",
            "Epoch 50, train Loss: 0.927  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.48289942741394 ms\n",
            "Epoch 51:[0/16], Current Loss: 0.9200104475021362, Current Training Accuracy: 98.4375, Time: 0.2743391990661621 ms\n",
            "Epoch 51:[5/16], Current Loss: 0.9202815890312195, Current Training Accuracy: 98.17708333333333, Time: 0.2583625316619873 ms\n",
            "Epoch 51:[10/16], Current Loss: 0.9348131418228149, Current Training Accuracy: 97.65625, Time: 0.25757741928100586 ms\n",
            "Epoch 51:[15/16], Current Loss: 0.9050821661949158, Current Training Accuracy: 97.802734375, Time: 0.2535068988800049 ms\n",
            "Epoch 51, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 7.490436553955078 ms\n",
            "Epoch 52:[0/16], Current Loss: 0.9051657915115356, Current Training Accuracy: 100.0, Time: 0.2838099002838135 ms\n",
            "Epoch 52:[5/16], Current Loss: 0.9346889853477478, Current Training Accuracy: 98.046875, Time: 0.2577643394470215 ms\n",
            "Epoch 52:[10/16], Current Loss: 0.9128574728965759, Current Training Accuracy: 97.86931818181819, Time: 0.2647082805633545 ms\n",
            "Epoch 52:[15/16], Current Loss: 0.9424520134925842, Current Training Accuracy: 97.8515625, Time: 0.25331926345825195 ms\n",
            "Epoch 52, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.491177082061768 ms\n",
            "Epoch 53:[0/16], Current Loss: 0.9206587076187134, Current Training Accuracy: 98.4375, Time: 0.27246546745300293 ms\n",
            "Epoch 53:[5/16], Current Loss: 0.9281075596809387, Current Training Accuracy: 97.39583333333333, Time: 0.25921130180358887 ms\n",
            "Epoch 53:[10/16], Current Loss: 0.9206873774528503, Current Training Accuracy: 97.79829545454545, Time: 0.259385347366333 ms\n",
            "Epoch 53:[15/16], Current Loss: 0.9124370813369751, Current Training Accuracy: 97.900390625, Time: 0.2538309097290039 ms\n",
            "Epoch 53, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.458465337753296 ms\n",
            "Epoch 54:[0/16], Current Loss: 0.935026228427887, Current Training Accuracy: 96.875, Time: 0.2829627990722656 ms\n",
            "Epoch 54:[5/16], Current Loss: 0.9125069379806519, Current Training Accuracy: 98.17708333333333, Time: 0.25835609436035156 ms\n",
            "Epoch 54:[10/16], Current Loss: 0.9351419806480408, Current Training Accuracy: 98.01136363636364, Time: 0.268143892288208 ms\n",
            "Epoch 54:[15/16], Current Loss: 0.9206768274307251, Current Training Accuracy: 97.8515625, Time: 0.2524604797363281 ms\n",
            "Epoch 54, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.4834535121917725 ms\n",
            "Epoch 55:[0/16], Current Loss: 0.9285259246826172, Current Training Accuracy: 97.65625, Time: 0.2775125503540039 ms\n",
            "Epoch 55:[5/16], Current Loss: 0.9284601807594299, Current Training Accuracy: 97.39583333333333, Time: 0.26029229164123535 ms\n",
            "Epoch 55:[10/16], Current Loss: 0.9273753762245178, Current Training Accuracy: 97.79829545454545, Time: 0.2594447135925293 ms\n",
            "Epoch 55:[15/16], Current Loss: 0.9206656217575073, Current Training Accuracy: 97.8515625, Time: 0.25485825538635254 ms\n",
            "Epoch 55, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.489984512329102 ms\n",
            "Epoch 56:[0/16], Current Loss: 0.9206776022911072, Current Training Accuracy: 98.4375, Time: 0.28127622604370117 ms\n",
            "Epoch 56:[5/16], Current Loss: 0.919710636138916, Current Training Accuracy: 98.046875, Time: 0.25536012649536133 ms\n",
            "Epoch 56:[10/16], Current Loss: 0.9277364015579224, Current Training Accuracy: 97.79829545454545, Time: 0.25810909271240234 ms\n",
            "Epoch 56:[15/16], Current Loss: 0.9206445813179016, Current Training Accuracy: 97.8515625, Time: 0.2552363872528076 ms\n",
            "Epoch 56, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.459708213806152 ms\n",
            "Epoch 57:[0/16], Current Loss: 0.9206356406211853, Current Training Accuracy: 98.4375, Time: 0.28158998489379883 ms\n",
            "Epoch 57:[5/16], Current Loss: 0.9362085461616516, Current Training Accuracy: 98.56770833333333, Time: 0.25660133361816406 ms\n",
            "Epoch 57:[10/16], Current Loss: 0.9506074786186218, Current Training Accuracy: 98.22443181818181, Time: 0.2590465545654297 ms\n",
            "Epoch 57:[15/16], Current Loss: 0.9431701302528381, Current Training Accuracy: 97.8515625, Time: 0.2597804069519043 ms\n",
            "Epoch 57, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.526286840438843 ms\n",
            "Epoch 58:[0/16], Current Loss: 0.9205992817878723, Current Training Accuracy: 98.4375, Time: 0.2785351276397705 ms\n",
            "Epoch 58:[5/16], Current Loss: 0.9439355134963989, Current Training Accuracy: 97.39583333333333, Time: 0.2543165683746338 ms\n",
            "Epoch 58:[10/16], Current Loss: 0.9205493927001953, Current Training Accuracy: 98.08238636363636, Time: 0.25740909576416016 ms\n",
            "Epoch 58:[15/16], Current Loss: 0.958179771900177, Current Training Accuracy: 97.8515625, Time: 0.25523996353149414 ms\n",
            "Epoch 58, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.464948892593384 ms\n",
            "Epoch 59:[0/16], Current Loss: 0.9200718998908997, Current Training Accuracy: 98.4375, Time: 0.28081417083740234 ms\n",
            "Epoch 59:[5/16], Current Loss: 0.9197543859481812, Current Training Accuracy: 98.046875, Time: 0.2557981014251709 ms\n",
            "Epoch 59:[10/16], Current Loss: 0.9421889185905457, Current Training Accuracy: 98.01136363636364, Time: 0.2567732334136963 ms\n",
            "Epoch 59:[15/16], Current Loss: 0.9362635612487793, Current Training Accuracy: 97.8515625, Time: 0.2525064945220947 ms\n",
            "Epoch 59, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.483895301818848 ms\n",
            "Epoch 60:[0/16], Current Loss: 0.9652611017227173, Current Training Accuracy: 93.75, Time: 0.2841181755065918 ms\n",
            "Epoch 60:[5/16], Current Loss: 0.9195681810379028, Current Training Accuracy: 97.13541666666667, Time: 0.2583582401275635 ms\n",
            "Epoch 60:[10/16], Current Loss: 0.9273561835289001, Current Training Accuracy: 97.72727272727273, Time: 0.2592892646789551 ms\n",
            "Epoch 60:[15/16], Current Loss: 0.9123764038085938, Current Training Accuracy: 97.8515625, Time: 0.25469112396240234 ms\n",
            "Epoch 60, train Loss: 0.926  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 66 % Epoch Time: 7.5243823528289795 ms\n",
            "Epoch 61:[0/16], Current Loss: 0.9282982349395752, Current Training Accuracy: 97.65625, Time: 0.2847459316253662 ms\n",
            "Epoch 61:[5/16], Current Loss: 0.9512421488761902, Current Training Accuracy: 97.91666666666667, Time: 0.25577807426452637 ms\n",
            "Epoch 61:[10/16], Current Loss: 0.9198659062385559, Current Training Accuracy: 98.22443181818181, Time: 0.25766706466674805 ms\n",
            "Epoch 61:[15/16], Current Loss: 0.9049949049949646, Current Training Accuracy: 97.900390625, Time: 0.25662708282470703 ms\n",
            "Epoch 61, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.489267349243164 ms\n",
            "Epoch 62:[0/16], Current Loss: 0.9357619881629944, Current Training Accuracy: 96.875, Time: 0.27855849266052246 ms\n",
            "Epoch 62:[5/16], Current Loss: 0.9282123446464539, Current Training Accuracy: 97.65625, Time: 0.25936388969421387 ms\n",
            "Epoch 62:[10/16], Current Loss: 0.9350595474243164, Current Training Accuracy: 97.72727272727273, Time: 0.25850462913513184 ms\n",
            "Epoch 62:[15/16], Current Loss: 0.9202687740325928, Current Training Accuracy: 97.900390625, Time: 0.25426721572875977 ms\n",
            "Epoch 62, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.486241579055786 ms\n",
            "Epoch 63:[0/16], Current Loss: 0.9280116558074951, Current Training Accuracy: 97.65625, Time: 0.27643609046936035 ms\n",
            "Epoch 63:[5/16], Current Loss: 0.9128012657165527, Current Training Accuracy: 97.91666666666667, Time: 0.25438427925109863 ms\n",
            "Epoch 63:[10/16], Current Loss: 0.9346644878387451, Current Training Accuracy: 98.1534090909091, Time: 0.25765299797058105 ms\n",
            "Epoch 63:[15/16], Current Loss: 0.9199678897857666, Current Training Accuracy: 97.94921875, Time: 0.25374674797058105 ms\n",
            "Epoch 63, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.519041299819946 ms\n",
            "Epoch 64:[0/16], Current Loss: 0.9127619862556458, Current Training Accuracy: 99.21875, Time: 0.2771451473236084 ms\n",
            "Epoch 64:[5/16], Current Loss: 0.9205887317657471, Current Training Accuracy: 97.52604166666667, Time: 0.25783658027648926 ms\n",
            "Epoch 64:[10/16], Current Loss: 0.9355316162109375, Current Training Accuracy: 97.72727272727273, Time: 0.25893139839172363 ms\n",
            "Epoch 64:[15/16], Current Loss: 0.920124888420105, Current Training Accuracy: 97.900390625, Time: 0.2552638053894043 ms\n",
            "Epoch 64, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.46729588508606 ms\n",
            "Epoch 65:[0/16], Current Loss: 0.9356752038002014, Current Training Accuracy: 96.875, Time: 0.27548933029174805 ms\n",
            "Epoch 65:[5/16], Current Loss: 0.9280391335487366, Current Training Accuracy: 97.52604166666667, Time: 0.26084089279174805 ms\n",
            "Epoch 65:[10/16], Current Loss: 0.9433864951133728, Current Training Accuracy: 97.51420454545455, Time: 0.2594795227050781 ms\n",
            "Epoch 65:[15/16], Current Loss: 0.9350572824478149, Current Training Accuracy: 97.900390625, Time: 0.2547950744628906 ms\n",
            "Epoch 65, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 7.524389266967773 ms\n",
            "Epoch 66:[0/16], Current Loss: 0.9121319055557251, Current Training Accuracy: 99.21875, Time: 0.27657604217529297 ms\n",
            "Epoch 66:[5/16], Current Loss: 0.9271203875541687, Current Training Accuracy: 97.78645833333333, Time: 0.25489306449890137 ms\n",
            "Epoch 66:[10/16], Current Loss: 0.92058265209198, Current Training Accuracy: 97.79829545454545, Time: 0.2557260990142822 ms\n",
            "Epoch 66:[15/16], Current Loss: 0.9273042678833008, Current Training Accuracy: 97.900390625, Time: 0.25826239585876465 ms\n",
            "Epoch 66, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 7.454845428466797 ms\n",
            "Epoch 67:[0/16], Current Loss: 0.9128019213676453, Current Training Accuracy: 99.21875, Time: 0.2812340259552002 ms\n",
            "Epoch 67:[5/16], Current Loss: 0.9284012913703918, Current Training Accuracy: 97.78645833333333, Time: 0.25850844383239746 ms\n",
            "Epoch 67:[10/16], Current Loss: 0.9125306010246277, Current Training Accuracy: 97.51420454545455, Time: 0.25940823554992676 ms\n",
            "Epoch 67:[15/16], Current Loss: 0.9127995371818542, Current Training Accuracy: 97.900390625, Time: 0.25548267364501953 ms\n",
            "Epoch 67, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 7.458431720733643 ms\n",
            "Epoch 68:[0/16], Current Loss: 0.9275994896888733, Current Training Accuracy: 97.65625, Time: 0.2796664237976074 ms\n",
            "Epoch 68:[5/16], Current Loss: 0.9199594259262085, Current Training Accuracy: 97.91666666666667, Time: 0.25691938400268555 ms\n",
            "Epoch 68:[10/16], Current Loss: 0.9283817410469055, Current Training Accuracy: 97.9403409090909, Time: 0.2678871154785156 ms\n",
            "Epoch 68:[15/16], Current Loss: 0.9361932873725891, Current Training Accuracy: 97.900390625, Time: 0.25351953506469727 ms\n",
            "Epoch 68, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.536590099334717 ms\n",
            "Epoch 69:[0/16], Current Loss: 0.9421263933181763, Current Training Accuracy: 96.09375, Time: 0.2806894779205322 ms\n",
            "Epoch 69:[5/16], Current Loss: 0.9345283508300781, Current Training Accuracy: 97.13541666666667, Time: 0.2538578510284424 ms\n",
            "Epoch 69:[10/16], Current Loss: 0.9284263253211975, Current Training Accuracy: 97.72727272727273, Time: 0.25274062156677246 ms\n",
            "Epoch 69:[15/16], Current Loss: 0.9049899578094482, Current Training Accuracy: 97.94921875, Time: 0.25284790992736816 ms\n",
            "Epoch 69, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 7.469914436340332 ms\n",
            "Epoch 70:[0/16], Current Loss: 0.9283941984176636, Current Training Accuracy: 97.65625, Time: 0.27896881103515625 ms\n",
            "Epoch 70:[5/16], Current Loss: 0.9049665331840515, Current Training Accuracy: 97.78645833333333, Time: 0.2582221031188965 ms\n",
            "Epoch 70:[10/16], Current Loss: 0.9289954304695129, Current Training Accuracy: 97.9403409090909, Time: 0.2589535713195801 ms\n",
            "Epoch 70:[15/16], Current Loss: 0.9273604154586792, Current Training Accuracy: 97.94921875, Time: 0.25537753105163574 ms\n",
            "Epoch 70, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.495676040649414 ms\n",
            "Epoch 71:[0/16], Current Loss: 0.9430864453315735, Current Training Accuracy: 96.09375, Time: 0.28183460235595703 ms\n",
            "Epoch 71:[5/16], Current Loss: 0.9282970428466797, Current Training Accuracy: 97.91666666666667, Time: 0.2602667808532715 ms\n",
            "Epoch 71:[10/16], Current Loss: 0.9278843402862549, Current Training Accuracy: 98.08238636363636, Time: 0.2552978992462158 ms\n",
            "Epoch 71:[15/16], Current Loss: 0.9272332191467285, Current Training Accuracy: 97.900390625, Time: 0.2542586326599121 ms\n",
            "Epoch 71, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 7.5047361850738525 ms\n",
            "Epoch 72:[0/16], Current Loss: 0.9127628803253174, Current Training Accuracy: 99.21875, Time: 0.28003501892089844 ms\n",
            "Epoch 72:[5/16], Current Loss: 0.928406834602356, Current Training Accuracy: 98.046875, Time: 0.25843167304992676 ms\n",
            "Epoch 72:[10/16], Current Loss: 0.9280084371566772, Current Training Accuracy: 98.22443181818181, Time: 0.2561759948730469 ms\n",
            "Epoch 72:[15/16], Current Loss: 0.9347493052482605, Current Training Accuracy: 97.900390625, Time: 0.2555198669433594 ms\n",
            "Epoch 72, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.455970287322998 ms\n",
            "Epoch 73:[0/16], Current Loss: 0.9205999374389648, Current Training Accuracy: 98.4375, Time: 0.27965331077575684 ms\n",
            "Epoch 73:[5/16], Current Loss: 0.9273712038993835, Current Training Accuracy: 97.91666666666667, Time: 0.2580111026763916 ms\n",
            "Epoch 73:[10/16], Current Loss: 0.9123645424842834, Current Training Accuracy: 97.72727272727273, Time: 0.26775360107421875 ms\n",
            "Epoch 73:[15/16], Current Loss: 0.9127576351165771, Current Training Accuracy: 97.900390625, Time: 0.2543039321899414 ms\n",
            "Epoch 73, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 7.47809910774231 ms\n",
            "Epoch 74:[0/16], Current Loss: 0.9205408096313477, Current Training Accuracy: 98.4375, Time: 0.281099796295166 ms\n",
            "Epoch 74:[5/16], Current Loss: 0.9201110005378723, Current Training Accuracy: 97.65625, Time: 0.2590677738189697 ms\n",
            "Epoch 74:[10/16], Current Loss: 0.9123093485832214, Current Training Accuracy: 97.9403409090909, Time: 0.25870418548583984 ms\n",
            "Epoch 74:[15/16], Current Loss: 0.9125791788101196, Current Training Accuracy: 97.900390625, Time: 0.2535896301269531 ms\n",
            "Epoch 74, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 7.440805435180664 ms\n",
            "Epoch 75:[0/16], Current Loss: 0.9278350472450256, Current Training Accuracy: 97.65625, Time: 0.2786984443664551 ms\n",
            "Epoch 75:[5/16], Current Loss: 0.9361962080001831, Current Training Accuracy: 97.52604166666667, Time: 0.25827980041503906 ms\n",
            "Epoch 75:[10/16], Current Loss: 0.9202605485916138, Current Training Accuracy: 97.79829545454545, Time: 0.2684011459350586 ms\n",
            "Epoch 75:[15/16], Current Loss: 0.9205827713012695, Current Training Accuracy: 97.94921875, Time: 0.253739595413208 ms\n",
            "Epoch 75, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.492836236953735 ms\n",
            "Epoch 76:[0/16], Current Loss: 0.9121471047401428, Current Training Accuracy: 99.21875, Time: 0.2773447036743164 ms\n",
            "Epoch 76:[5/16], Current Loss: 0.9440122246742249, Current Training Accuracy: 98.17708333333333, Time: 0.26021528244018555 ms\n",
            "Epoch 76:[10/16], Current Loss: 0.9275993704795837, Current Training Accuracy: 97.79829545454545, Time: 0.25933146476745605 ms\n",
            "Epoch 76:[15/16], Current Loss: 0.9049525856971741, Current Training Accuracy: 97.900390625, Time: 0.25588321685791016 ms\n",
            "Epoch 76, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.466725587844849 ms\n",
            "Epoch 77:[0/16], Current Loss: 0.9361594915390015, Current Training Accuracy: 96.875, Time: 0.27844929695129395 ms\n",
            "Epoch 77:[5/16], Current Loss: 0.9155557155609131, Current Training Accuracy: 98.56770833333333, Time: 0.25756025314331055 ms\n",
            "Epoch 77:[10/16], Current Loss: 0.9208971858024597, Current Training Accuracy: 98.01136363636364, Time: 0.25425219535827637 ms\n",
            "Epoch 77:[15/16], Current Loss: 0.9356119632720947, Current Training Accuracy: 97.94921875, Time: 0.25827693939208984 ms\n",
            "Epoch 77, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 7.458869457244873 ms\n",
            "Epoch 78:[0/16], Current Loss: 0.9049687385559082, Current Training Accuracy: 100.0, Time: 0.2837698459625244 ms\n",
            "Epoch 78:[5/16], Current Loss: 0.9239848852157593, Current Training Accuracy: 98.95833333333333, Time: 0.25919198989868164 ms\n",
            "Epoch 78:[10/16], Current Loss: 0.913316547870636, Current Training Accuracy: 98.36647727272727, Time: 0.25847411155700684 ms\n",
            "Epoch 78:[15/16], Current Loss: 0.9347234964370728, Current Training Accuracy: 97.998046875, Time: 0.2546572685241699 ms\n",
            "Epoch 78, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.446131229400635 ms\n",
            "Epoch 79:[0/16], Current Loss: 0.9051187634468079, Current Training Accuracy: 100.0, Time: 0.279813289642334 ms\n",
            "Epoch 79:[5/16], Current Loss: 0.9201518297195435, Current Training Accuracy: 98.17708333333333, Time: 0.25418853759765625 ms\n",
            "Epoch 79:[10/16], Current Loss: 0.9283872842788696, Current Training Accuracy: 98.22443181818181, Time: 0.26024436950683594 ms\n",
            "Epoch 79:[15/16], Current Loss: 0.9283844828605652, Current Training Accuracy: 98.046875, Time: 0.25546717643737793 ms\n",
            "Epoch 79, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.445780038833618 ms\n",
            "Epoch 80:[0/16], Current Loss: 0.9204256534576416, Current Training Accuracy: 98.4375, Time: 0.2777085304260254 ms\n",
            "Epoch 80:[5/16], Current Loss: 0.9206000566482544, Current Training Accuracy: 98.56770833333333, Time: 0.2681155204772949 ms\n",
            "Epoch 80:[10/16], Current Loss: 0.9503891468048096, Current Training Accuracy: 98.01136363636364, Time: 0.25713348388671875 ms\n",
            "Epoch 80:[15/16], Current Loss: 0.9128022789955139, Current Training Accuracy: 98.046875, Time: 0.2519960403442383 ms\n",
            "Epoch 80, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.514122486114502 ms\n",
            "Epoch 81:[0/16], Current Loss: 0.9049682021141052, Current Training Accuracy: 100.0, Time: 0.2822589874267578 ms\n",
            "Epoch 81:[5/16], Current Loss: 0.9202222228050232, Current Training Accuracy: 97.78645833333333, Time: 0.25434160232543945 ms\n",
            "Epoch 81:[10/16], Current Loss: 0.9205566644668579, Current Training Accuracy: 97.9403409090909, Time: 0.26101183891296387 ms\n",
            "Epoch 81:[15/16], Current Loss: 0.9284848570823669, Current Training Accuracy: 98.046875, Time: 0.25847649574279785 ms\n",
            "Epoch 81, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.439805269241333 ms\n",
            "Epoch 82:[0/16], Current Loss: 0.9279117584228516, Current Training Accuracy: 97.65625, Time: 0.2811112403869629 ms\n",
            "Epoch 82:[5/16], Current Loss: 0.9200693368911743, Current Training Accuracy: 98.046875, Time: 0.260728120803833 ms\n",
            "Epoch 82:[10/16], Current Loss: 0.9205737113952637, Current Training Accuracy: 98.01136363636364, Time: 0.2588005065917969 ms\n",
            "Epoch 82:[15/16], Current Loss: 0.928399384021759, Current Training Accuracy: 98.046875, Time: 0.2518429756164551 ms\n",
            "Epoch 82, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 7.508092164993286 ms\n",
            "Epoch 83:[0/16], Current Loss: 0.9284193515777588, Current Training Accuracy: 97.65625, Time: 0.28099870681762695 ms\n",
            "Epoch 83:[5/16], Current Loss: 0.9199613332748413, Current Training Accuracy: 97.91666666666667, Time: 0.25674009323120117 ms\n",
            "Epoch 83:[10/16], Current Loss: 0.9127776622772217, Current Training Accuracy: 97.79829545454545, Time: 0.2534477710723877 ms\n",
            "Epoch 83:[15/16], Current Loss: 0.9205932021141052, Current Training Accuracy: 98.046875, Time: 0.2558751106262207 ms\n",
            "Epoch 83, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.43078875541687 ms\n",
            "Epoch 84:[0/16], Current Loss: 0.920043408870697, Current Training Accuracy: 98.4375, Time: 0.28254079818725586 ms\n",
            "Epoch 84:[5/16], Current Loss: 0.9278333187103271, Current Training Accuracy: 97.91666666666667, Time: 0.2555081844329834 ms\n",
            "Epoch 84:[10/16], Current Loss: 0.9198264479637146, Current Training Accuracy: 98.08238636363636, Time: 0.25446319580078125 ms\n",
            "Epoch 84:[15/16], Current Loss: 0.9274933338165283, Current Training Accuracy: 98.046875, Time: 0.2541532516479492 ms\n",
            "Epoch 84, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.503751754760742 ms\n",
            "Epoch 85:[0/16], Current Loss: 0.9205539226531982, Current Training Accuracy: 98.4375, Time: 0.2877366542816162 ms\n",
            "Epoch 85:[5/16], Current Loss: 0.9434674382209778, Current Training Accuracy: 97.65625, Time: 0.25447559356689453 ms\n",
            "Epoch 85:[10/16], Current Loss: 0.9205552935600281, Current Training Accuracy: 98.36647727272727, Time: 0.2547333240509033 ms\n",
            "Epoch 85:[15/16], Current Loss: 0.9191970825195312, Current Training Accuracy: 98.095703125, Time: 0.2610142230987549 ms\n",
            "Epoch 85, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.449341535568237 ms\n",
            "Epoch 86:[0/16], Current Loss: 0.9667025208473206, Current Training Accuracy: 93.75, Time: 0.2846071720123291 ms\n",
            "Epoch 86:[5/16], Current Loss: 0.9350322484970093, Current Training Accuracy: 97.78645833333333, Time: 0.2551884651184082 ms\n",
            "Epoch 86:[10/16], Current Loss: 0.9271878004074097, Current Training Accuracy: 97.72727272727273, Time: 0.25695228576660156 ms\n",
            "Epoch 86:[15/16], Current Loss: 0.9049180746078491, Current Training Accuracy: 98.095703125, Time: 0.25143885612487793 ms\n",
            "Epoch 86, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.4578516483306885 ms\n",
            "Epoch 87:[0/16], Current Loss: 0.9120755791664124, Current Training Accuracy: 99.21875, Time: 0.27527761459350586 ms\n",
            "Epoch 87:[5/16], Current Loss: 0.9360240697860718, Current Training Accuracy: 97.91666666666667, Time: 0.25511598587036133 ms\n",
            "Epoch 87:[10/16], Current Loss: 0.9127324819564819, Current Training Accuracy: 98.1534090909091, Time: 0.25844550132751465 ms\n",
            "Epoch 87:[15/16], Current Loss: 0.9199298024177551, Current Training Accuracy: 98.046875, Time: 0.25228238105773926 ms\n",
            "Epoch 87, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.456851243972778 ms\n",
            "Epoch 88:[0/16], Current Loss: 0.920542299747467, Current Training Accuracy: 98.4375, Time: 0.2854304313659668 ms\n",
            "Epoch 88:[5/16], Current Loss: 0.9277454018592834, Current Training Accuracy: 97.65625, Time: 0.2566361427307129 ms\n",
            "Epoch 88:[10/16], Current Loss: 0.9202748537063599, Current Training Accuracy: 97.86931818181819, Time: 0.2554001808166504 ms\n",
            "Epoch 88:[15/16], Current Loss: 0.9127718210220337, Current Training Accuracy: 98.095703125, Time: 0.25362515449523926 ms\n",
            "Epoch 88, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.4565489292144775 ms\n",
            "Epoch 89:[0/16], Current Loss: 0.9435641169548035, Current Training Accuracy: 96.09375, Time: 0.28186774253845215 ms\n",
            "Epoch 89:[5/16], Current Loss: 0.9121145606040955, Current Training Accuracy: 97.39583333333333, Time: 0.2596096992492676 ms\n",
            "Epoch 89:[10/16], Current Loss: 0.9205250144004822, Current Training Accuracy: 97.79829545454545, Time: 0.2653629779815674 ms\n",
            "Epoch 89:[15/16], Current Loss: 0.9121346473693848, Current Training Accuracy: 98.046875, Time: 0.2538888454437256 ms\n",
            "Epoch 89, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 7.5220255851745605 ms\n",
            "Epoch 90:[0/16], Current Loss: 0.9199904203414917, Current Training Accuracy: 98.4375, Time: 0.27579450607299805 ms\n",
            "Epoch 90:[5/16], Current Loss: 0.9198430776596069, Current Training Accuracy: 98.30729166666667, Time: 0.25463223457336426 ms\n",
            "Epoch 90:[10/16], Current Loss: 0.943173885345459, Current Training Accuracy: 97.86931818181819, Time: 0.25799107551574707 ms\n",
            "Epoch 90:[15/16], Current Loss: 0.9127135276794434, Current Training Accuracy: 98.046875, Time: 0.25296568870544434 ms\n",
            "Epoch 90, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.508457899093628 ms\n",
            "Epoch 91:[0/16], Current Loss: 0.9127236604690552, Current Training Accuracy: 99.21875, Time: 0.2847862243652344 ms\n",
            "Epoch 91:[5/16], Current Loss: 0.919592022895813, Current Training Accuracy: 98.046875, Time: 0.25696516036987305 ms\n",
            "Epoch 91:[10/16], Current Loss: 0.9205452799797058, Current Training Accuracy: 97.72727272727273, Time: 0.25794339179992676 ms\n",
            "Epoch 91:[15/16], Current Loss: 0.9205588698387146, Current Training Accuracy: 98.046875, Time: 0.255094051361084 ms\n",
            "Epoch 91, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.460519552230835 ms\n",
            "Epoch 92:[0/16], Current Loss: 0.904920756816864, Current Training Accuracy: 100.0, Time: 0.28469157218933105 ms\n",
            "Epoch 92:[5/16], Current Loss: 0.9283713698387146, Current Training Accuracy: 98.4375, Time: 0.2602853775024414 ms\n",
            "Epoch 92:[10/16], Current Loss: 0.9193634390830994, Current Training Accuracy: 98.36647727272727, Time: 0.2563927173614502 ms\n",
            "Epoch 92:[15/16], Current Loss: 0.9198716282844543, Current Training Accuracy: 98.046875, Time: 0.2543973922729492 ms\n",
            "Epoch 92, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.51792049407959 ms\n",
            "Epoch 93:[0/16], Current Loss: 0.9361675977706909, Current Training Accuracy: 96.875, Time: 0.28140997886657715 ms\n",
            "Epoch 93:[5/16], Current Loss: 0.9108571410179138, Current Training Accuracy: 98.30729166666667, Time: 0.2547914981842041 ms\n",
            "Epoch 93:[10/16], Current Loss: 0.9285315275192261, Current Training Accuracy: 97.86931818181819, Time: 0.2561025619506836 ms\n",
            "Epoch 93:[15/16], Current Loss: 0.9049352407455444, Current Training Accuracy: 98.095703125, Time: 0.2537961006164551 ms\n",
            "Epoch 93, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 7.4813551902771 ms\n",
            "Epoch 94:[0/16], Current Loss: 0.9201966524124146, Current Training Accuracy: 98.4375, Time: 0.2805311679840088 ms\n",
            "Epoch 94:[5/16], Current Loss: 0.9200757145881653, Current Training Accuracy: 97.265625, Time: 0.26479363441467285 ms\n",
            "Epoch 94:[10/16], Current Loss: 0.9205217957496643, Current Training Accuracy: 97.86931818181819, Time: 0.25597262382507324 ms\n",
            "Epoch 94:[15/16], Current Loss: 0.9209164977073669, Current Training Accuracy: 98.14453125, Time: 0.2548491954803467 ms\n",
            "Epoch 94, train Loss: 0.923  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.463520526885986 ms\n",
            "Epoch 95:[0/16], Current Loss: 0.9050610065460205, Current Training Accuracy: 100.0, Time: 0.28139376640319824 ms\n",
            "Epoch 95:[5/16], Current Loss: 0.906597912311554, Current Training Accuracy: 98.69791666666667, Time: 0.25486087799072266 ms\n",
            "Epoch 95:[10/16], Current Loss: 0.9127805829048157, Current Training Accuracy: 98.29545454545455, Time: 0.25417041778564453 ms\n",
            "Epoch 95:[15/16], Current Loss: 0.932458221912384, Current Training Accuracy: 98.14453125, Time: 0.25573301315307617 ms\n",
            "Epoch 95, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.468465566635132 ms\n",
            "Epoch 96:[0/16], Current Loss: 0.9362690448760986, Current Training Accuracy: 96.875, Time: 0.2835562229156494 ms\n",
            "Epoch 96:[5/16], Current Loss: 0.9291157126426697, Current Training Accuracy: 98.046875, Time: 0.2590787410736084 ms\n",
            "Epoch 96:[10/16], Current Loss: 0.9358112812042236, Current Training Accuracy: 97.72727272727273, Time: 0.25743627548217773 ms\n",
            "Epoch 96:[15/16], Current Loss: 0.9205624461174011, Current Training Accuracy: 97.021484375, Time: 0.2539987564086914 ms\n",
            "Epoch 96, train Loss: 0.937  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.48835563659668 ms\n",
            "Epoch 97:[0/16], Current Loss: 0.9407384395599365, Current Training Accuracy: 96.875, Time: 0.27858710289001465 ms\n",
            "Epoch 97:[5/16], Current Loss: 0.9502844214439392, Current Training Accuracy: 97.52604166666667, Time: 0.26114439964294434 ms\n",
            "Epoch 97:[10/16], Current Loss: 0.9328093528747559, Current Training Accuracy: 97.01704545454545, Time: 0.25631022453308105 ms\n",
            "Epoch 97:[15/16], Current Loss: 0.9392693042755127, Current Training Accuracy: 96.875, Time: 0.25368690490722656 ms\n",
            "Epoch 97, train Loss: 0.940  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.4866623878479 ms\n",
            "Epoch 98:[0/16], Current Loss: 0.9472183585166931, Current Training Accuracy: 96.09375, Time: 0.2590346336364746 ms\n",
            "Epoch 98:[5/16], Current Loss: 0.9380297064781189, Current Training Accuracy: 96.484375, Time: 0.2556896209716797 ms\n",
            "Epoch 98:[10/16], Current Loss: 0.969154953956604, Current Training Accuracy: 96.44886363636364, Time: 0.2619588375091553 ms\n",
            "Epoch 98:[15/16], Current Loss: 0.9453232288360596, Current Training Accuracy: 96.38671875, Time: 0.25299692153930664 ms\n",
            "Epoch 98, train Loss: 0.945  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 67 % Epoch Time: 7.416797161102295 ms\n",
            "Epoch 99:[0/16], Current Loss: 0.9396170973777771, Current Training Accuracy: 96.875, Time: 0.2799091339111328 ms\n",
            "Epoch 99:[5/16], Current Loss: 0.9312371015548706, Current Training Accuracy: 96.09375, Time: 0.25458288192749023 ms\n",
            "Epoch 99:[10/16], Current Loss: 0.935278058052063, Current Training Accuracy: 95.8096590909091, Time: 0.261951208114624 ms\n",
            "Epoch 99:[15/16], Current Loss: 0.9541940093040466, Current Training Accuracy: 95.361328125, Time: 0.255443811416626 ms\n",
            "Epoch 99, train Loss: 0.951  Avg Training Accuracy: {95 %} Avg Validation Accuracy: 66 % Epoch Time: 7.470208168029785 ms\n",
            "Epoch 100:[0/16], Current Loss: 0.90737384557724, Current Training Accuracy: 100.0, Time: 0.2927384376525879 ms\n",
            "Epoch 100:[5/16], Current Loss: 0.946215808391571, Current Training Accuracy: 95.18229166666667, Time: 0.2572157382965088 ms\n",
            "Epoch 100:[10/16], Current Loss: 0.944585919380188, Current Training Accuracy: 95.8096590909091, Time: 0.2530341148376465 ms\n",
            "Epoch 100:[15/16], Current Loss: 0.9724590182304382, Current Training Accuracy: 95.947265625, Time: 0.25144100189208984 ms\n",
            "Epoch 100, train Loss: 0.950  Avg Training Accuracy: {95 %} Avg Validation Accuracy: 62 % Epoch Time: 7.5023438930511475 ms\n",
            "Epoch 101:[0/16], Current Loss: 0.9270795583724976, Current Training Accuracy: 97.65625, Time: 0.2816154956817627 ms\n",
            "Epoch 101:[5/16], Current Loss: 0.9710574746131897, Current Training Accuracy: 95.96354166666667, Time: 0.25855493545532227 ms\n",
            "Epoch 101:[10/16], Current Loss: 0.9350243806838989, Current Training Accuracy: 96.3778409090909, Time: 0.25829577445983887 ms\n",
            "Epoch 101:[15/16], Current Loss: 0.9418871998786926, Current Training Accuracy: 96.38671875, Time: 0.2517399787902832 ms\n",
            "Epoch 101, train Loss: 0.941  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 65 % Epoch Time: 7.460125207901001 ms\n",
            "Epoch 102:[0/16], Current Loss: 0.9327743649482727, Current Training Accuracy: 97.65625, Time: 0.27318406105041504 ms\n",
            "Epoch 102:[5/16], Current Loss: 0.9237720370292664, Current Training Accuracy: 97.265625, Time: 0.2577695846557617 ms\n",
            "Epoch 102:[10/16], Current Loss: 0.9554722905158997, Current Training Accuracy: 96.73295454545455, Time: 0.2568378448486328 ms\n",
            "Epoch 102:[15/16], Current Loss: 0.924750566482544, Current Training Accuracy: 96.875, Time: 0.2516207695007324 ms\n",
            "Epoch 102, train Loss: 0.940  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 63 % Epoch Time: 7.451068639755249 ms\n",
            "Epoch 103:[0/16], Current Loss: 0.94443678855896, Current Training Accuracy: 96.09375, Time: 0.283022403717041 ms\n",
            "Epoch 103:[5/16], Current Loss: 0.9497190713882446, Current Training Accuracy: 97.265625, Time: 0.25775718688964844 ms\n",
            "Epoch 103:[10/16], Current Loss: 0.9452762603759766, Current Training Accuracy: 97.65625, Time: 0.2530834674835205 ms\n",
            "Epoch 103:[15/16], Current Loss: 0.9252291917800903, Current Training Accuracy: 97.705078125, Time: 0.2505199909210205 ms\n",
            "Epoch 103, train Loss: 0.929  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 68 % Epoch Time: 7.470347881317139 ms\n",
            "Epoch 104:[0/16], Current Loss: 0.913907527923584, Current Training Accuracy: 99.21875, Time: 0.2843351364135742 ms\n",
            "Epoch 104:[5/16], Current Loss: 0.93284010887146, Current Training Accuracy: 98.56770833333333, Time: 0.25716519355773926 ms\n",
            "Epoch 104:[10/16], Current Loss: 0.9438809752464294, Current Training Accuracy: 98.08238636363636, Time: 0.25745415687561035 ms\n",
            "Epoch 104:[15/16], Current Loss: 0.9209887981414795, Current Training Accuracy: 97.8515625, Time: 0.2557237148284912 ms\n",
            "Epoch 104, train Loss: 0.927  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.4535510540008545 ms\n",
            "Epoch 105:[0/16], Current Loss: 0.9126338362693787, Current Training Accuracy: 99.21875, Time: 0.27730536460876465 ms\n",
            "Epoch 105:[5/16], Current Loss: 0.9433581829071045, Current Training Accuracy: 97.65625, Time: 0.2550969123840332 ms\n",
            "Epoch 105:[10/16], Current Loss: 0.9229980111122131, Current Training Accuracy: 97.79829545454545, Time: 0.2588992118835449 ms\n",
            "Epoch 105:[15/16], Current Loss: 0.9309778213500977, Current Training Accuracy: 97.8515625, Time: 0.25548839569091797 ms\n",
            "Epoch 105, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 7.474524736404419 ms\n",
            "Epoch 106:[0/16], Current Loss: 0.9209902286529541, Current Training Accuracy: 98.4375, Time: 0.2787010669708252 ms\n",
            "Epoch 106:[5/16], Current Loss: 0.9205079674720764, Current Training Accuracy: 98.046875, Time: 0.2565035820007324 ms\n",
            "Epoch 106:[10/16], Current Loss: 0.9423512816429138, Current Training Accuracy: 98.29545454545455, Time: 0.2560102939605713 ms\n",
            "Epoch 106:[15/16], Current Loss: 0.9214480519294739, Current Training Accuracy: 98.095703125, Time: 0.256237268447876 ms\n",
            "Epoch 106, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.429139852523804 ms\n",
            "Epoch 107:[0/16], Current Loss: 0.917441189289093, Current Training Accuracy: 99.21875, Time: 0.28169775009155273 ms\n",
            "Epoch 107:[5/16], Current Loss: 0.9199365377426147, Current Training Accuracy: 98.56770833333333, Time: 0.25472545623779297 ms\n",
            "Epoch 107:[10/16], Current Loss: 0.9279434084892273, Current Training Accuracy: 98.08238636363636, Time: 0.25841712951660156 ms\n",
            "Epoch 107:[15/16], Current Loss: 0.9283350706100464, Current Training Accuracy: 98.2421875, Time: 0.2504112720489502 ms\n",
            "Epoch 107, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.464754343032837 ms\n",
            "Epoch 108:[0/16], Current Loss: 0.9230758547782898, Current Training Accuracy: 98.4375, Time: 0.2836189270019531 ms\n",
            "Epoch 108:[5/16], Current Loss: 0.9283162355422974, Current Training Accuracy: 98.17708333333333, Time: 0.25867295265197754 ms\n",
            "Epoch 108:[10/16], Current Loss: 0.9135423302650452, Current Training Accuracy: 98.1534090909091, Time: 0.26468944549560547 ms\n",
            "Epoch 108:[15/16], Current Loss: 0.9205066561698914, Current Training Accuracy: 98.14453125, Time: 0.251359224319458 ms\n",
            "Epoch 108, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.456026792526245 ms\n",
            "Epoch 109:[0/16], Current Loss: 0.9205244779586792, Current Training Accuracy: 98.4375, Time: 0.2770049571990967 ms\n",
            "Epoch 109:[5/16], Current Loss: 0.9205670952796936, Current Training Accuracy: 98.17708333333333, Time: 0.25446009635925293 ms\n",
            "Epoch 109:[10/16], Current Loss: 0.920512855052948, Current Training Accuracy: 98.4375, Time: 0.25637388229370117 ms\n",
            "Epoch 109:[15/16], Current Loss: 0.9581187963485718, Current Training Accuracy: 98.2421875, Time: 0.2511417865753174 ms\n",
            "Epoch 109, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.476715087890625 ms\n",
            "Epoch 110:[0/16], Current Loss: 0.9359872937202454, Current Training Accuracy: 96.875, Time: 0.27321696281433105 ms\n",
            "Epoch 110:[5/16], Current Loss: 0.9204840660095215, Current Training Accuracy: 98.30729166666667, Time: 0.2545163631439209 ms\n",
            "Epoch 110:[10/16], Current Loss: 0.9274365901947021, Current Training Accuracy: 98.36647727272727, Time: 0.2576892375946045 ms\n",
            "Epoch 110:[15/16], Current Loss: 0.9200282692909241, Current Training Accuracy: 98.2421875, Time: 0.2555267810821533 ms\n",
            "Epoch 110, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.437899827957153 ms\n",
            "Epoch 111:[0/16], Current Loss: 0.9204837083816528, Current Training Accuracy: 98.4375, Time: 0.2837495803833008 ms\n",
            "Epoch 111:[5/16], Current Loss: 0.9193776845932007, Current Training Accuracy: 99.08854166666667, Time: 0.25864148139953613 ms\n",
            "Epoch 111:[10/16], Current Loss: 0.9204942584037781, Current Training Accuracy: 98.36647727272727, Time: 0.2585735321044922 ms\n",
            "Epoch 111:[15/16], Current Loss: 0.9198207855224609, Current Training Accuracy: 98.2421875, Time: 0.2534973621368408 ms\n",
            "Epoch 111, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.468962907791138 ms\n",
            "Epoch 112:[0/16], Current Loss: 0.9125001430511475, Current Training Accuracy: 99.21875, Time: 0.27513813972473145 ms\n",
            "Epoch 112:[5/16], Current Loss: 0.9127463102340698, Current Training Accuracy: 99.08854166666667, Time: 0.25384044647216797 ms\n",
            "Epoch 112:[10/16], Current Loss: 0.9510765671730042, Current Training Accuracy: 98.36647727272727, Time: 0.2531013488769531 ms\n",
            "Epoch 112:[15/16], Current Loss: 0.919257640838623, Current Training Accuracy: 98.291015625, Time: 0.25248169898986816 ms\n",
            "Epoch 112, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.396696329116821 ms\n",
            "Epoch 113:[0/16], Current Loss: 0.9283322691917419, Current Training Accuracy: 97.65625, Time: 0.27664732933044434 ms\n",
            "Epoch 113:[5/16], Current Loss: 0.9344193339347839, Current Training Accuracy: 97.91666666666667, Time: 0.2539632320404053 ms\n",
            "Epoch 113:[10/16], Current Loss: 0.9201354384422302, Current Training Accuracy: 98.29545454545455, Time: 0.25312018394470215 ms\n",
            "Epoch 113:[15/16], Current Loss: 0.951089084148407, Current Training Accuracy: 98.33984375, Time: 0.25141215324401855 ms\n",
            "Epoch 113, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.4867494106292725 ms\n",
            "Epoch 114:[0/16], Current Loss: 0.912666380405426, Current Training Accuracy: 99.21875, Time: 0.2729835510253906 ms\n",
            "Epoch 114:[5/16], Current Loss: 0.9468879699707031, Current Training Accuracy: 97.13541666666667, Time: 0.256394624710083 ms\n",
            "Epoch 114:[10/16], Current Loss: 0.9048947691917419, Current Training Accuracy: 97.9403409090909, Time: 0.25647544860839844 ms\n",
            "Epoch 114:[15/16], Current Loss: 0.920453667640686, Current Training Accuracy: 98.33984375, Time: 0.25836801528930664 ms\n",
            "Epoch 114, train Loss: 0.921  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 7.495100259780884 ms\n",
            "Epoch 115:[0/16], Current Loss: 0.912783682346344, Current Training Accuracy: 99.21875, Time: 0.27425265312194824 ms\n",
            "Epoch 115:[5/16], Current Loss: 0.9126712083816528, Current Training Accuracy: 98.95833333333333, Time: 0.2601199150085449 ms\n",
            "Epoch 115:[10/16], Current Loss: 0.9278746843338013, Current Training Accuracy: 98.4375, Time: 0.2612183094024658 ms\n",
            "Epoch 115:[15/16], Current Loss: 0.9124149680137634, Current Training Accuracy: 98.388671875, Time: 0.2519683837890625 ms\n",
            "Epoch 115, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.473785877227783 ms\n",
            "Epoch 116:[0/16], Current Loss: 0.9126810431480408, Current Training Accuracy: 99.21875, Time: 0.27825236320495605 ms\n",
            "Epoch 116:[5/16], Current Loss: 0.912272036075592, Current Training Accuracy: 98.4375, Time: 0.2569308280944824 ms\n",
            "Epoch 116:[10/16], Current Loss: 0.9277974367141724, Current Training Accuracy: 98.50852272727273, Time: 0.2766246795654297 ms\n",
            "Epoch 116:[15/16], Current Loss: 0.9195672273635864, Current Training Accuracy: 98.33984375, Time: 0.2511296272277832 ms\n",
            "Epoch 116, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.494840383529663 ms\n",
            "Epoch 117:[0/16], Current Loss: 0.9278246164321899, Current Training Accuracy: 97.65625, Time: 0.26995277404785156 ms\n",
            "Epoch 117:[5/16], Current Loss: 0.9205067157745361, Current Training Accuracy: 98.69791666666667, Time: 0.256502628326416 ms\n",
            "Epoch 117:[10/16], Current Loss: 0.9203715920448303, Current Training Accuracy: 98.29545454545455, Time: 0.256927490234375 ms\n",
            "Epoch 117:[15/16], Current Loss: 0.9121007919311523, Current Training Accuracy: 98.388671875, Time: 0.2551095485687256 ms\n",
            "Epoch 117, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.430749416351318 ms\n",
            "Epoch 118:[0/16], Current Loss: 0.9202181100845337, Current Training Accuracy: 98.4375, Time: 0.2758185863494873 ms\n",
            "Epoch 118:[5/16], Current Loss: 0.9126869440078735, Current Training Accuracy: 98.4375, Time: 0.2553527355194092 ms\n",
            "Epoch 118:[10/16], Current Loss: 0.928000271320343, Current Training Accuracy: 98.36647727272727, Time: 0.26549792289733887 ms\n",
            "Epoch 118:[15/16], Current Loss: 0.9126801490783691, Current Training Accuracy: 98.388671875, Time: 0.25121092796325684 ms\n",
            "Epoch 118, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.477526664733887 ms\n",
            "Epoch 119:[0/16], Current Loss: 0.9126772284507751, Current Training Accuracy: 99.21875, Time: 0.2755568027496338 ms\n",
            "Epoch 119:[5/16], Current Loss: 0.9361263513565063, Current Training Accuracy: 98.69791666666667, Time: 0.2555420398712158 ms\n",
            "Epoch 119:[10/16], Current Loss: 0.920484185218811, Current Training Accuracy: 98.29545454545455, Time: 0.2582840919494629 ms\n",
            "Epoch 119:[15/16], Current Loss: 0.9197939038276672, Current Training Accuracy: 98.388671875, Time: 0.25201940536499023 ms\n",
            "Epoch 119, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.439681529998779 ms\n",
            "Epoch 120:[0/16], Current Loss: 0.935632050037384, Current Training Accuracy: 96.875, Time: 0.2774975299835205 ms\n",
            "Epoch 120:[5/16], Current Loss: 0.9351086616516113, Current Training Accuracy: 98.046875, Time: 0.25806188583374023 ms\n",
            "Epoch 120:[10/16], Current Loss: 0.92049241065979, Current Training Accuracy: 98.29545454545455, Time: 0.2651181221008301 ms\n",
            "Epoch 120:[15/16], Current Loss: 0.9277341365814209, Current Training Accuracy: 98.4375, Time: 0.25306248664855957 ms\n",
            "Epoch 120, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.5166192054748535 ms\n",
            "Epoch 121:[0/16], Current Loss: 0.9361112713813782, Current Training Accuracy: 96.875, Time: 0.2744426727294922 ms\n",
            "Epoch 121:[5/16], Current Loss: 0.9193887114524841, Current Training Accuracy: 98.4375, Time: 0.2592751979827881 ms\n",
            "Epoch 121:[10/16], Current Loss: 0.9048635363578796, Current Training Accuracy: 98.57954545454545, Time: 0.2583026885986328 ms\n",
            "Epoch 121:[15/16], Current Loss: 0.9198145866394043, Current Training Accuracy: 98.388671875, Time: 0.25124216079711914 ms\n",
            "Epoch 121, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 7.450951337814331 ms\n",
            "Epoch 122:[0/16], Current Loss: 0.9200696349143982, Current Training Accuracy: 98.4375, Time: 0.28360700607299805 ms\n",
            "Epoch 122:[5/16], Current Loss: 0.920101523399353, Current Training Accuracy: 98.4375, Time: 0.2575035095214844 ms\n",
            "Epoch 122:[10/16], Current Loss: 0.945801317691803, Current Training Accuracy: 98.1534090909091, Time: 0.2595665454864502 ms\n",
            "Epoch 122:[15/16], Current Loss: 0.9127022624015808, Current Training Accuracy: 98.388671875, Time: 0.2584226131439209 ms\n",
            "Epoch 122, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.512171506881714 ms\n",
            "Epoch 123:[0/16], Current Loss: 0.9127207398414612, Current Training Accuracy: 99.21875, Time: 0.2782464027404785 ms\n",
            "Epoch 123:[5/16], Current Loss: 0.9049389958381653, Current Training Accuracy: 98.30729166666667, Time: 0.266068696975708 ms\n",
            "Epoch 123:[10/16], Current Loss: 0.9277979135513306, Current Training Accuracy: 98.36647727272727, Time: 0.26110315322875977 ms\n",
            "Epoch 123:[15/16], Current Loss: 0.9126339554786682, Current Training Accuracy: 98.486328125, Time: 0.2509284019470215 ms\n",
            "Epoch 123, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.547966003417969 ms\n",
            "Epoch 124:[0/16], Current Loss: 0.9355208873748779, Current Training Accuracy: 96.875, Time: 0.2878427505493164 ms\n",
            "Epoch 124:[5/16], Current Loss: 0.9048588871955872, Current Training Accuracy: 98.69791666666667, Time: 0.2700693607330322 ms\n",
            "Epoch 124:[10/16], Current Loss: 0.9204865097999573, Current Training Accuracy: 98.50852272727273, Time: 0.25479650497436523 ms\n",
            "Epoch 124:[15/16], Current Loss: 0.9355777502059937, Current Training Accuracy: 98.4375, Time: 0.2510237693786621 ms\n",
            "Epoch 124, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.538198232650757 ms\n",
            "Epoch 125:[0/16], Current Loss: 0.9279077053070068, Current Training Accuracy: 97.65625, Time: 0.2872445583343506 ms\n",
            "Epoch 125:[5/16], Current Loss: 0.904902458190918, Current Training Accuracy: 98.69791666666667, Time: 0.2586538791656494 ms\n",
            "Epoch 125:[10/16], Current Loss: 0.9126729369163513, Current Training Accuracy: 98.65056818181819, Time: 0.255129337310791 ms\n",
            "Epoch 125:[15/16], Current Loss: 0.9049043655395508, Current Training Accuracy: 98.53515625, Time: 0.2511565685272217 ms\n",
            "Epoch 125, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.474381923675537 ms\n",
            "Epoch 126:[0/16], Current Loss: 0.9276936054229736, Current Training Accuracy: 97.65625, Time: 0.28086423873901367 ms\n",
            "Epoch 126:[5/16], Current Loss: 0.920428991317749, Current Training Accuracy: 97.78645833333333, Time: 0.25408506393432617 ms\n",
            "Epoch 126:[10/16], Current Loss: 0.9126730561256409, Current Training Accuracy: 98.22443181818181, Time: 0.2630269527435303 ms\n",
            "Epoch 126:[15/16], Current Loss: 0.9048699736595154, Current Training Accuracy: 98.486328125, Time: 0.2542726993560791 ms\n",
            "Epoch 126, train Loss: 0.920  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 7.529590129852295 ms\n",
            "Epoch 127:[0/16], Current Loss: 0.9276018142700195, Current Training Accuracy: 97.65625, Time: 0.2841675281524658 ms\n",
            "Epoch 127:[5/16], Current Loss: 0.9048634767532349, Current Training Accuracy: 98.4375, Time: 0.25858449935913086 ms\n",
            "Epoch 127:[10/16], Current Loss: 0.9126667380332947, Current Training Accuracy: 98.50852272727273, Time: 0.25728368759155273 ms\n",
            "Epoch 127:[15/16], Current Loss: 0.9204879999160767, Current Training Accuracy: 98.486328125, Time: 0.2548685073852539 ms\n",
            "Epoch 127, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.476967096328735 ms\n",
            "Epoch 128:[0/16], Current Loss: 0.920384407043457, Current Training Accuracy: 98.4375, Time: 0.2743360996246338 ms\n",
            "Epoch 128:[5/16], Current Loss: 0.9204863905906677, Current Training Accuracy: 98.046875, Time: 0.2557716369628906 ms\n",
            "Epoch 128:[10/16], Current Loss: 0.9126779437065125, Current Training Accuracy: 98.36647727272727, Time: 0.25354886054992676 ms\n",
            "Epoch 128:[15/16], Current Loss: 0.9048702716827393, Current Training Accuracy: 98.53515625, Time: 0.2507638931274414 ms\n",
            "Epoch 128, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 7.429986953735352 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "pred_correct_num=[]\n",
        "pred_total_num=[]\n",
        "pred_result_list=[]\n",
        "pred_prob_list = []\n",
        "label_prob_list=[]\n",
        "label_list=[]\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "    t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
        "    mask=mask.cuda()\n",
        "    output_test=model(t_image)\n",
        "    pred_prob_list.append(output_test)\n",
        "    label_prob_list.append(data[1])\n",
        "    label_list.append(mask)\n",
        "    output=torch.max(output_test,1)[1].long()\n",
        "    pred_result_list.append(output)\n",
        "    pred_correct_num.append(output.eq(mask).sum().item())\n",
        "    pred_total_num.append(output_test.shape[0])\n",
        "acc_test=sum(pred_correct_num)/sum(pred_total_num)\n",
        "print(\"The accuracy of detecting news bias: {}\".format(('%.4f%%'%(acc_test*100))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCfSqNzR_4Gh",
        "outputId": "028d802c-075d-46bb-fcb5-bc7f56ffb421"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of detecting news bias: 82.5521%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "for i in range(len(pred_result_list)):\n",
        "  if len(pred_result_list) == 1:\n",
        "    pred_result = pred_result_list[0]\n",
        "    label = label_list[0]\n",
        "  if len(pred_result_list) == 2:\n",
        "    pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
        "    label = torch.cat((label_list[0], label_list[1]), -1)\n",
        "  if len(pred_result_list) > 2:\n",
        "    pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
        "    label = torch.cat((label_list[0], label_list[1]), -1)\n",
        "    for j in range(len(pred_result_list)-2):\n",
        "      pred_result = torch.cat((pred_result, pred_result_list[j+2]), -1)\n",
        "      label = torch.cat((label, label_list[j+2]), -1)\n",
        "label = label.cpu()\n",
        "pred_result = pred_result.cpu()\n",
        "C=confusion_matrix(label,pred_result)\n",
        "df=pd.DataFrame(C,index=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"],columns=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"])\n",
        "p1=sns.heatmap(df,annot=True,cmap=\"hot_r\")\n",
        "s1 = p1.get_figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "v2LKsZT0_6SC",
        "outputId": "f0bab731-5809-4ddb-9a55-be696cad1e04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(pred_prob_list)):\n",
        "  if len(pred_prob_list) == 1:\n",
        "    pred_prob = pred_prob_list[0]\n",
        "    label_prob = label_prob_list[0]\n",
        "  if len(pred_prob_list) == 2:\n",
        "    pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
        "    label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
        "  if len(pred_prob_list) > 2:\n",
        "    pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
        "    label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
        "    for j in range(len(pred_prob_list)-2):\n",
        "      pred_prob = torch.cat((pred_prob, pred_prob_list[j+2]), -1)\n",
        "      label_prob = torch.cat((label_prob, label_prob_list[j+2]), -1)\n",
        "label_prob = label_prob.cpu()\n",
        "pred_prob = pred_prob.cpu()\n",
        "criterion=nn.L1Loss(reduction=\"mean\")\n",
        "loss=criterion(pred_prob, label_prob)\n",
        "print(\"MAE Value: {}\".format(\"%.4f\" % loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwXYFQem_8F_",
        "outputId": "e76cbffa-5527-4ab9-d686-edc1f2d13d64"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE Value: 0.0713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score = f1_score(pred_result,label,average=\"macro\")\n",
        "print(\"Macro-F1 Score: {}\".format(\"%.4f\" % f1_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fTsr-x-ACeJ",
        "outputId": "680f1d92-c5f6-41ea-d79b-eb82fa6d1006"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-F1 Score: 0.7898\n"
          ]
        }
      ]
    }
  ]
}