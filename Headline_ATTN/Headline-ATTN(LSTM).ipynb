{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "40A1OeJTOghS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "import torch.utils.data as Data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from math import log"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')\n",
        "#改变当前工作目录到谷歌云盘的路径\n",
        "path=\"/content/drive/My Drive/Colab Notebooks/Bias Detection/\"\n",
        "os.chdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NisZNL_O3wr",
        "outputId": "681096b8-892e-49f5-daf7-c07126df4f13"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_process = np.load(\"X_train_glove_title.npy\")\n",
        "X_test_process = np.load(\"X_test_glove_title.npy\")\n",
        "X_valid_process = np.load(\"X_valid_glove_title.npy\")\n",
        "y_train_process = np.load(\"y_train_glove.npy\")\n",
        "y_test_process = np.load(\"y_test_glove.npy\")\n",
        "y_valid_process = np.load(\"y_valid_glove.npy\")\n",
        "H_train_process = np.load(\"X_train_glove_headline.npy\")\n",
        "H_test_process = np.load(\"X_test_glove_headline.npy\")\n",
        "H_valid_process = np.load(\"X_valid_glove_headline.npy\")"
      ],
      "metadata": {
        "id": "Ue40f2DlO67v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate([X_train_process, H_train_process], axis = 1)\n",
        "X_test = np.concatenate([X_test_process, H_test_process], axis = 1)\n",
        "X_valid = np.concatenate([X_valid_process, H_valid_process], axis = 1)"
      ],
      "metadata": {
        "id": "x4X0egHXQZt3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = Data.DataLoader(\n",
        "    dataset=Data.TensorDataset(torch.Tensor(X_train),torch.LongTensor(y_train_process)),      \n",
        "    batch_size=128,      \n",
        "    shuffle=True,               \n",
        "    num_workers=2, \n",
        "    drop_last=True\n",
        ")\n",
        "test_loader = Data.DataLoader(\n",
        "    dataset=Data.TensorDataset(torch.Tensor(X_test),torch.LongTensor(y_test_process)),      \n",
        "    batch_size=128,      \n",
        "    shuffle=True,               \n",
        "    num_workers=2,  \n",
        "    drop_last=True\n",
        ")\n",
        "val_loader = Data.DataLoader(\n",
        "    dataset=Data.TensorDataset(torch.Tensor(X_valid),torch.LongTensor(y_valid_process)),      \n",
        "    batch_size=128,      \n",
        "    shuffle=True,               \n",
        "    num_workers=2,\n",
        "    drop_last=True\n",
        ")"
      ],
      "metadata": {
        "id": "96pwQUWLPeCN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ECA(x,gamma=2,b=1):\n",
        "    N,C,H,W=x.size()\n",
        "    t=int(abs((log(C,2)+b)/gamma))\n",
        "    k=t if t%2 else t+1\n",
        "    \n",
        "    avg_pool=nn.AdaptiveAvgPool2d(1).cuda()\n",
        "    conv=nn.Conv1d(1,1,kernel_size=k,padding=int(k/2),bias=False).cuda()\n",
        "    sigmoid=nn.Sigmoid().cuda()\n",
        "    \n",
        "    y=avg_pool(x)\n",
        "    y=conv(y.squeeze(-1).transpose(-1,-2))\n",
        "    y=y.transpose(-1,-2).unsqueeze(-1)\n",
        "    y=sigmoid(y)\n",
        "    return y"
      ],
      "metadata": {
        "id": "JelDbiVuPx8D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextRCNN(nn.Module):\n",
        "    def __init__(self,vocab_size,embedding_dim,hidden_size,num_labels=5):\n",
        "        super(TextRCNN,self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=hidden_size,\n",
        "                            batch_first=True,bidirectional=True)\n",
        "        self.dropout = nn.Dropout(.3)\n",
        "        self.linear1 = nn.Linear(embedding_dim+2*hidden_size, 128)\n",
        "        self.linear2 = nn.Linear(600, 128)\n",
        "        self.linear3 = nn.Linear(128, num_labels)\n",
        "        self.conv1 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=6)#通过out_channel改变文中的feature map，且out_channel∈[10,50,100,200,400,600,800,1000]\n",
        "        self.conv2 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=7)\n",
        "        self.conv3 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=8)\n",
        "        self.conv4 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=9)\n",
        "        #self.w_omiga = torch.randn(128,hidden_size*2,1,requires_grad=True).cuda()\n",
        "\n",
        "    def forward(self, x):#x: [batch,L]\n",
        "        #x_embed = x.cuda()\n",
        "        headline = x[:, 500:, :].cuda()\n",
        "        head_hidden_state, (h_c, h_h) = self.lstm(headline)\n",
        "        U = head_hidden_state[:, -1, :].unsqueeze(1)\n",
        "        U = U.permute(0,2,1)\n",
        "        x_embed = x[:, :500, :].cuda()\n",
        "        last_hidden_state,(c,h) = self.lstm(x_embed) #last_hidden_state: [batch,L,hidden_size * num_bidirectional]\n",
        "        H = torch.nn.Tanh()(last_hidden_state)\n",
        "        weights=torch.nn.Softmax(dim=-1)(torch.bmm(H, U).squeeze(-1)).unsqueeze(dim=-1).repeat(1,1,2*12)  # LSTM+ATTN-Weight\n",
        "        last_hidden_state=torch.mul(last_hidden_state,weights)\n",
        "        out = torch.cat((last_hidden_state[:,:,:12],x_embed,last_hidden_state[:,:,12:]),2).cuda()#out: [batch,L,embedding_size + hidden_size * num_bidirectional]  \n",
        "        out = F.tanh(self.linear1(out))\n",
        "        out = out.permute(dims=[0,2,1]).cuda() #out: [batch,embedding_size + hidden_size * num_bidirectional,L]\n",
        "        out_1 = self.conv1(out)\n",
        "        out_1 = nn.ReLU()(out_1)\n",
        "        out_1 = nn.MaxPool1d(kernel_size=495)(out_1)\n",
        "        out_2 = self.conv1(out)\n",
        "        out_2 = nn.ReLU()(out_2)\n",
        "        out_2 = nn.MaxPool1d(kernel_size=494)(out_2)\n",
        "        out_3 = self.conv1(out)\n",
        "        out_3 = nn.ReLU()(out_3)\n",
        "        out_3 = nn.MaxPool1d(kernel_size=493)(out_3)\n",
        "        out_4 = self.conv1(out)\n",
        "        out_4 = nn.ReLU()(out_4)\n",
        "        out_4 = nn.MaxPool1d(kernel_size=492)(out_4)\n",
        "        out_1 = out_1.unsqueeze(1).cuda()\n",
        "        out_2 = out_2.unsqueeze(1).cuda()\n",
        "        out_3 = out_3.unsqueeze(1).cuda()\n",
        "        out_4 = out_4.unsqueeze(1).cuda()\n",
        "        out = torch.cat([out_1, out_2, out_3, out_4],dim=1).cuda()\n",
        "        channel_weights = F.softmax(ECA(out).squeeze().squeeze(),dim=1).unsqueeze(-1).unsqueeze(-1).expand_as(out)\n",
        "        out = torch.mul(channel_weights,out).cuda()\n",
        "        out = torch.sum(out, dim = 1)\n",
        "        out = self.linear2(out.squeeze()) #out: [batch,num_labels]\n",
        "        out = self.linear3(F.tanh(out))\n",
        "        out = F.softmax(out,dim=1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "4-h4m_vMRQwM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextRCNN(5302,200,12).cuda()"
      ],
      "metadata": {
        "id": "EEopGVolSodZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list, counter =[], []\n",
        "count = 0\n",
        "running_loss=0\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0)\n",
        "total_train = 0\n",
        "correct_train = 0\n",
        "train_epoch, train_loss = [], []\n",
        "train_acc, val_acc = [], []\n",
        "avg_epoch, avg_train_loss, avg_val_acc = [], [], []\n",
        "epoch_time=[]\n",
        "\n",
        "model.train()\n",
        "for epoch in range(128): \n",
        "    running_loss = 0\n",
        "    total_train = 0\n",
        "    correct_train = 0\n",
        "    total_accuracy = 0\n",
        "    total_val_accuracy = 0\n",
        "    correct_val = 0\n",
        "    total_val = 0   \n",
        "    start1 = time.time()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        start = time.time()\n",
        "        t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
        "        t_image=t_image.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(t_image) # forward\n",
        "        ###########################################################################\n",
        "        outputs=outputs.cuda()\n",
        "        mask=mask.cuda()\n",
        "        loss = criterion(outputs, mask.long()) # calculate the loss\n",
        "        loss.backward() # back propagation\n",
        "        optimizer.step() # update gradients\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += mask.nelement()\n",
        "        correct_train += predicted.eq(mask.data).sum().item()\n",
        "        train_accuracy = 100 * correct_train / total_train\n",
        "        total_accuracy += train_accuracy\n",
        "        if i % 5 == 0:\n",
        "            end = time.time()\n",
        "            print('Epoch {}:[{}/{}], Current Loss: {}, Current Training Accuracy: {}, Time: {} ms'.format(epoch+1, i, len(train_loader), loss.item(), train_accuracy, end - start))      \n",
        "            train_acc.append(train_accuracy)\n",
        "            train_loss.append(loss.item())\n",
        "            train_epoch.append(str(epoch+1) + '/' + str(i))\n",
        "\n",
        "            for j, data1 in enumerate(val_loader, 0):\n",
        "                t_image1, mask1 = data1[0],data1[1].long()\n",
        "                outputs1 = model(t_image1)\n",
        "                mask1_temp=torch.max(mask1.data,1)\n",
        "                mask1_temp1=mask1_temp[1].cuda()\n",
        "                _, predicted1 = torch.max(outputs1.data, 1)\n",
        "                total_val += mask1.nelement()\n",
        "                correct_val += predicted1.eq(mask1_temp1).sum().item()\n",
        "                val_accuracy= 100 * correct_val / total_val\n",
        "                total_val_accuracy += val_accuracy\n",
        "            val_acc.append(val_accuracy)\n",
        "    end1 = time.time()\n",
        "    print('Epoch {}, train Loss: {:.3f} '.format(epoch+1, running_loss/len(train_loader)), \"Avg Training Accuracy: {%d %%}\" % (total_accuracy/len(train_loader)), \"Avg Validation Accuracy: %d %%\" % (total_val_accuracy/len(val_loader)), \"Epoch Time: {} ms\".format(end1 - start1))\n",
        "    epoch_time.append(end1-start1)\n",
        "    avg_epoch.append(epoch+1)\n",
        "    avg_train_loss.append(running_loss/len(train_loader))\n",
        "    avg_val_acc.append(total_val_accuracy/len(val_loader))\n",
        "    #print(avg_epoch)\n",
        "    #print(avg_train_loss)\n",
        "    #print(avg_val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnN5q8V22mFL",
        "outputId": "303a64d7-bfa7-42e9-b223-676ba34a83bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:[0/16], Current Loss: 1.613163709640503, Current Training Accuracy: 12.5, Time: 5.089127540588379 ms\n",
            "Epoch 1:[5/16], Current Loss: 1.5396512746810913, Current Training Accuracy: 27.34375, Time: 0.24135351181030273 ms\n",
            "Epoch 1:[10/16], Current Loss: 1.5084919929504395, Current Training Accuracy: 30.326704545454547, Time: 0.24126195907592773 ms\n",
            "Epoch 1:[15/16], Current Loss: 1.42412531375885, Current Training Accuracy: 36.279296875, Time: 0.23861455917358398 ms\n",
            "Epoch 1, train Loss: 1.511  Avg Training Accuracy: {28 %} Avg Validation Accuracy: 28 % Epoch Time: 12.043017864227295 ms\n",
            "Epoch 2:[0/16], Current Loss: 1.40383780002594, Current Training Accuracy: 57.03125, Time: 0.26250171661376953 ms\n",
            "Epoch 2:[5/16], Current Loss: 1.3827824592590332, Current Training Accuracy: 56.380208333333336, Time: 0.2414407730102539 ms\n",
            "Epoch 2:[10/16], Current Loss: 1.3576416969299316, Current Training Accuracy: 56.32102272727273, Time: 0.24106836318969727 ms\n",
            "Epoch 2:[15/16], Current Loss: 1.3364696502685547, Current Training Accuracy: 55.95703125, Time: 0.23751592636108398 ms\n",
            "Epoch 2, train Loss: 1.350  Avg Training Accuracy: {56 %} Avg Validation Accuracy: 42 % Epoch Time: 7.162837743759155 ms\n",
            "Epoch 3:[0/16], Current Loss: 1.2862342596054077, Current Training Accuracy: 60.9375, Time: 0.26192545890808105 ms\n",
            "Epoch 3:[5/16], Current Loss: 1.2778019905090332, Current Training Accuracy: 58.854166666666664, Time: 0.24366378784179688 ms\n",
            "Epoch 3:[10/16], Current Loss: 1.2612272500991821, Current Training Accuracy: 62.14488636363637, Time: 0.24163365364074707 ms\n",
            "Epoch 3:[15/16], Current Loss: 1.2415558099746704, Current Training Accuracy: 63.720703125, Time: 0.24202656745910645 ms\n",
            "Epoch 3, train Loss: 1.274  Avg Training Accuracy: {60 %} Avg Validation Accuracy: 48 % Epoch Time: 7.173765420913696 ms\n",
            "Epoch 4:[0/16], Current Loss: 1.2628308534622192, Current Training Accuracy: 64.0625, Time: 0.26065564155578613 ms\n",
            "Epoch 4:[5/16], Current Loss: 1.3352335691452026, Current Training Accuracy: 67.578125, Time: 0.2478954792022705 ms\n",
            "Epoch 4:[10/16], Current Loss: 1.1986640691757202, Current Training Accuracy: 69.31818181818181, Time: 0.2427511215209961 ms\n",
            "Epoch 4:[15/16], Current Loss: 1.2124468088150024, Current Training Accuracy: 69.3359375, Time: 0.24029159545898438 ms\n",
            "Epoch 4, train Loss: 1.221  Avg Training Accuracy: {68 %} Avg Validation Accuracy: 52 % Epoch Time: 7.194463729858398 ms\n",
            "Epoch 5:[0/16], Current Loss: 1.1327487230300903, Current Training Accuracy: 79.6875, Time: 0.26876235008239746 ms\n",
            "Epoch 5:[5/16], Current Loss: 1.1448650360107422, Current Training Accuracy: 74.609375, Time: 0.24848079681396484 ms\n",
            "Epoch 5:[10/16], Current Loss: 1.1732746362686157, Current Training Accuracy: 73.08238636363636, Time: 0.2465975284576416 ms\n",
            "Epoch 5:[15/16], Current Loss: 1.1821634769439697, Current Training Accuracy: 72.55859375, Time: 0.24476909637451172 ms\n",
            "Epoch 5, train Loss: 1.187  Avg Training Accuracy: {74 %} Avg Validation Accuracy: 54 % Epoch Time: 7.2208404541015625 ms\n",
            "Epoch 6:[0/16], Current Loss: 1.1513643264770508, Current Training Accuracy: 77.34375, Time: 0.27102231979370117 ms\n",
            "Epoch 6:[5/16], Current Loss: 1.1187974214553833, Current Training Accuracy: 74.86979166666667, Time: 0.24531316757202148 ms\n",
            "Epoch 6:[10/16], Current Loss: 1.1169205904006958, Current Training Accuracy: 75.71022727272727, Time: 0.2499697208404541 ms\n",
            "Epoch 6:[15/16], Current Loss: 1.1496366262435913, Current Training Accuracy: 75.1953125, Time: 0.24537253379821777 ms\n",
            "Epoch 6, train Loss: 1.157  Avg Training Accuracy: {75 %} Avg Validation Accuracy: 55 % Epoch Time: 7.244120836257935 ms\n",
            "Epoch 7:[0/16], Current Loss: 1.1027592420578003, Current Training Accuracy: 82.03125, Time: 0.2732224464416504 ms\n",
            "Epoch 7:[5/16], Current Loss: 1.1183899641036987, Current Training Accuracy: 78.64583333333333, Time: 0.25545334815979004 ms\n",
            "Epoch 7:[10/16], Current Loss: 1.188615322113037, Current Training Accuracy: 77.34375, Time: 0.25336503982543945 ms\n",
            "Epoch 7:[15/16], Current Loss: 1.130873680114746, Current Training Accuracy: 77.44140625, Time: 0.25169920921325684 ms\n",
            "Epoch 7, train Loss: 1.136  Avg Training Accuracy: {78 %} Avg Validation Accuracy: 54 % Epoch Time: 7.335310935974121 ms\n",
            "Epoch 8:[0/16], Current Loss: 1.0929279327392578, Current Training Accuracy: 81.25, Time: 0.27129054069519043 ms\n",
            "Epoch 8:[5/16], Current Loss: 1.1269429922103882, Current Training Accuracy: 79.296875, Time: 0.25647902488708496 ms\n",
            "Epoch 8:[10/16], Current Loss: 1.1234878301620483, Current Training Accuracy: 79.04829545454545, Time: 0.2554161548614502 ms\n",
            "Epoch 8:[15/16], Current Loss: 1.1410313844680786, Current Training Accuracy: 78.22265625, Time: 0.24705958366394043 ms\n",
            "Epoch 8, train Loss: 1.120  Avg Training Accuracy: {79 %} Avg Validation Accuracy: 55 % Epoch Time: 7.326836824417114 ms\n",
            "Epoch 9:[0/16], Current Loss: 1.087147831916809, Current Training Accuracy: 81.25, Time: 0.2742888927459717 ms\n",
            "Epoch 9:[5/16], Current Loss: 1.08474862575531, Current Training Accuracy: 79.296875, Time: 0.26573777198791504 ms\n",
            "Epoch 9:[10/16], Current Loss: 1.0905492305755615, Current Training Accuracy: 79.9715909090909, Time: 0.256136417388916 ms\n",
            "Epoch 9:[15/16], Current Loss: 1.1272010803222656, Current Training Accuracy: 79.443359375, Time: 0.25098371505737305 ms\n",
            "Epoch 9, train Loss: 1.104  Avg Training Accuracy: {79 %} Avg Validation Accuracy: 55 % Epoch Time: 7.386833906173706 ms\n",
            "Epoch 10:[0/16], Current Loss: 1.0955920219421387, Current Training Accuracy: 84.375, Time: 0.2765312194824219 ms\n",
            "Epoch 10:[5/16], Current Loss: 1.0495768785476685, Current Training Accuracy: 84.375, Time: 0.2556138038635254 ms\n",
            "Epoch 10:[10/16], Current Loss: 1.0073217153549194, Current Training Accuracy: 85.36931818181819, Time: 0.262005090713501 ms\n",
            "Epoch 10:[15/16], Current Loss: 1.0728328227996826, Current Training Accuracy: 85.498046875, Time: 0.25267577171325684 ms\n",
            "Epoch 10, train Loss: 1.059  Avg Training Accuracy: {84 %} Avg Validation Accuracy: 60 % Epoch Time: 7.482239007949829 ms\n",
            "Epoch 11:[0/16], Current Loss: 1.084779977798462, Current Training Accuracy: 82.03125, Time: 0.2819850444793701 ms\n",
            "Epoch 11:[5/16], Current Loss: 1.0084853172302246, Current Training Accuracy: 84.765625, Time: 0.2590188980102539 ms\n",
            "Epoch 11:[10/16], Current Loss: 1.049420714378357, Current Training Accuracy: 85.79545454545455, Time: 0.25490331649780273 ms\n",
            "Epoch 11:[15/16], Current Loss: 1.0418745279312134, Current Training Accuracy: 86.572265625, Time: 0.25354933738708496 ms\n",
            "Epoch 11, train Loss: 1.040  Avg Training Accuracy: {84 %} Avg Validation Accuracy: 60 % Epoch Time: 7.412856578826904 ms\n",
            "Epoch 12:[0/16], Current Loss: 1.021526575088501, Current Training Accuracy: 88.28125, Time: 0.28654003143310547 ms\n",
            "Epoch 12:[5/16], Current Loss: 1.0816799402236938, Current Training Accuracy: 86.84895833333333, Time: 0.26276540756225586 ms\n",
            "Epoch 12:[10/16], Current Loss: 1.0498294830322266, Current Training Accuracy: 87.28693181818181, Time: 0.2585272789001465 ms\n",
            "Epoch 12:[15/16], Current Loss: 1.036069631576538, Current Training Accuracy: 87.79296875, Time: 0.25787353515625 ms\n",
            "Epoch 12, train Loss: 1.028  Avg Training Accuracy: {87 %} Avg Validation Accuracy: 59 % Epoch Time: 7.5248823165893555 ms\n",
            "Epoch 13:[0/16], Current Loss: 1.0370689630508423, Current Training Accuracy: 86.71875, Time: 0.2853825092315674 ms\n",
            "Epoch 13:[5/16], Current Loss: 0.9961946606636047, Current Training Accuracy: 88.02083333333333, Time: 0.26764750480651855 ms\n",
            "Epoch 13:[10/16], Current Loss: 1.0791406631469727, Current Training Accuracy: 87.9971590909091, Time: 0.2704293727874756 ms\n",
            "Epoch 13:[15/16], Current Loss: 1.0117043256759644, Current Training Accuracy: 88.232421875, Time: 0.2564244270324707 ms\n",
            "Epoch 13, train Loss: 1.022  Avg Training Accuracy: {88 %} Avg Validation Accuracy: 60 % Epoch Time: 7.521001815795898 ms\n",
            "Epoch 14:[0/16], Current Loss: 1.009502649307251, Current Training Accuracy: 89.0625, Time: 0.28082275390625 ms\n",
            "Epoch 14:[5/16], Current Loss: 0.9965866208076477, Current Training Accuracy: 89.0625, Time: 0.2613565921783447 ms\n",
            "Epoch 14:[10/16], Current Loss: 1.0137611627578735, Current Training Accuracy: 88.28125, Time: 0.26004648208618164 ms\n",
            "Epoch 14:[15/16], Current Loss: 0.9954655766487122, Current Training Accuracy: 89.453125, Time: 0.25945162773132324 ms\n",
            "Epoch 14, train Loss: 1.010  Avg Training Accuracy: {88 %} Avg Validation Accuracy: 60 % Epoch Time: 7.535049676895142 ms\n",
            "Epoch 15:[0/16], Current Loss: 0.9707038998603821, Current Training Accuracy: 97.65625, Time: 0.2868211269378662 ms\n",
            "Epoch 15:[5/16], Current Loss: 1.0323066711425781, Current Training Accuracy: 95.05208333333333, Time: 0.25815463066101074 ms\n",
            "Epoch 15:[10/16], Current Loss: 0.9713130593299866, Current Training Accuracy: 95.38352272727273, Time: 0.2620272636413574 ms\n",
            "Epoch 15:[15/16], Current Loss: 1.0075174570083618, Current Training Accuracy: 95.556640625, Time: 0.2542452812194824 ms\n",
            "Epoch 15, train Loss: 0.977  Avg Training Accuracy: {95 %} Avg Validation Accuracy: 60 % Epoch Time: 7.510140657424927 ms\n",
            "Epoch 16:[0/16], Current Loss: 0.9685333371162415, Current Training Accuracy: 95.3125, Time: 0.28089165687561035 ms\n",
            "Epoch 16:[5/16], Current Loss: 0.9831245541572571, Current Training Accuracy: 96.74479166666667, Time: 0.2616136074066162 ms\n",
            "Epoch 16:[10/16], Current Loss: 0.9250679016113281, Current Training Accuracy: 97.30113636363636, Time: 0.2563190460205078 ms\n",
            "Epoch 16:[15/16], Current Loss: 0.9742692112922668, Current Training Accuracy: 96.826171875, Time: 0.25711536407470703 ms\n",
            "Epoch 16, train Loss: 0.953  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 59 % Epoch Time: 7.517635345458984 ms\n",
            "Epoch 17:[0/16], Current Loss: 0.9302700757980347, Current Training Accuracy: 98.4375, Time: 0.27425217628479004 ms\n",
            "Epoch 17:[5/16], Current Loss: 0.9277002215385437, Current Training Accuracy: 98.046875, Time: 0.2584874629974365 ms\n",
            "Epoch 17:[10/16], Current Loss: 0.9328927993774414, Current Training Accuracy: 97.58522727272727, Time: 0.25827670097351074 ms\n",
            "Epoch 17:[15/16], Current Loss: 0.945713996887207, Current Training Accuracy: 97.4609375, Time: 0.2580225467681885 ms\n",
            "Epoch 17, train Loss: 0.938  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 62 % Epoch Time: 7.415400981903076 ms\n",
            "Epoch 18:[0/16], Current Loss: 0.9253792762756348, Current Training Accuracy: 98.4375, Time: 0.28208446502685547 ms\n",
            "Epoch 18:[5/16], Current Loss: 0.9311734437942505, Current Training Accuracy: 98.17708333333333, Time: 0.256732702255249 ms\n",
            "Epoch 18:[10/16], Current Loss: 0.9318231344223022, Current Training Accuracy: 97.51420454545455, Time: 0.2575240135192871 ms\n",
            "Epoch 18:[15/16], Current Loss: 0.9304574728012085, Current Training Accuracy: 97.65625, Time: 0.2525303363800049 ms\n",
            "Epoch 18, train Loss: 0.932  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 7.444636106491089 ms\n",
            "Epoch 19:[0/16], Current Loss: 0.9155762791633606, Current Training Accuracy: 99.21875, Time: 0.2750279903411865 ms\n",
            "Epoch 19:[5/16], Current Loss: 0.9146196842193604, Current Training Accuracy: 97.91666666666667, Time: 0.25938987731933594 ms\n",
            "Epoch 19:[10/16], Current Loss: 0.9304336309432983, Current Training Accuracy: 97.65625, Time: 0.25748777389526367 ms\n",
            "Epoch 19:[15/16], Current Loss: 0.9167318940162659, Current Training Accuracy: 97.705078125, Time: 0.2542078495025635 ms\n",
            "Epoch 19, train Loss: 0.929  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 62 % Epoch Time: 7.9880383014678955 ms\n",
            "Epoch 20:[0/16], Current Loss: 0.9229311943054199, Current Training Accuracy: 98.4375, Time: 0.2741429805755615 ms\n",
            "Epoch 20:[5/16], Current Loss: 0.914677083492279, Current Training Accuracy: 96.875, Time: 0.25821876525878906 ms\n",
            "Epoch 20:[10/16], Current Loss: 0.9148833751678467, Current Training Accuracy: 97.51420454545455, Time: 0.2566335201263428 ms\n",
            "Epoch 20:[15/16], Current Loss: 0.9145753383636475, Current Training Accuracy: 97.802734375, Time: 0.2537679672241211 ms\n",
            "Epoch 20, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 7.48882794380188 ms\n",
            "Epoch 21:[0/16], Current Loss: 0.9355195164680481, Current Training Accuracy: 96.875, Time: 0.28275442123413086 ms\n",
            "Epoch 21:[5/16], Current Loss: 0.9210646152496338, Current Training Accuracy: 98.4375, Time: 0.25591611862182617 ms\n",
            "Epoch 21:[10/16], Current Loss: 0.9211673736572266, Current Training Accuracy: 98.36647727272727, Time: 0.2584352493286133 ms\n",
            "Epoch 21:[15/16], Current Loss: 0.9593490362167358, Current Training Accuracy: 97.94921875, Time: 0.25529980659484863 ms\n",
            "Epoch 21, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 7.486654043197632 ms\n",
            "Epoch 22:[0/16], Current Loss: 0.9214031100273132, Current Training Accuracy: 98.4375, Time: 0.2850918769836426 ms\n",
            "Epoch 22:[5/16], Current Loss: 0.9213902354240417, Current Training Accuracy: 98.4375, Time: 0.2577478885650635 ms\n",
            "Epoch 22:[10/16], Current Loss: 0.9208675622940063, Current Training Accuracy: 97.72727272727273, Time: 0.25809359550476074 ms\n",
            "Epoch 22:[15/16], Current Loss: 0.9138097763061523, Current Training Accuracy: 97.900390625, Time: 0.2567138671875 ms\n",
            "Epoch 22, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 62 % Epoch Time: 7.494490623474121 ms\n",
            "Epoch 23:[0/16], Current Loss: 0.9280723333358765, Current Training Accuracy: 97.65625, Time: 0.27860021591186523 ms\n",
            "Epoch 23:[5/16], Current Loss: 0.9205237627029419, Current Training Accuracy: 97.78645833333333, Time: 0.2578701972961426 ms\n",
            "Epoch 23:[10/16], Current Loss: 0.9316791892051697, Current Training Accuracy: 97.65625, Time: 0.2585015296936035 ms\n",
            "Epoch 23:[15/16], Current Loss: 0.9232070446014404, Current Training Accuracy: 97.94921875, Time: 0.2537834644317627 ms\n",
            "Epoch 23, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 7.514143228530884 ms\n",
            "Epoch 24:[0/16], Current Loss: 0.9208961725234985, Current Training Accuracy: 98.4375, Time: 0.2679100036621094 ms\n",
            "Epoch 24:[5/16], Current Loss: 0.937089741230011, Current Training Accuracy: 98.69791666666667, Time: 0.2567594051361084 ms\n",
            "Epoch 24:[10/16], Current Loss: 0.9210813641548157, Current Training Accuracy: 98.1534090909091, Time: 0.25815844535827637 ms\n",
            "Epoch 24:[15/16], Current Loss: 0.950640857219696, Current Training Accuracy: 97.94921875, Time: 0.2614459991455078 ms\n",
            "Epoch 24, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.489086627960205 ms\n",
            "Epoch 25:[0/16], Current Loss: 0.9209480285644531, Current Training Accuracy: 98.4375, Time: 0.2860584259033203 ms\n",
            "Epoch 25:[5/16], Current Loss: 0.9323533177375793, Current Training Accuracy: 97.265625, Time: 0.2601029872894287 ms\n",
            "Epoch 25:[10/16], Current Loss: 0.9218332171440125, Current Training Accuracy: 97.9403409090909, Time: 0.26036739349365234 ms\n",
            "Epoch 25:[15/16], Current Loss: 0.9275074005126953, Current Training Accuracy: 97.94921875, Time: 0.25548505783081055 ms\n",
            "Epoch 25, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.502109050750732 ms\n",
            "Epoch 26:[0/16], Current Loss: 0.9128896594047546, Current Training Accuracy: 99.21875, Time: 0.2813117504119873 ms\n",
            "Epoch 26:[5/16], Current Loss: 0.9136260747909546, Current Training Accuracy: 98.56770833333333, Time: 0.2617673873901367 ms\n",
            "Epoch 26:[10/16], Current Loss: 0.9130452871322632, Current Training Accuracy: 98.50852272727273, Time: 0.26029515266418457 ms\n",
            "Epoch 26:[15/16], Current Loss: 0.9283827543258667, Current Training Accuracy: 97.998046875, Time: 0.25651097297668457 ms\n",
            "Epoch 26, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.515546798706055 ms\n",
            "Epoch 27:[0/16], Current Loss: 0.9287039637565613, Current Training Accuracy: 97.65625, Time: 0.2702341079711914 ms\n",
            "Epoch 27:[5/16], Current Loss: 0.9134597778320312, Current Training Accuracy: 97.52604166666667, Time: 0.25871920585632324 ms\n",
            "Epoch 27:[10/16], Current Loss: 0.913410484790802, Current Training Accuracy: 97.9403409090909, Time: 0.26494860649108887 ms\n",
            "Epoch 27:[15/16], Current Loss: 0.9357997179031372, Current Training Accuracy: 98.095703125, Time: 0.2564566135406494 ms\n",
            "Epoch 27, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 7.768978834152222 ms\n",
            "Epoch 28:[0/16], Current Loss: 0.9135242104530334, Current Training Accuracy: 99.21875, Time: 0.280994176864624 ms\n",
            "Epoch 28:[5/16], Current Loss: 0.9128337502479553, Current Training Accuracy: 98.17708333333333, Time: 0.2656524181365967 ms\n",
            "Epoch 28:[10/16], Current Loss: 0.9133334159851074, Current Training Accuracy: 98.08238636363636, Time: 0.25771093368530273 ms\n",
            "Epoch 28:[15/16], Current Loss: 0.9323410391807556, Current Training Accuracy: 98.095703125, Time: 0.2535223960876465 ms\n",
            "Epoch 28, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 8.106349229812622 ms\n",
            "Epoch 29:[0/16], Current Loss: 0.9513388276100159, Current Training Accuracy: 95.3125, Time: 0.2769463062286377 ms\n",
            "Epoch 29:[5/16], Current Loss: 0.9508317708969116, Current Training Accuracy: 98.046875, Time: 0.25720930099487305 ms\n",
            "Epoch 29:[10/16], Current Loss: 0.9132234454154968, Current Training Accuracy: 98.1534090909091, Time: 0.2565422058105469 ms\n",
            "Epoch 29:[15/16], Current Loss: 0.92056804895401, Current Training Accuracy: 98.193359375, Time: 0.2553110122680664 ms\n",
            "Epoch 29, train Loss: 0.923  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 7.8076701164245605 ms\n",
            "Epoch 30:[0/16], Current Loss: 0.9356844425201416, Current Training Accuracy: 96.875, Time: 0.27788400650024414 ms\n",
            "Epoch 30:[5/16], Current Loss: 0.935981273651123, Current Training Accuracy: 97.52604166666667, Time: 0.2588694095611572 ms\n",
            "Epoch 30:[10/16], Current Loss: 0.9204112887382507, Current Training Accuracy: 98.36647727272727, Time: 0.25999999046325684 ms\n",
            "Epoch 30:[15/16], Current Loss: 0.9201281666755676, Current Training Accuracy: 98.2421875, Time: 0.25667786598205566 ms\n",
            "Epoch 30, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.433695554733276 ms\n",
            "Epoch 31:[0/16], Current Loss: 0.9210363030433655, Current Training Accuracy: 98.4375, Time: 0.28192710876464844 ms\n",
            "Epoch 31:[5/16], Current Loss: 0.9208998680114746, Current Training Accuracy: 97.91666666666667, Time: 0.2610743045806885 ms\n",
            "Epoch 31:[10/16], Current Loss: 0.9124806523323059, Current Training Accuracy: 98.29545454545455, Time: 0.25862812995910645 ms\n",
            "Epoch 31:[15/16], Current Loss: 0.9281631112098694, Current Training Accuracy: 98.193359375, Time: 0.2546346187591553 ms\n",
            "Epoch 31, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.492824554443359 ms\n",
            "Epoch 32:[0/16], Current Loss: 0.928180456161499, Current Training Accuracy: 97.65625, Time: 0.27506017684936523 ms\n",
            "Epoch 32:[5/16], Current Loss: 0.9208889007568359, Current Training Accuracy: 98.30729166666667, Time: 0.25808072090148926 ms\n",
            "Epoch 32:[10/16], Current Loss: 0.9202001094818115, Current Training Accuracy: 98.29545454545455, Time: 0.26453661918640137 ms\n",
            "Epoch 32:[15/16], Current Loss: 0.9052747488021851, Current Training Accuracy: 98.193359375, Time: 0.25444459915161133 ms\n",
            "Epoch 32, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.518299579620361 ms\n",
            "Epoch 33:[0/16], Current Loss: 0.920460045337677, Current Training Accuracy: 98.4375, Time: 0.28734874725341797 ms\n",
            "Epoch 33:[5/16], Current Loss: 0.9281977415084839, Current Training Accuracy: 98.17708333333333, Time: 0.2737419605255127 ms\n",
            "Epoch 33:[10/16], Current Loss: 0.9199054837226868, Current Training Accuracy: 98.08238636363636, Time: 0.2591056823730469 ms\n",
            "Epoch 33:[15/16], Current Loss: 0.9130752682685852, Current Training Accuracy: 98.193359375, Time: 0.25713539123535156 ms\n",
            "Epoch 33, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.559231281280518 ms\n",
            "Epoch 34:[0/16], Current Loss: 0.9198059439659119, Current Training Accuracy: 98.4375, Time: 0.28034543991088867 ms\n",
            "Epoch 34:[5/16], Current Loss: 0.9051675200462341, Current Training Accuracy: 98.95833333333333, Time: 0.2560303211212158 ms\n",
            "Epoch 34:[10/16], Current Loss: 0.9281213283538818, Current Training Accuracy: 98.36647727272727, Time: 0.259258508682251 ms\n",
            "Epoch 34:[15/16], Current Loss: 0.936103343963623, Current Training Accuracy: 98.193359375, Time: 0.26180052757263184 ms\n",
            "Epoch 34, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.4724037647247314 ms\n",
            "Epoch 35:[0/16], Current Loss: 0.9364878535270691, Current Training Accuracy: 96.875, Time: 0.2798423767089844 ms\n",
            "Epoch 35:[5/16], Current Loss: 0.9130361080169678, Current Training Accuracy: 98.30729166666667, Time: 0.25905346870422363 ms\n",
            "Epoch 35:[10/16], Current Loss: 0.9208246469497681, Current Training Accuracy: 98.1534090909091, Time: 0.2589435577392578 ms\n",
            "Epoch 35:[15/16], Current Loss: 0.9124367237091064, Current Training Accuracy: 98.193359375, Time: 0.2536611557006836 ms\n",
            "Epoch 35, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.488624334335327 ms\n",
            "Epoch 36:[0/16], Current Loss: 0.9286034107208252, Current Training Accuracy: 97.65625, Time: 0.2770535945892334 ms\n",
            "Epoch 36:[5/16], Current Loss: 0.905166745185852, Current Training Accuracy: 98.4375, Time: 0.25865888595581055 ms\n",
            "Epoch 36:[10/16], Current Loss: 0.9208118915557861, Current Training Accuracy: 98.36647727272727, Time: 0.2572038173675537 ms\n",
            "Epoch 36:[15/16], Current Loss: 0.9201236367225647, Current Training Accuracy: 98.193359375, Time: 0.2526557445526123 ms\n",
            "Epoch 36, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.4856133460998535 ms\n",
            "Epoch 37:[0/16], Current Loss: 0.9208231568336487, Current Training Accuracy: 98.4375, Time: 0.2752261161804199 ms\n",
            "Epoch 37:[5/16], Current Loss: 0.919445812702179, Current Training Accuracy: 98.4375, Time: 0.2595853805541992 ms\n",
            "Epoch 37:[10/16], Current Loss: 0.9274948239326477, Current Training Accuracy: 98.1534090909091, Time: 0.26673460006713867 ms\n",
            "Epoch 37:[15/16], Current Loss: 0.9280074238777161, Current Training Accuracy: 98.193359375, Time: 0.25334906578063965 ms\n",
            "Epoch 37, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.490193605422974 ms\n",
            "Epoch 38:[0/16], Current Loss: 0.9207766652107239, Current Training Accuracy: 98.4375, Time: 0.2768733501434326 ms\n",
            "Epoch 38:[5/16], Current Loss: 0.9278241395950317, Current Training Accuracy: 98.56770833333333, Time: 0.25626516342163086 ms\n",
            "Epoch 38:[10/16], Current Loss: 0.9051476716995239, Current Training Accuracy: 98.36647727272727, Time: 0.25931525230407715 ms\n",
            "Epoch 38:[15/16], Current Loss: 0.9420568346977234, Current Training Accuracy: 98.193359375, Time: 0.2563514709472656 ms\n",
            "Epoch 38, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.501716136932373 ms\n",
            "Epoch 39:[0/16], Current Loss: 0.912473738193512, Current Training Accuracy: 99.21875, Time: 0.2849159240722656 ms\n",
            "Epoch 39:[5/16], Current Loss: 0.9357158541679382, Current Training Accuracy: 98.17708333333333, Time: 0.25693821907043457 ms\n",
            "Epoch 39:[10/16], Current Loss: 0.912885844707489, Current Training Accuracy: 98.36647727272727, Time: 0.2594602108001709 ms\n",
            "Epoch 39:[15/16], Current Loss: 0.9356326460838318, Current Training Accuracy: 98.193359375, Time: 0.2563354969024658 ms\n",
            "Epoch 39, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.465845823287964 ms\n",
            "Epoch 40:[0/16], Current Loss: 0.9051423072814941, Current Training Accuracy: 100.0, Time: 0.2833130359649658 ms\n",
            "Epoch 40:[5/16], Current Loss: 0.9129227995872498, Current Training Accuracy: 98.30729166666667, Time: 0.25927233695983887 ms\n",
            "Epoch 40:[10/16], Current Loss: 0.9267228245735168, Current Training Accuracy: 98.08238636363636, Time: 0.26059937477111816 ms\n",
            "Epoch 40:[15/16], Current Loss: 0.9051083326339722, Current Training Accuracy: 98.2421875, Time: 0.25338315963745117 ms\n",
            "Epoch 40, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.512593507766724 ms\n",
            "Epoch 41:[0/16], Current Loss: 0.9123555421829224, Current Training Accuracy: 99.21875, Time: 0.2644038200378418 ms\n",
            "Epoch 41:[5/16], Current Loss: 0.9200544953346252, Current Training Accuracy: 98.046875, Time: 0.2591383457183838 ms\n",
            "Epoch 41:[10/16], Current Loss: 0.9238738417625427, Current Training Accuracy: 98.36647727272727, Time: 0.26448631286621094 ms\n",
            "Epoch 41:[15/16], Current Loss: 0.9203149080276489, Current Training Accuracy: 98.2421875, Time: 0.2571134567260742 ms\n",
            "Epoch 41, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.485210418701172 ms\n",
            "Epoch 42:[0/16], Current Loss: 0.9209384918212891, Current Training Accuracy: 98.4375, Time: 0.28270649909973145 ms\n",
            "Epoch 42:[5/16], Current Loss: 0.9413601160049438, Current Training Accuracy: 98.17708333333333, Time: 0.25691652297973633 ms\n",
            "Epoch 42:[10/16], Current Loss: 0.9207966327667236, Current Training Accuracy: 98.29545454545455, Time: 0.2742466926574707 ms\n",
            "Epoch 42:[15/16], Current Loss: 0.9357140064239502, Current Training Accuracy: 98.2421875, Time: 0.25366806983947754 ms\n",
            "Epoch 42, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.478570461273193 ms\n",
            "Epoch 43:[0/16], Current Loss: 0.9131368398666382, Current Training Accuracy: 99.21875, Time: 0.2778146266937256 ms\n",
            "Epoch 43:[5/16], Current Loss: 0.9204381704330444, Current Training Accuracy: 98.56770833333333, Time: 0.25870561599731445 ms\n",
            "Epoch 43:[10/16], Current Loss: 0.9130871295928955, Current Training Accuracy: 98.29545454545455, Time: 0.25785064697265625 ms\n",
            "Epoch 43:[15/16], Current Loss: 0.928733766078949, Current Training Accuracy: 98.291015625, Time: 0.2530484199523926 ms\n",
            "Epoch 43, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 7.517942428588867 ms\n",
            "Epoch 44:[0/16], Current Loss: 0.9431142210960388, Current Training Accuracy: 96.09375, Time: 0.28339648246765137 ms\n",
            "Epoch 44:[5/16], Current Loss: 0.9133251309394836, Current Training Accuracy: 98.4375, Time: 0.2581336498260498 ms\n",
            "Epoch 44:[10/16], Current Loss: 0.9208394289016724, Current Training Accuracy: 98.36647727272727, Time: 0.25682687759399414 ms\n",
            "Epoch 44:[15/16], Current Loss: 0.9287459850311279, Current Training Accuracy: 98.388671875, Time: 0.25391387939453125 ms\n",
            "Epoch 44, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.449984073638916 ms\n",
            "Epoch 45:[0/16], Current Loss: 0.9131202697753906, Current Training Accuracy: 99.21875, Time: 0.2753918170928955 ms\n",
            "Epoch 45:[5/16], Current Loss: 0.9125789999961853, Current Training Accuracy: 98.95833333333333, Time: 0.26241302490234375 ms\n",
            "Epoch 45:[10/16], Current Loss: 0.9051315784454346, Current Training Accuracy: 99.00568181818181, Time: 0.2581913471221924 ms\n",
            "Epoch 45:[15/16], Current Loss: 0.9128175377845764, Current Training Accuracy: 98.4375, Time: 0.2540748119354248 ms\n",
            "Epoch 45, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.515180587768555 ms\n",
            "Epoch 46:[0/16], Current Loss: 0.9051799774169922, Current Training Accuracy: 100.0, Time: 0.2830514907836914 ms\n",
            "Epoch 46:[5/16], Current Loss: 0.9051538705825806, Current Training Accuracy: 99.08854166666667, Time: 0.25803256034851074 ms\n",
            "Epoch 46:[10/16], Current Loss: 0.9199727773666382, Current Training Accuracy: 98.79261363636364, Time: 0.2830197811126709 ms\n",
            "Epoch 46:[15/16], Current Loss: 0.9207247495651245, Current Training Accuracy: 98.4375, Time: 0.26580238342285156 ms\n",
            "Epoch 46, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.831197500228882 ms\n",
            "Epoch 47:[0/16], Current Loss: 0.9207211136817932, Current Training Accuracy: 98.4375, Time: 0.2827935218811035 ms\n",
            "Epoch 47:[5/16], Current Loss: 0.9279866814613342, Current Training Accuracy: 98.828125, Time: 0.25964975357055664 ms\n",
            "Epoch 47:[10/16], Current Loss: 0.9278117418289185, Current Training Accuracy: 98.50852272727273, Time: 0.25961875915527344 ms\n",
            "Epoch 47:[15/16], Current Loss: 0.9206907153129578, Current Training Accuracy: 98.4375, Time: 0.2553730010986328 ms\n",
            "Epoch 47, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.494165897369385 ms\n",
            "Epoch 48:[0/16], Current Loss: 0.9206674098968506, Current Training Accuracy: 98.4375, Time: 0.28058481216430664 ms\n",
            "Epoch 48:[5/16], Current Loss: 0.9202276468276978, Current Training Accuracy: 98.17708333333333, Time: 0.2564671039581299 ms\n",
            "Epoch 48:[10/16], Current Loss: 0.9128913283348083, Current Training Accuracy: 98.50852272727273, Time: 0.26024389266967773 ms\n",
            "Epoch 48:[15/16], Current Loss: 0.9123272895812988, Current Training Accuracy: 98.4375, Time: 0.2572047710418701 ms\n",
            "Epoch 48, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.456271648406982 ms\n",
            "Epoch 49:[0/16], Current Loss: 0.927250862121582, Current Training Accuracy: 97.65625, Time: 0.2820725440979004 ms\n",
            "Epoch 49:[5/16], Current Loss: 0.9362845420837402, Current Training Accuracy: 98.828125, Time: 0.25806212425231934 ms\n",
            "Epoch 49:[10/16], Current Loss: 0.9431131482124329, Current Training Accuracy: 98.22443181818181, Time: 0.25922369956970215 ms\n",
            "Epoch 49:[15/16], Current Loss: 0.9124115109443665, Current Training Accuracy: 98.4375, Time: 0.2560608386993408 ms\n",
            "Epoch 49, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.499505281448364 ms\n",
            "Epoch 50:[0/16], Current Loss: 0.9301030039787292, Current Training Accuracy: 97.65625, Time: 0.2785506248474121 ms\n",
            "Epoch 50:[5/16], Current Loss: 0.9143449068069458, Current Training Accuracy: 98.046875, Time: 0.2581770420074463 ms\n",
            "Epoch 50:[10/16], Current Loss: 0.921116828918457, Current Training Accuracy: 98.29545454545455, Time: 0.26770663261413574 ms\n",
            "Epoch 50:[15/16], Current Loss: 0.9205123782157898, Current Training Accuracy: 98.486328125, Time: 0.25285816192626953 ms\n",
            "Epoch 50, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.478800535202026 ms\n",
            "Epoch 51:[0/16], Current Loss: 0.9431808590888977, Current Training Accuracy: 96.09375, Time: 0.2791562080383301 ms\n",
            "Epoch 51:[5/16], Current Loss: 0.9212502241134644, Current Training Accuracy: 98.4375, Time: 0.2587301731109619 ms\n",
            "Epoch 51:[10/16], Current Loss: 0.912906289100647, Current Training Accuracy: 98.50852272727273, Time: 0.2561619281768799 ms\n",
            "Epoch 51:[15/16], Current Loss: 0.9202125668525696, Current Training Accuracy: 98.6328125, Time: 0.25731563568115234 ms\n",
            "Epoch 51, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.504047155380249 ms\n",
            "Epoch 52:[0/16], Current Loss: 0.9127606749534607, Current Training Accuracy: 99.21875, Time: 0.2839937210083008 ms\n",
            "Epoch 52:[5/16], Current Loss: 0.9205322861671448, Current Training Accuracy: 99.08854166666667, Time: 0.25763940811157227 ms\n",
            "Epoch 52:[10/16], Current Loss: 0.9354256987571716, Current Training Accuracy: 98.79261363636364, Time: 0.2738656997680664 ms\n",
            "Epoch 52:[15/16], Current Loss: 0.9206721782684326, Current Training Accuracy: 98.6328125, Time: 0.2580556869506836 ms\n",
            "Epoch 52, train Loss: 0.919  Avg Training Accuracy: {99 %} Avg Validation Accuracy: 65 % Epoch Time: 7.516238689422607 ms\n",
            "Epoch 53:[0/16], Current Loss: 0.9201638698577881, Current Training Accuracy: 98.4375, Time: 0.2750685214996338 ms\n",
            "Epoch 53:[5/16], Current Loss: 0.9128457903862, Current Training Accuracy: 98.828125, Time: 0.25937604904174805 ms\n",
            "Epoch 53:[10/16], Current Loss: 0.9199638366699219, Current Training Accuracy: 98.50852272727273, Time: 0.25557899475097656 ms\n",
            "Epoch 53:[15/16], Current Loss: 0.9128535985946655, Current Training Accuracy: 98.6328125, Time: 0.25667262077331543 ms\n",
            "Epoch 53, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.483402252197266 ms\n",
            "Epoch 54:[0/16], Current Loss: 0.9050635695457458, Current Training Accuracy: 100.0, Time: 0.2776939868927002 ms\n",
            "Epoch 54:[5/16], Current Loss: 0.9279152750968933, Current Training Accuracy: 99.08854166666667, Time: 0.26021313667297363 ms\n",
            "Epoch 54:[10/16], Current Loss: 0.9128134846687317, Current Training Accuracy: 98.7215909090909, Time: 0.27257442474365234 ms\n",
            "Epoch 54:[15/16], Current Loss: 0.9128114581108093, Current Training Accuracy: 98.6328125, Time: 0.25518083572387695 ms\n",
            "Epoch 54, train Loss: 0.918  Avg Training Accuracy: {99 %} Avg Validation Accuracy: 64 % Epoch Time: 7.536733388900757 ms\n",
            "Epoch 55:[0/16], Current Loss: 0.9199549555778503, Current Training Accuracy: 98.4375, Time: 0.28185057640075684 ms\n",
            "Epoch 55:[5/16], Current Loss: 0.9127609133720398, Current Training Accuracy: 98.4375, Time: 0.25664258003234863 ms\n",
            "Epoch 55:[10/16], Current Loss: 0.9125131964683533, Current Training Accuracy: 98.65056818181819, Time: 0.26041316986083984 ms\n",
            "Epoch 55:[15/16], Current Loss: 0.920631468296051, Current Training Accuracy: 98.6328125, Time: 0.2560746669769287 ms\n",
            "Epoch 55, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.4910242557525635 ms\n",
            "Epoch 56:[0/16], Current Loss: 0.9200688600540161, Current Training Accuracy: 98.4375, Time: 0.29814624786376953 ms\n",
            "Epoch 56:[5/16], Current Loss: 0.9128153920173645, Current Training Accuracy: 98.4375, Time: 0.25814175605773926 ms\n",
            "Epoch 56:[10/16], Current Loss: 0.9125253558158875, Current Training Accuracy: 98.4375, Time: 0.2588818073272705 ms\n",
            "Epoch 56:[15/16], Current Loss: 0.9207013249397278, Current Training Accuracy: 98.6328125, Time: 0.2553079128265381 ms\n",
            "Epoch 56, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.513998508453369 ms\n",
            "Epoch 57:[0/16], Current Loss: 0.9128851294517517, Current Training Accuracy: 99.21875, Time: 0.28340840339660645 ms\n",
            "Epoch 57:[5/16], Current Loss: 0.9122151732444763, Current Training Accuracy: 98.828125, Time: 0.2586827278137207 ms\n",
            "Epoch 57:[10/16], Current Loss: 0.9049695134162903, Current Training Accuracy: 98.86363636363636, Time: 0.27016592025756836 ms\n",
            "Epoch 57:[15/16], Current Loss: 0.9362455010414124, Current Training Accuracy: 98.6328125, Time: 0.25562143325805664 ms\n",
            "Epoch 57, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.555590629577637 ms\n",
            "Epoch 58:[0/16], Current Loss: 0.9128686189651489, Current Training Accuracy: 99.21875, Time: 0.28819918632507324 ms\n",
            "Epoch 58:[5/16], Current Loss: 0.9206143617630005, Current Training Accuracy: 98.828125, Time: 0.2564363479614258 ms\n",
            "Epoch 58:[10/16], Current Loss: 0.9049744009971619, Current Training Accuracy: 98.9346590909091, Time: 0.25659775733947754 ms\n",
            "Epoch 58:[15/16], Current Loss: 0.9205908179283142, Current Training Accuracy: 98.6328125, Time: 0.25499868392944336 ms\n",
            "Epoch 58, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.52360463142395 ms\n",
            "Epoch 59:[0/16], Current Loss: 0.9127801656723022, Current Training Accuracy: 99.21875, Time: 0.27992796897888184 ms\n",
            "Epoch 59:[5/16], Current Loss: 0.9049636721611023, Current Training Accuracy: 98.69791666666667, Time: 0.2560245990753174 ms\n",
            "Epoch 59:[10/16], Current Loss: 0.9278141856193542, Current Training Accuracy: 98.50852272727273, Time: 0.2653837203979492 ms\n",
            "Epoch 59:[15/16], Current Loss: 0.9202353954315186, Current Training Accuracy: 98.6328125, Time: 0.25420451164245605 ms\n",
            "Epoch 59, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.549404144287109 ms\n",
            "Epoch 60:[0/16], Current Loss: 0.9206163287162781, Current Training Accuracy: 98.4375, Time: 0.282001256942749 ms\n",
            "Epoch 60:[5/16], Current Loss: 0.9127718210220337, Current Training Accuracy: 98.828125, Time: 0.2608804702758789 ms\n",
            "Epoch 60:[10/16], Current Loss: 0.9382220506668091, Current Training Accuracy: 98.65056818181819, Time: 0.26740217208862305 ms\n",
            "Epoch 60:[15/16], Current Loss: 0.9207125306129456, Current Training Accuracy: 98.681640625, Time: 0.2530331611633301 ms\n",
            "Epoch 60, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.5205161571502686 ms\n",
            "Epoch 61:[0/16], Current Loss: 0.920196533203125, Current Training Accuracy: 98.4375, Time: 0.27733612060546875 ms\n",
            "Epoch 61:[5/16], Current Loss: 0.9122107625007629, Current Training Accuracy: 98.69791666666667, Time: 0.2612583637237549 ms\n",
            "Epoch 61:[10/16], Current Loss: 0.9202434420585632, Current Training Accuracy: 98.7215909090909, Time: 0.262162446975708 ms\n",
            "Epoch 61:[15/16], Current Loss: 0.9207096099853516, Current Training Accuracy: 98.681640625, Time: 0.2542252540588379 ms\n",
            "Epoch 61, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.506488561630249 ms\n",
            "Epoch 62:[0/16], Current Loss: 0.9128684997558594, Current Training Accuracy: 99.21875, Time: 0.2852334976196289 ms\n",
            "Epoch 62:[5/16], Current Loss: 0.9206583499908447, Current Training Accuracy: 98.4375, Time: 0.26112818717956543 ms\n",
            "Epoch 62:[10/16], Current Loss: 0.9206314086914062, Current Training Accuracy: 98.36647727272727, Time: 0.2610898017883301 ms\n",
            "Epoch 62:[15/16], Current Loss: 0.9207408428192139, Current Training Accuracy: 98.681640625, Time: 0.2550055980682373 ms\n",
            "Epoch 62, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 7.505851984024048 ms\n",
            "Epoch 63:[0/16], Current Loss: 0.9205675721168518, Current Training Accuracy: 98.4375, Time: 0.28363680839538574 ms\n",
            "Epoch 63:[5/16], Current Loss: 0.9128349423408508, Current Training Accuracy: 98.69791666666667, Time: 0.25934672355651855 ms\n",
            "Epoch 63:[10/16], Current Loss: 0.9281788468360901, Current Training Accuracy: 98.50852272727273, Time: 0.261798620223999 ms\n",
            "Epoch 63:[15/16], Current Loss: 0.9278436899185181, Current Training Accuracy: 98.681640625, Time: 0.2537200450897217 ms\n",
            "Epoch 63, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.534362554550171 ms\n",
            "Epoch 64:[0/16], Current Loss: 0.9205262660980225, Current Training Accuracy: 98.4375, Time: 0.29270052909851074 ms\n",
            "Epoch 64:[5/16], Current Loss: 0.9121487140655518, Current Training Accuracy: 98.828125, Time: 0.26067376136779785 ms\n",
            "Epoch 64:[10/16], Current Loss: 0.9205808043479919, Current Training Accuracy: 98.86363636363636, Time: 0.25458669662475586 ms\n",
            "Epoch 64:[15/16], Current Loss: 0.9284042716026306, Current Training Accuracy: 98.681640625, Time: 0.25559377670288086 ms\n",
            "Epoch 64, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.524722099304199 ms\n",
            "Epoch 65:[0/16], Current Loss: 0.92842036485672, Current Training Accuracy: 97.65625, Time: 0.28106069564819336 ms\n",
            "Epoch 65:[5/16], Current Loss: 0.9049736261367798, Current Training Accuracy: 98.56770833333333, Time: 0.2558290958404541 ms\n",
            "Epoch 65:[10/16], Current Loss: 0.9127426743507385, Current Training Accuracy: 98.7215909090909, Time: 0.2708866596221924 ms\n",
            "Epoch 65:[15/16], Current Loss: 0.9127511382102966, Current Training Accuracy: 98.681640625, Time: 0.25678372383117676 ms\n",
            "Epoch 65, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.534776926040649 ms\n",
            "Epoch 66:[0/16], Current Loss: 0.9205865263938904, Current Training Accuracy: 98.4375, Time: 0.28302955627441406 ms\n",
            "Epoch 66:[5/16], Current Loss: 0.9120727181434631, Current Training Accuracy: 98.4375, Time: 0.25980329513549805 ms\n",
            "Epoch 66:[10/16], Current Loss: 0.9127508401870728, Current Training Accuracy: 98.4375, Time: 0.25945353507995605 ms\n",
            "Epoch 66:[15/16], Current Loss: 0.9127559065818787, Current Training Accuracy: 98.681640625, Time: 0.25345754623413086 ms\n",
            "Epoch 66, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.49983811378479 ms\n",
            "Epoch 67:[0/16], Current Loss: 0.93621826171875, Current Training Accuracy: 96.875, Time: 0.27942824363708496 ms\n",
            "Epoch 67:[5/16], Current Loss: 0.9127406477928162, Current Training Accuracy: 98.4375, Time: 0.2580442428588867 ms\n",
            "Epoch 67:[10/16], Current Loss: 0.9198793768882751, Current Training Accuracy: 98.50852272727273, Time: 0.26200366020202637 ms\n",
            "Epoch 67:[15/16], Current Loss: 0.9127697944641113, Current Training Accuracy: 98.681640625, Time: 0.25534963607788086 ms\n",
            "Epoch 67, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.526906728744507 ms\n",
            "Epoch 68:[0/16], Current Loss: 0.9433220028877258, Current Training Accuracy: 96.09375, Time: 0.2855370044708252 ms\n",
            "Epoch 68:[5/16], Current Loss: 0.9198887944221497, Current Training Accuracy: 98.4375, Time: 0.2602989673614502 ms\n",
            "Epoch 68:[10/16], Current Loss: 0.9127567410469055, Current Training Accuracy: 98.50852272727273, Time: 0.262115478515625 ms\n",
            "Epoch 68:[15/16], Current Loss: 0.9127503037452698, Current Training Accuracy: 98.681640625, Time: 0.2558281421661377 ms\n",
            "Epoch 68, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.500304937362671 ms\n",
            "Epoch 69:[0/16], Current Loss: 0.9127680659294128, Current Training Accuracy: 99.21875, Time: 0.2764148712158203 ms\n",
            "Epoch 69:[5/16], Current Loss: 0.9201156497001648, Current Training Accuracy: 98.828125, Time: 0.25648045539855957 ms\n",
            "Epoch 69:[10/16], Current Loss: 0.9202283024787903, Current Training Accuracy: 98.57954545454545, Time: 0.2666172981262207 ms\n",
            "Epoch 69:[15/16], Current Loss: 0.9127421975135803, Current Training Accuracy: 98.681640625, Time: 0.2544116973876953 ms\n",
            "Epoch 69, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.502909421920776 ms\n",
            "Epoch 70:[0/16], Current Loss: 0.920551061630249, Current Training Accuracy: 98.4375, Time: 0.2914416790008545 ms\n",
            "Epoch 70:[5/16], Current Loss: 0.9205700755119324, Current Training Accuracy: 98.828125, Time: 0.2587239742279053 ms\n",
            "Epoch 70:[10/16], Current Loss: 0.912751317024231, Current Training Accuracy: 98.79261363636364, Time: 0.2604990005493164 ms\n",
            "Epoch 70:[15/16], Current Loss: 0.912738561630249, Current Training Accuracy: 98.73046875, Time: 0.25591349601745605 ms\n",
            "Epoch 70, train Loss: 0.917  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.492290496826172 ms\n",
            "Epoch 71:[0/16], Current Loss: 0.9278532862663269, Current Training Accuracy: 97.65625, Time: 0.2885279655456543 ms\n",
            "Epoch 71:[5/16], Current Loss: 0.9127463102340698, Current Training Accuracy: 98.4375, Time: 0.2559685707092285 ms\n",
            "Epoch 71:[10/16], Current Loss: 0.9355299472808838, Current Training Accuracy: 98.7215909090909, Time: 0.26017045974731445 ms\n",
            "Epoch 71:[15/16], Current Loss: 0.9049228429794312, Current Training Accuracy: 98.681640625, Time: 0.25684595108032227 ms\n",
            "Epoch 71, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.48793625831604 ms\n",
            "Epoch 72:[0/16], Current Loss: 0.9127494096755981, Current Training Accuracy: 99.21875, Time: 0.2814300060272217 ms\n",
            "Epoch 72:[5/16], Current Loss: 0.9283732771873474, Current Training Accuracy: 97.91666666666667, Time: 0.2594592571258545 ms\n",
            "Epoch 72:[10/16], Current Loss: 0.9049239158630371, Current Training Accuracy: 98.36647727272727, Time: 0.2577245235443115 ms\n",
            "Epoch 72:[15/16], Current Loss: 0.9049189686775208, Current Training Accuracy: 98.681640625, Time: 0.2533740997314453 ms\n",
            "Epoch 72, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.565474271774292 ms\n",
            "Epoch 73:[0/16], Current Loss: 0.9283703565597534, Current Training Accuracy: 97.65625, Time: 0.29334115982055664 ms\n",
            "Epoch 73:[5/16], Current Loss: 0.9120847582817078, Current Training Accuracy: 98.17708333333333, Time: 0.2662978172302246 ms\n",
            "Epoch 73:[10/16], Current Loss: 0.9127447009086609, Current Training Accuracy: 98.29545454545455, Time: 0.269453763961792 ms\n",
            "Epoch 73:[15/16], Current Loss: 0.9120373129844666, Current Training Accuracy: 98.681640625, Time: 0.2577080726623535 ms\n",
            "Epoch 73, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.713205575942993 ms\n",
            "Epoch 74:[0/16], Current Loss: 0.9205424785614014, Current Training Accuracy: 98.4375, Time: 0.30391740798950195 ms\n",
            "Epoch 74:[5/16], Current Loss: 0.9199538230895996, Current Training Accuracy: 98.69791666666667, Time: 0.27390170097351074 ms\n",
            "Epoch 74:[10/16], Current Loss: 0.9271708726882935, Current Training Accuracy: 98.79261363636364, Time: 0.255490779876709 ms\n",
            "Epoch 74:[15/16], Current Loss: 0.9278259873390198, Current Training Accuracy: 98.681640625, Time: 0.25542378425598145 ms\n",
            "Epoch 74, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.936777353286743 ms\n",
            "Epoch 75:[0/16], Current Loss: 0.9205594658851624, Current Training Accuracy: 98.4375, Time: 0.2770352363586426 ms\n",
            "Epoch 75:[5/16], Current Loss: 0.9278392791748047, Current Training Accuracy: 98.56770833333333, Time: 0.2583317756652832 ms\n",
            "Epoch 75:[10/16], Current Loss: 0.9280993342399597, Current Training Accuracy: 98.57954545454545, Time: 0.2596421241760254 ms\n",
            "Epoch 75:[15/16], Current Loss: 0.9199076294898987, Current Training Accuracy: 98.681640625, Time: 0.2554361820220947 ms\n",
            "Epoch 75, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.561010360717773 ms\n",
            "Epoch 76:[0/16], Current Loss: 0.9127381443977356, Current Training Accuracy: 99.21875, Time: 0.2738199234008789 ms\n",
            "Epoch 76:[5/16], Current Loss: 0.9439660310745239, Current Training Accuracy: 98.046875, Time: 0.2584969997406006 ms\n",
            "Epoch 76:[10/16], Current Loss: 0.9201263189315796, Current Training Accuracy: 98.65056818181819, Time: 0.2672138214111328 ms\n",
            "Epoch 76:[15/16], Current Loss: 0.9277362823486328, Current Training Accuracy: 98.73046875, Time: 0.25554442405700684 ms\n",
            "Epoch 76, train Loss: 0.917  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.515572547912598 ms\n",
            "Epoch 77:[0/16], Current Loss: 0.9350990653038025, Current Training Accuracy: 96.875, Time: 0.2839076519012451 ms\n",
            "Epoch 77:[5/16], Current Loss: 0.9358870387077332, Current Training Accuracy: 98.30729166666667, Time: 0.25998973846435547 ms\n",
            "Epoch 77:[10/16], Current Loss: 0.9049273729324341, Current Training Accuracy: 98.4375, Time: 0.26764631271362305 ms\n",
            "Epoch 77:[15/16], Current Loss: 0.904914379119873, Current Training Accuracy: 98.681640625, Time: 0.2562582492828369 ms\n",
            "Epoch 77, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.507894515991211 ms\n",
            "Epoch 78:[0/16], Current Loss: 0.9127250909805298, Current Training Accuracy: 99.21875, Time: 0.28559136390686035 ms\n",
            "Epoch 78:[5/16], Current Loss: 0.9127295613288879, Current Training Accuracy: 98.56770833333333, Time: 0.2564733028411865 ms\n",
            "Epoch 78:[10/16], Current Loss: 0.9121188521385193, Current Training Accuracy: 98.4375, Time: 0.2587473392486572 ms\n",
            "Epoch 78:[15/16], Current Loss: 0.9127223491668701, Current Training Accuracy: 98.681640625, Time: 0.2558603286743164 ms\n",
            "Epoch 78, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.55172324180603 ms\n",
            "Epoch 79:[0/16], Current Loss: 0.9205486178398132, Current Training Accuracy: 98.4375, Time: 0.27625250816345215 ms\n",
            "Epoch 79:[5/16], Current Loss: 0.9122098684310913, Current Training Accuracy: 98.95833333333333, Time: 0.2602996826171875 ms\n",
            "Epoch 79:[10/16], Current Loss: 0.9127246141433716, Current Training Accuracy: 98.9346590909091, Time: 0.2608048915863037 ms\n",
            "Epoch 79:[15/16], Current Loss: 0.935124397277832, Current Training Accuracy: 98.681640625, Time: 0.25586724281311035 ms\n",
            "Epoch 79, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.553590297698975 ms\n",
            "Epoch 80:[0/16], Current Loss: 0.9277616739273071, Current Training Accuracy: 97.65625, Time: 0.2855379581451416 ms\n",
            "Epoch 80:[5/16], Current Loss: 0.9198916554450989, Current Training Accuracy: 98.4375, Time: 0.2588365077972412 ms\n",
            "Epoch 80:[10/16], Current Loss: 0.9202715754508972, Current Training Accuracy: 98.79261363636364, Time: 0.25864291191101074 ms\n",
            "Epoch 80:[15/16], Current Loss: 0.9205581545829773, Current Training Accuracy: 98.681640625, Time: 0.25634336471557617 ms\n",
            "Epoch 80, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.520668268203735 ms\n",
            "Epoch 81:[0/16], Current Loss: 0.9127336144447327, Current Training Accuracy: 99.21875, Time: 0.2826216220855713 ms\n",
            "Epoch 81:[5/16], Current Loss: 0.9127369523048401, Current Training Accuracy: 98.828125, Time: 0.26011204719543457 ms\n",
            "Epoch 81:[10/16], Current Loss: 0.9205395579338074, Current Training Accuracy: 98.57954545454545, Time: 0.26093554496765137 ms\n",
            "Epoch 81:[15/16], Current Loss: 0.9127386212348938, Current Training Accuracy: 98.73046875, Time: 0.2578752040863037 ms\n",
            "Epoch 81, train Loss: 0.917  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.494991302490234 ms\n",
            "Epoch 82:[0/16], Current Loss: 0.9127341508865356, Current Training Accuracy: 99.21875, Time: 0.27668070793151855 ms\n",
            "Epoch 82:[5/16], Current Loss: 0.9270070791244507, Current Training Accuracy: 98.828125, Time: 0.2592654228210449 ms\n",
            "Epoch 82:[10/16], Current Loss: 0.9049131870269775, Current Training Accuracy: 99.14772727272727, Time: 0.2651247978210449 ms\n",
            "Epoch 82:[15/16], Current Loss: 0.9205421805381775, Current Training Accuracy: 98.681640625, Time: 0.256558895111084 ms\n",
            "Epoch 82, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.488498210906982 ms\n",
            "Epoch 83:[0/16], Current Loss: 0.9049085378646851, Current Training Accuracy: 100.0, Time: 0.28742456436157227 ms\n",
            "Epoch 83:[5/16], Current Loss: 0.9191789627075195, Current Training Accuracy: 98.30729166666667, Time: 0.26152992248535156 ms\n",
            "Epoch 83:[10/16], Current Loss: 0.9205408096313477, Current Training Accuracy: 98.4375, Time: 0.2555515766143799 ms\n",
            "Epoch 83:[15/16], Current Loss: 0.9049208164215088, Current Training Accuracy: 98.681640625, Time: 0.2540123462677002 ms\n",
            "Epoch 83, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.5002665519714355 ms\n",
            "Epoch 84:[0/16], Current Loss: 0.9205382466316223, Current Training Accuracy: 98.4375, Time: 0.27970218658447266 ms\n",
            "Epoch 84:[5/16], Current Loss: 0.9127203226089478, Current Training Accuracy: 98.828125, Time: 0.25873494148254395 ms\n",
            "Epoch 84:[10/16], Current Loss: 0.9283337593078613, Current Training Accuracy: 98.7215909090909, Time: 0.2704277038574219 ms\n",
            "Epoch 84:[15/16], Current Loss: 0.920063853263855, Current Training Accuracy: 98.681640625, Time: 0.25625038146972656 ms\n",
            "Epoch 84, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.514864921569824 ms\n",
            "Epoch 85:[0/16], Current Loss: 0.9127131700515747, Current Training Accuracy: 99.21875, Time: 0.28429126739501953 ms\n",
            "Epoch 85:[5/16], Current Loss: 0.9277697205543518, Current Training Accuracy: 98.95833333333333, Time: 0.2596547603607178 ms\n",
            "Epoch 85:[10/16], Current Loss: 0.9205203652381897, Current Training Accuracy: 98.79261363636364, Time: 0.25803494453430176 ms\n",
            "Epoch 85:[15/16], Current Loss: 0.9127184152603149, Current Training Accuracy: 98.681640625, Time: 0.2543473243713379 ms\n",
            "Epoch 85, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.5371763706207275 ms\n",
            "Epoch 86:[0/16], Current Loss: 0.9127145409584045, Current Training Accuracy: 99.21875, Time: 0.27971410751342773 ms\n",
            "Epoch 86:[5/16], Current Loss: 0.9283339977264404, Current Training Accuracy: 98.4375, Time: 0.2575359344482422 ms\n",
            "Epoch 86:[10/16], Current Loss: 0.9283444285392761, Current Training Accuracy: 98.57954545454545, Time: 0.25722837448120117 ms\n",
            "Epoch 86:[15/16], Current Loss: 0.9277034401893616, Current Training Accuracy: 98.681640625, Time: 0.2569746971130371 ms\n",
            "Epoch 86, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.526686429977417 ms\n",
            "Epoch 87:[0/16], Current Loss: 0.9283403158187866, Current Training Accuracy: 97.65625, Time: 0.2888777256011963 ms\n",
            "Epoch 87:[5/16], Current Loss: 0.9283381104469299, Current Training Accuracy: 98.4375, Time: 0.25492167472839355 ms\n",
            "Epoch 87:[10/16], Current Loss: 0.904904842376709, Current Training Accuracy: 98.50852272727273, Time: 0.26216983795166016 ms\n",
            "Epoch 87:[15/16], Current Loss: 0.9048986434936523, Current Training Accuracy: 98.681640625, Time: 0.25527024269104004 ms\n",
            "Epoch 87, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.5198822021484375 ms\n",
            "Epoch 88:[0/16], Current Loss: 0.9283276796340942, Current Training Accuracy: 97.65625, Time: 0.27539968490600586 ms\n",
            "Epoch 88:[5/16], Current Loss: 0.9276331067085266, Current Training Accuracy: 97.91666666666667, Time: 0.26102590560913086 ms\n",
            "Epoch 88:[10/16], Current Loss: 0.9205207824707031, Current Training Accuracy: 98.4375, Time: 0.2602086067199707 ms\n",
            "Epoch 88:[15/16], Current Loss: 0.9127040505409241, Current Training Accuracy: 98.681640625, Time: 0.25408029556274414 ms\n",
            "Epoch 88, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.533637046813965 ms\n",
            "Epoch 89:[0/16], Current Loss: 0.9049022793769836, Current Training Accuracy: 100.0, Time: 0.2823143005371094 ms\n",
            "Epoch 89:[5/16], Current Loss: 0.9198892712593079, Current Training Accuracy: 98.56770833333333, Time: 0.2566394805908203 ms\n",
            "Epoch 89:[10/16], Current Loss: 0.9198193550109863, Current Training Accuracy: 98.65056818181819, Time: 0.2764608860015869 ms\n",
            "Epoch 89:[15/16], Current Loss: 0.9048943519592285, Current Training Accuracy: 98.681640625, Time: 0.2566568851470947 ms\n",
            "Epoch 89, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.51723837852478 ms\n",
            "Epoch 90:[0/16], Current Loss: 0.9127121567726135, Current Training Accuracy: 99.21875, Time: 0.2787652015686035 ms\n",
            "Epoch 90:[5/16], Current Loss: 0.9205199480056763, Current Training Accuracy: 98.69791666666667, Time: 0.2607128620147705 ms\n",
            "Epoch 90:[10/16], Current Loss: 0.9127016067504883, Current Training Accuracy: 98.57954545454545, Time: 0.25792860984802246 ms\n",
            "Epoch 90:[15/16], Current Loss: 0.9283220171928406, Current Training Accuracy: 98.681640625, Time: 0.25397729873657227 ms\n",
            "Epoch 90, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.532212972640991 ms\n",
            "Epoch 91:[0/16], Current Loss: 0.9119994640350342, Current Training Accuracy: 99.21875, Time: 0.2813758850097656 ms\n",
            "Epoch 91:[5/16], Current Loss: 0.9048938751220703, Current Training Accuracy: 98.828125, Time: 0.2573258876800537 ms\n",
            "Epoch 91:[10/16], Current Loss: 0.920524001121521, Current Training Accuracy: 98.79261363636364, Time: 0.26992249488830566 ms\n",
            "Epoch 91:[15/16], Current Loss: 0.90488600730896, Current Training Accuracy: 98.779296875, Time: 0.2545900344848633 ms\n",
            "Epoch 91, train Loss: 0.917  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.574605464935303 ms\n",
            "Epoch 92:[0/16], Current Loss: 0.9048961400985718, Current Training Accuracy: 100.0, Time: 0.2831254005432129 ms\n",
            "Epoch 92:[5/16], Current Loss: 0.9048984050750732, Current Training Accuracy: 98.69791666666667, Time: 0.25737714767456055 ms\n",
            "Epoch 92:[10/16], Current Loss: 0.9205090403556824, Current Training Accuracy: 98.79261363636364, Time: 0.2572000026702881 ms\n",
            "Epoch 92:[15/16], Current Loss: 0.9127023816108704, Current Training Accuracy: 98.681640625, Time: 0.25556063652038574 ms\n",
            "Epoch 92, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.562173128128052 ms\n",
            "Epoch 93:[0/16], Current Loss: 0.9276362657546997, Current Training Accuracy: 97.65625, Time: 0.2780625820159912 ms\n",
            "Epoch 93:[5/16], Current Loss: 0.9127041697502136, Current Training Accuracy: 98.30729166666667, Time: 0.25679922103881836 ms\n",
            "Epoch 93:[10/16], Current Loss: 0.9127015471458435, Current Training Accuracy: 98.86363636363636, Time: 0.2567150592803955 ms\n",
            "Epoch 93:[15/16], Current Loss: 0.9276732206344604, Current Training Accuracy: 98.681640625, Time: 0.25578951835632324 ms\n",
            "Epoch 93, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.521427869796753 ms\n",
            "Epoch 94:[0/16], Current Loss: 0.9120303988456726, Current Training Accuracy: 99.21875, Time: 0.28194713592529297 ms\n",
            "Epoch 94:[5/16], Current Loss: 0.912702202796936, Current Training Accuracy: 98.69791666666667, Time: 0.2561166286468506 ms\n",
            "Epoch 94:[10/16], Current Loss: 0.9348711371421814, Current Training Accuracy: 98.50852272727273, Time: 0.26337671279907227 ms\n",
            "Epoch 94:[15/16], Current Loss: 0.9127137660980225, Current Training Accuracy: 98.681640625, Time: 0.2567322254180908 ms\n",
            "Epoch 94, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.546010255813599 ms\n",
            "Epoch 95:[0/16], Current Loss: 0.9127028584480286, Current Training Accuracy: 99.21875, Time: 0.2865746021270752 ms\n",
            "Epoch 95:[5/16], Current Loss: 0.9127040505409241, Current Training Accuracy: 98.56770833333333, Time: 0.26123929023742676 ms\n",
            "Epoch 95:[10/16], Current Loss: 0.9361368417739868, Current Training Accuracy: 98.36647727272727, Time: 0.26561737060546875 ms\n",
            "Epoch 95:[15/16], Current Loss: 0.9048922061920166, Current Training Accuracy: 98.681640625, Time: 0.25474047660827637 ms\n",
            "Epoch 95, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.518578052520752 ms\n",
            "Epoch 96:[0/16], Current Loss: 0.904893159866333, Current Training Accuracy: 100.0, Time: 0.2842855453491211 ms\n",
            "Epoch 96:[5/16], Current Loss: 0.9204556345939636, Current Training Accuracy: 98.56770833333333, Time: 0.26180195808410645 ms\n",
            "Epoch 96:[10/16], Current Loss: 0.9048904180526733, Current Training Accuracy: 98.7215909090909, Time: 0.2577841281890869 ms\n",
            "Epoch 96:[15/16], Current Loss: 0.928341805934906, Current Training Accuracy: 98.681640625, Time: 0.25506114959716797 ms\n",
            "Epoch 96, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.534071922302246 ms\n",
            "Epoch 97:[0/16], Current Loss: 0.9271959662437439, Current Training Accuracy: 97.65625, Time: 0.2786073684692383 ms\n",
            "Epoch 97:[5/16], Current Loss: 0.9127053022384644, Current Training Accuracy: 98.828125, Time: 0.26026010513305664 ms\n",
            "Epoch 97:[10/16], Current Loss: 0.9283331036567688, Current Training Accuracy: 98.9346590909091, Time: 0.26366090774536133 ms\n",
            "Epoch 97:[15/16], Current Loss: 0.9198256731033325, Current Training Accuracy: 98.681640625, Time: 0.255551815032959 ms\n",
            "Epoch 97, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.563352108001709 ms\n",
            "Epoch 98:[0/16], Current Loss: 0.9205131530761719, Current Training Accuracy: 98.4375, Time: 0.2819218635559082 ms\n",
            "Epoch 98:[5/16], Current Loss: 0.9048953652381897, Current Training Accuracy: 98.69791666666667, Time: 0.2577667236328125 ms\n",
            "Epoch 98:[10/16], Current Loss: 0.9283257722854614, Current Training Accuracy: 98.50852272727273, Time: 0.2712879180908203 ms\n",
            "Epoch 98:[15/16], Current Loss: 0.9127035737037659, Current Training Accuracy: 98.681640625, Time: 0.2544431686401367 ms\n",
            "Epoch 98, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.532200574874878 ms\n",
            "Epoch 99:[0/16], Current Loss: 0.9205151796340942, Current Training Accuracy: 98.4375, Time: 0.278439998626709 ms\n",
            "Epoch 99:[5/16], Current Loss: 0.9350377321243286, Current Training Accuracy: 98.56770833333333, Time: 0.26035284996032715 ms\n",
            "Epoch 99:[10/16], Current Loss: 0.9127071499824524, Current Training Accuracy: 98.86363636363636, Time: 0.2593967914581299 ms\n",
            "Epoch 99:[15/16], Current Loss: 0.9277392625808716, Current Training Accuracy: 98.681640625, Time: 0.25439453125 ms\n",
            "Epoch 99, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.481441020965576 ms\n",
            "Epoch 100:[0/16], Current Loss: 0.9200438261032104, Current Training Accuracy: 98.4375, Time: 0.2796196937561035 ms\n",
            "Epoch 100:[5/16], Current Loss: 0.9048858284950256, Current Training Accuracy: 98.828125, Time: 0.2565193176269531 ms\n",
            "Epoch 100:[10/16], Current Loss: 0.9048948287963867, Current Training Accuracy: 98.7215909090909, Time: 0.25993967056274414 ms\n",
            "Epoch 100:[15/16], Current Loss: 0.9123357534408569, Current Training Accuracy: 98.681640625, Time: 0.2534360885620117 ms\n",
            "Epoch 100, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.568803548812866 ms\n",
            "Epoch 101:[0/16], Current Loss: 0.9127081632614136, Current Training Accuracy: 99.21875, Time: 0.29032325744628906 ms\n",
            "Epoch 101:[5/16], Current Loss: 0.9198260307312012, Current Training Accuracy: 98.95833333333333, Time: 0.2748680114746094 ms\n",
            "Epoch 101:[10/16], Current Loss: 0.9355701804161072, Current Training Accuracy: 98.57954545454545, Time: 0.26175522804260254 ms\n",
            "Epoch 101:[15/16], Current Loss: 0.9205253720283508, Current Training Accuracy: 98.681640625, Time: 0.25432825088500977 ms\n",
            "Epoch 101, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 8.033935546875 ms\n",
            "Epoch 102:[0/16], Current Loss: 0.9283562302589417, Current Training Accuracy: 97.65625, Time: 0.28646063804626465 ms\n",
            "Epoch 102:[5/16], Current Loss: 0.9048835039138794, Current Training Accuracy: 98.56770833333333, Time: 0.2596909999847412 ms\n",
            "Epoch 102:[10/16], Current Loss: 0.9127063155174255, Current Training Accuracy: 98.57954545454545, Time: 0.2592136859893799 ms\n",
            "Epoch 102:[15/16], Current Loss: 0.9205231666564941, Current Training Accuracy: 98.681640625, Time: 0.2537715435028076 ms\n",
            "Epoch 102, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.542830944061279 ms\n",
            "Epoch 103:[0/16], Current Loss: 0.9048981666564941, Current Training Accuracy: 100.0, Time: 0.28479981422424316 ms\n",
            "Epoch 103:[5/16], Current Loss: 0.912091076374054, Current Training Accuracy: 98.56770833333333, Time: 0.25948119163513184 ms\n",
            "Epoch 103:[10/16], Current Loss: 0.9048956036567688, Current Training Accuracy: 98.79261363636364, Time: 0.2676124572753906 ms\n",
            "Epoch 103:[15/16], Current Loss: 0.920523464679718, Current Training Accuracy: 98.681640625, Time: 0.2552516460418701 ms\n",
            "Epoch 103, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.535398960113525 ms\n",
            "Epoch 104:[0/16], Current Loss: 0.9205067157745361, Current Training Accuracy: 98.4375, Time: 0.2758662700653076 ms\n",
            "Epoch 104:[5/16], Current Loss: 0.9126999974250793, Current Training Accuracy: 98.828125, Time: 0.2577977180480957 ms\n",
            "Epoch 104:[10/16], Current Loss: 0.9205121994018555, Current Training Accuracy: 98.79261363636364, Time: 0.25963735580444336 ms\n",
            "Epoch 104:[15/16], Current Loss: 0.919837236404419, Current Training Accuracy: 98.681640625, Time: 0.25504207611083984 ms\n",
            "Epoch 104, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.505180835723877 ms\n",
            "Epoch 105:[0/16], Current Loss: 0.9198175072669983, Current Training Accuracy: 98.4375, Time: 0.2850306034088135 ms\n",
            "Epoch 105:[5/16], Current Loss: 0.9126994609832764, Current Training Accuracy: 98.56770833333333, Time: 0.25724124908447266 ms\n",
            "Epoch 105:[10/16], Current Loss: 0.920508623123169, Current Training Accuracy: 98.79261363636364, Time: 0.2658200263977051 ms\n",
            "Epoch 105:[15/16], Current Loss: 0.9276282787322998, Current Training Accuracy: 98.681640625, Time: 0.2568638324737549 ms\n",
            "Epoch 105, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.540762901306152 ms\n",
            "Epoch 106:[0/16], Current Loss: 0.9198125004768372, Current Training Accuracy: 98.4375, Time: 0.27960753440856934 ms\n",
            "Epoch 106:[5/16], Current Loss: 0.9205085635185242, Current Training Accuracy: 98.56770833333333, Time: 0.25747108459472656 ms\n",
            "Epoch 106:[10/16], Current Loss: 0.9126997590065002, Current Training Accuracy: 98.65056818181819, Time: 0.2683830261230469 ms\n",
            "Epoch 106:[15/16], Current Loss: 0.9126943945884705, Current Training Accuracy: 98.681640625, Time: 0.2538158893585205 ms\n",
            "Epoch 106, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.523248195648193 ms\n",
            "Epoch 107:[0/16], Current Loss: 0.9126942753791809, Current Training Accuracy: 99.21875, Time: 0.2740185260772705 ms\n",
            "Epoch 107:[5/16], Current Loss: 0.9191058874130249, Current Training Accuracy: 98.046875, Time: 0.25792551040649414 ms\n",
            "Epoch 107:[10/16], Current Loss: 0.9119818210601807, Current Training Accuracy: 98.65056818181819, Time: 0.25678277015686035 ms\n",
            "Epoch 107:[15/16], Current Loss: 0.9354214072227478, Current Training Accuracy: 98.681640625, Time: 0.2567720413208008 ms\n",
            "Epoch 107, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.482521057128906 ms\n",
            "Epoch 108:[0/16], Current Loss: 0.927611231803894, Current Training Accuracy: 97.65625, Time: 0.2772536277770996 ms\n",
            "Epoch 108:[5/16], Current Loss: 0.9283161163330078, Current Training Accuracy: 98.56770833333333, Time: 0.2564382553100586 ms\n",
            "Epoch 108:[10/16], Current Loss: 0.9276105165481567, Current Training Accuracy: 98.50852272727273, Time: 0.2610940933227539 ms\n",
            "Epoch 108:[15/16], Current Loss: 0.9276098608970642, Current Training Accuracy: 98.681640625, Time: 0.25325798988342285 ms\n",
            "Epoch 108, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.541079998016357 ms\n",
            "Epoch 109:[0/16], Current Loss: 0.9126908183097839, Current Training Accuracy: 99.21875, Time: 0.2864651679992676 ms\n",
            "Epoch 109:[5/16], Current Loss: 0.9126923680305481, Current Training Accuracy: 98.56770833333333, Time: 0.25811219215393066 ms\n",
            "Epoch 109:[10/16], Current Loss: 0.9205090999603271, Current Training Accuracy: 98.65056818181819, Time: 0.26950907707214355 ms\n",
            "Epoch 109:[15/16], Current Loss: 0.9126886129379272, Current Training Accuracy: 98.73046875, Time: 0.25656747817993164 ms\n",
            "Epoch 109, train Loss: 0.917  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.5471577644348145 ms\n",
            "Epoch 110:[0/16], Current Loss: 0.9354277849197388, Current Training Accuracy: 96.875, Time: 0.2789762020111084 ms\n",
            "Epoch 110:[5/16], Current Loss: 0.9048754572868347, Current Training Accuracy: 98.95833333333333, Time: 0.2572171688079834 ms\n",
            "Epoch 110:[10/16], Current Loss: 0.9204957485198975, Current Training Accuracy: 98.36647727272727, Time: 0.2599978446960449 ms\n",
            "Epoch 110:[15/16], Current Loss: 0.9197937250137329, Current Training Accuracy: 98.681640625, Time: 0.2524123191833496 ms\n",
            "Epoch 110, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.497203826904297 ms\n",
            "Epoch 111:[0/16], Current Loss: 0.9126924276351929, Current Training Accuracy: 99.21875, Time: 0.2813084125518799 ms\n",
            "Epoch 111:[5/16], Current Loss: 0.9354373216629028, Current Training Accuracy: 98.30729166666667, Time: 0.2613370418548584 ms\n",
            "Epoch 111:[10/16], Current Loss: 0.9126894474029541, Current Training Accuracy: 98.50852272727273, Time: 0.2569408416748047 ms\n",
            "Epoch 111:[15/16], Current Loss: 0.9205001592636108, Current Training Accuracy: 98.681640625, Time: 0.2567481994628906 ms\n",
            "Epoch 111, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.531392574310303 ms\n",
            "Epoch 112:[0/16], Current Loss: 0.9204902052879333, Current Training Accuracy: 98.4375, Time: 0.282637357711792 ms\n",
            "Epoch 112:[5/16], Current Loss: 0.9048776030540466, Current Training Accuracy: 99.08854166666667, Time: 0.2569420337677002 ms\n",
            "Epoch 112:[10/16], Current Loss: 0.9269852638244629, Current Training Accuracy: 98.7215909090909, Time: 0.2611720561981201 ms\n",
            "Epoch 112:[15/16], Current Loss: 0.9048753380775452, Current Training Accuracy: 98.73046875, Time: 0.2566516399383545 ms\n",
            "Epoch 112, train Loss: 0.917  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.530732154846191 ms\n",
            "Epoch 113:[0/16], Current Loss: 0.958148181438446, Current Training Accuracy: 94.53125, Time: 0.2698850631713867 ms\n",
            "Epoch 113:[5/16], Current Loss: 0.9276289343833923, Current Training Accuracy: 98.30729166666667, Time: 0.2612733840942383 ms\n",
            "Epoch 113:[10/16], Current Loss: 0.9282907247543335, Current Training Accuracy: 98.50852272727273, Time: 0.25718021392822266 ms\n",
            "Epoch 113:[15/16], Current Loss: 0.9119955897331238, Current Training Accuracy: 98.681640625, Time: 0.25261664390563965 ms\n",
            "Epoch 113, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.511277198791504 ms\n",
            "Epoch 114:[0/16], Current Loss: 0.9197973012924194, Current Training Accuracy: 98.4375, Time: 0.2806270122528076 ms\n",
            "Epoch 114:[5/16], Current Loss: 0.9205000996589661, Current Training Accuracy: 98.4375, Time: 0.25967884063720703 ms\n",
            "Epoch 114:[10/16], Current Loss: 0.920495331287384, Current Training Accuracy: 98.57954545454545, Time: 0.26024889945983887 ms\n",
            "Epoch 114:[15/16], Current Loss: 0.9276188015937805, Current Training Accuracy: 98.681640625, Time: 0.2560081481933594 ms\n",
            "Epoch 114, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.530130386352539 ms\n",
            "Epoch 115:[0/16], Current Loss: 0.9361189007759094, Current Training Accuracy: 96.875, Time: 0.28820300102233887 ms\n",
            "Epoch 115:[5/16], Current Loss: 0.9283173084259033, Current Training Accuracy: 98.17708333333333, Time: 0.25468945503234863 ms\n",
            "Epoch 115:[10/16], Current Loss: 0.9269054532051086, Current Training Accuracy: 98.4375, Time: 0.2728273868560791 ms\n",
            "Epoch 115:[15/16], Current Loss: 0.9119783043861389, Current Training Accuracy: 98.681640625, Time: 0.25568509101867676 ms\n",
            "Epoch 115, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.535218954086304 ms\n",
            "Epoch 116:[0/16], Current Loss: 0.9119938611984253, Current Training Accuracy: 99.21875, Time: 0.2822847366333008 ms\n",
            "Epoch 116:[5/16], Current Loss: 0.9205061197280884, Current Training Accuracy: 98.828125, Time: 0.2600672245025635 ms\n",
            "Epoch 116:[10/16], Current Loss: 0.9276095032691956, Current Training Accuracy: 98.7215909090909, Time: 0.2576572895050049 ms\n",
            "Epoch 116:[15/16], Current Loss: 0.9048767685890198, Current Training Accuracy: 98.681640625, Time: 0.25326991081237793 ms\n",
            "Epoch 116, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.525745391845703 ms\n",
            "Epoch 117:[0/16], Current Loss: 0.9283091425895691, Current Training Accuracy: 97.65625, Time: 0.28360795974731445 ms\n",
            "Epoch 117:[5/16], Current Loss: 0.9120000004768372, Current Training Accuracy: 98.4375, Time: 0.2562906742095947 ms\n",
            "Epoch 117:[10/16], Current Loss: 0.9198091626167297, Current Training Accuracy: 98.50852272727273, Time: 0.26964902877807617 ms\n",
            "Epoch 117:[15/16], Current Loss: 0.935421347618103, Current Training Accuracy: 98.681640625, Time: 0.25472235679626465 ms\n",
            "Epoch 117, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.556969881057739 ms\n",
            "Epoch 118:[0/16], Current Loss: 0.9354448914527893, Current Training Accuracy: 96.875, Time: 0.2800934314727783 ms\n",
            "Epoch 118:[5/16], Current Loss: 0.9197893142700195, Current Training Accuracy: 98.17708333333333, Time: 0.25957393646240234 ms\n",
            "Epoch 118:[10/16], Current Loss: 0.9126880168914795, Current Training Accuracy: 98.7215909090909, Time: 0.2592918872833252 ms\n",
            "Epoch 118:[15/16], Current Loss: 0.9198224544525146, Current Training Accuracy: 98.681640625, Time: 0.2560920715332031 ms\n",
            "Epoch 118, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 7.517131805419922 ms\n",
            "Epoch 119:[0/16], Current Loss: 0.9276964664459229, Current Training Accuracy: 97.65625, Time: 0.2780916690826416 ms\n",
            "Epoch 119:[5/16], Current Loss: 0.9197874665260315, Current Training Accuracy: 98.828125, Time: 0.25708675384521484 ms\n",
            "Epoch 119:[10/16], Current Loss: 0.9276036620140076, Current Training Accuracy: 98.86363636363636, Time: 0.26834726333618164 ms\n",
            "Epoch 119:[15/16], Current Loss: 0.9126840829849243, Current Training Accuracy: 98.681640625, Time: 0.25265955924987793 ms\n",
            "Epoch 119, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.50038480758667 ms\n",
            "Epoch 120:[0/16], Current Loss: 0.9126830697059631, Current Training Accuracy: 99.21875, Time: 0.28156185150146484 ms\n",
            "Epoch 120:[5/16], Current Loss: 0.9283111095428467, Current Training Accuracy: 98.56770833333333, Time: 0.2570767402648926 ms\n",
            "Epoch 120:[10/16], Current Loss: 0.9119749665260315, Current Training Accuracy: 98.79261363636364, Time: 0.26964640617370605 ms\n",
            "Epoch 120:[15/16], Current Loss: 0.9283033609390259, Current Training Accuracy: 98.681640625, Time: 0.2559342384338379 ms\n",
            "Epoch 120, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.5429675579071045 ms\n",
            "Epoch 121:[0/16], Current Loss: 0.9126812219619751, Current Training Accuracy: 99.21875, Time: 0.2832050323486328 ms\n",
            "Epoch 121:[5/16], Current Loss: 0.9119788408279419, Current Training Accuracy: 99.08854166666667, Time: 0.261096715927124 ms\n",
            "Epoch 121:[10/16], Current Loss: 0.9126856923103333, Current Training Accuracy: 98.9346590909091, Time: 0.26044487953186035 ms\n",
            "Epoch 121:[15/16], Current Loss: 0.9048697352409363, Current Training Accuracy: 98.73046875, Time: 0.2559010982513428 ms\n",
            "Epoch 121, train Loss: 0.917  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.513394594192505 ms\n",
            "Epoch 122:[0/16], Current Loss: 0.9191970825195312, Current Training Accuracy: 98.4375, Time: 0.28526854515075684 ms\n",
            "Epoch 122:[5/16], Current Loss: 0.9204933643341064, Current Training Accuracy: 98.69791666666667, Time: 0.25783538818359375 ms\n",
            "Epoch 122:[10/16], Current Loss: 0.9204962253570557, Current Training Accuracy: 98.50852272727273, Time: 0.26298093795776367 ms\n",
            "Epoch 122:[15/16], Current Loss: 0.9197931289672852, Current Training Accuracy: 98.73046875, Time: 0.25627803802490234 ms\n",
            "Epoch 122, train Loss: 0.917  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.4970433712005615 ms\n",
            "Epoch 123:[0/16], Current Loss: 0.9048700928688049, Current Training Accuracy: 100.0, Time: 0.2826976776123047 ms\n",
            "Epoch 123:[5/16], Current Loss: 0.9361141324043274, Current Training Accuracy: 98.56770833333333, Time: 0.25857019424438477 ms\n",
            "Epoch 123:[10/16], Current Loss: 0.9283085465431213, Current Training Accuracy: 98.7215909090909, Time: 0.2589263916015625 ms\n",
            "Epoch 123:[15/16], Current Loss: 0.9198102355003357, Current Training Accuracy: 98.681640625, Time: 0.25664710998535156 ms\n",
            "Epoch 123, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.511287689208984 ms\n",
            "Epoch 124:[0/16], Current Loss: 0.9276201128959656, Current Training Accuracy: 97.65625, Time: 0.2796590328216553 ms\n",
            "Epoch 124:[5/16], Current Loss: 0.9126824140548706, Current Training Accuracy: 98.30729166666667, Time: 0.2619967460632324 ms\n",
            "Epoch 124:[10/16], Current Loss: 0.9361159205436707, Current Training Accuracy: 98.4375, Time: 0.261523962020874 ms\n",
            "Epoch 124:[15/16], Current Loss: 0.9269120693206787, Current Training Accuracy: 98.681640625, Time: 0.2532632350921631 ms\n",
            "Epoch 124, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.521378517150879 ms\n",
            "Epoch 125:[0/16], Current Loss: 0.9198005795478821, Current Training Accuracy: 98.4375, Time: 0.27576112747192383 ms\n",
            "Epoch 125:[5/16], Current Loss: 0.9197860360145569, Current Training Accuracy: 99.08854166666667, Time: 0.26192212104797363 ms\n",
            "Epoch 125:[10/16], Current Loss: 0.9193726778030396, Current Training Accuracy: 98.65056818181819, Time: 0.257343053817749 ms\n",
            "Epoch 125:[15/16], Current Loss: 0.9126818180084229, Current Training Accuracy: 98.681640625, Time: 0.2544269561767578 ms\n",
            "Epoch 125, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.529455661773682 ms\n",
            "Epoch 126:[0/16], Current Loss: 0.9126831889152527, Current Training Accuracy: 99.21875, Time: 0.27657389640808105 ms\n",
            "Epoch 126:[5/16], Current Loss: 0.9048710465431213, Current Training Accuracy: 98.4375, Time: 0.2559328079223633 ms\n",
            "Epoch 126:[10/16], Current Loss: 0.9198013544082642, Current Training Accuracy: 98.50852272727273, Time: 0.26292991638183594 ms\n",
            "Epoch 126:[15/16], Current Loss: 0.9355807304382324, Current Training Accuracy: 98.681640625, Time: 0.25347423553466797 ms\n",
            "Epoch 126, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 7.566296339035034 ms\n",
            "Epoch 127:[0/16], Current Loss: 0.9204915165901184, Current Training Accuracy: 98.4375, Time: 0.27254796028137207 ms\n",
            "Epoch 127:[5/16], Current Loss: 0.9204905033111572, Current Training Accuracy: 98.4375, Time: 0.2598724365234375 ms\n",
            "Epoch 127:[10/16], Current Loss: 0.9126787781715393, Current Training Accuracy: 98.79261363636364, Time: 0.264965295791626 ms\n",
            "Epoch 127:[15/16], Current Loss: 0.9204927086830139, Current Training Accuracy: 98.681640625, Time: 0.2556953430175781 ms\n",
            "Epoch 127, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.558377265930176 ms\n",
            "Epoch 128:[0/16], Current Loss: 0.9510403871536255, Current Training Accuracy: 95.3125, Time: 0.2797362804412842 ms\n",
            "Epoch 128:[5/16], Current Loss: 0.9204675555229187, Current Training Accuracy: 98.046875, Time: 0.25932788848876953 ms\n",
            "Epoch 128:[10/16], Current Loss: 0.9119972586631775, Current Training Accuracy: 98.57954545454545, Time: 0.2758951187133789 ms\n",
            "Epoch 128:[15/16], Current Loss: 0.904869556427002, Current Training Accuracy: 98.681640625, Time: 0.2543447017669678 ms\n",
            "Epoch 128, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 8.071480512619019 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "pred_correct_num=[]\n",
        "pred_total_num=[]\n",
        "pred_result_list=[]\n",
        "pred_prob_list = []\n",
        "label_prob_list=[]\n",
        "label_list=[]\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "    t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
        "    mask=mask.cuda()\n",
        "    output_test=model(t_image)\n",
        "    pred_prob_list.append(output_test)\n",
        "    label_prob_list.append(data[1])\n",
        "    label_list.append(mask)\n",
        "    output=torch.max(output_test,1)[1].long()\n",
        "    pred_result_list.append(output)\n",
        "    pred_correct_num.append(output.eq(mask).sum().item())\n",
        "    pred_total_num.append(output_test.shape[0])\n",
        "acc_test=sum(pred_correct_num)/sum(pred_total_num)\n",
        "print(\"The accuracy of detecting news bias: {}\".format(('%.4f%%'%(acc_test*100))))"
      ],
      "metadata": {
        "id": "owW4GYgt6B5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ad7daa-4b98-4033-cbf7-cd0351cee0ac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of detecting news bias: 83.0729%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "for i in range(len(pred_result_list)):\n",
        "  if len(pred_result_list) == 1:\n",
        "    pred_result = pred_result_list[0]\n",
        "    label = label_list[0]\n",
        "  if len(pred_result_list) == 2:\n",
        "    pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
        "    label = torch.cat((label_list[0], label_list[1]), -1)\n",
        "  if len(pred_result_list) > 2:\n",
        "    pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
        "    label = torch.cat((label_list[0], label_list[1]), -1)\n",
        "    for j in range(len(pred_result_list)-2):\n",
        "      pred_result = torch.cat((pred_result, pred_result_list[j+2]), -1)\n",
        "      label = torch.cat((label, label_list[j+2]), -1)\n",
        "label = label.cpu()\n",
        "pred_result = pred_result.cpu()\n",
        "C=confusion_matrix(label,pred_result)\n",
        "df=pd.DataFrame(C,index=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"],columns=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"])\n",
        "p1=sns.heatmap(df,annot=True,cmap=\"hot_r\")\n",
        "s1 = p1.get_figure()"
      ],
      "metadata": {
        "id": "bSbCoHbn6GIW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "29e5bab0-1d18-4595-cdc1-aacc9feb1d58"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD4CAYAAAD//dEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwU9f3H8dcnlwIRkGujgGA4pCICFUWgWg5BFGkoCV5Y0UJjf1qpxQuPgtKqtYd3raSgoPVEUaip9QApVAQFgShgPYAalATlDghJls/vj5nQFQOZ7JHJrJ/n4zGP7M7s7rwnuzuf/X6/s7OiqhhjjDE1SfE7gDHGmGCwgmGMMcYTKxjGGGM8sYJhjDHGEysYxhhjPEnzO0D9MywJDxvL9ztAAvT2O0CCZPkdIAG2+x0ggZpKLPfOFPG8vylTjWld8WAtDGOMMZ5YC8MYY3wStE/sVjCMMcYn6X4HqCUrGMYY45NUvwPUkhUMY4zxiRUMY4wxntgYhjHGGE+shWGMMcYTKxjGGGM8saOkjDHGeGJjGMYYYzyxLiljjDGeWMEwxhjjiXVJGWOM8STD7wC1ZAXDGGN8Yi0MY4wxntgYhjHGGE+shZFAIlKmqpkeb9sSeBmnm3A80E1VH05kvkPZtKmCG27YzJYtlYgI55/fmDFjmvLKK2U89NBWPv20nFmz2tCt25F+xIuLmTP/zaxZS1GFUaNO47LLzvA7Usz27dvH6NHjKS+vIBwOc/bZP2T8+J/6HSsuFi5cyB133MH+/fsZNWoU+fnB/lXGTZtKueGG29iyZav7HhvBmDEX+h2rRtbCqD8GAe+r6jgRaQ/8BfClYKSmChMnNqdr1yMpK9tPbm4x/fo1pHPnDB58MIvJkzf7EStuPvqohFmzljJr1tWkp6cybtx0Bgz4Hu3atfA7WkwyMjKYOfNeGjVqSEVFJRdf/AvOPLM3PXp09TtaTMLhMFOmTOGxxx4jFAqRl5fHwIED6dixo9/RopaamsrEib+ka9culJXtJjd3DP36nUbHjtl+RzusoBWMoLWIvkVEOojIP0VkuYgsEpEuItID+D2QIyIrgbuBDiKyUkT+UNcZW7VKo2tXp/WQmZlCdnYGpaWVdOiQQXZ20I6T+LZPP93MyScfR4MGGaSlpXLqqdm89toHfseKmYjQqFFDACorK6msdFqIQVdUVES7du1o27YtGRkZDBs2jHnz5vkdKyatWrWga9cuAGRmNiI7uz2lpV/6nKpm6bWY6oPAFwygALhaVU8BrgMeVtWVwCTgWVXtAdwIfKqqPVT1eh+zsnFjBWvX7qN79+B2Px2sc+cQy5evZ9u23Xz9dTkLF35IScl2v2PFRTgcJidnLH37jqBv3150736i35FiVlpaSlZW1oHroVCI0tJSHxPF18aNX7B27Ud0717/W4KptZjqg0B3SYlIJtAXmBXxye+IKB4nH8gHmDr1JPLzj4tbxki7d+9n/PgSbr65BZmZyVCrHR06hBg3rj9jx06jQYMMunQ5lpSU5Ni+1NRU5syZzs6du7jqqlv56KN1dO5cv7s5vst2797D+PETufnmX5GZ6Wm401dBe5cEumDg/L+3u62IqKlqAU5LBRimscf6tooKZfz4TQwfnsmQIfX/hVxbo0adxqhRpwFwzz2vEAo18TlRfDVufBS9e/dk0aJ3Al8wQqEQJSUlB66XlpYSCoV8TBQfFRWVjB8/keHDhzJkyAC/43hSX1oOXgWtwH2Dqu4E1ovIKABxdK/mpruAo+o0XARV5ZZbNpOdncHllx/tV4yE2rKlDIAvvtjGa699wPDhPX1OFLutW7ezc+cuAPbu3cfixcvIzk5M67MudevWjQ0bNlBcXEx5eTmFhYUMHDjQ71gxcd5jvyU7uz2XX36x33E8S6nFVB8ErYXRUEQ2Rly/BxgN/EVEbsUZG3oGWBV5J1XdIiJvicgHwCt1PY6xfPle5szZRefOGeTkfAbAhAnNKS9XfvObL9m6NcwVV2zie9/LYPr01nUZLW6uvvpxtm/fQ1paKpMnj6Bx4wZ+R4rZ5s1bmDjxTsLh/agqQ4f2Z8CAvn7HillaWhqTJk1i3LhxhMNhcnNz6dSpk9+xYrJ8+SrmzHmFzp07kpNzCQATJvwfP/xhP5+THV7QDnkR1YT0wARYYrqk/BXsY+yr19vvAAmSVfNNAic5DoCoXtOYDpu7WMTz/uYp1cOuS0QeBc4DNqvqSe68ZsCzQHtgA3C+qm4TZ9D3fuBcYA9wmaq+V1OG+tLSMcaY75w4HyU1Axh60LyJwDxV7QTMc68DnAN0cqd8nO+p1cgKhjHG+CSeBUNVFwJbD5qdA8x0L88ERkTMf1wdS4CmInJMTeuwgmGMMT6pzaC3iOSLyLKIyUtfc0hVN7mXS4Cqw+FaA8URt9vozjusoA16G2NM0qjNYbXfPPy/9lRVpRZjJtWxgmGMMT6pg1N+lIrIMaq6ye1yqjpx3edA24jbtXHnHZZ1SRljjE/q4NQgc4Ex7uUxwJyI+Ze63107HdgR0XV1SNbCMMYYn8TzE7uIPA30B1q431ebDPwOeE5ExgL/Bc53b/4PnENqP8E5rPZyL+uwgmGMMT6J56lBVPWiQywaVM1tFbiqtuuwgmGMMT4J2rmkrGAYY4xPgjaIbAXDGGN8Ul9+GMkrKxjGGOMT65IyxhjjiRUMY4wxntgYhjHGGE+shWGMMcYTG/QOvCl+B4i/qb38ThB/V2zzO4Hx7FO/AyTQKTHd21oYxhhjPLExDGOMMZ5YC8MYY4wnVjCMMcZ4Yl1SxhhjPMnwO0AtWcEwxhifWAvDGGOMJzaGYYwxxhNrYRhjjPHEWhjGGGM8sYJhjDHGEzuXlDHGGE+shWGMMcYTG/Q2xhjjibUwjDHGeGItDGOMMZ7YqUGMMcZ48p1rYYhImapmxiOMh3VtAHqp6lcebnsEUAi0AO4COqjqnYlN6M3Onbu59da/8tFHxYgId96ZT8+enf2OFZXwfsh98jhCmZVM/fEXXPxsG3aXO2+DLXvSODlrLw/nfOFzyuhs2lTKDTfcxpYtWxERzj9/BGPGXOh3rLhYuHAhd9xxB/v372fUqFHk5+f7HSlmQXxf2RhG/dETQFV7gFPYgHpRMO6443HOOKM7DzxwDeXllezdu8/vSFF7fEVTOjQrp8wtEk9dsPHAsqvnHsOgjmV+RYtZamoqEyf+kq5du1BWtpvc3DH063caHTtm+x0tJuFwmClTpvDYY48RCoXIy8tj4MCBdOzY0e9oMQni+ypoBSMhLSIR6SAi/xSR5SKySES6uPOHi8hSEVkhIm+ISMidf5uIPCoiC0RknYiMr8W6WorICyLyrjv1E5FWwN+AU0VkpYjMAhq4l59MxDZ7tWvXHt5990Py8voDkJGRRuPGjfyMFLWSXWksWJdJXrcd31pWti+FJcUNOavDbh+SxUerVi3o2rULAJmZjcjObk9p6Zc+p4pdUVER7dq1o23btmRkZDBs2DDmzZvnd6yYBPV9lVKLyQsR+ZWIrBaRD0TkaRE5UkSOd/e7n4jIsyIS9dBJorrQCoCrVfUU4DrgYXf+v4HTVbUn8AxwQ8R9ugBnA6cBk0XE65cg7wfuVdVTgVxgmqpuBsYBi1S1h6qOAr52L4+OdeNisXHjZpo1O4qbbprKiBE3ccstBezZs9fPSFG7c0FLrj/zS1Lk28ve+LQRfY7bQ+YR++s+WAJs3PgFa9d+RPfuXf2OErPS0lKysrIOXA+FQpSWlvqYKHZBfV+l1mKqiYi0BsbjdNuf5N7tQuBunH1kR2AbMDbavHEvGCKSCfQFZonISmAqcIy7uA3wqoi8D1wPRL77ClV1nzs+sRkIeVzlWcBD7rrmAo3dDPVSZeV+1qzZwEUXncVLL91FgwZHUFAw1+9YtfbmukY0axjmpFD1zf6XP2zMsBN21XGqxNi9ew/jx0/k5pt/RWZmvX1pfacF9X2VXovJozSc3pQ0oCGwCRgIPO8unwmMiDZvIloYKcB299N81fQ9d9mDwEOq2g24Ajgy4n6Re54w3sdXUnBaLVXraq2qteo4F5F8EVkmIssKCmbX5q61lpXVjKysZnTv7vQXDx3amzVrNiR0nYnw3ucNmP9pIwZOO54JhcewpLgh1/3D+dS69esU3i85kv7Zwe2OqlJRUcn48RMZPnwoQ4YM8DtOXIRCIUpKSg5cLy0tJRTy+vmsfgrq+yqeLQxV/Rz4I/AZTqHYASzH2R9XujfbCLSONm/cC4aq7gTWi8goAHF0dxc3AT53L4+J0ypfA66uuiIiPQ5xu4pDdXOpaoGq9lLVXvn5I+MUq3otWzYlK6s569Y5Rw69/fYHdOgQ9fPnm2vP+IqF+euZP2499wzbxOlt9/DHc52d0KsfHUX/7DKOSFOfU8ZGVbnllt+Snd2eyy+/2O84cdOtWzc2bNhAcXEx5eXlFBYWMnDgQL9jxSSo76vajGFEfrB1p28c2iYiRwM5wPHAsUAjYGg888bjKKmGIrIx4vo9wGjgLyJyK05r6hlgFXAbTlfVNmA+zobVVpGIVHWMP4fTZ/dnESnC2Z6FwM+ruV+Be9/3/B7H+PWvx3DddX+moqKStm1bcdddV/gZJ+7+8Z+j+NmpW/2OEbPly1cxZ84rdO7ckZycSwCYMOH/+OEP+/mcLDZpaWlMmjSJcePGEQ6Hyc3NpVOnTn7HilkQ31e1OUpKVQtw9mOHchawXlW/BBCR2UA/oKmIpLmtjDb870N7rYlqsD8Fxt/y5PuHTO3ld4L4u2Kb3wkSpKnfARJgud8BEuiUag758G6diOf9TbbqYdclIr2BR4FTga+BGcAy4EzgBVV9RkQeAYpU9eFDPtBhBO2LhsYYkzTieVitqi7FGdx+D3jfvVsBcCMwQUQ+AZoD06PNm8xf3DPGmHot3j+gpKqTgckHzV6H83WFmFnBMMYYnwTtm95WMIwxxidWMIwxxngStEFkKxjGGOMTa2EYY4zxJN6D3olmBcMYY3xiLQxjjDGe2BiGMcYYT6yFYYwxxhMrGMYYY7wJWJ+UFQxjjPFL1D+W6g8rGMYY4xdrYRhjjPEkYIMYVjCMMcYvVjCMMcZ4ErAuKfvFvW9Lwn/Is34HiLsucqHfERLiw6R8P5b4HSCBsmL6xT2yvP/iHiWH/8W9umAtDGOM8Yt1SRljjPHECoYxxhhPAjaGYQXDGGP8Yi0MY4wxnljBMMYY40nAfkHJCoYxxvjFxjCMMcZ4Yl1SxhhjPLGCYYwxxhPrkjLGGOOJtTCMMcZ4YkdJGWOM8SRgLYyA9aAZY0wSSanF5IGINBWR50XkQxFZKyJ9RKSZiLwuIh+7f4+OJa4xxhg/pNZi8uZ+4J+q2gXoDqwFJgLzVLUTMM+9HhUrGMYY45c4FgwRaQKcCUwHUNVyVd0O5AAz3ZvNBEZEG9cKhjHG+CXd+yQi+SKyLGLKP+jRjge+BB4TkRUiMk1EGgEhVd3k3qYECEUb15eCISJZIvKMiHwqIstF5B8i0jmKx7lMRI5NRMZEWrhwIWeffTaDBw+moKDA7zhRu+mmF+nT527OO++hA/O2b9/D5ZfPYMiQ+7j88hns2PF1nee6Y/p03iotZe7771e7/PgTTuCZxYsp2ruXn157bVzWmZ6RwT3PPMOrH3/Ms0uW0LpdOwD6nnUWLyxbxtyiIl5YtozeAwbEZX2xSpbXYJV9+/aRl3cFP/rRTxk2bAwPPPCo35G8qUULQ1ULVLVXxHTwE5cGfB/4i6r2BHZzUPeTOj+xGvXPOtZ5wRARAV4EFqhqB1U9BbiJ6KreZUCtCoaI+HpkWDgcZsqUKUybNo3CwkJefvllPvnkEz8jRW3kyJ5Mm/aTb8wrKFhEnz7ZvPbaNfTpk01BwaI6z/XijBn8bOjQQy7fsXUrvx0/nkf/+MdaP3brdu14/M03vzU/b+xYdm7bxtmdOjHz3nu59u67Adj21Vf83/Dh/Ojkk5k4Zgy/f+KJWq8z3pLpNVglIyODmTPvZe7cR3nppeksWvQOK1eu9jtWzeI76L0R2KiqS93rz+MUkFIROQbA/bs5lrh1bQBQoaqPVM1Q1VWqukhErheRd0WkSERuBxCR9u5o/19FZLWIvCYiDUQkD+gFPCkiK915p4jIv9xWy6sR/6QFInKfiCwDfunDNh9QVFREu3btaNu2LRkZGQwbNox58+b5GSlqp57aniZNGnxj3rx5HzJiRE8ARozoyRtvrK3zXMsWLWLH1q2HXL71yy/5YNkyKisqvrVs+OjRPLd0KS+uWMHtjzxCSoq3t8ignBxemul0E7/6/PP0GTQIgLUrV7J5k9Mb8PHq1RzRoAHpGRm13aS4SqbXYBURoVGjhgBUVlZSWVmJ89m0novjGIaqlgDFInKCO2sQsAaYC4xx540B5kQb14+CcRKw/OCZIjIE6AScBvQAThGRM93FnYA/q2pXYDuQq6rPA8uA0araA6gEHgTy3FbLo8AdEavIcJtxf0rQdnlSWlpKVlbWgeuhUIjS0lIfE8XXli27adXqKABatsxky5bdPifyLrtLF8694AIu7tePH/fsSTgcZvjo0Z7u26p1azYVFwPOJ/hdO3bQtHnzb9zm7Nxc1rz3HhXl5XHPXhvJ+hoMh8Pk5Iylb98R9O3bi+7dT/Q7Us3ifFgtcDXOh+ginP3oncDvgMEi8jFwlns9KvXpi3tD3GmFez0Tp1B8BqxX1ZXu/OVA+2rufwJOMXrd/WSRCmyKWP7soVbsDh7lA0ydOpX8/IPHkkw0RIQgfMir0mfQILqecgqz3n0XgCMbNGDrZqf1/uDs2bQ5/njSMzI45rjjeHGF8zJ94v77mT1jRo2P3fHEE7n27rsZO2RIwvJ/16WmpjJnznR27tzFVVfdykcfraNz52y/Yx1enL+45+4ne1WzaFA8Ht+PgrEayKtmvgB3qerUb8wUaQ/si5gVBr7ZD/K/+69W1T6HWO8hP+q6g0dVA0hRDwh5EQqFKCkpOXC9tLSUUCjqgxbqnebNG7F58y5atTqKzZt30axZI78jeSYivDRzJvfcfPO3ll09ciTgjGHcNWMGlx40eL358885pm1bSj//nNTUVI5q0oTtW7YAEGrdmodefJEbL72U4nXrEr8hNUj212DjxkfRu3dPFi16p/4XjICdGsSPLqn5wBGRh4SJyMnATuCnIpLpzmstIq1qeKxdwFHu5f8ALUWkj3v/dBHpGvf0MerWrRsbNmyguLiY8vJyCgsLGThwoN+x4mbgwC689JLz6full1YwaFAXnxN59/a8eQzJy6NZy5YANDn6aI497jhP950/dy4jxjjdxGfn5bFk/nwAjmrShKmFhfxp4kRWLF6cmOC1lIyvwa1bt7Nz5y4A9u7dx+LFy8jO9vbc+Sr+X9xLqDpvYaiqisiPgftE5EZgL7ABuAZnfOJtt0upDLgEp0VxKDOAR0Tka6APTsvlAfcLLGnAfTgtmnojLS2NSZMmMW7cOMLhMLm5uXTq1MnvWFGZMGEW77yznm3b9nDmmX/k6qsHkJ9/Btdc8yzPP/8exx7blPvuO7/Oc/3pqac4tX9/jm7RggXFxTw4eTJp6c5HuWenTqVFKMTzy5aR2bgx+/fv59JrrmHYiSfy6dq13H/rrUx/7TVSUlKorKhgylVX8cVnn9W4zuenT+f3TzzBqx9/zI6tW5lw4YUAjP7FLziuY0eunDSJKydNAmDskCFs/fLLxP0DapBMr8EqmzdvYeLEOwmH96OqDB3anwED+vodq2b1pBB4Jc5huSZCEv5DDjl8E1hd5EK/IyTEh0n5fiyp+SaBlRXbKN0V4v0Jn6q+jwjWp0FvY4z5bglYC8MKhjHG+CVgJ2eygmGMMX7x9zuctWYFwxhj/GItDGOMMZ7YGIYxxhhPrGAYY4zxxLqkjDHGeBKwU4NYwTDGGL9Yl5QxxhhPrGAYY4zxxMYwjDHGeGItDGOMMZ5YwTDGGOOJHSVljDHGExvDMMYY44l1SQXdXr8DJECO3wHi7kNd5neEBGnvd4AE2OB3gPrLCoYxxhhPrEvKGGOMJ9bCMMYY44kdJWWMMcYTa2EYY4zxxMYwjDHGeGItDGOMMZ5YwTDGGONJwAa9A9aDZowxSSSlFpNHIpIqIitE5GX3+vEislREPhGRZ0UkI5a4xhhj/JBai8m7XwJrI67fDdyrqh2BbcDYaONawTDGGL/EuWCISBtgGDDNvS7AQOB59yYzgRHRxrWCYYwxfqlFl5SI5IvIsogpv5pHvA+4AdjvXm8ObFfVSvf6RqB1tHFt0NsYY/xSi64mVS0ACg61XETOAzar6nIR6R9ztmpYwTDGGL/E9yipfsCPRORc4EigMXA/0FRE0txWRhvg82hXYF1SxhjjlziOYajqTaraRlXbAxcC81V1NPAmkOfebAwwJ9q4VjCMMcYvCTistho3AhNE5BOcMY3p0T6QdUkZY4xfEvRNb1VdACxwL68DTovH49ZYt0SkLB4r8kJENojI+yJSJCL/EpF2EcsWe7x/i2rm9xeRvvHOG42bbppEnz79Oe+8kX5Hiatk3a6dO3czfvx9DB16Leeccx0rVnzkd6SobNoEP/lJOueem86wYenMnPm/PdUTT6QwdKgz//e/D9i5KiIsXLiQs88+m8GDB1NQcMix4folMd/DSJj62MIYoKpficjtwK3AzwBUNZYdfn+gDKix6CTayJE5XHLJRdx44y1+R4mrZN2uO+54nDPO6M4DD1xDeXkle/fu8ztSVFJTYeLESrp2VcrKIDc3nX799vPVVzBvXipz51aQkQFbtvidNDrhcJgpU6bw2GOPEQqFyMvLY+DAgXTs2NHvaIf3XTg1iIh0EJF/ishyEVkkIl3c+cPdr6CvEJE3RCTkzr9NRB4VkQUisk5ExntYzdtEHC9c1dIRkRQReVhEPhSR10XkHyKSF3G/q0XkPbel0kVE2gM/B34lIitF5IxotjleTj31FJo0aexnhIRIxu3atWsP7777IXl5/QHIyEijceNG/oaKUqtW0LWrApCZCdnZSmkpPP10Kvn5lWS4J4to3tzHkDEoKiqiXbt2tG3bloyMDIYNG8a8efP8jlWzgLUwoh1KKQCuVtVTgOuAh935/wZOV9WewDM4XyCp0gU4G6cvbbKI1FRbhwIvVTN/JNAeOBH4CdDnoOVfqer3gb8A16nqBuARnK/G91DVRZ620Hznbdy4mWbNjuKmm6YyYsRN3HJLAXv27PU7Vsw2boS1a1Po3l3ZsEFYtiyFUaPSueSSdIqKxO94USktLSUrK+vA9VAoRGlpqY+JPKqbQe+4qXUMEckE+gKzRGQlMBU4xl3cBnhVRN4Hrge6Rty1UFX3qepXwGYgdIhVvCkinwPnAE9Xs/wHwCxV3a+qJTiHjEWa7f5djlNYjIlKZeV+1qzZwEUXncVLL91FgwZHUFAw1+9YMdm9G8aPT+fmmyvJzIRwGHbsEJ57roIbbqjkmmvSUfU75XfId6CFkYLzVfMeEdP33GUPAg+pajfgCpwvj1SJ7PwNc+jxkwFAO2AlcHsU+arWc7h1fEPkV+4LCqI+4swkmaysZmRlNaN7d6cffOjQ3qxZs8HfUDGoqHCKxfDh+xkyxDlzRCgEgweHEYGTT1ZSUmDbNp+DRiEUClFSUnLgemlpKaHQoT6T1iPJ3sJQ1Z3AehEZBc7JrUSku7u4Cf/7FuGYaEO530i8BrhURJodtPgtINcdywjhDGjXZBdw1GHWV6CqvVS1V35+1CdyNEmmZcumZGU1Z926LwB4++0P6NAh6tPw+EoVbrkljezs/Vx+efjA/LPOCrN0qbMbWL9eqKiAo4/2K2X0unXrxoYNGyguLqa8vJzCwkIGDhzod6yaJWELo6GIbIyYJgCjgbEisgpYDeS4t70Np6tqOfBVLMFUdRNOl9RVBy16AecEWmuAvwHvATtqeLi/Az+uD4PeEybcyIUXXsr69f/lzDMHM2vW7JrvFADJul2//vUYrrvuzwwffiNr1/6Xn/88p+Y71UPLlwtz5qSyZEkKOTnp5OSk869/pZCbu5/iYuG889KZMCGN3/2uAgngMEZaWhqTJk1i3LhxnHvuuZxzzjl06tTJ71g1S6/FVA+IBrDDUkQyVbVMRJoD7wD93PGMONgbvH/Id9JqvwMkSK7fARJgg98BEim28rpFvO9vmqvvpbw+fg/Di5dFpCmQAfwmfsXCGGPqUD3pavIqkAVDVfv7ncEYY2JWTwazvQpkwTDGmKRgLQxjjDGeWAvDGGOMJxl+B6gdKxjGGOMXa2EYY4zxRII1iGEFwxhjfBOsXXCw0hpjTFIJ1i44WGmNMSapHFnzTeoRKxjGGOObYO2Cg5XWGGOSSrB2wcFKa4wxSSVYu+BgpTXGmKRih9UaY4zxJFi74GClNcaYpGJHSRljjPEkWLvgYKWtE8v9DpAATf0OkADN/Q6QIBv8DhB3mUH8zVePymL+xdJg7YKDldYYY5JKsHbBwUprjDFJJVi74ICdXNcYY5JJWi2mwxORtiLypoisEZHVIvJLd34zEXldRD52/x4dbVorGMYY45sjazHVqBK4VlVPBE4HrhKRE4GJwDxV7QTMc69HxQqGMcb4Jn4tDFXdpKrvuZd3AWuB1kAOMNO92UxgRCxpjTHG+ML7LlhE8oH8iFkFqlpwiNu2B3oCS4GQqm5yF5UAoWiSghUMY4zxkfddsFscqi0QkUQkE3gBuEZVd0rEYc2qqiIS9bHAVjCMMcY38d0Fi0g6TrF4UlVnu7NLReQYVd0kIscAm6N9fBvDMMYY3xxRi+nwxGlKTAfWquo9EYvmAmPcy2OAOdGmtRaGMcb4Jq674H7AT4D3RWSlO+9m4HfAcyIyFvgvcH60K7CCYYwxvonfLlhV/w0c6jwsg+KxDisYxhjjm2DtgoOV1hhjkkqwdsHBSmuMMUklWLvgYKU1xpikYj+gZIwxxpNg7YKDldYYY5JKsHbB9eqLeyISFpGVIvKBiPxdRJq6848Vkec93L/sEPNHuGdt9N26dZvIyZl8YPr+969kxozX/I4VFwMHXsHw4deQkzOBkSOv9ztO3ITDYUaMuJIrruSatd0AAA1TSURBVPi131HiZuHChZx99tkMHjyYgoIazzaRMA9Pn8760lLeef/9apeff/HFLFm1iqVFRbzx1lucdPLJMa8zIyODmc88w6qPP+bNJUs4rl07AAacdRaLli1jaVERi5Yt44cDBsS8rprF7+SDdaFeFQzga1XtoaonAVuBqwBU9QtVzYvhcUcA9aJgZGcfw5w5tzNnzu3Mnj2ZBg0yGDz4+37HipuZM6cwZ849zJ79B7+jxM3jj79Ehw5t/Y4RN+FwmClTpjBt2jQKCwt5+eWX+eSTT3zJ8uSMGYwYOvSQy/+7fj1Df/hDep98Mnf/5jc8WIvidly7drzy5pvfmj9m7Fi2b9tG906d+PO99/Kbu+8GYMtXXzFq+HB6n3wyV4wZw1+feKL2G1RrVjDi5W2cU/MiIu1F5AP3ckMRec79kZAXRWSpiPSqupOI3CEiq0RkiYiERKQv8CPgD27rpYMvW1ONt99eQ9u2rWjduoXfUcwhlJR8yYIF75CXd47fUeKmqKiIdu3a0bZtWzIyMhg2bBjz5s3zJctbixaxbevWQy5f+vbbbN++HYB3lyyhdZs2B5ZdMHo0C5YuZfGKFTzwyCOkpHjbnQ3LyeHJmc7Zvl98/nn6D3K+01a0ciUlm5yTuq5ZvZojGzQgIyMjqu3yzgpGzEQkFeebiXOrWXwlsM39kZBfA6dELGsELFHV7sBC4Gequth9nOvd1suniU3vXWHhO5x3Xm+/Y8SRMHbs7YwceR3PPpsc3Wx33vkI118/jpSUQ32BNnhKS0vJyso6cD0UClFaWupjIm8uHTuW1155BYATunQh94ILOKtfP/r27Ek4HOaC0aM9Pc6xrVuzsbgYcFpbO3bsoHnz5t+4zYjcXFa99x7l5eXx3YhviesPKCVc/Shb/9PAPQdKa5wf/3i9mtv8ALgfQFU/EJGiiGXlwMvu5eXAYC8rjTzP/NSp15OfnxNd+looL69k/vyVXHttbsLXVVeefvoOQqHmbNmyncsvv53s7NacempXv2NF7c03l9CsWVNOOqkTS5eu8jvOd9qZ/fszZuxYBv/gBwD0HzSInqecwsJ33wXgyAYN+HKzcxLWp2fPpt3xx5ORkUGb445j8YoVADx8//38bcaMGtf1vRNPZMrdd5MzZEhiNuYb6tsu+PDqW9qvVbWHiDQEXsUZw3igFvevUNWqc72H8bh93zzP/FtRnyu+NhYufJ+uXdvRokWTulhdnQiFnE9pzZs3ZfDg3hQVfRzogvHee2uYP38JCxe+y7595ZSV7eG66+7mj3+80e9oMQmFQpSUlBy4XlpaSigU9W/qJFzXbt14aNo0Rp5zDlvd7isR4cmZM7nt5pu/dfuLRo4EnDGMqTNmcM5Bg9dffP45bdq25YvPPyc1NZUmTZqwZcsWwGl9PPXii+Rfeinr161L8JYBpNbBOuKnXnZJqeoeYDxwrYgcvNN/C/dsi+6RT908POQu4Ki4hoxRYeFShg07ze8YcbNnz17Kyr4+cPmtt1bRqdNxPqeKzbXX/pSFC59k/vzHueeemzj99O6BLxYA3bp1Y8OGDRQXF1NeXk5hYSEDBw70O1a12rRty1OzZ/Ozn/yETz7++MD8BfPmMSIvj5YtWwJw9NFH0/Y4b6+3f8ydy+gxztm+f5yXx7/mzwegSZMmvFBYyOSJE1myeHGct+RQgjWGUT9SVENVV7jdTRcBiyIWPQzMFJE1wIfAamBHDQ/3DPBXERkP5Pk9jrFnzz4WL17NlCmX+hkjrrZs2c5VVzlHm4TD+znvvDM488zkOformaSlpTFp0iTGjRtHOBwmNzeXTp06+ZLlsaee4oz+/WneogX/KS7mjsmTSU9PB2D61KlMnDSJZs2bc+/DDwNQWVnJmaeeyodr1/KbW29lzmuvkZKSQkVFBROuuorizz6rcZ0zp09n2hNPsOrjj9m2dSuXXXghAFf84hdkd+zIxEmTmDhpEgA5Q4bw5ZdfJmjroR7vgqsl/+vBCQZ3QDxdVfe6Rzy9AZygqnEanaqbLqm61dTvAAnQyO8ACdLe7wBxlynJc8DAwcpUY9y4ObXY3+T4/o8MVnlzNATedH+KUIAr41csjDGmLgVrFxystICq7gJ61XhDY4yp94K1Cw5WWmOMSSrB2gUHK60xxiSVYO2Cg5XWGGOSSrB2wcFKa4wxSaV+nPLDKysYxhjjm2DtgoOV1hhjkkqwdsHBSmuMMUklWLvgYKU1xpikEqxdcLDSGmNMUgnW2WqtYBhjjG/sKCljjDGeBGsXHKy0xhiTVIK1C66XP6BkjDHfDfH9ASURGSoi/xGRT0RkYiLSGmOM8UX8dsHubwX9GRgMbATeFZG5qromXuuwgmGMMb6J66D3acAnqroOQESeAXIAKxiJ069OftVKRPJVtaAu1lWXbLuCo662qayOf9UzYM+V5/2NiOQD+RGzCg7aztZAccT1jUDv2OJ9k41h+Ce/5psEkm1XcCTjNkGSbpeqFqhqr4ipzouiFQxjjEkOnwNtI663cefFjRUMY4xJDu8CnUTkeBHJAC4E5sZzBTaG4Z+g9LHWlm1XcCTjNkHybtdhqWqliPwCeBXnnCOPqurqeK5DtI4HpIwxxgSTdUkZY4zxxAqGMcYYT6xgJIiIlNXiti1FZKmIrBCRM0TkykRmc9fpOV8c1rVBRFp4vO0RIvKGiKwUkQtE5OY4ZcgSkWdE5FMRWS4i/xCRzlE8zmUicmw8Mh1mHXX93LwvIkUi8i8RaRexbLHH+3/ruRWR/iLSN04Zw+7r4QMR+buINHXnHysiz3u4f7X/TxEZISInxiPjd4UVjPphEPC+qvbE+eJNwgtGPdYTQFV7qOqzQMwFQ0QEeBFYoKodVPUU4CYgFMXDXQbUqmCISH0/uGSAqp4MLABurZqpqrHs8PsDcSkYwNfu6+EkYCtwFYCqfqGqeTE87gjACkYtWMGoQyLSQUT+6X7CXSQiXUSkB/B7IEdEVgJ3Ax3cT1R/8DufO394RAvoDREJufNvE5FHRWSBiKwTkfG1WFdLEXlBRN51p34i0gr4G3Cqu/2zgAbu5Sdj2LQBQIWqPlI1Q1VXqeoiEbneXX+RiNzuZmsvImtF5K8islpEXhORBiKSB/QCnnQzNRCRU9xP5stF5FUROcZ9jAUicp+ILAN+GUN23Meri+fmbZxvC1ets8z9myIiD4vIhyLyuts6i9xRXy0i77ktlS4i0h74OfAr9/90RqzbX11G93n6wL3cUESeE5E1IvKi+z/pFbEtd4jIKhFZIiIht/XzI+APbsYOccyYvFTVpgRMQFk18+YBndzLvYH57uXLgIfcy+2BD+pZvqP53xF144A/uZdvAxYDRwAtgC1AejWPuwFocdC8p4AfuJePA9a6l/sDLx8uZxTbOh64t5r5Q3AOwRScD08vA2e6z0El0MO93XPAJe7lBUAv93K6u/0t3esX4BzKWHW7h4P03AD3AfkH5wDygH+4/6MsYBuQF3H/q93LVwLTItZ/XTxfqziHis4Chh78XgGuA6a6l09yn7+q50mB4e7l3wO3updnVG2HTd6m+t5UThoikonTRJ/l9JAAzpu5XqghXxvgWffTcwawPuKuhaq6D9gnIptxunk2eljlWcCJEetq7GaoS0PcaYV7PRPoBHwGrFfVle785Tg7p4OdgLNzet3djlRgU8TyZ+MRsg6emzdFpBlQBvy6muU/AGap6n6gRETePGj5bPfvcmBkrTbOmwZu67s1sBZ4/RAZ7wdQ1Q9EpChiWTnOh4GqjIMTkPE7wQpG3UkBtqtqD7+DHMLh8j0I3KOqc0WkP86nxyr7Ii6H8f6aSgFOV9W9kTMjdojxtBrnU/LBBLhLVacelKE9396uBoe4/2pV7XOI9e6uddLqJfq5GQBsB54Ebgcm1DJf1Xpq8/zXxteq2kNEGuJ8Ke0q4IFa3L9C3SYFicv4nWBjGHVEVXcC60VkFDgDsSLSvZqb7gKOqtNw1JivCf87J82YOK3yNeDqqivuWE51KkQkPcZ1zQeOEOdsn1XrOxnYCfy0qmUjIq3dcZTDiXx+/gO0FJE+7v3TRaRrjFm/pS6eG1WtBK4BLnVbG5HeAnLdsYwQTrdhTeL+OlbVPTjdi9fKtw8keAs4H0CcI5+6+ZEx2VnBSJyGIrIxYpoAjAbGisgqnE+9OQffSVW3AG+JcwhhIge9a5PvNpzukOXAV1GuryhiXffgvPF7iTPYvAZnkLQ6Be59ox70dj9d/hg4S5zDalcDd+GMozwFvC0i7wPPU/MOZAbwiNtFkorTcrnb/Z+tJD5HBtX1cwOAqm4CnsY9CinCCzhdWWtwDkp4D9hRw8P9HfhxvAe9VXUFUARcdNCih3GK9xrgtzj/o5oyPgNc7x4wYIPeHtipQYwxNRKRTFUtE5HmwDtAP1Ut8TtXFXF+bS5dVfe6O/83gBNUtdznaEnF+vKMMV68LM4X5jKA39SnYuFqiDN4n44ztnSlFYv4sxaGMcYYT2wMwxhjjCdWMIwxxnhiBcMYY4wnVjCMMcZ4YgXDGGOMJ/8PCdD8x3uUAN8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(pred_prob_list)):\n",
        "  if len(pred_prob_list) == 1:\n",
        "    pred_prob = pred_prob_list[0]\n",
        "    label_prob = label_prob_list[0]\n",
        "  if len(pred_prob_list) == 2:\n",
        "    pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
        "    label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
        "  if len(pred_prob_list) > 2:\n",
        "    pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
        "    label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
        "    for j in range(len(pred_prob_list)-2):\n",
        "      pred_prob = torch.cat((pred_prob, pred_prob_list[j+2]), -1)\n",
        "      label_prob = torch.cat((label_prob, label_prob_list[j+2]), -1)\n",
        "label_prob = label_prob.cpu()\n",
        "pred_prob = pred_prob.cpu()\n",
        "criterion=nn.L1Loss(reduction=\"mean\")\n",
        "loss=criterion(pred_prob, label_prob)\n",
        "print(\"MAE Value: {}\".format(\"%.4f\" % loss))"
      ],
      "metadata": {
        "id": "CmfvbxV-6L9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1edc7834-84d8-445b-a444-1973f09920aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE Value: 0.0700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score = f1_score(pred_result,label,average=\"macro\")\n",
        "print(\"Macro-F1 Score: {}\".format(\"%.4f\" % f1_score))"
      ],
      "metadata": {
        "id": "5DblSrXM6YAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b92939-6c1a-4d7a-f4eb-1d4957f8f873"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-F1 Score: 0.7911\n"
          ]
        }
      ]
    }
  ]
}