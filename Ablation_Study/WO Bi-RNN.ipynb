{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d5144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4bb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_process1=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\X_train_glove_title.npy\")\n",
    "X_test_process1=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\X_test_glove_title.npy\")\n",
    "X_valid_process1=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\X_valid_glove_title.npy\")\n",
    "y_train_process=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\y_train_glove.npy\")\n",
    "y_test_process=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\y_test_glove.npy\")\n",
    "y_valid_process=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\y_valid_glove.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c25bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(\n",
    "    dataset=Data.TensorDataset(torch.Tensor(X_train_process1),torch.LongTensor(y_train_process)),      \n",
    "    batch_size=128,      \n",
    "    shuffle=True,               \n",
    "    num_workers=0, \n",
    "    drop_last=True\n",
    ")\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=Data.TensorDataset(torch.Tensor(X_test_process1),torch.LongTensor(y_test_process)),      \n",
    "    batch_size=128,      \n",
    "    shuffle=True,               \n",
    "    num_workers=0,  \n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = Data.DataLoader(\n",
    "    dataset=Data.TensorDataset(torch.Tensor(X_valid_process1),torch.LongTensor(y_valid_process)),      \n",
    "    batch_size=128,      \n",
    "    shuffle=True,               \n",
    "    num_workers=0,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef3572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECA(x,gamma=2,b=1):\n",
    "    N,C,H,W=x.size()\n",
    "    t=int(abs((log(C,2)+b)/gamma))\n",
    "    k=t if t%2 else t+1\n",
    "    \n",
    "    avg_pool=nn.AdaptiveAvgPool2d(1).cuda()\n",
    "    conv=nn.Conv1d(1,1,kernel_size=k,padding=int(k/2),bias=False).cuda()\n",
    "    sigmoid=nn.Sigmoid().cuda()\n",
    "    \n",
    "    y=avg_pool(x)\n",
    "    y=conv(y.squeeze(-1).transpose(-1,-2))\n",
    "    y=y.transpose(-1,-2).unsqueeze(-1)\n",
    "    y=sigmoid(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a03d21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRCNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_size,num_labels=5):\n",
    "        super(TextRCNN,self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=hidden_size,\n",
    "                            batch_first=True,bidirectional=False)\n",
    "        self.dropout = nn.Dropout(.3)\n",
    "        self.linear1 = nn.Linear(embedding_dim+hidden_size, 128)\n",
    "        self.linear2 = nn.Linear(600, 128)\n",
    "        self.linear3 = nn.Linear(128, num_labels)\n",
    "        self.conv1 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=6)#通过out_channel改变文中的feature map，且out_channel∈[10,50,100,200,400,600,800,1000]\n",
    "        self.conv2 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=7)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=8)\n",
    "        self.conv4 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=9)\n",
    "        self.w_omiga = torch.randn(128,hidden_size,1,requires_grad=True).cuda()\n",
    "\n",
    "    def forward(self, x):#x: [batch,L]\n",
    "        x_embed = x.cuda()\n",
    "        last_hidden_state,(c,h) = self.lstm(x_embed) #last_hidden_state: [batch,L,hidden_size * num_bidirectional]\n",
    "        H = torch.nn.Tanh()(last_hidden_state)\n",
    "        weights=torch.nn.Softmax(dim=-1)(torch.bmm(H,self.w_omiga).squeeze(-1)).unsqueeze(dim=-1).repeat(1,1,12)  # LSTM+ATTN-Weight\n",
    "        last_hidden_state=torch.mul(last_hidden_state,weights)\n",
    "        out = torch.cat((last_hidden_state[:,:,:12],x_embed,last_hidden_state[:,:,12:]),2)#out: [batch,L,embedding_size + hidden_size * num_bidirectional]  \n",
    "        out = F.tanh(self.linear1(out))\n",
    "        out = out.permute(dims=[0,2,1]) #out: [batch,embedding_size + hidden_size * num_bidirectional,L]\n",
    "        out_1 = self.conv1(out)\n",
    "        out_1 = nn.ReLU()(out_1)\n",
    "        out_1 = nn.MaxPool1d(kernel_size=495)(out_1)\n",
    "        out_2 = self.conv1(out)\n",
    "        out_2 = nn.ReLU()(out_2)\n",
    "        out_2 = nn.MaxPool1d(kernel_size=494)(out_2)\n",
    "        out_3 = self.conv1(out)\n",
    "        out_3 = nn.ReLU()(out_3)\n",
    "        out_3 = nn.MaxPool1d(kernel_size=493)(out_3)\n",
    "        out_4 = self.conv1(out)\n",
    "        out_4 = nn.ReLU()(out_4)\n",
    "        out_4 = nn.MaxPool1d(kernel_size=492)(out_4)\n",
    "        out_1 = out_1.unsqueeze(1).cuda()\n",
    "        out_2 = out_2.unsqueeze(1).cuda()\n",
    "        out_3 = out_3.unsqueeze(1).cuda()\n",
    "        out_4 = out_4.unsqueeze(1).cuda()\n",
    "        out = torch.cat([out_1, out_2, out_3, out_4],dim=1).cuda()\n",
    "        channel_weights = F.softmax(ECA(out).squeeze().squeeze(),dim=1).unsqueeze(-1).unsqueeze(-1).expand_as(out)\n",
    "        out = torch.mul(channel_weights,out)\n",
    "        out = torch.sum(out, dim = 1)\n",
    "        out = self.linear2(out.squeeze()) #out: [batch,num_labels]\n",
    "        out = self.linear3(F.tanh(out))\n",
    "        out = F.softmax(out,dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c53da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextRCNN(5302,200,12).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e91e097",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:[0/16], Current Loss: 1.6075019836425781, Current Training Accuracy: 14.84375, Time: 4.019031047821045 ms\n",
      "Epoch 1:[5/16], Current Loss: 1.5319551229476929, Current Training Accuracy: 28.90625, Time: 0.13763689994812012 ms\n",
      "Epoch 1:[10/16], Current Loss: 1.4671714305877686, Current Training Accuracy: 32.95454545454545, Time: 0.1416490077972412 ms\n",
      "Epoch 1:[15/16], Current Loss: 1.439016342163086, Current Training Accuracy: 39.794921875, Time: 0.14127874374389648 ms\n",
      "Epoch 1, train Loss: 1.506  Avg Training Accuracy: {31 %} Avg Validation Accuracy: 27 % Epoch Time: 7.617933988571167 ms\n",
      "Epoch 2:[0/16], Current Loss: 1.3762669563293457, Current Training Accuracy: 58.59375, Time: 0.14133429527282715 ms\n",
      "Epoch 2:[5/16], Current Loss: 1.349553108215332, Current Training Accuracy: 56.770833333333336, Time: 0.14131569862365723 ms\n",
      "Epoch 2:[10/16], Current Loss: 1.3180567026138306, Current Training Accuracy: 56.17897727272727, Time: 0.13483953475952148 ms\n",
      "Epoch 2:[15/16], Current Loss: 1.3769714832305908, Current Training Accuracy: 55.95703125, Time: 0.14172077178955078 ms\n",
      "Epoch 2, train Loss: 1.349  Avg Training Accuracy: {56 %} Avg Validation Accuracy: 42 % Epoch Time: 3.536273717880249 ms\n",
      "Epoch 3:[0/16], Current Loss: 1.3000805377960205, Current Training Accuracy: 58.59375, Time: 0.12585067749023438 ms\n",
      "Epoch 3:[5/16], Current Loss: 1.3342193365097046, Current Training Accuracy: 60.546875, Time: 0.1421351432800293 ms\n",
      "Epoch 3:[10/16], Current Loss: 1.2521729469299316, Current Training Accuracy: 63.06818181818182, Time: 0.13421916961669922 ms\n",
      "Epoch 3:[15/16], Current Loss: 1.1785180568695068, Current Training Accuracy: 63.916015625, Time: 0.13146400451660156 ms\n",
      "Epoch 3, train Loss: 1.274  Avg Training Accuracy: {61 %} Avg Validation Accuracy: 46 % Epoch Time: 3.51086163520813 ms\n",
      "Epoch 4:[0/16], Current Loss: 1.2529475688934326, Current Training Accuracy: 64.84375, Time: 0.1420140266418457 ms\n",
      "Epoch 4:[5/16], Current Loss: 1.1920760869979858, Current Training Accuracy: 68.88020833333333, Time: 0.13576817512512207 ms\n",
      "Epoch 4:[10/16], Current Loss: 1.2652381658554077, Current Training Accuracy: 69.0340909090909, Time: 0.1255636215209961 ms\n",
      "Epoch 4:[15/16], Current Loss: 1.1827726364135742, Current Training Accuracy: 70.703125, Time: 0.14077210426330566 ms\n",
      "Epoch 4, train Loss: 1.212  Avg Training Accuracy: {69 %} Avg Validation Accuracy: 52 % Epoch Time: 3.508242130279541 ms\n",
      "Epoch 5:[0/16], Current Loss: 1.1594423055648804, Current Training Accuracy: 75.78125, Time: 0.13812613487243652 ms\n",
      "Epoch 5:[5/16], Current Loss: 1.152449369430542, Current Training Accuracy: 72.265625, Time: 0.14403104782104492 ms\n",
      "Epoch 5:[10/16], Current Loss: 1.174044132232666, Current Training Accuracy: 73.08238636363636, Time: 0.14253616333007812 ms\n",
      "Epoch 5:[15/16], Current Loss: 1.2068690061569214, Current Training Accuracy: 73.33984375, Time: 0.14380335807800293 ms\n",
      "Epoch 5, train Loss: 1.177  Avg Training Accuracy: {73 %} Avg Validation Accuracy: 53 % Epoch Time: 3.5642168521881104 ms\n",
      "Epoch 6:[0/16], Current Loss: 1.1703548431396484, Current Training Accuracy: 73.4375, Time: 0.1411733627319336 ms\n",
      "Epoch 6:[5/16], Current Loss: 1.1683958768844604, Current Training Accuracy: 73.69791666666667, Time: 0.13487458229064941 ms\n",
      "Epoch 6:[10/16], Current Loss: 1.1293723583221436, Current Training Accuracy: 76.2784090909091, Time: 0.14381647109985352 ms\n",
      "Epoch 6:[15/16], Current Loss: 1.1683310270309448, Current Training Accuracy: 76.171875, Time: 0.13050031661987305 ms\n",
      "Epoch 6, train Loss: 1.149  Avg Training Accuracy: {75 %} Avg Validation Accuracy: 54 % Epoch Time: 3.4998528957366943 ms\n",
      "Epoch 7:[0/16], Current Loss: 1.1184574365615845, Current Training Accuracy: 78.90625, Time: 0.14110732078552246 ms\n",
      "Epoch 7:[5/16], Current Loss: 1.1002070903778076, Current Training Accuracy: 77.99479166666667, Time: 0.12811279296875 ms\n",
      "Epoch 7:[10/16], Current Loss: 1.1115390062332153, Current Training Accuracy: 79.04829545454545, Time: 0.12633848190307617 ms\n",
      "Epoch 7:[15/16], Current Loss: 1.13844633102417, Current Training Accuracy: 77.83203125, Time: 0.14219117164611816 ms\n",
      "Epoch 7, train Loss: 1.133  Avg Training Accuracy: {78 %} Avg Validation Accuracy: 54 % Epoch Time: 3.5186688899993896 ms\n",
      "Epoch 8:[0/16], Current Loss: 1.1573171615600586, Current Training Accuracy: 75.0, Time: 0.14102387428283691 ms\n",
      "Epoch 8:[5/16], Current Loss: 1.188772439956665, Current Training Accuracy: 76.69270833333333, Time: 0.141432523727417 ms\n",
      "Epoch 8:[10/16], Current Loss: 1.1331701278686523, Current Training Accuracy: 78.33806818181819, Time: 0.13591837882995605 ms\n",
      "Epoch 8:[15/16], Current Loss: 1.1327797174453735, Current Training Accuracy: 78.173828125, Time: 0.13732576370239258 ms\n",
      "Epoch 8, train Loss: 1.125  Avg Training Accuracy: {77 %} Avg Validation Accuracy: 53 % Epoch Time: 3.5238096714019775 ms\n",
      "Epoch 9:[0/16], Current Loss: 1.1215568780899048, Current Training Accuracy: 78.125, Time: 0.14188432693481445 ms\n",
      "Epoch 9:[5/16], Current Loss: 1.0966942310333252, Current Training Accuracy: 79.03645833333333, Time: 0.1392674446105957 ms\n",
      "Epoch 9:[10/16], Current Loss: 1.0981295108795166, Current Training Accuracy: 78.125, Time: 0.14089369773864746 ms\n",
      "Epoch 9:[15/16], Current Loss: 1.1000640392303467, Current Training Accuracy: 79.150390625, Time: 0.13744473457336426 ms\n",
      "Epoch 9, train Loss: 1.113  Avg Training Accuracy: {78 %} Avg Validation Accuracy: 53 % Epoch Time: 3.5534257888793945 ms\n",
      "Epoch 10:[0/16], Current Loss: 1.1388602256774902, Current Training Accuracy: 76.5625, Time: 0.13840365409851074 ms\n",
      "Epoch 10:[5/16], Current Loss: 1.0934419631958008, Current Training Accuracy: 80.078125, Time: 0.14021587371826172 ms\n",
      "Epoch 10:[10/16], Current Loss: 1.1003508567810059, Current Training Accuracy: 79.6875, Time: 0.1407921314239502 ms\n",
      "Epoch 10:[15/16], Current Loss: 1.0879302024841309, Current Training Accuracy: 79.8828125, Time: 0.14044451713562012 ms\n",
      "Epoch 10, train Loss: 1.102  Avg Training Accuracy: {79 %} Avg Validation Accuracy: 55 % Epoch Time: 3.533141613006592 ms\n",
      "Epoch 11:[0/16], Current Loss: 1.1362826824188232, Current Training Accuracy: 75.78125, Time: 0.14104962348937988 ms\n",
      "Epoch 11:[5/16], Current Loss: 1.0787179470062256, Current Training Accuracy: 80.98958333333333, Time: 0.13997483253479004 ms\n",
      "Epoch 11:[10/16], Current Loss: 1.0287396907806396, Current Training Accuracy: 83.0965909090909, Time: 0.14107155799865723 ms\n",
      "Epoch 11:[15/16], Current Loss: 1.0232101678848267, Current Training Accuracy: 84.033203125, Time: 0.14119863510131836 ms\n",
      "Epoch 11, train Loss: 1.073  Avg Training Accuracy: {81 %} Avg Validation Accuracy: 56 % Epoch Time: 3.5423049926757812 ms\n",
      "Epoch 12:[0/16], Current Loss: 1.0525463819503784, Current Training Accuracy: 85.9375, Time: 0.1416635513305664 ms\n",
      "Epoch 12:[5/16], Current Loss: 1.0423585176467896, Current Training Accuracy: 86.71875, Time: 0.1402425765991211 ms\n",
      "Epoch 12:[10/16], Current Loss: 1.0287991762161255, Current Training Accuracy: 86.4346590909091, Time: 0.14319825172424316 ms\n",
      "Epoch 12:[15/16], Current Loss: 1.0169297456741333, Current Training Accuracy: 86.62109375, Time: 0.14036846160888672 ms\n",
      "Epoch 12, train Loss: 1.042  Avg Training Accuracy: {86 %} Avg Validation Accuracy: 58 % Epoch Time: 3.531588554382324 ms\n",
      "Epoch 13:[0/16], Current Loss: 1.0178455114364624, Current Training Accuracy: 88.28125, Time: 0.13129401206970215 ms\n",
      "Epoch 13:[5/16], Current Loss: 1.0580713748931885, Current Training Accuracy: 85.546875, Time: 0.13039660453796387 ms\n",
      "Epoch 13:[10/16], Current Loss: 1.0845212936401367, Current Training Accuracy: 86.50568181818181, Time: 0.13211703300476074 ms\n",
      "Epoch 13:[15/16], Current Loss: 1.031732201576233, Current Training Accuracy: 87.20703125, Time: 0.1410520076751709 ms\n",
      "Epoch 13, train Loss: 1.032  Avg Training Accuracy: {86 %} Avg Validation Accuracy: 60 % Epoch Time: 3.5694761276245117 ms\n",
      "Epoch 14:[0/16], Current Loss: 1.0284605026245117, Current Training Accuracy: 87.5, Time: 0.1412186622619629 ms\n",
      "Epoch 14:[5/16], Current Loss: 1.011644721031189, Current Training Accuracy: 87.63020833333333, Time: 0.1359858512878418 ms\n",
      "Epoch 14:[10/16], Current Loss: 1.0268255472183228, Current Training Accuracy: 88.28125, Time: 0.14104628562927246 ms\n",
      "Epoch 14:[15/16], Current Loss: 1.0591826438903809, Current Training Accuracy: 87.646484375, Time: 0.14106082916259766 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, train Loss: 1.027  Avg Training Accuracy: {88 %} Avg Validation Accuracy: 61 % Epoch Time: 3.5386321544647217 ms\n",
      "Epoch 15:[0/16], Current Loss: 1.0033000707626343, Current Training Accuracy: 89.84375, Time: 0.14220237731933594 ms\n",
      "Epoch 15:[5/16], Current Loss: 1.0193434953689575, Current Training Accuracy: 89.0625, Time: 0.14106488227844238 ms\n",
      "Epoch 15:[10/16], Current Loss: 1.0275229215621948, Current Training Accuracy: 88.42329545454545, Time: 0.14180731773376465 ms\n",
      "Epoch 15:[15/16], Current Loss: 1.0091497898101807, Current Training Accuracy: 88.232421875, Time: 0.1415092945098877 ms\n",
      "Epoch 15, train Loss: 1.020  Avg Training Accuracy: {88 %} Avg Validation Accuracy: 60 % Epoch Time: 3.542747974395752 ms\n",
      "Epoch 16:[0/16], Current Loss: 1.0059016942977905, Current Training Accuracy: 89.0625, Time: 0.1415872573852539 ms\n",
      "Epoch 16:[5/16], Current Loss: 0.9870454668998718, Current Training Accuracy: 89.84375, Time: 0.14568567276000977 ms\n",
      "Epoch 16:[10/16], Current Loss: 0.9918349981307983, Current Training Accuracy: 91.83238636363636, Time: 0.1459507942199707 ms\n",
      "Epoch 16:[15/16], Current Loss: 1.032523512840271, Current Training Accuracy: 92.3828125, Time: 0.13985681533813477 ms\n",
      "Epoch 16, train Loss: 0.998  Avg Training Accuracy: {90 %} Avg Validation Accuracy: 59 % Epoch Time: 3.5663068294525146 ms\n",
      "Epoch 17:[0/16], Current Loss: 0.9618672132492065, Current Training Accuracy: 96.09375, Time: 0.1270766258239746 ms\n",
      "Epoch 17:[5/16], Current Loss: 0.97139573097229, Current Training Accuracy: 93.22916666666667, Time: 0.14107179641723633 ms\n",
      "Epoch 17:[10/16], Current Loss: 0.992068886756897, Current Training Accuracy: 93.82102272727273, Time: 0.14595913887023926 ms\n",
      "Epoch 17:[15/16], Current Loss: 0.9797640442848206, Current Training Accuracy: 93.9453125, Time: 0.1419825553894043 ms\n",
      "Epoch 17, train Loss: 0.980  Avg Training Accuracy: {93 %} Avg Validation Accuracy: 60 % Epoch Time: 3.6048073768615723 ms\n",
      "Epoch 18:[0/16], Current Loss: 0.9509808421134949, Current Training Accuracy: 97.65625, Time: 0.14260411262512207 ms\n",
      "Epoch 18:[5/16], Current Loss: 0.9576614499092102, Current Training Accuracy: 96.484375, Time: 0.14018654823303223 ms\n",
      "Epoch 18:[10/16], Current Loss: 0.9846038222312927, Current Training Accuracy: 95.88068181818181, Time: 0.14051294326782227 ms\n",
      "Epoch 18:[15/16], Current Loss: 0.9582473635673523, Current Training Accuracy: 95.458984375, Time: 0.14061331748962402 ms\n",
      "Epoch 18, train Loss: 0.965  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 61 % Epoch Time: 3.608119249343872 ms\n",
      "Epoch 19:[0/16], Current Loss: 0.9511616826057434, Current Training Accuracy: 96.875, Time: 0.1452162265777588 ms\n",
      "Epoch 19:[5/16], Current Loss: 0.9303790330886841, Current Training Accuracy: 98.046875, Time: 0.1262340545654297 ms\n",
      "Epoch 19:[10/16], Current Loss: 0.9456159472465515, Current Training Accuracy: 97.65625, Time: 0.12491297721862793 ms\n",
      "Epoch 19:[15/16], Current Loss: 0.9233489036560059, Current Training Accuracy: 96.923828125, Time: 0.15285563468933105 ms\n",
      "Epoch 19, train Loss: 0.945  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 3.5758585929870605 ms\n",
      "Epoch 20:[0/16], Current Loss: 0.9317171573638916, Current Training Accuracy: 97.65625, Time: 0.14347505569458008 ms\n",
      "Epoch 20:[5/16], Current Loss: 0.9493998885154724, Current Training Accuracy: 97.65625, Time: 0.14012622833251953 ms\n",
      "Epoch 20:[10/16], Current Loss: 0.9357476234436035, Current Training Accuracy: 97.30113636363636, Time: 0.12900519371032715 ms\n",
      "Epoch 20:[15/16], Current Loss: 0.9359669089317322, Current Training Accuracy: 97.314453125, Time: 0.14467620849609375 ms\n",
      "Epoch 20, train Loss: 0.937  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 62 % Epoch Time: 3.5833563804626465 ms\n",
      "Epoch 21:[0/16], Current Loss: 0.9254531264305115, Current Training Accuracy: 98.4375, Time: 0.13994073867797852 ms\n",
      "Epoch 21:[5/16], Current Loss: 0.9219964146614075, Current Training Accuracy: 98.17708333333333, Time: 0.14063525199890137 ms\n",
      "Epoch 21:[10/16], Current Loss: 0.9303120374679565, Current Training Accuracy: 97.86931818181819, Time: 0.13205528259277344 ms\n",
      "Epoch 21:[15/16], Current Loss: 0.9443451166152954, Current Training Accuracy: 97.412109375, Time: 0.1408994197845459 ms\n",
      "Epoch 21, train Loss: 0.933  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.5587069988250732 ms\n",
      "Epoch 22:[0/16], Current Loss: 0.9209069013595581, Current Training Accuracy: 98.4375, Time: 0.1385798454284668 ms\n",
      "Epoch 22:[5/16], Current Loss: 0.9222474694252014, Current Training Accuracy: 97.65625, Time: 0.14073872566223145 ms\n",
      "Epoch 22:[10/16], Current Loss: 0.938044011592865, Current Training Accuracy: 97.1590909090909, Time: 0.14108824729919434 ms\n",
      "Epoch 22:[15/16], Current Loss: 0.9144979119300842, Current Training Accuracy: 97.509765625, Time: 0.1426999568939209 ms\n",
      "Epoch 22, train Loss: 0.931  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.5696263313293457 ms\n",
      "Epoch 23:[0/16], Current Loss: 0.9435755610466003, Current Training Accuracy: 96.09375, Time: 0.14224839210510254 ms\n",
      "Epoch 23:[5/16], Current Loss: 0.9146933555603027, Current Training Accuracy: 97.39583333333333, Time: 0.1407325267791748 ms\n",
      "Epoch 23:[10/16], Current Loss: 0.9210907816886902, Current Training Accuracy: 97.44318181818181, Time: 0.1409740447998047 ms\n",
      "Epoch 23:[15/16], Current Loss: 0.9217830300331116, Current Training Accuracy: 97.55859375, Time: 0.15243124961853027 ms\n",
      "Epoch 23, train Loss: 0.930  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.586014747619629 ms\n",
      "Epoch 24:[0/16], Current Loss: 0.9217108488082886, Current Training Accuracy: 98.4375, Time: 0.14003276824951172 ms\n",
      "Epoch 24:[5/16], Current Loss: 0.9514211416244507, Current Training Accuracy: 97.52604166666667, Time: 0.1444234848022461 ms\n",
      "Epoch 24:[10/16], Current Loss: 0.9369872212409973, Current Training Accuracy: 97.51420454545455, Time: 0.14130330085754395 ms\n",
      "Epoch 24:[15/16], Current Loss: 0.9151760339736938, Current Training Accuracy: 97.607421875, Time: 0.14177298545837402 ms\n",
      "Epoch 24, train Loss: 0.930  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.5967533588409424 ms\n",
      "Epoch 25:[0/16], Current Loss: 0.905826210975647, Current Training Accuracy: 100.0, Time: 0.14021968841552734 ms\n",
      "Epoch 25:[5/16], Current Loss: 0.9428208470344543, Current Training Accuracy: 98.046875, Time: 0.14174556732177734 ms\n",
      "Epoch 25:[10/16], Current Loss: 0.9290456771850586, Current Training Accuracy: 97.72727272727273, Time: 0.14696311950683594 ms\n",
      "Epoch 25:[15/16], Current Loss: 0.9206451177597046, Current Training Accuracy: 97.607421875, Time: 0.13703632354736328 ms\n",
      "Epoch 25, train Loss: 0.929  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.5984537601470947 ms\n",
      "Epoch 26:[0/16], Current Loss: 0.9137778282165527, Current Training Accuracy: 99.21875, Time: 0.13912296295166016 ms\n",
      "Epoch 26:[5/16], Current Loss: 0.9206234216690063, Current Training Accuracy: 98.046875, Time: 0.14330816268920898 ms\n",
      "Epoch 26:[10/16], Current Loss: 0.9287900328636169, Current Training Accuracy: 97.72727272727273, Time: 0.139754056930542 ms\n",
      "Epoch 26:[15/16], Current Loss: 0.9283179044723511, Current Training Accuracy: 97.65625, Time: 0.14132285118103027 ms\n",
      "Epoch 26, train Loss: 0.929  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.594975233078003 ms\n",
      "Epoch 27:[0/16], Current Loss: 0.9284189343452454, Current Training Accuracy: 97.65625, Time: 0.14163517951965332 ms\n",
      "Epoch 27:[5/16], Current Loss: 0.9279472827911377, Current Training Accuracy: 97.52604166666667, Time: 0.14220690727233887 ms\n",
      "Epoch 27:[10/16], Current Loss: 0.9207088351249695, Current Training Accuracy: 97.65625, Time: 0.13249683380126953 ms\n",
      "Epoch 27:[15/16], Current Loss: 0.9212084412574768, Current Training Accuracy: 97.65625, Time: 0.12995409965515137 ms\n",
      "Epoch 27, train Loss: 0.929  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.5988612174987793 ms\n",
      "Epoch 28:[0/16], Current Loss: 0.928003191947937, Current Training Accuracy: 97.65625, Time: 0.14201951026916504 ms\n",
      "Epoch 28:[5/16], Current Loss: 0.913318395614624, Current Training Accuracy: 98.30729166666667, Time: 0.13166213035583496 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:[10/16], Current Loss: 0.9513014554977417, Current Training Accuracy: 97.79829545454545, Time: 0.12944626808166504 ms\n",
      "Epoch 28:[15/16], Current Loss: 0.9285399913787842, Current Training Accuracy: 97.65625, Time: 0.14265680313110352 ms\n",
      "Epoch 28, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.5816354751586914 ms\n",
      "Epoch 29:[0/16], Current Loss: 0.9212614893913269, Current Training Accuracy: 98.4375, Time: 0.1414787769317627 ms\n",
      "Epoch 29:[5/16], Current Loss: 0.9203563332557678, Current Training Accuracy: 98.046875, Time: 0.14145255088806152 ms\n",
      "Epoch 29:[10/16], Current Loss: 0.9212549924850464, Current Training Accuracy: 97.72727272727273, Time: 0.15076208114624023 ms\n",
      "Epoch 29:[15/16], Current Loss: 0.928885817527771, Current Training Accuracy: 97.65625, Time: 0.14111995697021484 ms\n",
      "Epoch 29, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.566263437271118 ms\n",
      "Epoch 30:[0/16], Current Loss: 0.9355369806289673, Current Training Accuracy: 96.875, Time: 0.14687061309814453 ms\n",
      "Epoch 30:[5/16], Current Loss: 0.9287700057029724, Current Training Accuracy: 98.30729166666667, Time: 0.14150452613830566 ms\n",
      "Epoch 30:[10/16], Current Loss: 0.9444546103477478, Current Training Accuracy: 97.9403409090909, Time: 0.1409919261932373 ms\n",
      "Epoch 30:[15/16], Current Loss: 0.9366275668144226, Current Training Accuracy: 97.65625, Time: 0.15264296531677246 ms\n",
      "Epoch 30, train Loss: 0.928  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.5838987827301025 ms\n",
      "Epoch 31:[0/16], Current Loss: 0.9429614543914795, Current Training Accuracy: 96.09375, Time: 0.14031004905700684 ms\n",
      "Epoch 31:[5/16], Current Loss: 0.9132270216941833, Current Training Accuracy: 98.17708333333333, Time: 0.14717507362365723 ms\n",
      "Epoch 31:[10/16], Current Loss: 0.9427066445350647, Current Training Accuracy: 97.86931818181819, Time: 0.14061737060546875 ms\n",
      "Epoch 31:[15/16], Current Loss: 0.9365578889846802, Current Training Accuracy: 97.705078125, Time: 0.1463460922241211 ms\n",
      "Epoch 31, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6053757667541504 ms\n",
      "Epoch 32:[0/16], Current Loss: 0.9284242391586304, Current Training Accuracy: 97.65625, Time: 0.14799714088439941 ms\n",
      "Epoch 32:[5/16], Current Loss: 0.9209091663360596, Current Training Accuracy: 98.30729166666667, Time: 0.13950324058532715 ms\n",
      "Epoch 32:[10/16], Current Loss: 0.9210910797119141, Current Training Accuracy: 97.72727272727273, Time: 0.14489054679870605 ms\n",
      "Epoch 32:[15/16], Current Loss: 0.9208275675773621, Current Training Accuracy: 97.705078125, Time: 0.14196419715881348 ms\n",
      "Epoch 32, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5679986476898193 ms\n",
      "Epoch 33:[0/16], Current Loss: 0.927301287651062, Current Training Accuracy: 97.65625, Time: 0.1398618221282959 ms\n",
      "Epoch 33:[5/16], Current Loss: 0.9125111699104309, Current Training Accuracy: 98.17708333333333, Time: 0.1420149803161621 ms\n",
      "Epoch 33:[10/16], Current Loss: 0.9288392663002014, Current Training Accuracy: 97.86931818181819, Time: 0.14005494117736816 ms\n",
      "Epoch 33:[15/16], Current Loss: 0.935466468334198, Current Training Accuracy: 97.65625, Time: 0.1394636631011963 ms\n",
      "Epoch 33, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5661497116088867 ms\n",
      "Epoch 34:[0/16], Current Loss: 0.9365304112434387, Current Training Accuracy: 96.875, Time: 0.14308428764343262 ms\n",
      "Epoch 34:[5/16], Current Loss: 0.9429486393928528, Current Training Accuracy: 97.39583333333333, Time: 0.1400132179260254 ms\n",
      "Epoch 34:[10/16], Current Loss: 0.9132664203643799, Current Training Accuracy: 97.58522727272727, Time: 0.14017486572265625 ms\n",
      "Epoch 34:[15/16], Current Loss: 0.9355935454368591, Current Training Accuracy: 97.65625, Time: 0.14006638526916504 ms\n",
      "Epoch 34, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.585488796234131 ms\n",
      "Epoch 35:[0/16], Current Loss: 0.9575080871582031, Current Training Accuracy: 94.53125, Time: 0.14109492301940918 ms\n",
      "Epoch 35:[5/16], Current Loss: 0.9274322986602783, Current Training Accuracy: 97.265625, Time: 0.1405339241027832 ms\n",
      "Epoch 35:[10/16], Current Loss: 0.9203149080276489, Current Training Accuracy: 97.58522727272727, Time: 0.1446666717529297 ms\n",
      "Epoch 35:[15/16], Current Loss: 0.9437170028686523, Current Training Accuracy: 97.65625, Time: 0.14093613624572754 ms\n",
      "Epoch 35, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.5978195667266846 ms\n",
      "Epoch 36:[0/16], Current Loss: 0.9209470152854919, Current Training Accuracy: 98.4375, Time: 0.14014649391174316 ms\n",
      "Epoch 36:[5/16], Current Loss: 0.9209423661231995, Current Training Accuracy: 98.30729166666667, Time: 0.14316558837890625 ms\n",
      "Epoch 36:[10/16], Current Loss: 0.9204202890396118, Current Training Accuracy: 97.86931818181819, Time: 0.14034175872802734 ms\n",
      "Epoch 36:[15/16], Current Loss: 0.9188950061798096, Current Training Accuracy: 97.65625, Time: 0.14359354972839355 ms\n",
      "Epoch 36, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6202609539031982 ms\n",
      "Epoch 37:[0/16], Current Loss: 0.9274322986602783, Current Training Accuracy: 97.65625, Time: 0.14150238037109375 ms\n",
      "Epoch 37:[5/16], Current Loss: 0.9132837057113647, Current Training Accuracy: 98.17708333333333, Time: 0.13819599151611328 ms\n",
      "Epoch 37:[10/16], Current Loss: 0.935620903968811, Current Training Accuracy: 97.9403409090909, Time: 0.14114046096801758 ms\n",
      "Epoch 37:[15/16], Current Loss: 0.9280411005020142, Current Training Accuracy: 97.705078125, Time: 0.142411470413208 ms\n",
      "Epoch 37, train Loss: 0.928  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.5977416038513184 ms\n",
      "Epoch 38:[0/16], Current Loss: 0.9288418889045715, Current Training Accuracy: 97.65625, Time: 0.14128446578979492 ms\n",
      "Epoch 38:[5/16], Current Loss: 0.9275283813476562, Current Training Accuracy: 97.78645833333333, Time: 0.141737699508667 ms\n",
      "Epoch 38:[10/16], Current Loss: 0.9052537679672241, Current Training Accuracy: 97.9403409090909, Time: 0.14137053489685059 ms\n",
      "Epoch 38:[15/16], Current Loss: 0.9359028339385986, Current Training Accuracy: 97.705078125, Time: 0.142228364944458 ms\n",
      "Epoch 38, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.606778860092163 ms\n",
      "Epoch 39:[0/16], Current Loss: 0.9431684613227844, Current Training Accuracy: 96.09375, Time: 0.14494633674621582 ms\n",
      "Epoch 39:[5/16], Current Loss: 0.9281297326087952, Current Training Accuracy: 98.17708333333333, Time: 0.13315701484680176 ms\n",
      "Epoch 39:[10/16], Current Loss: 0.9270265102386475, Current Training Accuracy: 98.08238636363636, Time: 0.1409304141998291 ms\n",
      "Epoch 39:[15/16], Current Loss: 0.9359229207038879, Current Training Accuracy: 97.705078125, Time: 0.14122939109802246 ms\n",
      "Epoch 39, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.5703136920928955 ms\n",
      "Epoch 40:[0/16], Current Loss: 0.9358724355697632, Current Training Accuracy: 96.875, Time: 0.1413741111755371 ms\n",
      "Epoch 40:[5/16], Current Loss: 0.9288010597229004, Current Training Accuracy: 97.91666666666667, Time: 0.13768219947814941 ms\n",
      "Epoch 40:[10/16], Current Loss: 0.935872495174408, Current Training Accuracy: 97.79829545454545, Time: 0.13907194137573242 ms\n",
      "Epoch 40:[15/16], Current Loss: 0.9286121726036072, Current Training Accuracy: 97.705078125, Time: 0.14432072639465332 ms\n",
      "Epoch 40, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.587564468383789 ms\n",
      "Epoch 41:[0/16], Current Loss: 0.9203986525535583, Current Training Accuracy: 98.4375, Time: 0.12864279747009277 ms\n",
      "Epoch 41:[5/16], Current Loss: 0.9286175966262817, Current Training Accuracy: 97.78645833333333, Time: 0.1387331485748291 ms\n",
      "Epoch 41:[10/16], Current Loss: 0.9207989573478699, Current Training Accuracy: 97.65625, Time: 0.14158225059509277 ms\n",
      "Epoch 41:[15/16], Current Loss: 0.920798659324646, Current Training Accuracy: 97.705078125, Time: 0.13941740989685059 ms\n",
      "Epoch 41, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5885279178619385 ms\n",
      "Epoch 42:[0/16], Current Loss: 0.9202961921691895, Current Training Accuracy: 98.4375, Time: 0.13946962356567383 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42:[5/16], Current Loss: 0.9509543180465698, Current Training Accuracy: 98.17708333333333, Time: 0.14353656768798828 ms\n",
      "Epoch 42:[10/16], Current Loss: 0.928616464138031, Current Training Accuracy: 97.79829545454545, Time: 0.12857627868652344 ms\n",
      "Epoch 42:[15/16], Current Loss: 0.9124367833137512, Current Training Accuracy: 97.705078125, Time: 0.14521503448486328 ms\n",
      "Epoch 42, train Loss: 0.928  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6025636196136475 ms\n",
      "Epoch 43:[0/16], Current Loss: 0.9129838943481445, Current Training Accuracy: 99.21875, Time: 0.14175152778625488 ms\n",
      "Epoch 43:[5/16], Current Loss: 0.9213383197784424, Current Training Accuracy: 97.91666666666667, Time: 0.13064885139465332 ms\n",
      "Epoch 43:[10/16], Current Loss: 0.9435888528823853, Current Training Accuracy: 97.58522727272727, Time: 0.14136576652526855 ms\n",
      "Epoch 43:[15/16], Current Loss: 0.9197825789451599, Current Training Accuracy: 97.75390625, Time: 0.14076495170593262 ms\n",
      "Epoch 43, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.5937418937683105 ms\n",
      "Epoch 44:[0/16], Current Loss: 0.9362165927886963, Current Training Accuracy: 96.875, Time: 0.13735508918762207 ms\n",
      "Epoch 44:[5/16], Current Loss: 0.9429112076759338, Current Training Accuracy: 97.91666666666667, Time: 0.13857197761535645 ms\n",
      "Epoch 44:[10/16], Current Loss: 0.9275456666946411, Current Training Accuracy: 97.23011363636364, Time: 0.15447473526000977 ms\n",
      "Epoch 44:[15/16], Current Loss: 0.912472665309906, Current Training Accuracy: 97.75390625, Time: 0.15082955360412598 ms\n",
      "Epoch 44, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6010334491729736 ms\n",
      "Epoch 45:[0/16], Current Loss: 0.9201171398162842, Current Training Accuracy: 98.4375, Time: 0.12813377380371094 ms\n",
      "Epoch 45:[5/16], Current Loss: 0.9207412600517273, Current Training Accuracy: 97.265625, Time: 0.14170265197753906 ms\n",
      "Epoch 45:[10/16], Current Loss: 0.919996976852417, Current Training Accuracy: 97.72727272727273, Time: 0.13091063499450684 ms\n",
      "Epoch 45:[15/16], Current Loss: 0.9505379796028137, Current Training Accuracy: 97.75390625, Time: 0.1273059844970703 ms\n",
      "Epoch 45, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.570667028427124 ms\n",
      "Epoch 46:[0/16], Current Loss: 0.9201279878616333, Current Training Accuracy: 98.4375, Time: 0.1340179443359375 ms\n",
      "Epoch 46:[5/16], Current Loss: 0.935737669467926, Current Training Accuracy: 97.91666666666667, Time: 0.14222025871276855 ms\n",
      "Epoch 46:[10/16], Current Loss: 0.9279909133911133, Current Training Accuracy: 97.86931818181819, Time: 0.14041924476623535 ms\n",
      "Epoch 46:[15/16], Current Loss: 0.935722291469574, Current Training Accuracy: 97.75390625, Time: 0.14766335487365723 ms\n",
      "Epoch 46, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.61318039894104 ms\n",
      "Epoch 47:[0/16], Current Loss: 0.9205266237258911, Current Training Accuracy: 98.4375, Time: 0.14273500442504883 ms\n",
      "Epoch 47:[5/16], Current Loss: 0.9051759243011475, Current Training Accuracy: 98.30729166666667, Time: 0.1388247013092041 ms\n",
      "Epoch 47:[10/16], Current Loss: 0.9123697280883789, Current Training Accuracy: 97.9403409090909, Time: 0.13579583168029785 ms\n",
      "Epoch 47:[15/16], Current Loss: 0.9353338479995728, Current Training Accuracy: 97.802734375, Time: 0.12630176544189453 ms\n",
      "Epoch 47, train Loss: 0.927  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.592010021209717 ms\n",
      "Epoch 48:[0/16], Current Loss: 0.9195772409439087, Current Training Accuracy: 98.4375, Time: 0.1380324363708496 ms\n",
      "Epoch 48:[5/16], Current Loss: 0.9437998533248901, Current Training Accuracy: 98.4375, Time: 0.15663719177246094 ms\n",
      "Epoch 48:[10/16], Current Loss: 0.9359551668167114, Current Training Accuracy: 97.65625, Time: 0.1410062313079834 ms\n",
      "Epoch 48:[15/16], Current Loss: 0.9202896952629089, Current Training Accuracy: 97.8515625, Time: 0.14083600044250488 ms\n",
      "Epoch 48, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.556222438812256 ms\n",
      "Epoch 49:[0/16], Current Loss: 0.912905216217041, Current Training Accuracy: 99.21875, Time: 0.1407456398010254 ms\n",
      "Epoch 49:[5/16], Current Loss: 0.9198888540267944, Current Training Accuracy: 98.046875, Time: 0.1436767578125 ms\n",
      "Epoch 49:[10/16], Current Loss: 0.9277910590171814, Current Training Accuracy: 97.79829545454545, Time: 0.14117097854614258 ms\n",
      "Epoch 49:[15/16], Current Loss: 0.9207392334938049, Current Training Accuracy: 97.802734375, Time: 0.1411130428314209 ms\n",
      "Epoch 49, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5698037147521973 ms\n",
      "Epoch 50:[0/16], Current Loss: 0.9284958839416504, Current Training Accuracy: 97.65625, Time: 0.141465425491333 ms\n",
      "Epoch 50:[5/16], Current Loss: 0.9051197171211243, Current Training Accuracy: 98.69791666666667, Time: 0.1420590877532959 ms\n",
      "Epoch 50:[10/16], Current Loss: 0.935531497001648, Current Training Accuracy: 97.79829545454545, Time: 0.14166736602783203 ms\n",
      "Epoch 50:[15/16], Current Loss: 0.9201368093490601, Current Training Accuracy: 97.8515625, Time: 0.13909530639648438 ms\n",
      "Epoch 50, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.56005859375 ms\n",
      "Epoch 51:[0/16], Current Loss: 0.9280115962028503, Current Training Accuracy: 97.65625, Time: 0.14106345176696777 ms\n",
      "Epoch 51:[5/16], Current Loss: 0.9285035729408264, Current Training Accuracy: 98.4375, Time: 0.14136528968811035 ms\n",
      "Epoch 51:[10/16], Current Loss: 0.9424167275428772, Current Training Accuracy: 97.9403409090909, Time: 0.14145135879516602 ms\n",
      "Epoch 51:[15/16], Current Loss: 0.9428721070289612, Current Training Accuracy: 97.8515625, Time: 0.14072346687316895 ms\n",
      "Epoch 51, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5727949142456055 ms\n",
      "Epoch 52:[0/16], Current Loss: 0.9347435832023621, Current Training Accuracy: 96.875, Time: 0.1436917781829834 ms\n",
      "Epoch 52:[5/16], Current Loss: 0.9431847929954529, Current Training Accuracy: 98.30729166666667, Time: 0.1456620693206787 ms\n",
      "Epoch 52:[10/16], Current Loss: 0.9269230365753174, Current Training Accuracy: 98.08238636363636, Time: 0.12678933143615723 ms\n",
      "Epoch 52:[15/16], Current Loss: 0.9430055618286133, Current Training Accuracy: 97.802734375, Time: 0.14931225776672363 ms\n",
      "Epoch 52, train Loss: 0.927  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.579047441482544 ms\n",
      "Epoch 53:[0/16], Current Loss: 0.9206777811050415, Current Training Accuracy: 98.4375, Time: 0.14330530166625977 ms\n",
      "Epoch 53:[5/16], Current Loss: 0.9122541546821594, Current Training Accuracy: 97.65625, Time: 0.14070415496826172 ms\n",
      "Epoch 53:[10/16], Current Loss: 0.9206505417823792, Current Training Accuracy: 97.86931818181819, Time: 0.13033485412597656 ms\n",
      "Epoch 53:[15/16], Current Loss: 0.9284908771514893, Current Training Accuracy: 97.802734375, Time: 0.14191174507141113 ms\n",
      "Epoch 53, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.567578077316284 ms\n",
      "Epoch 54:[0/16], Current Loss: 0.9285060167312622, Current Training Accuracy: 97.65625, Time: 0.14702320098876953 ms\n",
      "Epoch 54:[5/16], Current Loss: 0.9349260330200195, Current Training Accuracy: 97.78645833333333, Time: 0.13693547248840332 ms\n",
      "Epoch 54:[10/16], Current Loss: 0.9276776909828186, Current Training Accuracy: 97.44318181818181, Time: 0.1378159523010254 ms\n",
      "Epoch 54:[15/16], Current Loss: 0.9206588268280029, Current Training Accuracy: 97.802734375, Time: 0.14679312705993652 ms\n",
      "Epoch 54, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5784668922424316 ms\n",
      "Epoch 55:[0/16], Current Loss: 0.9278251528739929, Current Training Accuracy: 97.65625, Time: 0.127793550491333 ms\n",
      "Epoch 55:[5/16], Current Loss: 0.9199907779693604, Current Training Accuracy: 98.046875, Time: 0.13219547271728516 ms\n",
      "Epoch 55:[10/16], Current Loss: 0.9274407029151917, Current Training Accuracy: 97.51420454545455, Time: 0.1400926113128662 ms\n",
      "Epoch 55:[15/16], Current Loss: 0.9206318855285645, Current Training Accuracy: 97.802734375, Time: 0.14119243621826172 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.5564768314361572 ms\n",
      "Epoch 56:[0/16], Current Loss: 0.9050432443618774, Current Training Accuracy: 100.0, Time: 0.14526987075805664 ms\n",
      "Epoch 56:[5/16], Current Loss: 0.9503771662712097, Current Training Accuracy: 97.52604166666667, Time: 0.13290047645568848 ms\n",
      "Epoch 56:[10/16], Current Loss: 0.9206733703613281, Current Training Accuracy: 97.44318181818181, Time: 0.13190460205078125 ms\n",
      "Epoch 56:[15/16], Current Loss: 0.9362900257110596, Current Training Accuracy: 97.802734375, Time: 0.1416466236114502 ms\n",
      "Epoch 56, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5621700286865234 ms\n",
      "Epoch 57:[0/16], Current Loss: 0.9203278422355652, Current Training Accuracy: 98.4375, Time: 0.14459753036499023 ms\n",
      "Epoch 57:[5/16], Current Loss: 0.9513049721717834, Current Training Accuracy: 98.17708333333333, Time: 0.15574049949645996 ms\n",
      "Epoch 57:[10/16], Current Loss: 0.9275374412536621, Current Training Accuracy: 98.01136363636364, Time: 0.13948392868041992 ms\n",
      "Epoch 57:[15/16], Current Loss: 0.9108684062957764, Current Training Accuracy: 97.802734375, Time: 0.14090323448181152 ms\n",
      "Epoch 57, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.571094274520874 ms\n",
      "Epoch 58:[0/16], Current Loss: 0.919244110584259, Current Training Accuracy: 98.4375, Time: 0.12891149520874023 ms\n",
      "Epoch 58:[5/16], Current Loss: 0.9285897016525269, Current Training Accuracy: 97.65625, Time: 0.13533735275268555 ms\n",
      "Epoch 58:[10/16], Current Loss: 0.9051735997200012, Current Training Accuracy: 98.01136363636364, Time: 0.13095545768737793 ms\n",
      "Epoch 58:[15/16], Current Loss: 0.9129414558410645, Current Training Accuracy: 97.8515625, Time: 0.1429579257965088 ms\n",
      "Epoch 58, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.590956687927246 ms\n",
      "Epoch 59:[0/16], Current Loss: 0.9427603483200073, Current Training Accuracy: 96.09375, Time: 0.13966870307922363 ms\n",
      "Epoch 59:[5/16], Current Loss: 0.9273005723953247, Current Training Accuracy: 97.78645833333333, Time: 0.13270020484924316 ms\n",
      "Epoch 59:[10/16], Current Loss: 0.933691143989563, Current Training Accuracy: 97.65625, Time: 0.12522339820861816 ms\n",
      "Epoch 59:[15/16], Current Loss: 0.9149042963981628, Current Training Accuracy: 97.900390625, Time: 0.13647198677062988 ms\n",
      "Epoch 59, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 68 % Epoch Time: 3.558073043823242 ms\n",
      "Epoch 60:[0/16], Current Loss: 0.9358454942703247, Current Training Accuracy: 96.875, Time: 0.13793492317199707 ms\n",
      "Epoch 60:[5/16], Current Loss: 0.9223374724388123, Current Training Accuracy: 98.30729166666667, Time: 0.1406693458557129 ms\n",
      "Epoch 60:[10/16], Current Loss: 0.9128416776657104, Current Training Accuracy: 97.79829545454545, Time: 0.12663936614990234 ms\n",
      "Epoch 60:[15/16], Current Loss: 0.9132663607597351, Current Training Accuracy: 97.94921875, Time: 0.13944268226623535 ms\n",
      "Epoch 60, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.5502758026123047 ms\n",
      "Epoch 61:[0/16], Current Loss: 0.9210508465766907, Current Training Accuracy: 98.4375, Time: 0.14252519607543945 ms\n",
      "Epoch 61:[5/16], Current Loss: 0.9585980772972107, Current Training Accuracy: 97.39583333333333, Time: 0.14149141311645508 ms\n",
      "Epoch 61:[10/16], Current Loss: 0.9288933873176575, Current Training Accuracy: 97.72727272727273, Time: 0.13737130165100098 ms\n",
      "Epoch 61:[15/16], Current Loss: 0.9200564622879028, Current Training Accuracy: 97.94921875, Time: 0.14099335670471191 ms\n",
      "Epoch 61, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6096079349517822 ms\n",
      "Epoch 62:[0/16], Current Loss: 0.9283093214035034, Current Training Accuracy: 97.65625, Time: 0.1280684471130371 ms\n",
      "Epoch 62:[5/16], Current Loss: 0.9279065728187561, Current Training Accuracy: 98.046875, Time: 0.14490056037902832 ms\n",
      "Epoch 62:[10/16], Current Loss: 0.9362409114837646, Current Training Accuracy: 97.72727272727273, Time: 0.14039039611816406 ms\n",
      "Epoch 62:[15/16], Current Loss: 0.9360549449920654, Current Training Accuracy: 97.94921875, Time: 0.13988947868347168 ms\n",
      "Epoch 62, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.600480556488037 ms\n",
      "Epoch 63:[0/16], Current Loss: 0.9275270104408264, Current Training Accuracy: 97.65625, Time: 0.1409904956817627 ms\n",
      "Epoch 63:[5/16], Current Loss: 0.9206762313842773, Current Training Accuracy: 97.52604166666667, Time: 0.1383206844329834 ms\n",
      "Epoch 63:[10/16], Current Loss: 0.904985249042511, Current Training Accuracy: 98.22443181818181, Time: 0.128068208694458 ms\n",
      "Epoch 63:[15/16], Current Loss: 0.9207014441490173, Current Training Accuracy: 97.94921875, Time: 0.14130711555480957 ms\n",
      "Epoch 63, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.602644205093384 ms\n",
      "Epoch 64:[0/16], Current Loss: 0.912832498550415, Current Training Accuracy: 99.21875, Time: 0.1453075408935547 ms\n",
      "Epoch 64:[5/16], Current Loss: 0.9282733798027039, Current Training Accuracy: 98.17708333333333, Time: 0.14122462272644043 ms\n",
      "Epoch 64:[10/16], Current Loss: 0.9354920387268066, Current Training Accuracy: 98.1534090909091, Time: 0.13332557678222656 ms\n",
      "Epoch 64:[15/16], Current Loss: 0.9285670518875122, Current Training Accuracy: 98.046875, Time: 0.1457977294921875 ms\n",
      "Epoch 64, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.585476875305176 ms\n",
      "Epoch 65:[0/16], Current Loss: 0.9286879301071167, Current Training Accuracy: 97.65625, Time: 0.12803411483764648 ms\n",
      "Epoch 65:[5/16], Current Loss: 0.9645283222198486, Current Training Accuracy: 97.91666666666667, Time: 0.14145755767822266 ms\n",
      "Epoch 65:[10/16], Current Loss: 0.9212367534637451, Current Training Accuracy: 98.01136363636364, Time: 0.12577486038208008 ms\n",
      "Epoch 65:[15/16], Current Loss: 0.9204984307289124, Current Training Accuracy: 97.998046875, Time: 0.14043664932250977 ms\n",
      "Epoch 65, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.5713393688201904 ms\n",
      "Epoch 66:[0/16], Current Loss: 0.9128771424293518, Current Training Accuracy: 99.21875, Time: 0.12895512580871582 ms\n",
      "Epoch 66:[5/16], Current Loss: 0.9206591844558716, Current Training Accuracy: 98.046875, Time: 0.15302753448486328 ms\n",
      "Epoch 66:[10/16], Current Loss: 0.9139567613601685, Current Training Accuracy: 97.86931818181819, Time: 0.13188886642456055 ms\n",
      "Epoch 66:[15/16], Current Loss: 0.9349653720855713, Current Training Accuracy: 97.998046875, Time: 0.13587188720703125 ms\n",
      "Epoch 66, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.546754837036133 ms\n",
      "Epoch 67:[0/16], Current Loss: 0.9188100695610046, Current Training Accuracy: 98.4375, Time: 0.1410388946533203 ms\n",
      "Epoch 67:[5/16], Current Loss: 0.9284564852714539, Current Training Accuracy: 98.17708333333333, Time: 0.1272416114807129 ms\n",
      "Epoch 67:[10/16], Current Loss: 0.9366607666015625, Current Training Accuracy: 98.36647727272727, Time: 0.12870383262634277 ms\n",
      "Epoch 67:[15/16], Current Loss: 0.9438308477401733, Current Training Accuracy: 98.14453125, Time: 0.14177227020263672 ms\n",
      "Epoch 67, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 62 % Epoch Time: 3.595214366912842 ms\n",
      "Epoch 68:[0/16], Current Loss: 0.9201763272285461, Current Training Accuracy: 98.4375, Time: 0.1340181827545166 ms\n",
      "Epoch 68:[5/16], Current Loss: 0.9290493726730347, Current Training Accuracy: 97.65625, Time: 0.14292001724243164 ms\n",
      "Epoch 68:[10/16], Current Loss: 0.9129693508148193, Current Training Accuracy: 98.01136363636364, Time: 0.13843059539794922 ms\n",
      "Epoch 68:[15/16], Current Loss: 0.9206531643867493, Current Training Accuracy: 98.046875, Time: 0.13079357147216797 ms\n",
      "Epoch 68, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.55643367767334 ms\n",
      "Epoch 69:[0/16], Current Loss: 0.9360610246658325, Current Training Accuracy: 96.875, Time: 0.13631677627563477 ms\n",
      "Epoch 69:[5/16], Current Loss: 0.9137230515480042, Current Training Accuracy: 97.65625, Time: 0.14098739624023438 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69:[10/16], Current Loss: 0.9358502626419067, Current Training Accuracy: 97.9403409090909, Time: 0.14504694938659668 ms\n",
      "Epoch 69:[15/16], Current Loss: 0.9205892086029053, Current Training Accuracy: 98.046875, Time: 0.1410083770751953 ms\n",
      "Epoch 69, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5685837268829346 ms\n",
      "Epoch 70:[0/16], Current Loss: 0.9281234741210938, Current Training Accuracy: 97.65625, Time: 0.12726926803588867 ms\n",
      "Epoch 70:[5/16], Current Loss: 0.9281975030899048, Current Training Accuracy: 97.91666666666667, Time: 0.13766026496887207 ms\n",
      "Epoch 70:[10/16], Current Loss: 0.9346131682395935, Current Training Accuracy: 97.72727272727273, Time: 0.12709879875183105 ms\n",
      "Epoch 70:[15/16], Current Loss: 0.9206150770187378, Current Training Accuracy: 98.046875, Time: 0.14168357849121094 ms\n",
      "Epoch 70, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5692951679229736 ms\n",
      "Epoch 71:[0/16], Current Loss: 0.9204203486442566, Current Training Accuracy: 98.4375, Time: 0.1419386863708496 ms\n",
      "Epoch 71:[5/16], Current Loss: 0.9206153154373169, Current Training Accuracy: 97.52604166666667, Time: 0.1415081024169922 ms\n",
      "Epoch 71:[10/16], Current Loss: 0.9206945896148682, Current Training Accuracy: 98.01136363636364, Time: 0.14198899269104004 ms\n",
      "Epoch 71:[15/16], Current Loss: 0.9053924679756165, Current Training Accuracy: 98.046875, Time: 0.14143896102905273 ms\n",
      "Epoch 71, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5588762760162354 ms\n",
      "Epoch 72:[0/16], Current Loss: 0.9288170337677002, Current Training Accuracy: 97.65625, Time: 0.14522147178649902 ms\n",
      "Epoch 72:[5/16], Current Loss: 0.9282552599906921, Current Training Accuracy: 97.91666666666667, Time: 0.13897013664245605 ms\n",
      "Epoch 72:[10/16], Current Loss: 0.9128081202507019, Current Training Accuracy: 97.86931818181819, Time: 0.14145588874816895 ms\n",
      "Epoch 72:[15/16], Current Loss: 0.9206118583679199, Current Training Accuracy: 98.095703125, Time: 0.14197373390197754 ms\n",
      "Epoch 72, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.5698251724243164 ms\n",
      "Epoch 73:[0/16], Current Loss: 0.9205780029296875, Current Training Accuracy: 98.4375, Time: 0.14183473587036133 ms\n",
      "Epoch 73:[5/16], Current Loss: 0.9122324585914612, Current Training Accuracy: 98.69791666666667, Time: 0.1417865753173828 ms\n",
      "Epoch 73:[10/16], Current Loss: 0.9127700924873352, Current Training Accuracy: 98.4375, Time: 0.14190244674682617 ms\n",
      "Epoch 73:[15/16], Current Loss: 0.9278977513313293, Current Training Accuracy: 98.095703125, Time: 0.1416780948638916 ms\n",
      "Epoch 73, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.539079427719116 ms\n",
      "Epoch 74:[0/16], Current Loss: 0.9273009300231934, Current Training Accuracy: 97.65625, Time: 0.1258094310760498 ms\n",
      "Epoch 74:[5/16], Current Loss: 0.9355816841125488, Current Training Accuracy: 97.78645833333333, Time: 0.14015984535217285 ms\n",
      "Epoch 74:[10/16], Current Loss: 0.9283245205879211, Current Training Accuracy: 98.08238636363636, Time: 0.12685847282409668 ms\n",
      "Epoch 74:[15/16], Current Loss: 0.9201855659484863, Current Training Accuracy: 98.095703125, Time: 0.14042377471923828 ms\n",
      "Epoch 74, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.5763704776763916 ms\n",
      "Epoch 75:[0/16], Current Loss: 0.9428339600563049, Current Training Accuracy: 96.09375, Time: 0.13955283164978027 ms\n",
      "Epoch 75:[5/16], Current Loss: 0.9049543738365173, Current Training Accuracy: 97.65625, Time: 0.14102435111999512 ms\n",
      "Epoch 75:[10/16], Current Loss: 0.928354799747467, Current Training Accuracy: 97.9403409090909, Time: 0.1381058692932129 ms\n",
      "Epoch 75:[15/16], Current Loss: 0.9279972314834595, Current Training Accuracy: 98.095703125, Time: 0.14118075370788574 ms\n",
      "Epoch 75, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5668606758117676 ms\n",
      "Epoch 76:[0/16], Current Loss: 0.9511977434158325, Current Training Accuracy: 95.3125, Time: 0.14224934577941895 ms\n",
      "Epoch 76:[5/16], Current Loss: 0.92795330286026, Current Training Accuracy: 97.52604166666667, Time: 0.14136147499084473 ms\n",
      "Epoch 76:[10/16], Current Loss: 0.9123153686523438, Current Training Accuracy: 97.9403409090909, Time: 0.14212536811828613 ms\n",
      "Epoch 76:[15/16], Current Loss: 0.9049264192581177, Current Training Accuracy: 98.14453125, Time: 0.14027714729309082 ms\n",
      "Epoch 76, train Loss: 0.923  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.589085578918457 ms\n",
      "Epoch 77:[0/16], Current Loss: 0.9049356579780579, Current Training Accuracy: 100.0, Time: 0.14177656173706055 ms\n",
      "Epoch 77:[5/16], Current Loss: 0.9049724340438843, Current Training Accuracy: 98.56770833333333, Time: 0.14036202430725098 ms\n",
      "Epoch 77:[10/16], Current Loss: 0.9127019047737122, Current Training Accuracy: 98.1534090909091, Time: 0.1414024829864502 ms\n",
      "Epoch 77:[15/16], Current Loss: 0.9200964570045471, Current Training Accuracy: 98.095703125, Time: 0.1262216567993164 ms\n",
      "Epoch 77, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.575315475463867 ms\n",
      "Epoch 78:[0/16], Current Loss: 0.9198709726333618, Current Training Accuracy: 98.4375, Time: 0.14053988456726074 ms\n",
      "Epoch 78:[5/16], Current Loss: 0.9127255082130432, Current Training Accuracy: 97.91666666666667, Time: 0.13640499114990234 ms\n",
      "Epoch 78:[10/16], Current Loss: 0.9204135537147522, Current Training Accuracy: 97.9403409090909, Time: 0.12598204612731934 ms\n",
      "Epoch 78:[15/16], Current Loss: 0.9361881017684937, Current Training Accuracy: 98.095703125, Time: 0.13759899139404297 ms\n",
      "Epoch 78, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.599229097366333 ms\n",
      "Epoch 79:[0/16], Current Loss: 0.951649010181427, Current Training Accuracy: 95.3125, Time: 0.13684940338134766 ms\n",
      "Epoch 79:[5/16], Current Loss: 0.9199731349945068, Current Training Accuracy: 98.046875, Time: 0.12580156326293945 ms\n",
      "Epoch 79:[10/16], Current Loss: 0.9352098107337952, Current Training Accuracy: 98.08238636363636, Time: 0.14173030853271484 ms\n",
      "Epoch 79:[15/16], Current Loss: 0.9127368330955505, Current Training Accuracy: 98.095703125, Time: 0.13863134384155273 ms\n",
      "Epoch 79, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5851337909698486 ms\n",
      "Epoch 80:[0/16], Current Loss: 0.9277999997138977, Current Training Accuracy: 97.65625, Time: 0.14938926696777344 ms\n",
      "Epoch 80:[5/16], Current Loss: 0.9283599257469177, Current Training Accuracy: 98.30729166666667, Time: 0.14209914207458496 ms\n",
      "Epoch 80:[10/16], Current Loss: 0.9127283096313477, Current Training Accuracy: 98.01136363636364, Time: 0.14998269081115723 ms\n",
      "Epoch 80:[15/16], Current Loss: 0.9283341765403748, Current Training Accuracy: 98.095703125, Time: 0.14128708839416504 ms\n",
      "Epoch 80, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5959455966949463 ms\n",
      "Epoch 81:[0/16], Current Loss: 0.9205448627471924, Current Training Accuracy: 98.4375, Time: 0.14371895790100098 ms\n",
      "Epoch 81:[5/16], Current Loss: 0.9126995205879211, Current Training Accuracy: 98.95833333333333, Time: 0.1414487361907959 ms\n",
      "Epoch 81:[10/16], Current Loss: 0.912144660949707, Current Training Accuracy: 98.29545454545455, Time: 0.13770461082458496 ms\n",
      "Epoch 81:[15/16], Current Loss: 0.912571907043457, Current Training Accuracy: 98.095703125, Time: 0.14208483695983887 ms\n",
      "Epoch 81, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5713083744049072 ms\n",
      "Epoch 82:[0/16], Current Loss: 0.9194167256355286, Current Training Accuracy: 98.4375, Time: 0.1414327621459961 ms\n",
      "Epoch 82:[5/16], Current Loss: 0.9429527521133423, Current Training Accuracy: 98.046875, Time: 0.1420001983642578 ms\n",
      "Epoch 82:[10/16], Current Loss: 0.91273432970047, Current Training Accuracy: 98.01136363636364, Time: 0.14664530754089355 ms\n",
      "Epoch 82:[15/16], Current Loss: 0.9348371624946594, Current Training Accuracy: 98.095703125, Time: 0.13812875747680664 ms\n",
      "Epoch 82, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5521843433380127 ms\n",
      "Epoch 83:[0/16], Current Loss: 0.9201329350471497, Current Training Accuracy: 98.4375, Time: 0.14188742637634277 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83:[5/16], Current Loss: 0.9205332398414612, Current Training Accuracy: 97.91666666666667, Time: 0.13185405731201172 ms\n",
      "Epoch 83:[10/16], Current Loss: 0.9277511835098267, Current Training Accuracy: 98.01136363636364, Time: 0.14235854148864746 ms\n",
      "Epoch 83:[15/16], Current Loss: 0.951785683631897, Current Training Accuracy: 98.095703125, Time: 0.14075684547424316 ms\n",
      "Epoch 83, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.566251754760742 ms\n",
      "Epoch 84:[0/16], Current Loss: 0.9049168825149536, Current Training Accuracy: 100.0, Time: 0.12947821617126465 ms\n",
      "Epoch 84:[5/16], Current Loss: 0.935030460357666, Current Training Accuracy: 97.65625, Time: 0.13989686965942383 ms\n",
      "Epoch 84:[10/16], Current Loss: 0.9049116373062134, Current Training Accuracy: 97.9403409090909, Time: 0.14136576652526855 ms\n",
      "Epoch 84:[15/16], Current Loss: 0.9049314260482788, Current Training Accuracy: 98.095703125, Time: 0.1384742259979248 ms\n",
      "Epoch 84, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5779058933258057 ms\n",
      "Epoch 85:[0/16], Current Loss: 0.9425023794174194, Current Training Accuracy: 96.09375, Time: 0.14663410186767578 ms\n",
      "Epoch 85:[5/16], Current Loss: 0.9049245119094849, Current Training Accuracy: 98.30729166666667, Time: 0.14200687408447266 ms\n",
      "Epoch 85:[10/16], Current Loss: 0.9205317497253418, Current Training Accuracy: 98.01136363636364, Time: 0.1258394718170166 ms\n",
      "Epoch 85:[15/16], Current Loss: 0.9283550977706909, Current Training Accuracy: 98.095703125, Time: 0.15702390670776367 ms\n",
      "Epoch 85, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.578303813934326 ms\n",
      "Epoch 86:[0/16], Current Loss: 0.9746263027191162, Current Training Accuracy: 92.96875, Time: 0.14185214042663574 ms\n",
      "Epoch 86:[5/16], Current Loss: 0.9127538800239563, Current Training Accuracy: 97.65625, Time: 0.13584327697753906 ms\n",
      "Epoch 86:[10/16], Current Loss: 0.9127179980278015, Current Training Accuracy: 97.86931818181819, Time: 0.14254498481750488 ms\n",
      "Epoch 86:[15/16], Current Loss: 0.9199605584144592, Current Training Accuracy: 98.14453125, Time: 0.14088964462280273 ms\n",
      "Epoch 86, train Loss: 0.923  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.569387197494507 ms\n",
      "Epoch 87:[0/16], Current Loss: 0.9205389022827148, Current Training Accuracy: 98.4375, Time: 0.1433877944946289 ms\n",
      "Epoch 87:[5/16], Current Loss: 0.9361610412597656, Current Training Accuracy: 98.046875, Time: 0.12617158889770508 ms\n",
      "Epoch 87:[10/16], Current Loss: 0.9121290445327759, Current Training Accuracy: 98.1534090909091, Time: 0.12962961196899414 ms\n",
      "Epoch 87:[15/16], Current Loss: 0.9277770519256592, Current Training Accuracy: 98.095703125, Time: 0.1420283317565918 ms\n",
      "Epoch 87, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.5563817024230957 ms\n",
      "Epoch 88:[0/16], Current Loss: 0.9199364185333252, Current Training Accuracy: 98.4375, Time: 0.15125322341918945 ms\n",
      "Epoch 88:[5/16], Current Loss: 0.9205447435379028, Current Training Accuracy: 97.52604166666667, Time: 0.1338958740234375 ms\n",
      "Epoch 88:[10/16], Current Loss: 0.9127218127250671, Current Training Accuracy: 97.86931818181819, Time: 0.14194846153259277 ms\n",
      "Epoch 88:[15/16], Current Loss: 0.9205394387245178, Current Training Accuracy: 98.14453125, Time: 0.1422135829925537 ms\n",
      "Epoch 88, train Loss: 0.923  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.586388111114502 ms\n",
      "Epoch 89:[0/16], Current Loss: 0.9277929067611694, Current Training Accuracy: 97.65625, Time: 0.13383269309997559 ms\n",
      "Epoch 89:[5/16], Current Loss: 0.9205294251441956, Current Training Accuracy: 98.30729166666667, Time: 0.14540719985961914 ms\n",
      "Epoch 89:[10/16], Current Loss: 0.9049142003059387, Current Training Accuracy: 98.22443181818181, Time: 0.14124035835266113 ms\n",
      "Epoch 89:[15/16], Current Loss: 0.9198176860809326, Current Training Accuracy: 98.095703125, Time: 0.14104557037353516 ms\n",
      "Epoch 89, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5795717239379883 ms\n",
      "Epoch 90:[0/16], Current Loss: 0.9439516067504883, Current Training Accuracy: 96.09375, Time: 0.14100217819213867 ms\n",
      "Epoch 90:[5/16], Current Loss: 0.9439332485198975, Current Training Accuracy: 97.39583333333333, Time: 0.13471746444702148 ms\n",
      "Epoch 90:[10/16], Current Loss: 0.9348257184028625, Current Training Accuracy: 97.72727272727273, Time: 0.14165234565734863 ms\n",
      "Epoch 90:[15/16], Current Loss: 0.9124430418014526, Current Training Accuracy: 98.095703125, Time: 0.12905383110046387 ms\n",
      "Epoch 90, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.574932336807251 ms\n",
      "Epoch 91:[0/16], Current Loss: 0.9283371567726135, Current Training Accuracy: 97.65625, Time: 0.14107799530029297 ms\n",
      "Epoch 91:[5/16], Current Loss: 0.9205339550971985, Current Training Accuracy: 98.17708333333333, Time: 0.1416330337524414 ms\n",
      "Epoch 91:[10/16], Current Loss: 0.9120423793792725, Current Training Accuracy: 98.36647727272727, Time: 0.1264798641204834 ms\n",
      "Epoch 91:[15/16], Current Loss: 0.928360641002655, Current Training Accuracy: 98.095703125, Time: 0.14146184921264648 ms\n",
      "Epoch 91, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.558941125869751 ms\n",
      "Epoch 92:[0/16], Current Loss: 0.9127222895622253, Current Training Accuracy: 99.21875, Time: 0.13950276374816895 ms\n",
      "Epoch 92:[5/16], Current Loss: 0.9127323627471924, Current Training Accuracy: 98.828125, Time: 0.13767123222351074 ms\n",
      "Epoch 92:[10/16], Current Loss: 0.9510462880134583, Current Training Accuracy: 98.1534090909091, Time: 0.14100122451782227 ms\n",
      "Epoch 92:[15/16], Current Loss: 0.9205334782600403, Current Training Accuracy: 98.095703125, Time: 0.14098119735717773 ms\n",
      "Epoch 92, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.695777416229248 ms\n",
      "Epoch 93:[0/16], Current Loss: 0.9048987627029419, Current Training Accuracy: 100.0, Time: 0.141981840133667 ms\n",
      "Epoch 93:[5/16], Current Loss: 0.9127107262611389, Current Training Accuracy: 98.17708333333333, Time: 0.1400008201599121 ms\n",
      "Epoch 93:[10/16], Current Loss: 0.919988751411438, Current Training Accuracy: 97.9403409090909, Time: 0.1411292552947998 ms\n",
      "Epoch 93:[15/16], Current Loss: 0.9355658292770386, Current Training Accuracy: 98.14453125, Time: 0.14401555061340332 ms\n",
      "Epoch 93, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6418685913085938 ms\n",
      "Epoch 94:[0/16], Current Loss: 0.9121143817901611, Current Training Accuracy: 99.21875, Time: 0.14004087448120117 ms\n",
      "Epoch 94:[5/16], Current Loss: 0.912731409072876, Current Training Accuracy: 98.95833333333333, Time: 0.141984224319458 ms\n",
      "Epoch 94:[10/16], Current Loss: 0.9121562242507935, Current Training Accuracy: 98.57954545454545, Time: 0.14000606536865234 ms\n",
      "Epoch 94:[15/16], Current Loss: 0.936140239238739, Current Training Accuracy: 98.095703125, Time: 0.13998675346374512 ms\n",
      "Epoch 94, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6562983989715576 ms\n",
      "Epoch 95:[0/16], Current Loss: 0.9355000853538513, Current Training Accuracy: 96.875, Time: 0.14299941062927246 ms\n",
      "Epoch 95:[5/16], Current Loss: 0.9281697273254395, Current Training Accuracy: 97.78645833333333, Time: 0.1399827003479004 ms\n",
      "Epoch 95:[10/16], Current Loss: 0.9283367395401001, Current Training Accuracy: 98.22443181818181, Time: 0.1399831771850586 ms\n",
      "Epoch 95:[15/16], Current Loss: 0.9200202226638794, Current Training Accuracy: 98.095703125, Time: 0.14000201225280762 ms\n",
      "Epoch 95, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.689948558807373 ms\n",
      "Epoch 96:[0/16], Current Loss: 0.9127135872840881, Current Training Accuracy: 99.21875, Time: 0.14410161972045898 ms\n",
      "Epoch 96:[5/16], Current Loss: 0.9205285906791687, Current Training Accuracy: 98.56770833333333, Time: 0.14304256439208984 ms\n",
      "Epoch 96:[10/16], Current Loss: 0.9127196073532104, Current Training Accuracy: 98.22443181818181, Time: 0.1419990062713623 ms\n",
      "Epoch 96:[15/16], Current Loss: 0.9361375570297241, Current Training Accuracy: 98.095703125, Time: 0.14200258255004883 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.710014581680298 ms\n",
      "Epoch 97:[0/16], Current Loss: 0.9283245205879211, Current Training Accuracy: 97.65625, Time: 0.14400219917297363 ms\n",
      "Epoch 97:[5/16], Current Loss: 0.9198125004768372, Current Training Accuracy: 97.65625, Time: 0.14101791381835938 ms\n",
      "Epoch 97:[10/16], Current Loss: 0.9049016237258911, Current Training Accuracy: 97.86931818181819, Time: 0.14199542999267578 ms\n",
      "Epoch 97:[15/16], Current Loss: 0.9120703935623169, Current Training Accuracy: 98.095703125, Time: 0.14201831817626953 ms\n",
      "Epoch 97, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6629834175109863 ms\n",
      "Epoch 98:[0/16], Current Loss: 0.9434607625007629, Current Training Accuracy: 96.09375, Time: 0.14002561569213867 ms\n",
      "Epoch 98:[5/16], Current Loss: 0.9048936367034912, Current Training Accuracy: 98.17708333333333, Time: 0.14500188827514648 ms\n",
      "Epoch 98:[10/16], Current Loss: 0.9354450106620789, Current Training Accuracy: 98.08238636363636, Time: 0.14300155639648438 ms\n",
      "Epoch 98:[15/16], Current Loss: 0.9205038547515869, Current Training Accuracy: 98.095703125, Time: 0.14099907875061035 ms\n",
      "Epoch 98, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6570329666137695 ms\n",
      "Epoch 99:[0/16], Current Loss: 0.935621976852417, Current Training Accuracy: 96.875, Time: 0.1399989128112793 ms\n",
      "Epoch 99:[5/16], Current Loss: 0.9283340573310852, Current Training Accuracy: 97.52604166666667, Time: 0.14099812507629395 ms\n",
      "Epoch 99:[10/16], Current Loss: 0.9361611604690552, Current Training Accuracy: 97.9403409090909, Time: 0.14100050926208496 ms\n",
      "Epoch 99:[15/16], Current Loss: 0.9120503664016724, Current Training Accuracy: 98.095703125, Time: 0.1420001983642578 ms\n",
      "Epoch 99, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.626990795135498 ms\n",
      "Epoch 100:[0/16], Current Loss: 0.9283179640769958, Current Training Accuracy: 97.65625, Time: 0.14200210571289062 ms\n",
      "Epoch 100:[5/16], Current Loss: 0.9198419451713562, Current Training Accuracy: 98.17708333333333, Time: 0.14100122451782227 ms\n",
      "Epoch 100:[10/16], Current Loss: 0.9420453310012817, Current Training Accuracy: 97.9403409090909, Time: 0.14200067520141602 ms\n",
      "Epoch 100:[15/16], Current Loss: 0.9205166101455688, Current Training Accuracy: 98.095703125, Time: 0.14000344276428223 ms\n",
      "Epoch 100, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.616954803466797 ms\n",
      "Epoch 101:[0/16], Current Loss: 0.9360380172729492, Current Training Accuracy: 96.875, Time: 0.14099979400634766 ms\n",
      "Epoch 101:[5/16], Current Loss: 0.9049009680747986, Current Training Accuracy: 98.046875, Time: 0.14100027084350586 ms\n",
      "Epoch 101:[10/16], Current Loss: 0.9348558783531189, Current Training Accuracy: 97.58522727272727, Time: 0.14100050926208496 ms\n",
      "Epoch 101:[15/16], Current Loss: 0.9127287864685059, Current Training Accuracy: 98.095703125, Time: 0.14200067520141602 ms\n",
      "Epoch 101, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.63200044631958 ms\n",
      "Epoch 102:[0/16], Current Loss: 0.9205054044723511, Current Training Accuracy: 98.4375, Time: 0.14200067520141602 ms\n",
      "Epoch 102:[5/16], Current Loss: 0.9070137739181519, Current Training Accuracy: 98.4375, Time: 0.143021821975708 ms\n",
      "Epoch 102:[10/16], Current Loss: 0.920512855052948, Current Training Accuracy: 98.08238636363636, Time: 0.14299941062927246 ms\n",
      "Epoch 102:[15/16], Current Loss: 0.9367077350616455, Current Training Accuracy: 98.14453125, Time: 0.14100027084350586 ms\n",
      "Epoch 102, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.67799973487854 ms\n",
      "Epoch 103:[0/16], Current Loss: 0.9362747669219971, Current Training Accuracy: 96.875, Time: 0.14300012588500977 ms\n",
      "Epoch 103:[5/16], Current Loss: 0.9050050377845764, Current Training Accuracy: 98.30729166666667, Time: 0.14400029182434082 ms\n",
      "Epoch 103:[10/16], Current Loss: 0.9514206051826477, Current Training Accuracy: 98.01136363636364, Time: 0.1419999599456787 ms\n",
      "Epoch 103:[15/16], Current Loss: 0.9363478422164917, Current Training Accuracy: 98.046875, Time: 0.1419992446899414 ms\n",
      "Epoch 103, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6420018672943115 ms\n",
      "Epoch 104:[0/16], Current Loss: 0.9430543184280396, Current Training Accuracy: 96.09375, Time: 0.14099884033203125 ms\n",
      "Epoch 104:[5/16], Current Loss: 0.9127260446548462, Current Training Accuracy: 97.39583333333333, Time: 0.14100050926208496 ms\n",
      "Epoch 104:[10/16], Current Loss: 0.9289000034332275, Current Training Accuracy: 97.9403409090909, Time: 0.14100074768066406 ms\n",
      "Epoch 104:[15/16], Current Loss: 0.9434515237808228, Current Training Accuracy: 97.998046875, Time: 0.14100050926208496 ms\n",
      "Epoch 104, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.626117706298828 ms\n",
      "Epoch 105:[0/16], Current Loss: 0.9439173340797424, Current Training Accuracy: 96.09375, Time: 0.1400003433227539 ms\n",
      "Epoch 105:[5/16], Current Loss: 1.0139909982681274, Current Training Accuracy: 91.92708333333333, Time: 0.1419994831085205 ms\n",
      "Epoch 105:[10/16], Current Loss: 0.9652438759803772, Current Training Accuracy: 93.39488636363636, Time: 0.14099979400634766 ms\n",
      "Epoch 105:[15/16], Current Loss: 0.9275537729263306, Current Training Accuracy: 93.798828125, Time: 0.141998291015625 ms\n",
      "Epoch 105, train Loss: 0.968  Avg Training Accuracy: {93 %} Avg Validation Accuracy: 61 % Epoch Time: 3.6249985694885254 ms\n",
      "Epoch 106:[0/16], Current Loss: 0.9505919814109802, Current Training Accuracy: 96.09375, Time: 0.1410057544708252 ms\n",
      "Epoch 106:[5/16], Current Loss: 0.9275971055030823, Current Training Accuracy: 96.875, Time: 0.14500141143798828 ms\n",
      "Epoch 106:[10/16], Current Loss: 0.9536339640617371, Current Training Accuracy: 96.09375, Time: 0.14100289344787598 ms\n",
      "Epoch 106:[15/16], Current Loss: 0.9245487451553345, Current Training Accuracy: 96.2890625, Time: 0.14400029182434082 ms\n",
      "Epoch 106, train Loss: 0.945  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 62 % Epoch Time: 3.6409850120544434 ms\n",
      "Epoch 107:[0/16], Current Loss: 0.9203121066093445, Current Training Accuracy: 98.4375, Time: 0.14399957656860352 ms\n",
      "Epoch 107:[5/16], Current Loss: 0.9139317274093628, Current Training Accuracy: 97.39583333333333, Time: 0.1420001983642578 ms\n",
      "Epoch 107:[10/16], Current Loss: 0.9198023080825806, Current Training Accuracy: 97.72727272727273, Time: 0.14399981498718262 ms\n",
      "Epoch 107:[15/16], Current Loss: 0.9696863889694214, Current Training Accuracy: 97.265625, Time: 0.14100193977355957 ms\n",
      "Epoch 107, train Loss: 0.935  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6899967193603516 ms\n",
      "Epoch 108:[0/16], Current Loss: 0.9790558815002441, Current Training Accuracy: 92.96875, Time: 0.14200067520141602 ms\n",
      "Epoch 108:[5/16], Current Loss: 0.9130480289459229, Current Training Accuracy: 96.22395833333333, Time: 0.1419975757598877 ms\n",
      "Epoch 108:[10/16], Current Loss: 0.9426044225692749, Current Training Accuracy: 96.66193181818181, Time: 0.14100193977355957 ms\n",
      "Epoch 108:[15/16], Current Loss: 0.9231299757957458, Current Training Accuracy: 97.216796875, Time: 0.14400005340576172 ms\n",
      "Epoch 108, train Loss: 0.935  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6479971408843994 ms\n",
      "Epoch 109:[0/16], Current Loss: 0.913454532623291, Current Training Accuracy: 99.21875, Time: 0.1439986228942871 ms\n",
      "Epoch 109:[5/16], Current Loss: 0.9210752248764038, Current Training Accuracy: 98.30729166666667, Time: 0.14299917221069336 ms\n",
      "Epoch 109:[10/16], Current Loss: 0.936126172542572, Current Training Accuracy: 98.29545454545455, Time: 0.1400001049041748 ms\n",
      "Epoch 109:[15/16], Current Loss: 0.9280986189842224, Current Training Accuracy: 98.193359375, Time: 0.1419963836669922 ms\n",
      "Epoch 109, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6490426063537598 ms\n",
      "Epoch 110:[0/16], Current Loss: 0.9366016983985901, Current Training Accuracy: 96.875, Time: 0.1419999599456787 ms\n",
      "Epoch 110:[5/16], Current Loss: 0.9305539131164551, Current Training Accuracy: 98.30729166666667, Time: 0.14400291442871094 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110:[10/16], Current Loss: 0.9361006021499634, Current Training Accuracy: 98.08238636363636, Time: 0.14299750328063965 ms\n",
      "Epoch 110:[15/16], Current Loss: 0.9287777543067932, Current Training Accuracy: 98.2421875, Time: 0.14099955558776855 ms\n",
      "Epoch 110, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6559560298919678 ms\n",
      "Epoch 111:[0/16], Current Loss: 0.904952347278595, Current Training Accuracy: 100.0, Time: 0.1419992446899414 ms\n",
      "Epoch 111:[5/16], Current Loss: 0.9128885865211487, Current Training Accuracy: 98.828125, Time: 0.14200139045715332 ms\n",
      "Epoch 111:[10/16], Current Loss: 0.9130404591560364, Current Training Accuracy: 98.29545454545455, Time: 0.14099574089050293 ms\n",
      "Epoch 111:[15/16], Current Loss: 0.9049871563911438, Current Training Accuracy: 98.2421875, Time: 0.1419994831085205 ms\n",
      "Epoch 111, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.676002264022827 ms\n",
      "Epoch 112:[0/16], Current Loss: 0.9199180006980896, Current Training Accuracy: 98.4375, Time: 0.14099860191345215 ms\n",
      "Epoch 112:[5/16], Current Loss: 0.9205576777458191, Current Training Accuracy: 98.4375, Time: 0.14100027084350586 ms\n",
      "Epoch 112:[10/16], Current Loss: 0.9205453991889954, Current Training Accuracy: 98.29545454545455, Time: 0.1419997215270996 ms\n",
      "Epoch 112:[15/16], Current Loss: 0.9357019066810608, Current Training Accuracy: 98.2421875, Time: 0.14200139045715332 ms\n",
      "Epoch 112, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6255035400390625 ms\n",
      "Epoch 113:[0/16], Current Loss: 0.9585360884666443, Current Training Accuracy: 94.53125, Time: 0.14200210571289062 ms\n",
      "Epoch 113:[5/16], Current Loss: 0.9205201268196106, Current Training Accuracy: 97.91666666666667, Time: 0.1419997215270996 ms\n",
      "Epoch 113:[10/16], Current Loss: 0.9049132466316223, Current Training Accuracy: 98.22443181818181, Time: 0.14400005340576172 ms\n",
      "Epoch 113:[15/16], Current Loss: 0.9282664656639099, Current Training Accuracy: 98.2421875, Time: 0.14100074768066406 ms\n",
      "Epoch 113, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.642965316772461 ms\n",
      "Epoch 114:[0/16], Current Loss: 0.9282671809196472, Current Training Accuracy: 97.65625, Time: 0.14300155639648438 ms\n",
      "Epoch 114:[5/16], Current Loss: 0.9121022820472717, Current Training Accuracy: 98.4375, Time: 0.14100027084350586 ms\n",
      "Epoch 114:[10/16], Current Loss: 0.9127203822135925, Current Training Accuracy: 98.29545454545455, Time: 0.14110517501831055 ms\n",
      "Epoch 114:[15/16], Current Loss: 0.9205184578895569, Current Training Accuracy: 98.2421875, Time: 0.14202070236206055 ms\n",
      "Epoch 114, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6299660205841064 ms\n",
      "Epoch 115:[0/16], Current Loss: 0.928325891494751, Current Training Accuracy: 97.65625, Time: 0.14101552963256836 ms\n",
      "Epoch 115:[5/16], Current Loss: 0.912714421749115, Current Training Accuracy: 97.91666666666667, Time: 0.14301800727844238 ms\n",
      "Epoch 115:[10/16], Current Loss: 0.9353474378585815, Current Training Accuracy: 98.01136363636364, Time: 0.1420426368713379 ms\n",
      "Epoch 115:[15/16], Current Loss: 0.9205220937728882, Current Training Accuracy: 98.2421875, Time: 0.1430037021636963 ms\n",
      "Epoch 115, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6640398502349854 ms\n",
      "Epoch 116:[0/16], Current Loss: 0.9202855825424194, Current Training Accuracy: 98.4375, Time: 0.1419992446899414 ms\n",
      "Epoch 116:[5/16], Current Loss: 0.9127100110054016, Current Training Accuracy: 98.56770833333333, Time: 0.14400053024291992 ms\n",
      "Epoch 116:[10/16], Current Loss: 0.9199170470237732, Current Training Accuracy: 98.4375, Time: 0.13997435569763184 ms\n",
      "Epoch 116:[15/16], Current Loss: 0.9205122590065002, Current Training Accuracy: 98.291015625, Time: 0.14200091361999512 ms\n",
      "Epoch 116, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6271274089813232 ms\n",
      "Epoch 117:[0/16], Current Loss: 0.9276671409606934, Current Training Accuracy: 97.65625, Time: 0.1419997215270996 ms\n",
      "Epoch 117:[5/16], Current Loss: 0.9201139807701111, Current Training Accuracy: 98.046875, Time: 0.14200091361999512 ms\n",
      "Epoch 117:[10/16], Current Loss: 0.9277394413948059, Current Training Accuracy: 97.86931818181819, Time: 0.14100027084350586 ms\n",
      "Epoch 117:[15/16], Current Loss: 0.912704586982727, Current Training Accuracy: 98.291015625, Time: 0.14199376106262207 ms\n",
      "Epoch 117, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6287660598754883 ms\n",
      "Epoch 118:[0/16], Current Loss: 0.9126852750778198, Current Training Accuracy: 99.21875, Time: 0.14099907875061035 ms\n",
      "Epoch 118:[5/16], Current Loss: 0.9431953430175781, Current Training Accuracy: 97.52604166666667, Time: 0.14301681518554688 ms\n",
      "Epoch 118:[10/16], Current Loss: 0.9348917007446289, Current Training Accuracy: 98.29545454545455, Time: 0.14299869537353516 ms\n",
      "Epoch 118:[15/16], Current Loss: 0.9205098152160645, Current Training Accuracy: 98.291015625, Time: 0.1419963836669922 ms\n",
      "Epoch 118, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.627997875213623 ms\n",
      "Epoch 119:[0/16], Current Loss: 0.9126994609832764, Current Training Accuracy: 99.21875, Time: 0.1419990062713623 ms\n",
      "Epoch 119:[5/16], Current Loss: 0.9127116799354553, Current Training Accuracy: 98.69791666666667, Time: 0.14401578903198242 ms\n",
      "Epoch 119:[10/16], Current Loss: 0.920520007610321, Current Training Accuracy: 98.57954545454545, Time: 0.14099884033203125 ms\n",
      "Epoch 119:[15/16], Current Loss: 0.951095461845398, Current Training Accuracy: 98.33984375, Time: 0.14100170135498047 ms\n",
      "Epoch 119, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6230006217956543 ms\n",
      "Epoch 120:[0/16], Current Loss: 0.9349263906478882, Current Training Accuracy: 96.875, Time: 0.14200091361999512 ms\n",
      "Epoch 120:[5/16], Current Loss: 0.9126939177513123, Current Training Accuracy: 98.17708333333333, Time: 0.14299988746643066 ms\n",
      "Epoch 120:[10/16], Current Loss: 0.9126874208450317, Current Training Accuracy: 98.4375, Time: 0.14099836349487305 ms\n",
      "Epoch 120:[15/16], Current Loss: 0.9048843383789062, Current Training Accuracy: 98.291015625, Time: 0.14400076866149902 ms\n",
      "Epoch 120, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.664029121398926 ms\n",
      "Epoch 121:[0/16], Current Loss: 0.9126967191696167, Current Training Accuracy: 99.21875, Time: 0.14299941062927246 ms\n",
      "Epoch 121:[5/16], Current Loss: 0.9283211827278137, Current Training Accuracy: 98.30729166666667, Time: 0.14100265502929688 ms\n",
      "Epoch 121:[10/16], Current Loss: 0.9204601049423218, Current Training Accuracy: 98.36647727272727, Time: 0.14200162887573242 ms\n",
      "Epoch 121:[15/16], Current Loss: 0.9268742203712463, Current Training Accuracy: 98.291015625, Time: 0.1420001983642578 ms\n",
      "Epoch 121, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6122212409973145 ms\n",
      "Epoch 122:[0/16], Current Loss: 0.9048752188682556, Current Training Accuracy: 100.0, Time: 0.14200091361999512 ms\n",
      "Epoch 122:[5/16], Current Loss: 0.9204966425895691, Current Training Accuracy: 98.4375, Time: 0.14300036430358887 ms\n",
      "Epoch 122:[10/16], Current Loss: 0.9359679222106934, Current Training Accuracy: 97.9403409090909, Time: 0.14199590682983398 ms\n",
      "Epoch 122:[15/16], Current Loss: 0.9198715090751648, Current Training Accuracy: 98.291015625, Time: 0.14110565185546875 ms\n",
      "Epoch 122, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.638000965118408 ms\n",
      "Epoch 123:[0/16], Current Loss: 0.9361255764961243, Current Training Accuracy: 96.875, Time: 0.14300537109375 ms\n",
      "Epoch 123:[5/16], Current Loss: 0.9120122194290161, Current Training Accuracy: 97.91666666666667, Time: 0.14200067520141602 ms\n",
      "Epoch 123:[10/16], Current Loss: 0.9204934239387512, Current Training Accuracy: 98.01136363636364, Time: 0.14099979400634766 ms\n",
      "Epoch 123:[15/16], Current Loss: 0.9203956723213196, Current Training Accuracy: 98.291015625, Time: 0.14300012588500977 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6349995136260986 ms\n",
      "Epoch 124:[0/16], Current Loss: 0.9126826524734497, Current Training Accuracy: 99.21875, Time: 0.1419985294342041 ms\n",
      "Epoch 124:[5/16], Current Loss: 0.9588485956192017, Current Training Accuracy: 98.046875, Time: 0.139998197555542 ms\n",
      "Epoch 124:[10/16], Current Loss: 0.9433807134628296, Current Training Accuracy: 98.29545454545455, Time: 0.14200210571289062 ms\n",
      "Epoch 124:[15/16], Current Loss: 0.9355253577232361, Current Training Accuracy: 98.33984375, Time: 0.14299964904785156 ms\n",
      "Epoch 124, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6559994220733643 ms\n",
      "Epoch 125:[0/16], Current Loss: 0.9204976558685303, Current Training Accuracy: 98.4375, Time: 0.14100027084350586 ms\n",
      "Epoch 125:[5/16], Current Loss: 0.9126825332641602, Current Training Accuracy: 98.69791666666667, Time: 0.1419992446899414 ms\n",
      "Epoch 125:[10/16], Current Loss: 0.9121347069740295, Current Training Accuracy: 98.22443181818181, Time: 0.14101505279541016 ms\n",
      "Epoch 125:[15/16], Current Loss: 0.9283087253570557, Current Training Accuracy: 98.291015625, Time: 0.14100122451782227 ms\n",
      "Epoch 125, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.632002592086792 ms\n",
      "Epoch 126:[0/16], Current Loss: 0.9198004603385925, Current Training Accuracy: 98.4375, Time: 0.14300036430358887 ms\n",
      "Epoch 126:[5/16], Current Loss: 0.9204936027526855, Current Training Accuracy: 98.17708333333333, Time: 0.14100050926208496 ms\n",
      "Epoch 126:[10/16], Current Loss: 0.9198876023292542, Current Training Accuracy: 98.22443181818181, Time: 0.14099860191345215 ms\n",
      "Epoch 126:[15/16], Current Loss: 0.9126797318458557, Current Training Accuracy: 98.291015625, Time: 0.1419999599456787 ms\n",
      "Epoch 126, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6179962158203125 ms\n",
      "Epoch 127:[0/16], Current Loss: 0.9204992651939392, Current Training Accuracy: 98.4375, Time: 0.14299917221069336 ms\n",
      "Epoch 127:[5/16], Current Loss: 0.9432895183563232, Current Training Accuracy: 97.91666666666667, Time: 0.14399981498718262 ms\n",
      "Epoch 127:[10/16], Current Loss: 0.9347798824310303, Current Training Accuracy: 98.08238636363636, Time: 0.1430349349975586 ms\n",
      "Epoch 127:[15/16], Current Loss: 0.9197835922241211, Current Training Accuracy: 98.291015625, Time: 0.14200067520141602 ms\n",
      "Epoch 127, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6380012035369873 ms\n",
      "Epoch 128:[0/16], Current Loss: 0.9197884202003479, Current Training Accuracy: 98.4375, Time: 0.14499878883361816 ms\n",
      "Epoch 128:[5/16], Current Loss: 0.9198538064956665, Current Training Accuracy: 97.91666666666667, Time: 0.14200091361999512 ms\n",
      "Epoch 128:[10/16], Current Loss: 0.9048701524734497, Current Training Accuracy: 98.4375, Time: 0.14400243759155273 ms\n",
      "Epoch 128:[15/16], Current Loss: 0.9204961657524109, Current Training Accuracy: 98.291015625, Time: 0.1420001983642578 ms\n",
      "Epoch 128, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.63638973236084 ms\n"
     ]
    }
   ],
   "source": [
    "loss_list, counter =[], []\n",
    "count = 0\n",
    "running_loss=0\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0)\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "train_epoch, train_loss = [], []\n",
    "train_acc, val_acc = [], []\n",
    "avg_epoch, avg_train_loss, avg_val_acc = [], [], []\n",
    "epoch_time=[]\n",
    "\n",
    "model.train()\n",
    "for epoch in range(128): \n",
    "    running_loss = 0\n",
    "    total_train = 0\n",
    "    correct_train = 0\n",
    "    total_accuracy = 0\n",
    "    total_val_accuracy = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0   \n",
    "    start1 = time.time()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        start = time.time()\n",
    "        t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
    "        t_image=t_image.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(t_image) # forward\n",
    "        ###########################################################################\n",
    "        outputs=outputs.cuda()\n",
    "        mask=mask.cuda()\n",
    "        loss = criterion(outputs, mask.long()) # calculate the loss\n",
    "        loss.backward() # back propagation\n",
    "        optimizer.step() # update gradients\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += mask.nelement()\n",
    "        correct_train += predicted.eq(mask.data).sum().item()\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        total_accuracy += train_accuracy\n",
    "        if i % 5 == 0:\n",
    "            end = time.time()\n",
    "            print('Epoch {}:[{}/{}], Current Loss: {}, Current Training Accuracy: {}, Time: {} ms'.format(epoch+1, i, len(train_loader), loss.item(), train_accuracy, end - start))      \n",
    "            train_acc.append(train_accuracy)\n",
    "            train_loss.append(loss.item())\n",
    "            train_epoch.append(str(epoch+1) + '/' + str(i))\n",
    "\n",
    "            for j, data1 in enumerate(val_loader, 0):\n",
    "                t_image1, mask1 = data1[0],data1[1].long()\n",
    "                outputs1 = model(t_image1)\n",
    "                mask1_temp=torch.max(mask1.data,1)\n",
    "                mask1_temp1=mask1_temp[1].cuda()\n",
    "                _, predicted1 = torch.max(outputs1.data, 1)\n",
    "                total_val += mask1.nelement()\n",
    "                correct_val += predicted1.eq(mask1_temp1).sum().item()\n",
    "                val_accuracy= 100 * correct_val / total_val\n",
    "                total_val_accuracy += val_accuracy\n",
    "            val_acc.append(val_accuracy)\n",
    "    end1 = time.time()\n",
    "    print('Epoch {}, train Loss: {:.3f} '.format(epoch+1, running_loss/len(train_loader)), \"Avg Training Accuracy: {%d %%}\" % (total_accuracy/len(train_loader)), \"Avg Validation Accuracy: %d %%\" % (total_val_accuracy/len(val_loader)), \"Epoch Time: {} ms\".format(end1 - start1))\n",
    "    epoch_time.append(end1-start1)\n",
    "    avg_epoch.append(epoch+1)\n",
    "    avg_train_loss.append(running_loss/len(train_loader))\n",
    "    avg_val_acc.append(total_val_accuracy/len(val_loader))\n",
    "    #print(avg_epoch)\n",
    "    #print(avg_train_loss)\n",
    "    #print(avg_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2ee8dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of detecting news bias: 84.1146%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred_correct_num=[]\n",
    "pred_total_num=[]\n",
    "pred_result_list=[]\n",
    "pred_prob_list = []\n",
    "label_prob_list=[]\n",
    "label_list=[]\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
    "    mask=mask.cuda()\n",
    "    output_test=model(t_image)\n",
    "    pred_prob_list.append(output_test)\n",
    "    label_prob_list.append(data[1])\n",
    "    label_list.append(mask)\n",
    "    output=torch.max(output_test,1)[1].long()\n",
    "    pred_result_list.append(output)\n",
    "    pred_correct_num.append(output.eq(mask).sum().item())\n",
    "    pred_total_num.append(output_test.shape[0])\n",
    "acc_test=sum(pred_correct_num)/sum(pred_total_num)\n",
    "print(\"The accuracy of detecting news bias: {}\".format(('%.4f%%'%(acc_test*100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16656836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for i in range(len(pred_result_list)):\n",
    "    if len(pred_result_list) == 1:\n",
    "        pred_result = pred_result_list[0]\n",
    "        label = label_list[0]\n",
    "    if len(pred_result_list) == 2:\n",
    "        pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
    "        label = torch.cat((label_list[0], label_list[1]), -1)\n",
    "    if len(pred_result_list) > 2:\n",
    "        pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
    "        label = torch.cat((label_list[0], label_list[1]), -1)\n",
    "    for j in range(len(pred_result_list)-2):\n",
    "        pred_result = torch.cat((pred_result, pred_result_list[j+2]), -1)\n",
    "        label = torch.cat((label, label_list[j+2]), -1)\n",
    "label = label.cpu()\n",
    "pred_result = pred_result.cpu()\n",
    "C=confusion_matrix(label,pred_result)\n",
    "df=pd.DataFrame(C,index=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"],columns=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"])\n",
    "p1=sns.heatmap(df,annot=True,cmap=\"hot_r\")\n",
    "s1 = p1.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31b110de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Value: 0.0662\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred_prob_list)):\n",
    "    if len(pred_prob_list) == 1:\n",
    "        pred_prob = pred_prob_list[0]\n",
    "        label_prob = label_prob_list[0]\n",
    "    if len(pred_prob_list) == 2:\n",
    "        pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
    "        label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
    "    if len(pred_prob_list) > 2:\n",
    "        pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
    "        label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
    "    for j in range(len(pred_prob_list)-2):\n",
    "        pred_prob = torch.cat((pred_prob, pred_prob_list[j+2]), -1)\n",
    "        label_prob = torch.cat((label_prob, label_prob_list[j+2]), -1)\n",
    "label_prob = label_prob.cpu()\n",
    "pred_prob = pred_prob.cpu()\n",
    "criterion=nn.L1Loss(reduction=\"mean\")\n",
    "loss=criterion(pred_prob, label_prob)\n",
    "print(\"MAE Value: {}\".format(\"%.4f\" % loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94cdbc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-F1 Score: 0.8021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(pred_result,label,average=\"macro\")\n",
    "print(\"Macro-F1 Score: {}\".format(\"%.4f\" % f1_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
