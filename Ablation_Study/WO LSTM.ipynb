{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d547ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da478dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_process1=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\X_train_glove_title.npy\")\n",
    "X_test_process1=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\X_test_glove_title.npy\")\n",
    "X_valid_process1=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\X_valid_glove_title.npy\")\n",
    "y_train_process=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\y_train_glove.npy\")\n",
    "y_test_process=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\y_test_glove.npy\")\n",
    "y_valid_process=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\y_valid_glove.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a2a0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(\n",
    "    dataset=Data.TensorDataset(torch.Tensor(X_train_process1),torch.LongTensor(y_train_process)),      \n",
    "    batch_size=128,      \n",
    "    shuffle=True,               \n",
    "    num_workers=0, \n",
    "    drop_last=True\n",
    ")\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=Data.TensorDataset(torch.Tensor(X_test_process1),torch.LongTensor(y_test_process)),      \n",
    "    batch_size=128,      \n",
    "    shuffle=True,               \n",
    "    num_workers=0,  \n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = Data.DataLoader(\n",
    "    dataset=Data.TensorDataset(torch.Tensor(X_valid_process1),torch.LongTensor(y_valid_process)),      \n",
    "    batch_size=128, \n",
    "    shuffle=True,               \n",
    "    num_workers=0,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c72dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECA(x,gamma=2,b=1):\n",
    "    N,C,H,W=x.size()\n",
    "    t=int(abs((log(C,2)+b)/gamma))\n",
    "    k=t if t%2 else t+1\n",
    "    \n",
    "    avg_pool=nn.AdaptiveAvgPool2d(1).cuda()\n",
    "    conv=nn.Conv1d(1,1,kernel_size=k,padding=int(k/2),bias=False).cuda()\n",
    "    sigmoid=nn.Sigmoid().cuda()\n",
    "    \n",
    "    y=avg_pool(x)\n",
    "    y=conv(y.squeeze(-1).transpose(-1,-2))\n",
    "    y=y.transpose(-1,-2).unsqueeze(-1)\n",
    "    y=sigmoid(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d24ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRCNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_size,num_labels=5):\n",
    "        super(TextRCNN,self).__init__()\n",
    "        self.dropout = nn.Dropout(.3)\n",
    "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(600, 128)\n",
    "        self.linear3 = nn.Linear(128, num_labels)\n",
    "        self.conv1 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=6)#通过out_channel改变文中的feature map，且out_channel∈[10,50,100,200,400,600,800,1000]\n",
    "        self.conv2 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=7)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=8)\n",
    "        self.conv4 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=9)\n",
    "        self.w_omiga = torch.randn(128,hidden_size,1,requires_grad=True).cuda()\n",
    "\n",
    "    def forward(self, x):#x: [batch,L]\n",
    "        x_embed = x.cuda()\n",
    "        out = self.linear1(x_embed)\n",
    "        out = out.permute(dims=[0,2,1]) #out: [batch,embedding_size + hidden_size * num_bidirectional,L]\n",
    "        out_1 = self.conv1(out)\n",
    "        out_1 = nn.ReLU()(out_1)\n",
    "        out_1 = nn.MaxPool1d(kernel_size=495)(out_1)\n",
    "        out_2 = self.conv1(out)\n",
    "        out_2 = nn.ReLU()(out_2)\n",
    "        out_2 = nn.MaxPool1d(kernel_size=494)(out_2)\n",
    "        out_3 = self.conv1(out)\n",
    "        out_3 = nn.ReLU()(out_3)\n",
    "        out_3 = nn.MaxPool1d(kernel_size=493)(out_3)\n",
    "        out_4 = self.conv1(out)\n",
    "        out_4 = nn.ReLU()(out_4)\n",
    "        out_4 = nn.MaxPool1d(kernel_size=492)(out_4)\n",
    "        out_1 = out_1.unsqueeze(1).cuda()\n",
    "        out_2 = out_2.unsqueeze(1).cuda()\n",
    "        out_3 = out_3.unsqueeze(1).cuda()\n",
    "        out_4 = out_4.unsqueeze(1).cuda()\n",
    "        out = torch.cat([out_1, out_2, out_3, out_4],dim=1).cuda()\n",
    "        channel_weights = F.softmax(ECA(out).squeeze().squeeze(),dim=1).unsqueeze(-1).unsqueeze(-1).expand_as(out)\n",
    "        out = torch.mul(channel_weights,out)\n",
    "        out = torch.sum(out, dim = 1)\n",
    "        out = self.linear2(out.squeeze()) #out: [batch,num_labels]\n",
    "        out = self.linear3(F.tanh(out))\n",
    "        out = F.softmax(out,dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "880d15b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextRCNN(5302,200,12).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a9c829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:[0/16], Current Loss: 1.6181013584136963, Current Training Accuracy: 6.25, Time: 3.1193857192993164 ms\n",
      "Epoch 1:[5/16], Current Loss: 1.504160761833191, Current Training Accuracy: 29.296875, Time: 0.1360001564025879 ms\n",
      "Epoch 1:[10/16], Current Loss: 1.551331877708435, Current Training Accuracy: 31.960227272727273, Time: 0.1329808235168457 ms\n",
      "Epoch 1:[15/16], Current Loss: 1.48762047290802, Current Training Accuracy: 34.814453125, Time: 0.1340007781982422 ms\n",
      "Epoch 1, train Loss: 1.515  Avg Training Accuracy: {28 %} Avg Validation Accuracy: 27 % Epoch Time: 6.462805271148682 ms\n",
      "Epoch 2:[0/16], Current Loss: 1.4152953624725342, Current Training Accuracy: 51.5625, Time: 0.1340165138244629 ms\n",
      "Epoch 2:[5/16], Current Loss: 1.3799958229064941, Current Training Accuracy: 55.208333333333336, Time: 0.13301324844360352 ms\n",
      "Epoch 2:[10/16], Current Loss: 1.3250573873519897, Current Training Accuracy: 56.10795454545455, Time: 0.13402533531188965 ms\n",
      "Epoch 2:[15/16], Current Loss: 1.3113499879837036, Current Training Accuracy: 56.103515625, Time: 0.13300323486328125 ms\n",
      "Epoch 2, train Loss: 1.358  Avg Training Accuracy: {55 %} Avg Validation Accuracy: 42 % Epoch Time: 3.457981824874878 ms\n",
      "Epoch 3:[0/16], Current Loss: 1.3520934581756592, Current Training Accuracy: 54.6875, Time: 0.1340174674987793 ms\n",
      "Epoch 3:[5/16], Current Loss: 1.2338873147964478, Current Training Accuracy: 58.59375, Time: 0.13364362716674805 ms\n",
      "Epoch 3:[10/16], Current Loss: 1.3057299852371216, Current Training Accuracy: 57.52840909090909, Time: 0.13299226760864258 ms\n",
      "Epoch 3:[15/16], Current Loss: 1.2816948890686035, Current Training Accuracy: 59.619140625, Time: 0.13498282432556152 ms\n",
      "Epoch 3, train Loss: 1.303  Avg Training Accuracy: {57 %} Avg Validation Accuracy: 45 % Epoch Time: 3.5245490074157715 ms\n",
      "Epoch 4:[0/16], Current Loss: 1.255871295928955, Current Training Accuracy: 68.75, Time: 0.13300108909606934 ms\n",
      "Epoch 4:[5/16], Current Loss: 1.267945647239685, Current Training Accuracy: 66.53645833333333, Time: 0.13505029678344727 ms\n",
      "Epoch 4:[10/16], Current Loss: 1.1779593229293823, Current Training Accuracy: 69.60227272727273, Time: 0.13402247428894043 ms\n",
      "Epoch 4:[15/16], Current Loss: 1.2001696825027466, Current Training Accuracy: 69.677734375, Time: 0.13399958610534668 ms\n",
      "Epoch 4, train Loss: 1.231  Avg Training Accuracy: {68 %} Avg Validation Accuracy: 53 % Epoch Time: 3.47135853767395 ms\n",
      "Epoch 5:[0/16], Current Loss: 1.163655161857605, Current Training Accuracy: 77.34375, Time: 0.13299870491027832 ms\n",
      "Epoch 5:[5/16], Current Loss: 1.2480368614196777, Current Training Accuracy: 73.30729166666667, Time: 0.13500070571899414 ms\n",
      "Epoch 5:[10/16], Current Loss: 1.174517035484314, Current Training Accuracy: 73.36647727272727, Time: 0.13499855995178223 ms\n",
      "Epoch 5:[15/16], Current Loss: 1.212610125541687, Current Training Accuracy: 72.94921875, Time: 0.13499927520751953 ms\n",
      "Epoch 5, train Loss: 1.188  Avg Training Accuracy: {73 %} Avg Validation Accuracy: 52 % Epoch Time: 3.4539952278137207 ms\n",
      "Epoch 6:[0/16], Current Loss: 1.1773661375045776, Current Training Accuracy: 74.21875, Time: 0.13299965858459473 ms\n",
      "Epoch 6:[5/16], Current Loss: 1.1275439262390137, Current Training Accuracy: 73.4375, Time: 0.13500070571899414 ms\n",
      "Epoch 6:[10/16], Current Loss: 1.1733253002166748, Current Training Accuracy: 76.0653409090909, Time: 0.13584256172180176 ms\n",
      "Epoch 6:[15/16], Current Loss: 1.1690332889556885, Current Training Accuracy: 75.830078125, Time: 0.13399529457092285 ms\n",
      "Epoch 6, train Loss: 1.157  Avg Training Accuracy: {74 %} Avg Validation Accuracy: 53 % Epoch Time: 3.492300033569336 ms\n",
      "Epoch 7:[0/16], Current Loss: 1.0808420181274414, Current Training Accuracy: 82.8125, Time: 0.13499975204467773 ms\n",
      "Epoch 7:[5/16], Current Loss: 1.0934326648712158, Current Training Accuracy: 77.47395833333333, Time: 0.13600993156433105 ms\n",
      "Epoch 7:[10/16], Current Loss: 1.1334391832351685, Current Training Accuracy: 77.55681818181819, Time: 0.1329967975616455 ms\n",
      "Epoch 7:[15/16], Current Loss: 1.107645034790039, Current Training Accuracy: 77.392578125, Time: 0.13500046730041504 ms\n",
      "Epoch 7, train Loss: 1.135  Avg Training Accuracy: {77 %} Avg Validation Accuracy: 56 % Epoch Time: 3.466515302658081 ms\n",
      "Epoch 8:[0/16], Current Loss: 1.1670485734939575, Current Training Accuracy: 73.4375, Time: 0.13500070571899414 ms\n",
      "Epoch 8:[5/16], Current Loss: 1.1452716588974, Current Training Accuracy: 76.69270833333333, Time: 0.13499975204467773 ms\n",
      "Epoch 8:[10/16], Current Loss: 1.112237572669983, Current Training Accuracy: 77.13068181818181, Time: 0.13399958610534668 ms\n",
      "Epoch 8:[15/16], Current Loss: 1.0545061826705933, Current Training Accuracy: 78.61328125, Time: 0.13400053977966309 ms\n",
      "Epoch 8, train Loss: 1.119  Avg Training Accuracy: {76 %} Avg Validation Accuracy: 56 % Epoch Time: 3.501016139984131 ms\n",
      "Epoch 9:[0/16], Current Loss: 1.1317157745361328, Current Training Accuracy: 77.34375, Time: 0.13399839401245117 ms\n",
      "Epoch 9:[5/16], Current Loss: 1.0729897022247314, Current Training Accuracy: 79.296875, Time: 0.1340014934539795 ms\n",
      "Epoch 9:[10/16], Current Loss: 1.1469889879226685, Current Training Accuracy: 79.4034090909091, Time: 0.1360006332397461 ms\n",
      "Epoch 9:[15/16], Current Loss: 1.076621174812317, Current Training Accuracy: 79.296875, Time: 0.13499879837036133 ms\n",
      "Epoch 9, train Loss: 1.107  Avg Training Accuracy: {78 %} Avg Validation Accuracy: 55 % Epoch Time: 3.4480133056640625 ms\n",
      "Epoch 10:[0/16], Current Loss: 1.0764648914337158, Current Training Accuracy: 81.25, Time: 0.13499903678894043 ms\n",
      "Epoch 10:[5/16], Current Loss: 1.1021838188171387, Current Training Accuracy: 82.94270833333333, Time: 0.13399982452392578 ms\n",
      "Epoch 10:[10/16], Current Loss: 1.0698751211166382, Current Training Accuracy: 83.94886363636364, Time: 0.13499999046325684 ms\n",
      "Epoch 10:[15/16], Current Loss: 1.0832136869430542, Current Training Accuracy: 84.27734375, Time: 0.13500022888183594 ms\n",
      "Epoch 10, train Loss: 1.070  Avg Training Accuracy: {83 %} Avg Validation Accuracy: 58 % Epoch Time: 3.456063985824585 ms\n",
      "Epoch 11:[0/16], Current Loss: 1.064852237701416, Current Training Accuracy: 83.59375, Time: 0.1360013484954834 ms\n",
      "Epoch 11:[5/16], Current Loss: 1.0428534746170044, Current Training Accuracy: 86.06770833333333, Time: 0.13400030136108398 ms\n",
      "Epoch 11:[10/16], Current Loss: 1.0319346189498901, Current Training Accuracy: 86.57670454545455, Time: 0.13399958610534668 ms\n",
      "Epoch 11:[15/16], Current Loss: 1.0388890504837036, Current Training Accuracy: 86.669921875, Time: 0.1340177059173584 ms\n",
      "Epoch 11, train Loss: 1.041  Avg Training Accuracy: {86 %} Avg Validation Accuracy: 61 % Epoch Time: 3.468003988265991 ms\n",
      "Epoch 12:[0/16], Current Loss: 1.07432222366333, Current Training Accuracy: 82.03125, Time: 0.13400030136108398 ms\n",
      "Epoch 12:[5/16], Current Loss: 1.036210536956787, Current Training Accuracy: 85.28645833333333, Time: 0.13600444793701172 ms\n",
      "Epoch 12:[10/16], Current Loss: 1.016890287399292, Current Training Accuracy: 86.93181818181819, Time: 0.13399982452392578 ms\n",
      "Epoch 12:[15/16], Current Loss: 1.015175223350525, Current Training Accuracy: 87.40234375, Time: 0.1340022087097168 ms\n",
      "Epoch 12, train Loss: 1.032  Avg Training Accuracy: {85 %} Avg Validation Accuracy: 62 % Epoch Time: 3.4830002784729004 ms\n",
      "Epoch 13:[0/16], Current Loss: 1.0642831325531006, Current Training Accuracy: 84.375, Time: 0.1340019702911377 ms\n",
      "Epoch 13:[5/16], Current Loss: 1.015934944152832, Current Training Accuracy: 86.71875, Time: 0.13599872589111328 ms\n",
      "Epoch 13:[10/16], Current Loss: 0.9949902892112732, Current Training Accuracy: 87.42897727272727, Time: 0.1340012550354004 ms\n",
      "Epoch 13:[15/16], Current Loss: 1.0053743124008179, Current Training Accuracy: 88.330078125, Time: 0.13500094413757324 ms\n",
      "Epoch 13, train Loss: 1.021  Avg Training Accuracy: {87 %} Avg Validation Accuracy: 60 % Epoch Time: 3.495492935180664 ms\n",
      "Epoch 14:[0/16], Current Loss: 0.9756300449371338, Current Training Accuracy: 92.96875, Time: 0.13500070571899414 ms\n",
      "Epoch 14:[5/16], Current Loss: 1.0803301334381104, Current Training Accuracy: 87.63020833333333, Time: 0.13599705696105957 ms\n",
      "Epoch 14:[10/16], Current Loss: 0.9905045032501221, Current Training Accuracy: 88.5653409090909, Time: 0.1350243091583252 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:[15/16], Current Loss: 0.991074800491333, Current Training Accuracy: 88.8671875, Time: 0.13399744033813477 ms\n",
      "Epoch 14, train Loss: 1.014  Avg Training Accuracy: {89 %} Avg Validation Accuracy: 60 % Epoch Time: 3.462214946746826 ms\n",
      "Epoch 15:[0/16], Current Loss: 1.0788878202438354, Current Training Accuracy: 80.46875, Time: 0.13502097129821777 ms\n",
      "Epoch 15:[5/16], Current Loss: 1.0028660297393799, Current Training Accuracy: 90.10416666666667, Time: 0.136016845703125 ms\n",
      "Epoch 15:[10/16], Current Loss: 0.9811022281646729, Current Training Accuracy: 92.40056818181819, Time: 0.13399958610534668 ms\n",
      "Epoch 15:[15/16], Current Loss: 1.0181856155395508, Current Training Accuracy: 92.578125, Time: 0.13500046730041504 ms\n",
      "Epoch 15, train Loss: 0.994  Avg Training Accuracy: {90 %} Avg Validation Accuracy: 61 % Epoch Time: 3.4621222019195557 ms\n",
      "Epoch 16:[0/16], Current Loss: 0.9734108448028564, Current Training Accuracy: 96.875, Time: 0.13509798049926758 ms\n",
      "Epoch 16:[5/16], Current Loss: 0.9423572421073914, Current Training Accuracy: 96.22395833333333, Time: 0.12918496131896973 ms\n",
      "Epoch 16:[10/16], Current Loss: 0.9603821635246277, Current Training Accuracy: 96.30681818181819, Time: 0.14142560958862305 ms\n",
      "Epoch 16:[15/16], Current Loss: 0.9725285768508911, Current Training Accuracy: 95.849609375, Time: 0.13116931915283203 ms\n",
      "Epoch 16, train Loss: 0.969  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 61 % Epoch Time: 3.4467554092407227 ms\n",
      "Epoch 17:[0/16], Current Loss: 0.9724210500717163, Current Training Accuracy: 94.53125, Time: 0.1258227825164795 ms\n",
      "Epoch 17:[5/16], Current Loss: 0.9579851031303406, Current Training Accuracy: 96.875, Time: 0.12664175033569336 ms\n",
      "Epoch 17:[10/16], Current Loss: 0.9456887245178223, Current Training Accuracy: 96.94602272727273, Time: 0.14095807075500488 ms\n",
      "Epoch 17:[15/16], Current Loss: 0.9422280192375183, Current Training Accuracy: 97.0703125, Time: 0.12981867790222168 ms\n",
      "Epoch 17, train Loss: 0.948  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 64 % Epoch Time: 3.4813499450683594 ms\n",
      "Epoch 18:[0/16], Current Loss: 0.9381433129310608, Current Training Accuracy: 97.65625, Time: 0.12638163566589355 ms\n",
      "Epoch 18:[5/16], Current Loss: 0.9235468506813049, Current Training Accuracy: 97.00520833333333, Time: 0.12622642517089844 ms\n",
      "Epoch 18:[10/16], Current Loss: 0.9392923712730408, Current Training Accuracy: 97.3721590909091, Time: 0.1282815933227539 ms\n",
      "Epoch 18:[15/16], Current Loss: 0.9404370784759521, Current Training Accuracy: 97.314453125, Time: 0.1254124641418457 ms\n",
      "Epoch 18, train Loss: 0.939  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 3.466830253601074 ms\n",
      "Epoch 19:[0/16], Current Loss: 0.9415957927703857, Current Training Accuracy: 96.875, Time: 0.12631940841674805 ms\n",
      "Epoch 19:[5/16], Current Loss: 0.9339084625244141, Current Training Accuracy: 98.046875, Time: 0.14144182205200195 ms\n",
      "Epoch 19:[10/16], Current Loss: 0.907899022102356, Current Training Accuracy: 98.08238636363636, Time: 0.1296243667602539 ms\n",
      "Epoch 19:[15/16], Current Loss: 0.9465514421463013, Current Training Accuracy: 97.509765625, Time: 0.1299736499786377 ms\n",
      "Epoch 19, train Loss: 0.934  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 62 % Epoch Time: 3.4377593994140625 ms\n",
      "Epoch 20:[0/16], Current Loss: 0.9165410399436951, Current Training Accuracy: 99.21875, Time: 0.12571215629577637 ms\n",
      "Epoch 20:[5/16], Current Loss: 0.9367201328277588, Current Training Accuracy: 97.78645833333333, Time: 0.14144039154052734 ms\n",
      "Epoch 20:[10/16], Current Loss: 0.9227098226547241, Current Training Accuracy: 97.51420454545455, Time: 0.13889527320861816 ms\n",
      "Epoch 20:[15/16], Current Loss: 0.9311234354972839, Current Training Accuracy: 97.65625, Time: 0.1419360637664795 ms\n",
      "Epoch 20, train Loss: 0.931  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 3.4363718032836914 ms\n",
      "Epoch 21:[0/16], Current Loss: 0.9300276041030884, Current Training Accuracy: 97.65625, Time: 0.1259293556213379 ms\n",
      "Epoch 21:[5/16], Current Loss: 0.9296102523803711, Current Training Accuracy: 97.65625, Time: 0.12624669075012207 ms\n",
      "Epoch 21:[10/16], Current Loss: 0.9308074116706848, Current Training Accuracy: 97.86931818181819, Time: 0.12580513954162598 ms\n",
      "Epoch 21:[15/16], Current Loss: 0.9227494597434998, Current Training Accuracy: 97.802734375, Time: 0.14144325256347656 ms\n",
      "Epoch 21, train Loss: 0.929  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 3.451930284500122 ms\n",
      "Epoch 22:[0/16], Current Loss: 0.9227789640426636, Current Training Accuracy: 98.4375, Time: 0.12579083442687988 ms\n",
      "Epoch 22:[5/16], Current Loss: 0.9367741942405701, Current Training Accuracy: 97.39583333333333, Time: 0.1258864402770996 ms\n",
      "Epoch 22:[10/16], Current Loss: 0.9216968417167664, Current Training Accuracy: 97.72727272727273, Time: 0.14141488075256348 ms\n",
      "Epoch 22:[15/16], Current Loss: 0.9219385385513306, Current Training Accuracy: 97.75390625, Time: 0.13971972465515137 ms\n",
      "Epoch 22, train Loss: 0.929  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 62 % Epoch Time: 3.4556806087493896 ms\n",
      "Epoch 23:[0/16], Current Loss: 0.9287201166152954, Current Training Accuracy: 97.65625, Time: 0.14094305038452148 ms\n",
      "Epoch 23:[5/16], Current Loss: 0.9220228791236877, Current Training Accuracy: 98.17708333333333, Time: 0.13895177841186523 ms\n",
      "Epoch 23:[10/16], Current Loss: 0.9283983111381531, Current Training Accuracy: 97.9403409090909, Time: 0.12579083442687988 ms\n",
      "Epoch 23:[15/16], Current Loss: 0.9215366840362549, Current Training Accuracy: 97.8515625, Time: 0.14145469665527344 ms\n",
      "Epoch 23, train Loss: 0.927  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 3.473241090774536 ms\n",
      "Epoch 24:[0/16], Current Loss: 0.9376352429389954, Current Training Accuracy: 96.875, Time: 0.12578940391540527 ms\n",
      "Epoch 24:[5/16], Current Loss: 0.9214524626731873, Current Training Accuracy: 98.046875, Time: 0.1257939338684082 ms\n",
      "Epoch 24:[10/16], Current Loss: 0.9371262192726135, Current Training Accuracy: 98.1534090909091, Time: 0.14141154289245605 ms\n",
      "Epoch 24:[15/16], Current Loss: 0.9351738095283508, Current Training Accuracy: 97.900390625, Time: 0.14403915405273438 ms\n",
      "Epoch 24, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 3.439448118209839 ms\n",
      "Epoch 25:[0/16], Current Loss: 0.9521850347518921, Current Training Accuracy: 95.3125, Time: 0.12471437454223633 ms\n",
      "Epoch 25:[5/16], Current Loss: 0.9293699264526367, Current Training Accuracy: 97.265625, Time: 0.12617278099060059 ms\n",
      "Epoch 25:[10/16], Current Loss: 0.9286773800849915, Current Training Accuracy: 97.86931818181819, Time: 0.12580180168151855 ms\n",
      "Epoch 25:[15/16], Current Loss: 0.9134838581085205, Current Training Accuracy: 97.900390625, Time: 0.14162325859069824 ms\n",
      "Epoch 25, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.4617831707000732 ms\n",
      "Epoch 26:[0/16], Current Loss: 0.9288103580474854, Current Training Accuracy: 97.65625, Time: 0.14403223991394043 ms\n",
      "Epoch 26:[5/16], Current Loss: 0.944133460521698, Current Training Accuracy: 97.52604166666667, Time: 0.1414494514465332 ms\n",
      "Epoch 26:[10/16], Current Loss: 0.9594415426254272, Current Training Accuracy: 97.65625, Time: 0.13923954963684082 ms\n",
      "Epoch 26:[15/16], Current Loss: 0.9289445877075195, Current Training Accuracy: 97.900390625, Time: 0.12752771377563477 ms\n",
      "Epoch 26, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.5001747608184814 ms\n",
      "Epoch 27:[0/16], Current Loss: 0.9135939478874207, Current Training Accuracy: 99.21875, Time: 0.13460445404052734 ms\n",
      "Epoch 27:[5/16], Current Loss: 0.9592049717903137, Current Training Accuracy: 97.52604166666667, Time: 0.12578940391540527 ms\n",
      "Epoch 27:[10/16], Current Loss: 0.9351056814193726, Current Training Accuracy: 97.79829545454545, Time: 0.14136171340942383 ms\n",
      "Epoch 27:[15/16], Current Loss: 0.9290187954902649, Current Training Accuracy: 97.900390625, Time: 0.1257951259613037 ms\n",
      "Epoch 27, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.4538187980651855 ms\n",
      "Epoch 28:[0/16], Current Loss: 0.9199768900871277, Current Training Accuracy: 98.4375, Time: 0.13740777969360352 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:[5/16], Current Loss: 0.9354323148727417, Current Training Accuracy: 97.91666666666667, Time: 0.12833952903747559 ms\n",
      "Epoch 28:[10/16], Current Loss: 0.9283820390701294, Current Training Accuracy: 98.08238636363636, Time: 0.14384126663208008 ms\n",
      "Epoch 28:[15/16], Current Loss: 0.9514442682266235, Current Training Accuracy: 97.900390625, Time: 0.12314844131469727 ms\n",
      "Epoch 28, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 3.433307647705078 ms\n",
      "Epoch 29:[0/16], Current Loss: 0.942837119102478, Current Training Accuracy: 96.09375, Time: 0.14181137084960938 ms\n",
      "Epoch 29:[5/16], Current Loss: 0.9128354787826538, Current Training Accuracy: 97.78645833333333, Time: 0.12585854530334473 ms\n",
      "Epoch 29:[10/16], Current Loss: 0.9133485555648804, Current Training Accuracy: 97.79829545454545, Time: 0.1412672996520996 ms\n",
      "Epoch 29:[15/16], Current Loss: 0.9206183552742004, Current Training Accuracy: 97.900390625, Time: 0.1257774829864502 ms\n",
      "Epoch 29, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.466658353805542 ms\n",
      "Epoch 30:[0/16], Current Loss: 0.9270775318145752, Current Training Accuracy: 97.65625, Time: 0.12578177452087402 ms\n",
      "Epoch 30:[5/16], Current Loss: 0.9210713505744934, Current Training Accuracy: 98.17708333333333, Time: 0.141404390335083 ms\n",
      "Epoch 30:[10/16], Current Loss: 0.9353389143943787, Current Training Accuracy: 97.9403409090909, Time: 0.1319751739501953 ms\n",
      "Epoch 30:[15/16], Current Loss: 0.9206888675689697, Current Training Accuracy: 97.900390625, Time: 0.1419520378112793 ms\n",
      "Epoch 30, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 3.4414541721343994 ms\n",
      "Epoch 31:[0/16], Current Loss: 0.9204623103141785, Current Training Accuracy: 98.4375, Time: 0.12624526023864746 ms\n",
      "Epoch 31:[5/16], Current Loss: 0.942729115486145, Current Training Accuracy: 97.91666666666667, Time: 0.12581443786621094 ms\n",
      "Epoch 31:[10/16], Current Loss: 0.9209793210029602, Current Training Accuracy: 97.9403409090909, Time: 0.13681435585021973 ms\n",
      "Epoch 31:[15/16], Current Loss: 0.920921802520752, Current Training Accuracy: 97.900390625, Time: 0.14146208763122559 ms\n",
      "Epoch 31, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.460599422454834 ms\n",
      "Epoch 32:[0/16], Current Loss: 0.9511316418647766, Current Training Accuracy: 95.3125, Time: 0.1414346694946289 ms\n",
      "Epoch 32:[5/16], Current Loss: 0.9131855964660645, Current Training Accuracy: 98.046875, Time: 0.12581300735473633 ms\n",
      "Epoch 32:[10/16], Current Loss: 0.9204346537590027, Current Training Accuracy: 98.01136363636364, Time: 0.12582802772521973 ms\n",
      "Epoch 32:[15/16], Current Loss: 0.951111912727356, Current Training Accuracy: 97.900390625, Time: 0.13778138160705566 ms\n",
      "Epoch 32, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.44429612159729 ms\n",
      "Epoch 33:[0/16], Current Loss: 0.942633330821991, Current Training Accuracy: 96.09375, Time: 0.13081693649291992 ms\n",
      "Epoch 33:[5/16], Current Loss: 0.9204143285751343, Current Training Accuracy: 97.91666666666667, Time: 0.14143109321594238 ms\n",
      "Epoch 33:[10/16], Current Loss: 0.9132651090621948, Current Training Accuracy: 97.65625, Time: 0.14640140533447266 ms\n",
      "Epoch 33:[15/16], Current Loss: 0.9204275012016296, Current Training Accuracy: 97.900390625, Time: 0.1258080005645752 ms\n",
      "Epoch 33, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 3.445035219192505 ms\n",
      "Epoch 34:[0/16], Current Loss: 0.9272841811180115, Current Training Accuracy: 97.65625, Time: 0.1422123908996582 ms\n",
      "Epoch 34:[5/16], Current Loss: 0.9204409122467041, Current Training Accuracy: 98.30729166666667, Time: 0.14182567596435547 ms\n",
      "Epoch 34:[10/16], Current Loss: 0.9131959080696106, Current Training Accuracy: 97.72727272727273, Time: 0.1414175033569336 ms\n",
      "Epoch 34:[15/16], Current Loss: 0.9283928275108337, Current Training Accuracy: 97.900390625, Time: 0.12578654289245605 ms\n",
      "Epoch 34, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.438800096511841 ms\n",
      "Epoch 35:[0/16], Current Loss: 0.9365161061286926, Current Training Accuracy: 96.875, Time: 0.12579345703125 ms\n",
      "Epoch 35:[5/16], Current Loss: 0.9208559393882751, Current Training Accuracy: 97.91666666666667, Time: 0.1257922649383545 ms\n",
      "Epoch 35:[10/16], Current Loss: 0.9207761883735657, Current Training Accuracy: 98.08238636363636, Time: 0.13340473175048828 ms\n",
      "Epoch 35:[15/16], Current Loss: 0.9281517267227173, Current Training Accuracy: 97.94921875, Time: 0.13656973838806152 ms\n",
      "Epoch 35, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.4547879695892334 ms\n",
      "Epoch 36:[0/16], Current Loss: 0.9052810668945312, Current Training Accuracy: 100.0, Time: 0.14201092720031738 ms\n",
      "Epoch 36:[5/16], Current Loss: 0.9053090214729309, Current Training Accuracy: 98.046875, Time: 0.11909079551696777 ms\n",
      "Epoch 36:[10/16], Current Loss: 0.9130872488021851, Current Training Accuracy: 98.29545454545455, Time: 0.12578439712524414 ms\n",
      "Epoch 36:[15/16], Current Loss: 0.9275599122047424, Current Training Accuracy: 97.94921875, Time: 0.13332891464233398 ms\n",
      "Epoch 36, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 3.494980573654175 ms\n",
      "Epoch 37:[0/16], Current Loss: 0.9284799695014954, Current Training Accuracy: 97.65625, Time: 0.13352704048156738 ms\n",
      "Epoch 37:[5/16], Current Loss: 0.9197096228599548, Current Training Accuracy: 97.13541666666667, Time: 0.13225746154785156 ms\n",
      "Epoch 37:[10/16], Current Loss: 0.9123378396034241, Current Training Accuracy: 97.72727272727273, Time: 0.14193224906921387 ms\n",
      "Epoch 37:[15/16], Current Loss: 0.9278234243392944, Current Training Accuracy: 97.94921875, Time: 0.1283257007598877 ms\n",
      "Epoch 37, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.4462015628814697 ms\n",
      "Epoch 38:[0/16], Current Loss: 0.9130017161369324, Current Training Accuracy: 99.21875, Time: 0.1262960433959961 ms\n",
      "Epoch 38:[5/16], Current Loss: 0.9200416803359985, Current Training Accuracy: 98.17708333333333, Time: 0.1421499252319336 ms\n",
      "Epoch 38:[10/16], Current Loss: 0.9279166460037231, Current Training Accuracy: 97.86931818181819, Time: 0.14139842987060547 ms\n",
      "Epoch 38:[15/16], Current Loss: 0.9283555746078491, Current Training Accuracy: 98.095703125, Time: 0.14072465896606445 ms\n",
      "Epoch 38, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.452876091003418 ms\n",
      "Epoch 39:[0/16], Current Loss: 0.9358131885528564, Current Training Accuracy: 96.875, Time: 0.14224815368652344 ms\n",
      "Epoch 39:[5/16], Current Loss: 0.9285479784011841, Current Training Accuracy: 97.65625, Time: 0.1420602798461914 ms\n",
      "Epoch 39:[10/16], Current Loss: 0.9052939414978027, Current Training Accuracy: 98.22443181818181, Time: 0.12950730323791504 ms\n",
      "Epoch 39:[15/16], Current Loss: 0.9276716113090515, Current Training Accuracy: 97.998046875, Time: 0.12583160400390625 ms\n",
      "Epoch 39, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.4597654342651367 ms\n",
      "Epoch 40:[0/16], Current Loss: 0.9202401041984558, Current Training Accuracy: 98.4375, Time: 0.14229798316955566 ms\n",
      "Epoch 40:[5/16], Current Loss: 0.9200464487075806, Current Training Accuracy: 98.95833333333333, Time: 0.14354658126831055 ms\n",
      "Epoch 40:[10/16], Current Loss: 0.9292423129081726, Current Training Accuracy: 98.1534090909091, Time: 0.13157415390014648 ms\n",
      "Epoch 40:[15/16], Current Loss: 0.9361667633056641, Current Training Accuracy: 98.095703125, Time: 0.1428544521331787 ms\n",
      "Epoch 40, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.481745719909668 ms\n",
      "Epoch 41:[0/16], Current Loss: 0.912555456161499, Current Training Accuracy: 99.21875, Time: 0.13558483123779297 ms\n",
      "Epoch 41:[5/16], Current Loss: 0.9208183884620667, Current Training Accuracy: 98.17708333333333, Time: 0.12375640869140625 ms\n",
      "Epoch 41:[10/16], Current Loss: 0.9203374981880188, Current Training Accuracy: 98.01136363636364, Time: 0.14095115661621094 ms\n",
      "Epoch 41:[15/16], Current Loss: 0.9204213619232178, Current Training Accuracy: 98.095703125, Time: 0.135481595993042 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.4803390502929688 ms\n",
      "Epoch 42:[0/16], Current Loss: 0.9286112189292908, Current Training Accuracy: 97.65625, Time: 0.12876009941101074 ms\n",
      "Epoch 42:[5/16], Current Loss: 0.9054827690124512, Current Training Accuracy: 98.17708333333333, Time: 0.13304376602172852 ms\n",
      "Epoch 42:[10/16], Current Loss: 0.9208754301071167, Current Training Accuracy: 98.22443181818181, Time: 0.12556171417236328 ms\n",
      "Epoch 42:[15/16], Current Loss: 0.9208839535713196, Current Training Accuracy: 98.14453125, Time: 0.12582707405090332 ms\n",
      "Epoch 42, train Loss: 0.923  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.471198320388794 ms\n",
      "Epoch 43:[0/16], Current Loss: 0.9364522695541382, Current Training Accuracy: 96.875, Time: 0.13310933113098145 ms\n",
      "Epoch 43:[5/16], Current Loss: 0.920870304107666, Current Training Accuracy: 98.4375, Time: 0.12520146369934082 ms\n",
      "Epoch 43:[10/16], Current Loss: 0.9433690905570984, Current Training Accuracy: 98.1534090909091, Time: 0.13593816757202148 ms\n",
      "Epoch 43:[15/16], Current Loss: 0.9286323189735413, Current Training Accuracy: 98.193359375, Time: 0.14159464836120605 ms\n",
      "Epoch 43, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.4613170623779297 ms\n",
      "Epoch 44:[0/16], Current Loss: 0.9129476547241211, Current Training Accuracy: 99.21875, Time: 0.1282820701599121 ms\n",
      "Epoch 44:[5/16], Current Loss: 0.9426136016845703, Current Training Accuracy: 98.30729166666667, Time: 0.1414508819580078 ms\n",
      "Epoch 44:[10/16], Current Loss: 0.9281028509140015, Current Training Accuracy: 98.1534090909091, Time: 0.13553881645202637 ms\n",
      "Epoch 44:[15/16], Current Loss: 0.9129234552383423, Current Training Accuracy: 98.14453125, Time: 0.14155936241149902 ms\n",
      "Epoch 44, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.4816668033599854 ms\n",
      "Epoch 45:[0/16], Current Loss: 0.9281398057937622, Current Training Accuracy: 97.65625, Time: 0.1311805248260498 ms\n",
      "Epoch 45:[5/16], Current Loss: 0.936090350151062, Current Training Accuracy: 97.265625, Time: 0.14206290245056152 ms\n",
      "Epoch 45:[10/16], Current Loss: 0.9361861944198608, Current Training Accuracy: 97.79829545454545, Time: 0.12365555763244629 ms\n",
      "Epoch 45:[15/16], Current Loss: 0.9051291942596436, Current Training Accuracy: 98.14453125, Time: 0.14163661003112793 ms\n",
      "Epoch 45, train Loss: 0.923  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.507939100265503 ms\n",
      "Epoch 46:[0/16], Current Loss: 0.9207327365875244, Current Training Accuracy: 98.4375, Time: 0.13852477073669434 ms\n",
      "Epoch 46:[5/16], Current Loss: 0.9129347205162048, Current Training Accuracy: 98.17708333333333, Time: 0.14200496673583984 ms\n",
      "Epoch 46:[10/16], Current Loss: 0.9272707104682922, Current Training Accuracy: 98.08238636363636, Time: 0.12593460083007812 ms\n",
      "Epoch 46:[15/16], Current Loss: 0.9207334518432617, Current Training Accuracy: 98.14453125, Time: 0.14090824127197266 ms\n",
      "Epoch 46, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.47320818901062 ms\n",
      "Epoch 47:[0/16], Current Loss: 0.9122579097747803, Current Training Accuracy: 99.21875, Time: 0.14143633842468262 ms\n",
      "Epoch 47:[5/16], Current Loss: 0.9279695153236389, Current Training Accuracy: 97.78645833333333, Time: 0.140946626663208 ms\n",
      "Epoch 47:[10/16], Current Loss: 0.9385599493980408, Current Training Accuracy: 98.01136363636364, Time: 0.13076257705688477 ms\n",
      "Epoch 47:[15/16], Current Loss: 0.9056826829910278, Current Training Accuracy: 98.2421875, Time: 0.14157390594482422 ms\n",
      "Epoch 47, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.4544425010681152 ms\n",
      "Epoch 48:[0/16], Current Loss: 0.9208813905715942, Current Training Accuracy: 98.4375, Time: 0.1420450210571289 ms\n",
      "Epoch 48:[5/16], Current Loss: 0.9051331877708435, Current Training Accuracy: 98.046875, Time: 0.1262516975402832 ms\n",
      "Epoch 48:[10/16], Current Loss: 0.9130285978317261, Current Training Accuracy: 98.29545454545455, Time: 0.1315152645111084 ms\n",
      "Epoch 48:[15/16], Current Loss: 0.9201792478561401, Current Training Accuracy: 98.291015625, Time: 0.14144468307495117 ms\n",
      "Epoch 48, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.4626729488372803 ms\n",
      "Epoch 49:[0/16], Current Loss: 0.9129035472869873, Current Training Accuracy: 99.21875, Time: 0.14542841911315918 ms\n",
      "Epoch 49:[5/16], Current Loss: 0.9353082776069641, Current Training Accuracy: 98.4375, Time: 0.14142584800720215 ms\n",
      "Epoch 49:[10/16], Current Loss: 0.920793890953064, Current Training Accuracy: 98.1534090909091, Time: 0.13546442985534668 ms\n",
      "Epoch 49:[15/16], Current Loss: 0.9284992218017578, Current Training Accuracy: 98.33984375, Time: 0.12603449821472168 ms\n",
      "Epoch 49, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.489187717437744 ms\n",
      "Epoch 50:[0/16], Current Loss: 0.9127177000045776, Current Training Accuracy: 99.21875, Time: 0.1398470401763916 ms\n",
      "Epoch 50:[5/16], Current Loss: 0.9202454090118408, Current Training Accuracy: 98.69791666666667, Time: 0.1418144702911377 ms\n",
      "Epoch 50:[10/16], Current Loss: 0.9204177260398865, Current Training Accuracy: 98.4375, Time: 0.14169692993164062 ms\n",
      "Epoch 50:[15/16], Current Loss: 0.9206439852714539, Current Training Accuracy: 98.33984375, Time: 0.12579798698425293 ms\n",
      "Epoch 50, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.465104818344116 ms\n",
      "Epoch 51:[0/16], Current Loss: 0.9283006191253662, Current Training Accuracy: 97.65625, Time: 0.14134645462036133 ms\n",
      "Epoch 51:[5/16], Current Loss: 0.9363018274307251, Current Training Accuracy: 98.56770833333333, Time: 0.12845396995544434 ms\n",
      "Epoch 51:[10/16], Current Loss: 0.9345542192459106, Current Training Accuracy: 98.1534090909091, Time: 0.13736510276794434 ms\n",
      "Epoch 51:[15/16], Current Loss: 0.9128926396369934, Current Training Accuracy: 98.33984375, Time: 0.1328258514404297 ms\n",
      "Epoch 51, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.4645028114318848 ms\n",
      "Epoch 52:[0/16], Current Loss: 0.9124260544776917, Current Training Accuracy: 99.21875, Time: 0.14142799377441406 ms\n",
      "Epoch 52:[5/16], Current Loss: 0.9441089034080505, Current Training Accuracy: 98.17708333333333, Time: 0.12578320503234863 ms\n",
      "Epoch 52:[10/16], Current Loss: 0.928511381149292, Current Training Accuracy: 98.1534090909091, Time: 0.1420302391052246 ms\n",
      "Epoch 52:[15/16], Current Loss: 0.9129016995429993, Current Training Accuracy: 98.291015625, Time: 0.1259310245513916 ms\n",
      "Epoch 52, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.48799729347229 ms\n",
      "Epoch 53:[0/16], Current Loss: 0.9050410985946655, Current Training Accuracy: 100.0, Time: 0.14012742042541504 ms\n",
      "Epoch 53:[5/16], Current Loss: 0.9129026532173157, Current Training Accuracy: 99.08854166666667, Time: 0.12997961044311523 ms\n",
      "Epoch 53:[10/16], Current Loss: 0.9206392765045166, Current Training Accuracy: 98.65056818181819, Time: 0.12578368186950684 ms\n",
      "Epoch 53:[15/16], Current Loss: 0.9356741905212402, Current Training Accuracy: 98.291015625, Time: 0.13784217834472656 ms\n",
      "Epoch 53, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.4808826446533203 ms\n",
      "Epoch 54:[0/16], Current Loss: 0.9123751521110535, Current Training Accuracy: 99.21875, Time: 0.14076852798461914 ms\n",
      "Epoch 54:[5/16], Current Loss: 0.9434386491775513, Current Training Accuracy: 98.046875, Time: 0.14052724838256836 ms\n",
      "Epoch 54:[10/16], Current Loss: 0.9206886291503906, Current Training Accuracy: 98.4375, Time: 0.13558554649353027 ms\n",
      "Epoch 54:[15/16], Current Loss: 0.9279904365539551, Current Training Accuracy: 98.291015625, Time: 0.1424710750579834 ms\n",
      "Epoch 54, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.4926767349243164 ms\n",
      "Epoch 55:[0/16], Current Loss: 0.9207069277763367, Current Training Accuracy: 98.4375, Time: 0.14837050437927246 ms\n",
      "Epoch 55:[5/16], Current Loss: 0.9207000732421875, Current Training Accuracy: 98.69791666666667, Time: 0.13472914695739746 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55:[10/16], Current Loss: 0.9128310680389404, Current Training Accuracy: 98.50852272727273, Time: 0.1414341926574707 ms\n",
      "Epoch 55:[15/16], Current Loss: 0.9128332138061523, Current Training Accuracy: 98.291015625, Time: 0.12753963470458984 ms\n",
      "Epoch 55, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.4747724533081055 ms\n",
      "Epoch 56:[0/16], Current Loss: 0.9129005670547485, Current Training Accuracy: 99.21875, Time: 0.14242100715637207 ms\n",
      "Epoch 56:[5/16], Current Loss: 0.9356951117515564, Current Training Accuracy: 98.69791666666667, Time: 0.1353757381439209 ms\n",
      "Epoch 56:[10/16], Current Loss: 0.9204618334770203, Current Training Accuracy: 98.29545454545455, Time: 0.13531947135925293 ms\n",
      "Epoch 56:[15/16], Current Loss: 0.9128905534744263, Current Training Accuracy: 98.291015625, Time: 0.13940739631652832 ms\n",
      "Epoch 56, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.502148389816284 ms\n",
      "Epoch 57:[0/16], Current Loss: 0.9204347729682922, Current Training Accuracy: 98.4375, Time: 0.13527536392211914 ms\n",
      "Epoch 57:[5/16], Current Loss: 0.9352261424064636, Current Training Accuracy: 97.91666666666667, Time: 0.12579917907714844 ms\n",
      "Epoch 57:[10/16], Current Loss: 0.9205265045166016, Current Training Accuracy: 98.29545454545455, Time: 0.14103078842163086 ms\n",
      "Epoch 57:[15/16], Current Loss: 0.9363024234771729, Current Training Accuracy: 98.291015625, Time: 0.13620829582214355 ms\n",
      "Epoch 57, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.471107244491577 ms\n",
      "Epoch 58:[0/16], Current Loss: 0.9279167652130127, Current Training Accuracy: 97.65625, Time: 0.14193439483642578 ms\n",
      "Epoch 58:[5/16], Current Loss: 0.9156152009963989, Current Training Accuracy: 97.78645833333333, Time: 0.1308891773223877 ms\n",
      "Epoch 58:[10/16], Current Loss: 0.9214400053024292, Current Training Accuracy: 98.1534090909091, Time: 0.13843846321105957 ms\n",
      "Epoch 58:[15/16], Current Loss: 0.973530650138855, Current Training Accuracy: 97.216796875, Time: 0.1320509910583496 ms\n",
      "Epoch 58, train Loss: 0.934  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.487640380859375 ms\n",
      "Epoch 59:[0/16], Current Loss: 1.1107218265533447, Current Training Accuracy: 80.46875, Time: 0.14815330505371094 ms\n",
      "Epoch 59:[5/16], Current Loss: 0.9497736096382141, Current Training Accuracy: 86.58854166666667, Time: 0.13100886344909668 ms\n",
      "Epoch 59:[10/16], Current Loss: 0.9401458501815796, Current Training Accuracy: 90.19886363636364, Time: 0.13116002082824707 ms\n",
      "Epoch 59:[15/16], Current Loss: 0.9879746437072754, Current Training Accuracy: 90.72265625, Time: 0.14073729515075684 ms\n",
      "Epoch 59, train Loss: 1.007  Avg Training Accuracy: {87 %} Avg Validation Accuracy: 57 % Epoch Time: 3.482686758041382 ms\n",
      "Epoch 60:[0/16], Current Loss: 0.9660520553588867, Current Training Accuracy: 94.53125, Time: 0.14037418365478516 ms\n",
      "Epoch 60:[5/16], Current Loss: 0.9567921757698059, Current Training Accuracy: 94.27083333333333, Time: 0.12583374977111816 ms\n",
      "Epoch 60:[10/16], Current Loss: 0.9484936594963074, Current Training Accuracy: 94.88636363636364, Time: 0.13840126991271973 ms\n",
      "Epoch 60:[15/16], Current Loss: 0.9644300937652588, Current Training Accuracy: 95.21484375, Time: 0.12862706184387207 ms\n",
      "Epoch 60, train Loss: 0.958  Avg Training Accuracy: {94 %} Avg Validation Accuracy: 63 % Epoch Time: 3.478126287460327 ms\n",
      "Epoch 61:[0/16], Current Loss: 0.9310879111289978, Current Training Accuracy: 97.65625, Time: 0.12661170959472656 ms\n",
      "Epoch 61:[5/16], Current Loss: 0.9079957604408264, Current Training Accuracy: 97.265625, Time: 0.14143157005310059 ms\n",
      "Epoch 61:[10/16], Current Loss: 0.9462947249412537, Current Training Accuracy: 97.3721590909091, Time: 0.1427767276763916 ms\n",
      "Epoch 61:[15/16], Current Loss: 0.9398395419120789, Current Training Accuracy: 97.16796875, Time: 0.14302730560302734 ms\n",
      "Epoch 61, train Loss: 0.935  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.467827081680298 ms\n",
      "Epoch 62:[0/16], Current Loss: 0.930347204208374, Current Training Accuracy: 97.65625, Time: 0.13210582733154297 ms\n",
      "Epoch 62:[5/16], Current Loss: 0.9435351490974426, Current Training Accuracy: 97.265625, Time: 0.13113975524902344 ms\n",
      "Epoch 62:[10/16], Current Loss: 0.9226531386375427, Current Training Accuracy: 97.79829545454545, Time: 0.13500332832336426 ms\n",
      "Epoch 62:[15/16], Current Loss: 0.9139412045478821, Current Training Accuracy: 97.94921875, Time: 0.1414196491241455 ms\n",
      "Epoch 62, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.4799156188964844 ms\n",
      "Epoch 63:[0/16], Current Loss: 0.9228403568267822, Current Training Accuracy: 98.4375, Time: 0.14085912704467773 ms\n",
      "Epoch 63:[5/16], Current Loss: 0.9287644028663635, Current Training Accuracy: 98.046875, Time: 0.14237284660339355 ms\n",
      "Epoch 63:[10/16], Current Loss: 0.9218858480453491, Current Training Accuracy: 98.29545454545455, Time: 0.14587759971618652 ms\n",
      "Epoch 63:[15/16], Current Loss: 0.951532244682312, Current Training Accuracy: 98.14453125, Time: 0.14134573936462402 ms\n",
      "Epoch 63, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.4973690509796143 ms\n",
      "Epoch 64:[0/16], Current Loss: 0.9051109552383423, Current Training Accuracy: 100.0, Time: 0.13031673431396484 ms\n",
      "Epoch 64:[5/16], Current Loss: 0.9130036234855652, Current Training Accuracy: 98.56770833333333, Time: 0.13484954833984375 ms\n",
      "Epoch 64:[10/16], Current Loss: 0.9285596013069153, Current Training Accuracy: 98.22443181818181, Time: 0.1415543556213379 ms\n",
      "Epoch 64:[15/16], Current Loss: 0.9208908677101135, Current Training Accuracy: 98.14453125, Time: 0.1332991123199463 ms\n",
      "Epoch 64, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.4871554374694824 ms\n",
      "Epoch 65:[0/16], Current Loss: 0.9129270315170288, Current Training Accuracy: 99.21875, Time: 0.13496184349060059 ms\n",
      "Epoch 65:[5/16], Current Loss: 0.9050527215003967, Current Training Accuracy: 98.4375, Time: 0.13501524925231934 ms\n",
      "Epoch 65:[10/16], Current Loss: 0.9362471699714661, Current Training Accuracy: 98.22443181818181, Time: 0.13599848747253418 ms\n",
      "Epoch 65:[15/16], Current Loss: 0.9128340482711792, Current Training Accuracy: 98.14453125, Time: 0.13461828231811523 ms\n",
      "Epoch 65, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.484522819519043 ms\n",
      "Epoch 66:[0/16], Current Loss: 0.9205970168113708, Current Training Accuracy: 98.4375, Time: 0.1293337345123291 ms\n",
      "Epoch 66:[5/16], Current Loss: 0.9201104640960693, Current Training Accuracy: 98.046875, Time: 0.13168597221374512 ms\n",
      "Epoch 66:[10/16], Current Loss: 0.9129042625427246, Current Training Accuracy: 98.1534090909091, Time: 0.1262528896331787 ms\n",
      "Epoch 66:[15/16], Current Loss: 0.9361149072647095, Current Training Accuracy: 98.14453125, Time: 0.1288928985595703 ms\n",
      "Epoch 66, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.49678111076355 ms\n",
      "Epoch 67:[0/16], Current Loss: 0.9354448914527893, Current Training Accuracy: 96.875, Time: 0.14151978492736816 ms\n",
      "Epoch 67:[5/16], Current Loss: 0.9128500819206238, Current Training Accuracy: 98.4375, Time: 0.14371275901794434 ms\n",
      "Epoch 67:[10/16], Current Loss: 0.9362820386886597, Current Training Accuracy: 98.36647727272727, Time: 0.1321878433227539 ms\n",
      "Epoch 67:[15/16], Current Loss: 0.9199979901313782, Current Training Accuracy: 98.14453125, Time: 0.13410735130310059 ms\n",
      "Epoch 67, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.482813835144043 ms\n",
      "Epoch 68:[0/16], Current Loss: 0.9050301313400269, Current Training Accuracy: 100.0, Time: 0.1282048225402832 ms\n",
      "Epoch 68:[5/16], Current Loss: 0.9127984642982483, Current Training Accuracy: 98.828125, Time: 0.1269831657409668 ms\n",
      "Epoch 68:[10/16], Current Loss: 0.912837564945221, Current Training Accuracy: 98.29545454545455, Time: 0.12778568267822266 ms\n",
      "Epoch 68:[15/16], Current Loss: 0.9277949929237366, Current Training Accuracy: 98.14453125, Time: 0.1368272304534912 ms\n",
      "Epoch 68, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.5360679626464844 ms\n",
      "Epoch 69:[0/16], Current Loss: 0.9206128716468811, Current Training Accuracy: 98.4375, Time: 0.12525582313537598 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69:[5/16], Current Loss: 0.9362172484397888, Current Training Accuracy: 98.30729166666667, Time: 0.12700295448303223 ms\n",
      "Epoch 69:[10/16], Current Loss: 0.9440050721168518, Current Training Accuracy: 98.1534090909091, Time: 0.12885475158691406 ms\n",
      "Epoch 69:[15/16], Current Loss: 0.9194358587265015, Current Training Accuracy: 98.14453125, Time: 0.12754559516906738 ms\n",
      "Epoch 69, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5064566135406494 ms\n",
      "Epoch 70:[0/16], Current Loss: 0.9256561398506165, Current Training Accuracy: 97.65625, Time: 0.12086009979248047 ms\n",
      "Epoch 70:[5/16], Current Loss: 0.9284786581993103, Current Training Accuracy: 98.17708333333333, Time: 0.1436786651611328 ms\n",
      "Epoch 70:[10/16], Current Loss: 0.9207574725151062, Current Training Accuracy: 98.1534090909091, Time: 0.1253361701965332 ms\n",
      "Epoch 70:[15/16], Current Loss: 0.9206691980361938, Current Training Accuracy: 98.193359375, Time: 0.13875412940979004 ms\n",
      "Epoch 70, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.529130458831787 ms\n",
      "Epoch 71:[0/16], Current Loss: 0.9050618410110474, Current Training Accuracy: 100.0, Time: 0.14124131202697754 ms\n",
      "Epoch 71:[5/16], Current Loss: 0.9589577317237854, Current Training Accuracy: 98.046875, Time: 0.1350104808807373 ms\n",
      "Epoch 71:[10/16], Current Loss: 0.9128143787384033, Current Training Accuracy: 98.29545454545455, Time: 0.14186668395996094 ms\n",
      "Epoch 71:[15/16], Current Loss: 0.9283401370048523, Current Training Accuracy: 98.193359375, Time: 0.14144039154052734 ms\n",
      "Epoch 71, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5123019218444824 ms\n",
      "Epoch 72:[0/16], Current Loss: 0.9206768274307251, Current Training Accuracy: 98.4375, Time: 0.12889909744262695 ms\n",
      "Epoch 72:[5/16], Current Loss: 0.9206126928329468, Current Training Accuracy: 98.56770833333333, Time: 0.1466360092163086 ms\n",
      "Epoch 72:[10/16], Current Loss: 0.9362383484840393, Current Training Accuracy: 98.22443181818181, Time: 0.13508868217468262 ms\n",
      "Epoch 72:[15/16], Current Loss: 0.9176238775253296, Current Training Accuracy: 98.291015625, Time: 0.13219571113586426 ms\n",
      "Epoch 72, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.5292091369628906 ms\n",
      "Epoch 73:[0/16], Current Loss: 0.9206193089485168, Current Training Accuracy: 98.4375, Time: 0.12581348419189453 ms\n",
      "Epoch 73:[5/16], Current Loss: 0.9128481149673462, Current Training Accuracy: 98.046875, Time: 0.13687419891357422 ms\n",
      "Epoch 73:[10/16], Current Loss: 0.9362623691558838, Current Training Accuracy: 98.22443181818181, Time: 0.14220976829528809 ms\n",
      "Epoch 73:[15/16], Current Loss: 0.9206575751304626, Current Training Accuracy: 98.2421875, Time: 0.12830305099487305 ms\n",
      "Epoch 73, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.500786066055298 ms\n",
      "Epoch 74:[0/16], Current Loss: 0.9277853965759277, Current Training Accuracy: 97.65625, Time: 0.13286614418029785 ms\n",
      "Epoch 74:[5/16], Current Loss: 0.920574426651001, Current Training Accuracy: 98.30729166666667, Time: 0.14188313484191895 ms\n",
      "Epoch 74:[10/16], Current Loss: 0.9359317421913147, Current Training Accuracy: 98.7215909090909, Time: 0.13260483741760254 ms\n",
      "Epoch 74:[15/16], Current Loss: 0.9362257719039917, Current Training Accuracy: 98.33984375, Time: 0.13219904899597168 ms\n",
      "Epoch 74, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.4912054538726807 ms\n",
      "Epoch 75:[0/16], Current Loss: 0.9356682896614075, Current Training Accuracy: 96.875, Time: 0.1408100128173828 ms\n",
      "Epoch 75:[5/16], Current Loss: 0.9205822944641113, Current Training Accuracy: 98.17708333333333, Time: 0.1314685344696045 ms\n",
      "Epoch 75:[10/16], Current Loss: 0.9205790162086487, Current Training Accuracy: 98.22443181818181, Time: 0.13413381576538086 ms\n",
      "Epoch 75:[15/16], Current Loss: 0.9283754229545593, Current Training Accuracy: 98.291015625, Time: 0.14140009880065918 ms\n",
      "Epoch 75, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.4838054180145264 ms\n",
      "Epoch 76:[0/16], Current Loss: 0.9205941557884216, Current Training Accuracy: 98.4375, Time: 0.12336206436157227 ms\n",
      "Epoch 76:[5/16], Current Loss: 0.9121950268745422, Current Training Accuracy: 98.30729166666667, Time: 0.14141440391540527 ms\n",
      "Epoch 76:[10/16], Current Loss: 0.9360780715942383, Current Training Accuracy: 98.50852272727273, Time: 0.13591480255126953 ms\n",
      "Epoch 76:[15/16], Current Loss: 0.9277014136314392, Current Training Accuracy: 98.291015625, Time: 0.13512778282165527 ms\n",
      "Epoch 76, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.4749584197998047 ms\n",
      "Epoch 77:[0/16], Current Loss: 0.9205687642097473, Current Training Accuracy: 98.4375, Time: 0.13621044158935547 ms\n",
      "Epoch 77:[5/16], Current Loss: 0.9328550696372986, Current Training Accuracy: 98.30729166666667, Time: 0.14194130897521973 ms\n",
      "Epoch 77:[10/16], Current Loss: 0.9049926996231079, Current Training Accuracy: 98.36647727272727, Time: 0.149583101272583 ms\n",
      "Epoch 77:[15/16], Current Loss: 0.944166898727417, Current Training Accuracy: 98.291015625, Time: 0.12578487396240234 ms\n",
      "Epoch 77, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.4963603019714355 ms\n",
      "Epoch 78:[0/16], Current Loss: 0.9206799864768982, Current Training Accuracy: 98.4375, Time: 0.12572717666625977 ms\n",
      "Epoch 78:[5/16], Current Loss: 0.9278836250305176, Current Training Accuracy: 98.17708333333333, Time: 0.14142417907714844 ms\n",
      "Epoch 78:[10/16], Current Loss: 0.9205776453018188, Current Training Accuracy: 98.29545454545455, Time: 0.14081335067749023 ms\n",
      "Epoch 78:[15/16], Current Loss: 0.9127569198608398, Current Training Accuracy: 98.33984375, Time: 0.1268765926361084 ms\n",
      "Epoch 78, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.4847195148468018 ms\n",
      "Epoch 79:[0/16], Current Loss: 0.9439760446548462, Current Training Accuracy: 96.09375, Time: 0.12933874130249023 ms\n",
      "Epoch 79:[5/16], Current Loss: 0.9349278211593628, Current Training Accuracy: 97.91666666666667, Time: 0.14151835441589355 ms\n",
      "Epoch 79:[10/16], Current Loss: 0.9049546718597412, Current Training Accuracy: 98.4375, Time: 0.13378524780273438 ms\n",
      "Epoch 79:[15/16], Current Loss: 0.9127550721168518, Current Training Accuracy: 98.33984375, Time: 0.14041900634765625 ms\n",
      "Epoch 79, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5420703887939453 ms\n",
      "Epoch 80:[0/16], Current Loss: 0.9277036190032959, Current Training Accuracy: 97.65625, Time: 0.14402389526367188 ms\n",
      "Epoch 80:[5/16], Current Loss: 0.9049438238143921, Current Training Accuracy: 98.17708333333333, Time: 0.14145731925964355 ms\n",
      "Epoch 80:[10/16], Current Loss: 0.9270970821380615, Current Training Accuracy: 98.50852272727273, Time: 0.12563395500183105 ms\n",
      "Epoch 80:[15/16], Current Loss: 0.9330299496650696, Current Training Accuracy: 98.33984375, Time: 0.13212227821350098 ms\n",
      "Epoch 80, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5002598762512207 ms\n",
      "Epoch 81:[0/16], Current Loss: 0.9128952622413635, Current Training Accuracy: 99.21875, Time: 0.12577009201049805 ms\n",
      "Epoch 81:[5/16], Current Loss: 0.9051572680473328, Current Training Accuracy: 98.30729166666667, Time: 0.1281445026397705 ms\n",
      "Epoch 81:[10/16], Current Loss: 0.9205756783485413, Current Training Accuracy: 98.57954545454545, Time: 0.13189125061035156 ms\n",
      "Epoch 81:[15/16], Current Loss: 0.9284847974777222, Current Training Accuracy: 98.6328125, Time: 0.13685941696166992 ms\n",
      "Epoch 81, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5124595165252686 ms\n",
      "Epoch 82:[0/16], Current Loss: 0.9288663268089294, Current Training Accuracy: 97.65625, Time: 0.13743257522583008 ms\n",
      "Epoch 82:[5/16], Current Loss: 0.9128056168556213, Current Training Accuracy: 98.69791666666667, Time: 0.1360032558441162 ms\n",
      "Epoch 82:[10/16], Current Loss: 0.9202907681465149, Current Training Accuracy: 98.4375, Time: 0.13599848747253418 ms\n",
      "Epoch 82:[15/16], Current Loss: 0.9284260869026184, Current Training Accuracy: 98.6328125, Time: 0.13399839401245117 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.626323938369751 ms\n",
      "Epoch 83:[0/16], Current Loss: 0.9200165271759033, Current Training Accuracy: 98.4375, Time: 0.13399934768676758 ms\n",
      "Epoch 83:[5/16], Current Loss: 0.9123028516769409, Current Training Accuracy: 98.69791666666667, Time: 0.13599824905395508 ms\n",
      "Epoch 83:[10/16], Current Loss: 0.9283625483512878, Current Training Accuracy: 98.57954545454545, Time: 0.13699913024902344 ms\n",
      "Epoch 83:[15/16], Current Loss: 0.9127533435821533, Current Training Accuracy: 98.6328125, Time: 0.13499903678894043 ms\n",
      "Epoch 83, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.481004238128662 ms\n",
      "Epoch 84:[0/16], Current Loss: 0.9282495975494385, Current Training Accuracy: 97.65625, Time: 0.13399910926818848 ms\n",
      "Epoch 84:[5/16], Current Loss: 0.91234290599823, Current Training Accuracy: 98.95833333333333, Time: 0.13300061225891113 ms\n",
      "Epoch 84:[10/16], Current Loss: 0.9355931282043457, Current Training Accuracy: 98.57954545454545, Time: 0.13900208473205566 ms\n",
      "Epoch 84:[15/16], Current Loss: 0.9127392172813416, Current Training Accuracy: 98.6328125, Time: 0.13500094413757324 ms\n",
      "Epoch 84, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.472996950149536 ms\n",
      "Epoch 85:[0/16], Current Loss: 0.9127411842346191, Current Training Accuracy: 99.21875, Time: 0.13499999046325684 ms\n",
      "Epoch 85:[5/16], Current Loss: 0.9283614158630371, Current Training Accuracy: 98.828125, Time: 0.13700056076049805 ms\n",
      "Epoch 85:[10/16], Current Loss: 0.9356229901313782, Current Training Accuracy: 98.50852272727273, Time: 0.1380000114440918 ms\n",
      "Epoch 85:[15/16], Current Loss: 0.9205528497695923, Current Training Accuracy: 98.6328125, Time: 0.13800048828125 ms\n",
      "Epoch 85, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.49300217628479 ms\n",
      "Epoch 86:[0/16], Current Loss: 0.9205560088157654, Current Training Accuracy: 98.4375, Time: 0.13599872589111328 ms\n",
      "Epoch 86:[5/16], Current Loss: 0.9049376249313354, Current Training Accuracy: 98.56770833333333, Time: 0.1510026454925537 ms\n",
      "Epoch 86:[10/16], Current Loss: 0.9127278923988342, Current Training Accuracy: 98.7215909090909, Time: 0.1380021572113037 ms\n",
      "Epoch 86:[15/16], Current Loss: 0.9355430603027344, Current Training Accuracy: 98.6328125, Time: 0.13700079917907715 ms\n",
      "Epoch 86, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6060001850128174 ms\n",
      "Epoch 87:[0/16], Current Loss: 0.9049391746520996, Current Training Accuracy: 100.0, Time: 0.13699960708618164 ms\n",
      "Epoch 87:[5/16], Current Loss: 0.9199182391166687, Current Training Accuracy: 98.828125, Time: 0.1360006332397461 ms\n",
      "Epoch 87:[10/16], Current Loss: 0.9283493161201477, Current Training Accuracy: 98.57954545454545, Time: 0.13599872589111328 ms\n",
      "Epoch 87:[15/16], Current Loss: 0.9283531904220581, Current Training Accuracy: 98.681640625, Time: 0.13500022888183594 ms\n",
      "Epoch 87, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.4830005168914795 ms\n",
      "Epoch 88:[0/16], Current Loss: 0.9127286076545715, Current Training Accuracy: 99.21875, Time: 0.13599824905395508 ms\n",
      "Epoch 88:[5/16], Current Loss: 0.9205410480499268, Current Training Accuracy: 98.95833333333333, Time: 0.13700008392333984 ms\n",
      "Epoch 88:[10/16], Current Loss: 0.9361684322357178, Current Training Accuracy: 98.65056818181819, Time: 0.13499999046325684 ms\n",
      "Epoch 88:[15/16], Current Loss: 0.9205405116081238, Current Training Accuracy: 98.6328125, Time: 0.14100050926208496 ms\n",
      "Epoch 88, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.472996950149536 ms\n",
      "Epoch 89:[0/16], Current Loss: 0.9127392172813416, Current Training Accuracy: 99.21875, Time: 0.13900160789489746 ms\n",
      "Epoch 89:[5/16], Current Loss: 0.9127269387245178, Current Training Accuracy: 98.95833333333333, Time: 0.13500046730041504 ms\n",
      "Epoch 89:[10/16], Current Loss: 0.9283510446548462, Current Training Accuracy: 98.7215909090909, Time: 0.14000225067138672 ms\n",
      "Epoch 89:[15/16], Current Loss: 0.9283498525619507, Current Training Accuracy: 98.6328125, Time: 0.1359996795654297 ms\n",
      "Epoch 89, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.4960007667541504 ms\n",
      "Epoch 90:[0/16], Current Loss: 0.9199302196502686, Current Training Accuracy: 98.4375, Time: 0.13599538803100586 ms\n",
      "Epoch 90:[5/16], Current Loss: 0.9127294421195984, Current Training Accuracy: 98.56770833333333, Time: 0.13700008392333984 ms\n",
      "Epoch 90:[10/16], Current Loss: 0.9205483198165894, Current Training Accuracy: 98.7215909090909, Time: 0.13511300086975098 ms\n",
      "Epoch 90:[15/16], Current Loss: 0.9049156308174133, Current Training Accuracy: 98.681640625, Time: 0.1350998878479004 ms\n",
      "Epoch 90, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.4761874675750732 ms\n",
      "Epoch 91:[0/16], Current Loss: 0.9361565113067627, Current Training Accuracy: 96.875, Time: 0.1351025104522705 ms\n",
      "Epoch 91:[5/16], Current Loss: 0.9049094915390015, Current Training Accuracy: 98.69791666666667, Time: 0.13911128044128418 ms\n",
      "Epoch 91:[10/16], Current Loss: 0.9283453226089478, Current Training Accuracy: 98.7215909090909, Time: 0.1370985507965088 ms\n",
      "Epoch 91:[15/16], Current Loss: 0.9205424189567566, Current Training Accuracy: 98.6328125, Time: 0.13410162925720215 ms\n",
      "Epoch 91, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.5079612731933594 ms\n",
      "Epoch 92:[0/16], Current Loss: 0.9201576113700867, Current Training Accuracy: 98.4375, Time: 0.13500452041625977 ms\n",
      "Epoch 92:[5/16], Current Loss: 0.9205267429351807, Current Training Accuracy: 98.4375, Time: 0.13409638404846191 ms\n",
      "Epoch 92:[10/16], Current Loss: 0.9049189686775208, Current Training Accuracy: 98.65056818181819, Time: 0.1359996795654297 ms\n",
      "Epoch 92:[15/16], Current Loss: 0.9199122786521912, Current Training Accuracy: 98.6328125, Time: 0.13610577583312988 ms\n",
      "Epoch 92, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.4690017700195312 ms\n",
      "Epoch 93:[0/16], Current Loss: 0.9439720511436462, Current Training Accuracy: 96.09375, Time: 0.13610124588012695 ms\n",
      "Epoch 93:[5/16], Current Loss: 0.928341269493103, Current Training Accuracy: 98.30729166666667, Time: 0.13499999046325684 ms\n",
      "Epoch 93:[10/16], Current Loss: 0.9205362200737, Current Training Accuracy: 98.50852272727273, Time: 0.1340007781982422 ms\n",
      "Epoch 93:[15/16], Current Loss: 0.9127156734466553, Current Training Accuracy: 98.6328125, Time: 0.1360466480255127 ms\n",
      "Epoch 93, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.4809978008270264 ms\n",
      "Epoch 94:[0/16], Current Loss: 0.9120745658874512, Current Training Accuracy: 99.21875, Time: 0.1350390911102295 ms\n",
      "Epoch 94:[5/16], Current Loss: 0.9049113988876343, Current Training Accuracy: 99.34895833333333, Time: 0.13709282875061035 ms\n",
      "Epoch 94:[10/16], Current Loss: 0.9049135446548462, Current Training Accuracy: 99.28977272727273, Time: 0.1361067295074463 ms\n",
      "Epoch 94:[15/16], Current Loss: 0.9426923394203186, Current Training Accuracy: 98.681640625, Time: 0.13612008094787598 ms\n",
      "Epoch 94, train Loss: 0.918  Avg Training Accuracy: {99 %} Avg Validation Accuracy: 67 % Epoch Time: 3.4869415760040283 ms\n",
      "Epoch 95:[0/16], Current Loss: 0.9277160167694092, Current Training Accuracy: 97.65625, Time: 0.14010167121887207 ms\n",
      "Epoch 95:[5/16], Current Loss: 0.9127158522605896, Current Training Accuracy: 98.4375, Time: 0.13700199127197266 ms\n",
      "Epoch 95:[10/16], Current Loss: 0.9205335378646851, Current Training Accuracy: 98.65056818181819, Time: 0.13610458374023438 ms\n",
      "Epoch 95:[15/16], Current Loss: 0.912713348865509, Current Training Accuracy: 98.6328125, Time: 0.1380469799041748 ms\n",
      "Epoch 95, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.5059518814086914 ms\n",
      "Epoch 96:[0/16], Current Loss: 0.9271937012672424, Current Training Accuracy: 97.65625, Time: 0.1371157169342041 ms\n",
      "Epoch 96:[5/16], Current Loss: 0.9127086997032166, Current Training Accuracy: 98.56770833333333, Time: 0.13511133193969727 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96:[10/16], Current Loss: 0.9205309748649597, Current Training Accuracy: 98.79261363636364, Time: 0.13610029220581055 ms\n",
      "Epoch 96:[15/16], Current Loss: 0.928345799446106, Current Training Accuracy: 98.681640625, Time: 0.13700127601623535 ms\n",
      "Epoch 96, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.480001449584961 ms\n",
      "Epoch 97:[0/16], Current Loss: 0.9198579788208008, Current Training Accuracy: 98.4375, Time: 0.1411113739013672 ms\n",
      "Epoch 97:[5/16], Current Loss: 0.9205238819122314, Current Training Accuracy: 98.4375, Time: 0.14104056358337402 ms\n",
      "Epoch 97:[10/16], Current Loss: 0.9205224514007568, Current Training Accuracy: 98.65056818181819, Time: 0.1351029872894287 ms\n",
      "Epoch 97:[15/16], Current Loss: 0.9127151966094971, Current Training Accuracy: 98.6328125, Time: 0.13610148429870605 ms\n",
      "Epoch 97, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5090062618255615 ms\n",
      "Epoch 98:[0/16], Current Loss: 0.9127150774002075, Current Training Accuracy: 99.21875, Time: 0.137099027633667 ms\n",
      "Epoch 98:[5/16], Current Loss: 0.9127153158187866, Current Training Accuracy: 98.828125, Time: 0.13701844215393066 ms\n",
      "Epoch 98:[10/16], Current Loss: 0.9127112030982971, Current Training Accuracy: 98.65056818181819, Time: 0.1371016502380371 ms\n",
      "Epoch 98:[15/16], Current Loss: 0.9127134680747986, Current Training Accuracy: 98.6328125, Time: 0.1371021270751953 ms\n",
      "Epoch 98, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 3.473994493484497 ms\n",
      "Epoch 99:[0/16], Current Loss: 0.9198911786079407, Current Training Accuracy: 98.4375, Time: 0.13810038566589355 ms\n",
      "Epoch 99:[5/16], Current Loss: 0.9127056002616882, Current Training Accuracy: 98.4375, Time: 0.13808250427246094 ms\n",
      "Epoch 99:[10/16], Current Loss: 0.9205236434936523, Current Training Accuracy: 98.57954545454545, Time: 0.1351022720336914 ms\n",
      "Epoch 99:[15/16], Current Loss: 0.9205273389816284, Current Training Accuracy: 98.6328125, Time: 0.13510441780090332 ms\n",
      "Epoch 99, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.4719979763031006 ms\n",
      "Epoch 100:[0/16], Current Loss: 0.9205201864242554, Current Training Accuracy: 98.4375, Time: 0.13500046730041504 ms\n",
      "Epoch 100:[5/16], Current Loss: 0.9205241799354553, Current Training Accuracy: 98.69791666666667, Time: 0.14100885391235352 ms\n",
      "Epoch 100:[10/16], Current Loss: 0.9049016237258911, Current Training Accuracy: 98.86363636363636, Time: 0.13510584831237793 ms\n",
      "Epoch 100:[15/16], Current Loss: 0.9361396431922913, Current Training Accuracy: 98.6328125, Time: 0.13904237747192383 ms\n",
      "Epoch 100, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.548112392425537 ms\n",
      "Epoch 101:[0/16], Current Loss: 0.9276173710823059, Current Training Accuracy: 97.65625, Time: 0.13912606239318848 ms\n",
      "Epoch 101:[5/16], Current Loss: 0.9199389815330505, Current Training Accuracy: 98.69791666666667, Time: 0.1360006332397461 ms\n",
      "Epoch 101:[10/16], Current Loss: 0.9049012064933777, Current Training Accuracy: 98.86363636363636, Time: 0.13311004638671875 ms\n",
      "Epoch 101:[15/16], Current Loss: 0.9357337355613708, Current Training Accuracy: 98.681640625, Time: 0.13610243797302246 ms\n",
      "Epoch 101, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.526992082595825 ms\n",
      "Epoch 102:[0/16], Current Loss: 0.9205248951911926, Current Training Accuracy: 98.4375, Time: 0.13700246810913086 ms\n",
      "Epoch 102:[5/16], Current Loss: 0.9127156138420105, Current Training Accuracy: 98.4375, Time: 0.1370236873626709 ms\n",
      "Epoch 102:[10/16], Current Loss: 0.9277984499931335, Current Training Accuracy: 98.36647727272727, Time: 0.13707375526428223 ms\n",
      "Epoch 102:[15/16], Current Loss: 0.9048952460289001, Current Training Accuracy: 98.6328125, Time: 0.1360163688659668 ms\n",
      "Epoch 102, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.491997718811035 ms\n",
      "Epoch 103:[0/16], Current Loss: 0.9205307364463806, Current Training Accuracy: 98.4375, Time: 0.1360623836517334 ms\n",
      "Epoch 103:[5/16], Current Loss: 0.9122406840324402, Current Training Accuracy: 98.828125, Time: 0.13700079917907715 ms\n",
      "Epoch 103:[10/16], Current Loss: 0.9439516067504883, Current Training Accuracy: 98.7215909090909, Time: 0.13710498809814453 ms\n",
      "Epoch 103:[15/16], Current Loss: 0.9192147850990295, Current Training Accuracy: 98.6328125, Time: 0.1331007480621338 ms\n",
      "Epoch 103, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.484046220779419 ms\n",
      "Epoch 104:[0/16], Current Loss: 0.9048900008201599, Current Training Accuracy: 100.0, Time: 0.13609623908996582 ms\n",
      "Epoch 104:[5/16], Current Loss: 0.9205219745635986, Current Training Accuracy: 99.21875, Time: 0.13710570335388184 ms\n",
      "Epoch 104:[10/16], Current Loss: 0.9357629418373108, Current Training Accuracy: 98.57954545454545, Time: 0.13611245155334473 ms\n",
      "Epoch 104:[15/16], Current Loss: 0.9127069711685181, Current Training Accuracy: 98.6328125, Time: 0.13610219955444336 ms\n",
      "Epoch 104, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.4909543991088867 ms\n",
      "Epoch 105:[0/16], Current Loss: 0.9205193519592285, Current Training Accuracy: 98.4375, Time: 0.13700103759765625 ms\n",
      "Epoch 105:[5/16], Current Loss: 0.9205220341682434, Current Training Accuracy: 98.56770833333333, Time: 0.13510537147521973 ms\n",
      "Epoch 105:[10/16], Current Loss: 0.9126981496810913, Current Training Accuracy: 98.57954545454545, Time: 0.1351332664489746 ms\n",
      "Epoch 105:[15/16], Current Loss: 0.9199209213256836, Current Training Accuracy: 98.6328125, Time: 0.13712048530578613 ms\n",
      "Epoch 105, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.5109963417053223 ms\n",
      "Epoch 106:[0/16], Current Loss: 0.9205220937728882, Current Training Accuracy: 98.4375, Time: 0.13610100746154785 ms\n",
      "Epoch 106:[5/16], Current Loss: 0.9205151796340942, Current Training Accuracy: 98.69791666666667, Time: 0.13500285148620605 ms\n",
      "Epoch 106:[10/16], Current Loss: 0.9127016067504883, Current Training Accuracy: 98.57954545454545, Time: 0.13500261306762695 ms\n",
      "Epoch 106:[15/16], Current Loss: 0.9120001792907715, Current Training Accuracy: 98.6328125, Time: 0.1390984058380127 ms\n",
      "Epoch 106, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.478118658065796 ms\n",
      "Epoch 107:[0/16], Current Loss: 0.9360101222991943, Current Training Accuracy: 96.875, Time: 0.13700127601623535 ms\n",
      "Epoch 107:[5/16], Current Loss: 0.9127146005630493, Current Training Accuracy: 98.17708333333333, Time: 0.13609623908996582 ms\n",
      "Epoch 107:[10/16], Current Loss: 0.9205211400985718, Current Training Accuracy: 98.57954545454545, Time: 0.13605642318725586 ms\n",
      "Epoch 107:[15/16], Current Loss: 0.9283275008201599, Current Training Accuracy: 98.6328125, Time: 0.1340034008026123 ms\n",
      "Epoch 107, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.496005058288574 ms\n",
      "Epoch 108:[0/16], Current Loss: 0.9127095341682434, Current Training Accuracy: 99.21875, Time: 0.13612914085388184 ms\n",
      "Epoch 108:[5/16], Current Loss: 0.9282551407814026, Current Training Accuracy: 98.69791666666667, Time: 0.13798236846923828 ms\n",
      "Epoch 108:[10/16], Current Loss: 0.9361401200294495, Current Training Accuracy: 98.7215909090909, Time: 0.13501477241516113 ms\n",
      "Epoch 108:[15/16], Current Loss: 0.9283303618431091, Current Training Accuracy: 98.6328125, Time: 0.13701701164245605 ms\n",
      "Epoch 108, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.503878116607666 ms\n",
      "Epoch 109:[0/16], Current Loss: 0.9198669195175171, Current Training Accuracy: 98.4375, Time: 0.13606023788452148 ms\n",
      "Epoch 109:[5/16], Current Loss: 0.9127069711685181, Current Training Accuracy: 98.30729166666667, Time: 0.13610529899597168 ms\n",
      "Epoch 109:[10/16], Current Loss: 0.9126996397972107, Current Training Accuracy: 98.65056818181819, Time: 0.14109396934509277 ms\n",
      "Epoch 109:[15/16], Current Loss: 0.9280142188072205, Current Training Accuracy: 98.6328125, Time: 0.13901638984680176 ms\n",
      "Epoch 109, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5580132007598877 ms\n",
      "Epoch 110:[0/16], Current Loss: 0.9361420273780823, Current Training Accuracy: 96.875, Time: 0.13610029220581055 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110:[5/16], Current Loss: 0.9119873642921448, Current Training Accuracy: 98.95833333333333, Time: 0.1340024471282959 ms\n",
      "Epoch 110:[10/16], Current Loss: 0.9127047657966614, Current Training Accuracy: 98.50852272727273, Time: 0.14100074768066406 ms\n",
      "Epoch 110:[15/16], Current Loss: 0.9127016663551331, Current Training Accuracy: 98.6328125, Time: 0.13810229301452637 ms\n",
      "Epoch 110, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.5000195503234863 ms\n",
      "Epoch 111:[0/16], Current Loss: 0.9127048254013062, Current Training Accuracy: 99.21875, Time: 0.14013147354125977 ms\n",
      "Epoch 111:[5/16], Current Loss: 0.9205105900764465, Current Training Accuracy: 98.69791666666667, Time: 0.13701677322387695 ms\n",
      "Epoch 111:[10/16], Current Loss: 0.9283273816108704, Current Training Accuracy: 98.50852272727273, Time: 0.1371016502380371 ms\n",
      "Epoch 111:[15/16], Current Loss: 0.9205119609832764, Current Training Accuracy: 98.6328125, Time: 0.13610148429870605 ms\n",
      "Epoch 111, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.505963087081909 ms\n",
      "Epoch 112:[0/16], Current Loss: 0.9048932790756226, Current Training Accuracy: 100.0, Time: 0.13700199127197266 ms\n",
      "Epoch 112:[5/16], Current Loss: 0.9127018451690674, Current Training Accuracy: 98.69791666666667, Time: 0.13701510429382324 ms\n",
      "Epoch 112:[10/16], Current Loss: 0.9283221364021301, Current Training Accuracy: 98.7215909090909, Time: 0.1379997730255127 ms\n",
      "Epoch 112:[15/16], Current Loss: 0.9120592474937439, Current Training Accuracy: 98.6328125, Time: 0.1360015869140625 ms\n",
      "Epoch 112, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.504023790359497 ms\n",
      "Epoch 113:[0/16], Current Loss: 0.9119926691055298, Current Training Accuracy: 99.21875, Time: 0.13599920272827148 ms\n",
      "Epoch 113:[5/16], Current Loss: 0.904884934425354, Current Training Accuracy: 98.30729166666667, Time: 0.13509774208068848 ms\n",
      "Epoch 113:[10/16], Current Loss: 0.9127020239830017, Current Training Accuracy: 98.57954545454545, Time: 0.13704586029052734 ms\n",
      "Epoch 113:[15/16], Current Loss: 0.9126994609832764, Current Training Accuracy: 98.6328125, Time: 0.13710904121398926 ms\n",
      "Epoch 113, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.4849770069122314 ms\n",
      "Epoch 114:[0/16], Current Loss: 0.9126991629600525, Current Training Accuracy: 99.21875, Time: 0.1360013484954834 ms\n",
      "Epoch 114:[5/16], Current Loss: 0.9276812076568604, Current Training Accuracy: 98.69791666666667, Time: 0.13810467720031738 ms\n",
      "Epoch 114:[10/16], Current Loss: 0.9432514905929565, Current Training Accuracy: 98.4375, Time: 0.13506627082824707 ms\n",
      "Epoch 114:[15/16], Current Loss: 0.9048865437507629, Current Training Accuracy: 98.6328125, Time: 0.13701677322387695 ms\n",
      "Epoch 114, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.5269980430603027 ms\n",
      "Epoch 115:[0/16], Current Loss: 0.9432495832443237, Current Training Accuracy: 96.09375, Time: 0.1360018253326416 ms\n",
      "Epoch 115:[5/16], Current Loss: 0.9048859477043152, Current Training Accuracy: 98.56770833333333, Time: 0.13700056076049805 ms\n",
      "Epoch 115:[10/16], Current Loss: 0.9048843383789062, Current Training Accuracy: 98.36647727272727, Time: 0.13610196113586426 ms\n",
      "Epoch 115:[15/16], Current Loss: 0.9205082058906555, Current Training Accuracy: 98.6328125, Time: 0.1350691318511963 ms\n",
      "Epoch 115, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.5301249027252197 ms\n",
      "Epoch 116:[0/16], Current Loss: 0.9268875122070312, Current Training Accuracy: 97.65625, Time: 0.1341097354888916 ms\n",
      "Epoch 116:[5/16], Current Loss: 0.9127018451690674, Current Training Accuracy: 98.4375, Time: 0.13609838485717773 ms\n",
      "Epoch 116:[10/16], Current Loss: 0.9126905202865601, Current Training Accuracy: 98.65056818181819, Time: 0.15510010719299316 ms\n",
      "Epoch 116:[15/16], Current Loss: 0.9127057194709778, Current Training Accuracy: 98.6328125, Time: 0.1390237808227539 ms\n",
      "Epoch 116, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6079928874969482 ms\n",
      "Epoch 117:[0/16], Current Loss: 0.9048844575881958, Current Training Accuracy: 100.0, Time: 0.1360151767730713 ms\n",
      "Epoch 117:[5/16], Current Loss: 0.9127014875411987, Current Training Accuracy: 99.08854166666667, Time: 0.13699889183044434 ms\n",
      "Epoch 117:[10/16], Current Loss: 0.912053108215332, Current Training Accuracy: 98.57954545454545, Time: 0.13500213623046875 ms\n",
      "Epoch 117:[15/16], Current Loss: 0.9048794507980347, Current Training Accuracy: 98.6328125, Time: 0.13899731636047363 ms\n",
      "Epoch 117, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.5160162448883057 ms\n",
      "Epoch 118:[0/16], Current Loss: 0.9205142259597778, Current Training Accuracy: 98.4375, Time: 0.13504481315612793 ms\n",
      "Epoch 118:[5/16], Current Loss: 0.9198161959648132, Current Training Accuracy: 98.30729166666667, Time: 0.14009952545166016 ms\n",
      "Epoch 118:[10/16], Current Loss: 0.9126962423324585, Current Training Accuracy: 98.57954545454545, Time: 0.13800287246704102 ms\n",
      "Epoch 118:[15/16], Current Loss: 0.9048752188682556, Current Training Accuracy: 98.6328125, Time: 0.13600540161132812 ms\n",
      "Epoch 118, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.5939900875091553 ms\n",
      "Epoch 119:[0/16], Current Loss: 0.9126930236816406, Current Training Accuracy: 99.21875, Time: 0.13600373268127441 ms\n",
      "Epoch 119:[5/16], Current Loss: 0.9122465252876282, Current Training Accuracy: 98.69791666666667, Time: 0.13611125946044922 ms\n",
      "Epoch 119:[10/16], Current Loss: 0.9205101728439331, Current Training Accuracy: 98.79261363636364, Time: 0.13699960708618164 ms\n",
      "Epoch 119:[15/16], Current Loss: 0.9127048850059509, Current Training Accuracy: 98.6328125, Time: 0.13801312446594238 ms\n",
      "Epoch 119, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.654998302459717 ms\n",
      "Epoch 120:[0/16], Current Loss: 0.9126918911933899, Current Training Accuracy: 99.21875, Time: 0.13596844673156738 ms\n",
      "Epoch 120:[5/16], Current Loss: 0.919864296913147, Current Training Accuracy: 99.21875, Time: 0.13698363304138184 ms\n",
      "Epoch 120:[10/16], Current Loss: 0.9348533749580383, Current Training Accuracy: 98.50852272727273, Time: 0.13598418235778809 ms\n",
      "Epoch 120:[15/16], Current Loss: 0.9205057621002197, Current Training Accuracy: 98.6328125, Time: 0.14123177528381348 ms\n",
      "Epoch 120, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.5857717990875244 ms\n",
      "Epoch 121:[0/16], Current Loss: 0.9283274412155151, Current Training Accuracy: 97.65625, Time: 0.14112162590026855 ms\n",
      "Epoch 121:[5/16], Current Loss: 0.9126908779144287, Current Training Accuracy: 98.4375, Time: 0.1357722282409668 ms\n",
      "Epoch 121:[10/16], Current Loss: 0.9198818802833557, Current Training Accuracy: 98.4375, Time: 0.14187884330749512 ms\n",
      "Epoch 121:[15/16], Current Loss: 0.9048793911933899, Current Training Accuracy: 98.6328125, Time: 0.1413707733154297 ms\n",
      "Epoch 121, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.492143154144287 ms\n",
      "Epoch 122:[0/16], Current Loss: 0.9205068945884705, Current Training Accuracy: 98.4375, Time: 0.14106965065002441 ms\n",
      "Epoch 122:[5/16], Current Loss: 0.912691056728363, Current Training Accuracy: 98.828125, Time: 0.14194226264953613 ms\n",
      "Epoch 122:[10/16], Current Loss: 0.9205031394958496, Current Training Accuracy: 98.50852272727273, Time: 0.14143586158752441 ms\n",
      "Epoch 122:[15/16], Current Loss: 0.9354813694953918, Current Training Accuracy: 98.6328125, Time: 0.1257920265197754 ms\n",
      "Epoch 122, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.5570425987243652 ms\n",
      "Epoch 123:[0/16], Current Loss: 0.9048780202865601, Current Training Accuracy: 100.0, Time: 0.14110326766967773 ms\n",
      "Epoch 123:[5/16], Current Loss: 0.9126928448677063, Current Training Accuracy: 98.30729166666667, Time: 0.14146184921264648 ms\n",
      "Epoch 123:[10/16], Current Loss: 0.9205063581466675, Current Training Accuracy: 98.50852272727273, Time: 0.14142131805419922 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123:[15/16], Current Loss: 0.9048796892166138, Current Training Accuracy: 98.6328125, Time: 0.14201760292053223 ms\n",
      "Epoch 123, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.517369508743286 ms\n",
      "Epoch 124:[0/16], Current Loss: 0.9126946330070496, Current Training Accuracy: 99.21875, Time: 0.14174365997314453 ms\n",
      "Epoch 124:[5/16], Current Loss: 0.9120867848396301, Current Training Accuracy: 99.47916666666667, Time: 0.12581896781921387 ms\n",
      "Epoch 124:[10/16], Current Loss: 0.9355605840682983, Current Training Accuracy: 99.07670454545455, Time: 0.14087700843811035 ms\n",
      "Epoch 124:[15/16], Current Loss: 0.9355555176734924, Current Training Accuracy: 98.6328125, Time: 0.1441330909729004 ms\n",
      "Epoch 124, train Loss: 0.918  Avg Training Accuracy: {99 %} Avg Validation Accuracy: 68 % Epoch Time: 3.4979631900787354 ms\n",
      "Epoch 125:[0/16], Current Loss: 0.919991672039032, Current Training Accuracy: 98.4375, Time: 0.14243531227111816 ms\n",
      "Epoch 125:[5/16], Current Loss: 0.9126921892166138, Current Training Accuracy: 98.30729166666667, Time: 0.12479305267333984 ms\n",
      "Epoch 125:[10/16], Current Loss: 0.9121678471565247, Current Training Accuracy: 98.36647727272727, Time: 0.13553166389465332 ms\n",
      "Epoch 125:[15/16], Current Loss: 0.9205034375190735, Current Training Accuracy: 98.6328125, Time: 0.14122486114501953 ms\n",
      "Epoch 125, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.4927854537963867 ms\n",
      "Epoch 126:[0/16], Current Loss: 0.936129629611969, Current Training Accuracy: 96.875, Time: 0.14144253730773926 ms\n",
      "Epoch 126:[5/16], Current Loss: 0.9205043911933899, Current Training Accuracy: 98.046875, Time: 0.14203214645385742 ms\n",
      "Epoch 126:[10/16], Current Loss: 0.9199581742286682, Current Training Accuracy: 98.4375, Time: 0.1262226104736328 ms\n",
      "Epoch 126:[15/16], Current Loss: 0.9126974940299988, Current Training Accuracy: 98.6328125, Time: 0.1258091926574707 ms\n",
      "Epoch 126, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.4599826335906982 ms\n",
      "Epoch 127:[0/16], Current Loss: 0.919895350933075, Current Training Accuracy: 98.4375, Time: 0.1514909267425537 ms\n",
      "Epoch 127:[5/16], Current Loss: 0.9278202652931213, Current Training Accuracy: 98.56770833333333, Time: 0.14141178131103516 ms\n",
      "Epoch 127:[10/16], Current Loss: 0.9205069541931152, Current Training Accuracy: 98.36647727272727, Time: 0.12563133239746094 ms\n",
      "Epoch 127:[15/16], Current Loss: 0.9048777222633362, Current Training Accuracy: 98.681640625, Time: 0.12229204177856445 ms\n",
      "Epoch 127, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.508317708969116 ms\n",
      "Epoch 128:[0/16], Current Loss: 0.9200568199157715, Current Training Accuracy: 98.4375, Time: 0.1258542537689209 ms\n",
      "Epoch 128:[5/16], Current Loss: 0.9126940369606018, Current Training Accuracy: 98.828125, Time: 0.1414356231689453 ms\n",
      "Epoch 128:[10/16], Current Loss: 0.9121724367141724, Current Training Accuracy: 98.65056818181819, Time: 0.13459038734436035 ms\n",
      "Epoch 128:[15/16], Current Loss: 0.9048843383789062, Current Training Accuracy: 98.6328125, Time: 0.141463041305542 ms\n",
      "Epoch 128, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 3.4689881801605225 ms\n"
     ]
    }
   ],
   "source": [
    "loss_list, counter =[], []\n",
    "count = 0\n",
    "running_loss=0\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0)\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "train_epoch, train_loss = [], []\n",
    "train_acc, val_acc = [], []\n",
    "avg_epoch, avg_train_loss, avg_val_acc = [], [], []\n",
    "epoch_time=[]\n",
    "\n",
    "model.train()\n",
    "for epoch in range(128): \n",
    "    running_loss = 0\n",
    "    total_train = 0\n",
    "    correct_train = 0\n",
    "    total_accuracy = 0\n",
    "    total_val_accuracy = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0   \n",
    "    start1 = time.time()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        start = time.time()\n",
    "        t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
    "        t_image=t_image.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(t_image) # forward\n",
    "        ###########################################################################\n",
    "        outputs=outputs.cuda()\n",
    "        mask=mask.cuda()\n",
    "        loss = criterion(outputs, mask.long()) # calculate the loss\n",
    "        loss.backward() # back propagation\n",
    "        optimizer.step() # update gradients\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += mask.nelement()\n",
    "        correct_train += predicted.eq(mask.data).sum().item()\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        total_accuracy += train_accuracy\n",
    "        if i % 5 == 0:\n",
    "            end = time.time()\n",
    "            print('Epoch {}:[{}/{}], Current Loss: {}, Current Training Accuracy: {}, Time: {} ms'.format(epoch+1, i, len(train_loader), loss.item(), train_accuracy, end - start))      \n",
    "            train_acc.append(train_accuracy)\n",
    "            train_loss.append(loss.item())\n",
    "            train_epoch.append(str(epoch+1) + '/' + str(i))\n",
    "\n",
    "            for j, data1 in enumerate(val_loader, 0):\n",
    "                t_image1, mask1 = data1[0],data1[1].long()\n",
    "                outputs1 = model(t_image1)\n",
    "                mask1_temp=torch.max(mask1.data,1)\n",
    "                mask1_temp1=mask1_temp[1].cuda()\n",
    "                _, predicted1 = torch.max(outputs1.data, 1)\n",
    "                total_val += mask1.nelement()\n",
    "                correct_val += predicted1.eq(mask1_temp1).sum().item()\n",
    "                val_accuracy= 100 * correct_val / total_val\n",
    "                total_val_accuracy += val_accuracy\n",
    "            val_acc.append(val_accuracy)\n",
    "    end1 = time.time()\n",
    "    print('Epoch {}, train Loss: {:.3f} '.format(epoch+1, running_loss/len(train_loader)), \"Avg Training Accuracy: {%d %%}\" % (total_accuracy/len(train_loader)), \"Avg Validation Accuracy: %d %%\" % (total_val_accuracy/len(val_loader)), \"Epoch Time: {} ms\".format(end1 - start1))\n",
    "    epoch_time.append(end1-start1)\n",
    "    avg_epoch.append(epoch+1)\n",
    "    avg_train_loss.append(running_loss/len(train_loader))\n",
    "    avg_val_acc.append(total_val_accuracy/len(val_loader))\n",
    "    #print(avg_epoch)\n",
    "    #print(avg_train_loss)\n",
    "    #print(avg_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81550494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of detecting news bias: 81.5104%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred_correct_num=[]\n",
    "pred_total_num=[]\n",
    "pred_result_list=[]\n",
    "pred_prob_list = []\n",
    "label_prob_list=[]\n",
    "label_list=[]\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
    "    mask=mask.cuda()\n",
    "    output_test=model(t_image)\n",
    "    pred_prob_list.append(output_test)\n",
    "    label_prob_list.append(data[1])\n",
    "    label_list.append(mask)\n",
    "    output=torch.max(output_test,1)[1].long()\n",
    "    pred_result_list.append(output)\n",
    "    pred_correct_num.append(output.eq(mask).sum().item())\n",
    "    pred_total_num.append(output_test.shape[0])\n",
    "acc_test=sum(pred_correct_num)/sum(pred_total_num)\n",
    "print(\"The accuracy of detecting news bias: {}\".format(('%.4f%%'%(acc_test*100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4fddd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for i in range(len(pred_result_list)):\n",
    "    if len(pred_result_list) == 1:\n",
    "        pred_result = pred_result_list[0]\n",
    "        label = label_list[0]\n",
    "    if len(pred_result_list) == 2:\n",
    "        pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
    "        label = torch.cat((label_list[0], label_list[1]), -1)\n",
    "    if len(pred_result_list) > 2:\n",
    "        pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
    "        label = torch.cat((label_list[0], label_list[1]), -1)\n",
    "    for j in range(len(pred_result_list)-2):\n",
    "        pred_result = torch.cat((pred_result, pred_result_list[j+2]), -1)\n",
    "        label = torch.cat((label, label_list[j+2]), -1)\n",
    "label = label.cpu()\n",
    "pred_result = pred_result.cpu()\n",
    "C=confusion_matrix(label,pred_result)\n",
    "df=pd.DataFrame(C,index=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"],columns=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"])\n",
    "p1=sns.heatmap(df,annot=True,cmap=\"hot_r\")\n",
    "s1 = p1.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1009372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Value: 0.0746\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred_prob_list)):\n",
    "    if len(pred_prob_list) == 1:\n",
    "        pred_prob = pred_prob_list[0]\n",
    "        label_prob = label_prob_list[0]\n",
    "    if len(pred_prob_list) == 2:\n",
    "        pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
    "        label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
    "    if len(pred_prob_list) > 2:\n",
    "        pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
    "        label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
    "    for j in range(len(pred_prob_list)-2):\n",
    "        pred_prob = torch.cat((pred_prob, pred_prob_list[j+2]), -1)\n",
    "        label_prob = torch.cat((label_prob, label_prob_list[j+2]), -1)\n",
    "label_prob = label_prob.cpu()\n",
    "pred_prob = pred_prob.cpu()\n",
    "criterion=nn.L1Loss(reduction=\"mean\")\n",
    "loss=criterion(pred_prob, label_prob)\n",
    "print(\"MAE Value: {}\".format(\"%.4f\" % loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad7a5fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-F1 Score: 0.7677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(pred_result,label,average=\"macro\")\n",
    "print(\"Macro-F1 Score: {}\".format(\"%.4f\" % f1_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
