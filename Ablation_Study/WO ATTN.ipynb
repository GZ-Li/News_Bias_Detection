{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa32352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f01787",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_process1=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\X_train_glove_title.npy\")\n",
    "X_test_process1=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\X_test_glove_title.npy\")\n",
    "X_valid_process1=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\X_valid_glove_title.npy\")\n",
    "y_train_process=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\y_train_glove.npy\")\n",
    "y_test_process=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\y_test_glove.npy\")\n",
    "y_valid_process=np.load(\"C:\\\\Users\\\\pc\\\\Desktop\\\\Bias Detection\\\\y_valid_glove.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "643c2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(\n",
    "    dataset=Data.TensorDataset(torch.Tensor(X_train_process1),torch.LongTensor(y_train_process)),      \n",
    "    batch_size=128,      \n",
    "    shuffle=True,               \n",
    "    num_workers=0, \n",
    "    drop_last=True\n",
    ")\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=Data.TensorDataset(torch.Tensor(X_test_process1),torch.LongTensor(y_test_process)),      \n",
    "    batch_size=128,      \n",
    "    shuffle=True,               \n",
    "    num_workers=0,  \n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = Data.DataLoader(\n",
    "    dataset=Data.TensorDataset(torch.Tensor(X_valid_process1),torch.LongTensor(y_valid_process)),      \n",
    "    batch_size=128, \n",
    "    shuffle=True,               \n",
    "    num_workers=0,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dcbbc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECA(x,gamma=2,b=1):\n",
    "    N,C,H,W=x.size()\n",
    "    t=int(abs((log(C,2)+b)/gamma))\n",
    "    k=t if t%2 else t+1\n",
    "    \n",
    "    avg_pool=nn.AdaptiveAvgPool2d(1).cuda()\n",
    "    conv=nn.Conv1d(1,1,kernel_size=k,padding=int(k/2),bias=False).cuda()\n",
    "    sigmoid=nn.Sigmoid().cuda()\n",
    "    \n",
    "    y=avg_pool(x)\n",
    "    y=conv(y.squeeze(-1).transpose(-1,-2))\n",
    "    y=y.transpose(-1,-2).unsqueeze(-1)\n",
    "    y=sigmoid(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b4ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRCNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_size,num_labels=5):\n",
    "        super(TextRCNN,self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=hidden_size,\n",
    "                            batch_first=True,bidirectional=True)\n",
    "        self.dropout = nn.Dropout(.3)\n",
    "        self.linear1 = nn.Linear(embedding_dim+hidden_size*2, 128)\n",
    "        self.linear2 = nn.Linear(600, 128)\n",
    "        self.linear3 = nn.Linear(128, num_labels)\n",
    "        self.conv1 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=6)#通过out_channel改变文中的feature map，且out_channel∈[10,50,100,200,400,600,800,1000]\n",
    "        self.conv2 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=7)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=8)\n",
    "        self.conv4 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=9)\n",
    "\n",
    "    def forward(self, x):#x: [batch,L]\n",
    "        x_embed = x.cuda()\n",
    "        last_hidden_state,(c,h) = self.lstm(x_embed) #last_hidden_state: [batch,L,hidden_size * num_bidirectional]\n",
    "        out = torch.cat((last_hidden_state[:,:,:12],x_embed,last_hidden_state[:,:,12:]),2)#out: [batch,L,embedding_size + hidden_size * num_bidirectional]  \n",
    "        out = F.tanh(self.linear1(out))\n",
    "        out = out.permute(dims=[0,2,1]) #out: [batch,embedding_size + hidden_size * num_bidirectional,L]\n",
    "        out_1 = self.conv1(out)\n",
    "        out_1 = nn.ReLU()(out_1)\n",
    "        out_1 = nn.MaxPool1d(kernel_size=495)(out_1)\n",
    "        out_2 = self.conv1(out)\n",
    "        out_2 = nn.ReLU()(out_2)\n",
    "        out_2 = nn.MaxPool1d(kernel_size=494)(out_2)\n",
    "        out_3 = self.conv1(out)\n",
    "        out_3 = nn.ReLU()(out_3)\n",
    "        out_3 = nn.MaxPool1d(kernel_size=493)(out_3)\n",
    "        out_4 = self.conv1(out)\n",
    "        out_4 = nn.ReLU()(out_4)\n",
    "        out_4 = nn.MaxPool1d(kernel_size=492)(out_4)\n",
    "        out_1 = out_1.unsqueeze(1).cuda()\n",
    "        out_2 = out_2.unsqueeze(1).cuda()\n",
    "        out_3 = out_3.unsqueeze(1).cuda()\n",
    "        out_4 = out_4.unsqueeze(1).cuda()\n",
    "        out = torch.cat([out_1, out_2, out_3, out_4],dim=1).cuda()\n",
    "        channel_weights = F.softmax(ECA(out).squeeze().squeeze(),dim=1).unsqueeze(-1).unsqueeze(-1).expand_as(out)\n",
    "        out = torch.mul(channel_weights,out)\n",
    "        out = torch.sum(out, dim = 1)\n",
    "        out = self.linear2(out.squeeze()) #out: [batch,num_labels]\n",
    "        out = self.linear3(F.tanh(out))\n",
    "        out = F.softmax(out,dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e86b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextRCNN(5302,200,12).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab4ea0d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:[0/16], Current Loss: 1.5982410907745361, Current Training Accuracy: 27.34375, Time: 3.2849984169006348 ms\n",
      "Epoch 1:[5/16], Current Loss: 1.4833004474639893, Current Training Accuracy: 32.161458333333336, Time: 0.14099884033203125 ms\n",
      "Epoch 1:[10/16], Current Loss: 1.4728724956512451, Current Training Accuracy: 36.00852272727273, Time: 0.14099955558776855 ms\n",
      "Epoch 1:[15/16], Current Loss: 1.437701940536499, Current Training Accuracy: 40.8203125, Time: 0.1400010585784912 ms\n",
      "Epoch 1, train Loss: 1.506  Avg Training Accuracy: {34 %} Avg Validation Accuracy: 28 % Epoch Time: 6.777997970581055 ms\n",
      "Epoch 2:[0/16], Current Loss: 1.4016226530075073, Current Training Accuracy: 57.8125, Time: 0.1400008201599121 ms\n",
      "Epoch 2:[5/16], Current Loss: 1.403725028038025, Current Training Accuracy: 55.989583333333336, Time: 0.14299964904785156 ms\n",
      "Epoch 2:[10/16], Current Loss: 1.3426967859268188, Current Training Accuracy: 56.17897727272727, Time: 0.1399989128112793 ms\n",
      "Epoch 2:[15/16], Current Loss: 1.3613908290863037, Current Training Accuracy: 56.396484375, Time: 0.14099931716918945 ms\n",
      "Epoch 2, train Loss: 1.344  Avg Training Accuracy: {56 %} Avg Validation Accuracy: 43 % Epoch Time: 3.5929994583129883 ms\n",
      "Epoch 3:[0/16], Current Loss: 1.307456612586975, Current Training Accuracy: 58.59375, Time: 0.14200210571289062 ms\n",
      "Epoch 3:[5/16], Current Loss: 1.300937533378601, Current Training Accuracy: 57.161458333333336, Time: 0.14099979400634766 ms\n",
      "Epoch 3:[10/16], Current Loss: 1.223639726638794, Current Training Accuracy: 62.85511363636363, Time: 0.1420001983642578 ms\n",
      "Epoch 3:[15/16], Current Loss: 1.2131258249282837, Current Training Accuracy: 64.599609375, Time: 0.1399986743927002 ms\n",
      "Epoch 3, train Loss: 1.272  Avg Training Accuracy: {60 %} Avg Validation Accuracy: 48 % Epoch Time: 3.575007677078247 ms\n",
      "Epoch 4:[0/16], Current Loss: 1.1962080001831055, Current Training Accuracy: 72.65625, Time: 0.14100074768066406 ms\n",
      "Epoch 4:[5/16], Current Loss: 1.1667156219482422, Current Training Accuracy: 72.13541666666667, Time: 0.14099860191345215 ms\n",
      "Epoch 4:[10/16], Current Loss: 1.2288340330123901, Current Training Accuracy: 71.23579545454545, Time: 0.14299917221069336 ms\n",
      "Epoch 4:[15/16], Current Loss: 1.252632737159729, Current Training Accuracy: 70.80078125, Time: 0.14099693298339844 ms\n",
      "Epoch 4, train Loss: 1.207  Avg Training Accuracy: {71 %} Avg Validation Accuracy: 53 % Epoch Time: 3.570996046066284 ms\n",
      "Epoch 5:[0/16], Current Loss: 1.211107611656189, Current Training Accuracy: 70.3125, Time: 0.1400003433227539 ms\n",
      "Epoch 5:[5/16], Current Loss: 1.2264007329940796, Current Training Accuracy: 73.828125, Time: 0.1420001983642578 ms\n",
      "Epoch 5:[10/16], Current Loss: 1.1739431619644165, Current Training Accuracy: 72.86931818181819, Time: 0.1419992446899414 ms\n",
      "Epoch 5:[15/16], Current Loss: 1.1980360746383667, Current Training Accuracy: 72.900390625, Time: 0.14299941062927246 ms\n",
      "Epoch 5, train Loss: 1.186  Avg Training Accuracy: {73 %} Avg Validation Accuracy: 54 % Epoch Time: 3.5859978199005127 ms\n",
      "Epoch 6:[0/16], Current Loss: 1.1718746423721313, Current Training Accuracy: 74.21875, Time: 0.14201760292053223 ms\n",
      "Epoch 6:[5/16], Current Loss: 1.1584210395812988, Current Training Accuracy: 72.39583333333333, Time: 0.14100003242492676 ms\n",
      "Epoch 6:[10/16], Current Loss: 1.1135317087173462, Current Training Accuracy: 73.36647727272727, Time: 0.14400482177734375 ms\n",
      "Epoch 6:[15/16], Current Loss: 1.1538712978363037, Current Training Accuracy: 73.2421875, Time: 0.14099979400634766 ms\n",
      "Epoch 6, train Loss: 1.175  Avg Training Accuracy: {72 %} Avg Validation Accuracy: 51 % Epoch Time: 3.613999843597412 ms\n",
      "Epoch 7:[0/16], Current Loss: 1.1297047138214111, Current Training Accuracy: 78.125, Time: 0.1419994831085205 ms\n",
      "Epoch 7:[5/16], Current Loss: 1.1158702373504639, Current Training Accuracy: 76.43229166666667, Time: 0.14099979400634766 ms\n",
      "Epoch 7:[10/16], Current Loss: 1.1547913551330566, Current Training Accuracy: 75.78125, Time: 0.1439988613128662 ms\n",
      "Epoch 7:[15/16], Current Loss: 1.1543691158294678, Current Training Accuracy: 76.26953125, Time: 0.14300060272216797 ms\n",
      "Epoch 7, train Loss: 1.147  Avg Training Accuracy: {76 %} Avg Validation Accuracy: 53 % Epoch Time: 3.5959994792938232 ms\n",
      "Epoch 8:[0/16], Current Loss: 1.1018790006637573, Current Training Accuracy: 80.46875, Time: 0.1399991512298584 ms\n",
      "Epoch 8:[5/16], Current Loss: 1.1568610668182373, Current Training Accuracy: 78.515625, Time: 0.14299964904785156 ms\n",
      "Epoch 8:[10/16], Current Loss: 1.0972425937652588, Current Training Accuracy: 77.27272727272727, Time: 0.14300036430358887 ms\n",
      "Epoch 8:[15/16], Current Loss: 1.1197861433029175, Current Training Accuracy: 77.783203125, Time: 0.1419987678527832 ms\n",
      "Epoch 8, train Loss: 1.129  Avg Training Accuracy: {78 %} Avg Validation Accuracy: 54 % Epoch Time: 3.5930001735687256 ms\n",
      "Epoch 9:[0/16], Current Loss: 1.115548849105835, Current Training Accuracy: 78.90625, Time: 0.14300107955932617 ms\n",
      "Epoch 9:[5/16], Current Loss: 1.1207025051116943, Current Training Accuracy: 80.20833333333333, Time: 0.14200091361999512 ms\n",
      "Epoch 9:[10/16], Current Loss: 1.1285834312438965, Current Training Accuracy: 78.69318181818181, Time: 0.143019437789917 ms\n",
      "Epoch 9:[15/16], Current Loss: 1.1356587409973145, Current Training Accuracy: 78.80859375, Time: 0.14202213287353516 ms\n",
      "Epoch 9, train Loss: 1.117  Avg Training Accuracy: {79 %} Avg Validation Accuracy: 55 % Epoch Time: 3.59201979637146 ms\n",
      "Epoch 10:[0/16], Current Loss: 1.0909959077835083, Current Training Accuracy: 81.25, Time: 0.14212822914123535 ms\n",
      "Epoch 10:[5/16], Current Loss: 1.1080989837646484, Current Training Accuracy: 78.125, Time: 0.14300107955932617 ms\n",
      "Epoch 10:[10/16], Current Loss: 1.0856226682662964, Current Training Accuracy: 78.125, Time: 0.14405035972595215 ms\n",
      "Epoch 10:[15/16], Current Loss: 1.0454070568084717, Current Training Accuracy: 79.1015625, Time: 0.14300036430358887 ms\n",
      "Epoch 10, train Loss: 1.110  Avg Training Accuracy: {78 %} Avg Validation Accuracy: 55 % Epoch Time: 3.6054301261901855 ms\n",
      "Epoch 11:[0/16], Current Loss: 1.0985844135284424, Current Training Accuracy: 80.46875, Time: 0.14400053024291992 ms\n",
      "Epoch 11:[5/16], Current Loss: 1.1223922967910767, Current Training Accuracy: 79.16666666666667, Time: 0.14202141761779785 ms\n",
      "Epoch 11:[10/16], Current Loss: 1.0658576488494873, Current Training Accuracy: 80.1846590909091, Time: 0.14220547676086426 ms\n",
      "Epoch 11:[15/16], Current Loss: 1.1629663705825806, Current Training Accuracy: 79.39453125, Time: 0.14108824729919434 ms\n",
      "Epoch 11, train Loss: 1.106  Avg Training Accuracy: {79 %} Avg Validation Accuracy: 56 % Epoch Time: 3.5982298851013184 ms\n",
      "Epoch 12:[0/16], Current Loss: 1.0991451740264893, Current Training Accuracy: 79.6875, Time: 0.14609336853027344 ms\n",
      "Epoch 12:[5/16], Current Loss: 1.0466803312301636, Current Training Accuracy: 79.296875, Time: 0.14210247993469238 ms\n",
      "Epoch 12:[10/16], Current Loss: 1.0825718641281128, Current Training Accuracy: 79.1903409090909, Time: 0.14309144020080566 ms\n",
      "Epoch 12:[15/16], Current Loss: 1.077869176864624, Current Training Accuracy: 80.126953125, Time: 0.14209246635437012 ms\n",
      "Epoch 12, train Loss: 1.097  Avg Training Accuracy: {79 %} Avg Validation Accuracy: 55 % Epoch Time: 3.612955093383789 ms\n",
      "Epoch 13:[0/16], Current Loss: 1.0831564664840698, Current Training Accuracy: 84.375, Time: 0.1410977840423584 ms\n",
      "Epoch 13:[5/16], Current Loss: 1.0570182800292969, Current Training Accuracy: 85.02604166666667, Time: 0.14211416244506836 ms\n",
      "Epoch 13:[10/16], Current Loss: 1.015848159790039, Current Training Accuracy: 86.07954545454545, Time: 0.14107298851013184 ms\n",
      "Epoch 13:[15/16], Current Loss: 1.0751324892044067, Current Training Accuracy: 85.693359375, Time: 0.1441020965576172 ms\n",
      "Epoch 13, train Loss: 1.055  Avg Training Accuracy: {85 %} Avg Validation Accuracy: 60 % Epoch Time: 3.603903293609619 ms\n",
      "Epoch 14:[0/16], Current Loss: 1.0553975105285645, Current Training Accuracy: 85.15625, Time: 0.14205574989318848 ms\n",
      "Epoch 14:[5/16], Current Loss: 1.0260676145553589, Current Training Accuracy: 86.19791666666667, Time: 0.14111924171447754 ms\n",
      "Epoch 14:[10/16], Current Loss: 1.0388190746307373, Current Training Accuracy: 86.2215909090909, Time: 0.14200115203857422 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:[15/16], Current Loss: 0.9871799945831299, Current Training Accuracy: 87.01171875, Time: 0.1410057544708252 ms\n",
      "Epoch 14, train Loss: 1.035  Avg Training Accuracy: {86 %} Avg Validation Accuracy: 61 % Epoch Time: 3.5830624103546143 ms\n",
      "Epoch 15:[0/16], Current Loss: 1.0127891302108765, Current Training Accuracy: 89.0625, Time: 0.14400100708007812 ms\n",
      "Epoch 15:[5/16], Current Loss: 1.027396559715271, Current Training Accuracy: 87.5, Time: 0.14099955558776855 ms\n",
      "Epoch 15:[10/16], Current Loss: 0.9697962999343872, Current Training Accuracy: 87.57102272727273, Time: 0.1419999599456787 ms\n",
      "Epoch 15:[15/16], Current Loss: 1.0269380807876587, Current Training Accuracy: 88.0859375, Time: 0.14099836349487305 ms\n",
      "Epoch 15, train Loss: 1.023  Avg Training Accuracy: {87 %} Avg Validation Accuracy: 61 % Epoch Time: 3.613999366760254 ms\n",
      "Epoch 16:[0/16], Current Loss: 0.9773218035697937, Current Training Accuracy: 92.96875, Time: 0.14500117301940918 ms\n",
      "Epoch 16:[5/16], Current Loss: 1.0194329023361206, Current Training Accuracy: 89.58333333333333, Time: 0.14100193977355957 ms\n",
      "Epoch 16:[10/16], Current Loss: 1.0174089670181274, Current Training Accuracy: 89.70170454545455, Time: 0.14202880859375 ms\n",
      "Epoch 16:[15/16], Current Loss: 1.0084928274154663, Current Training Accuracy: 88.76953125, Time: 0.14100122451782227 ms\n",
      "Epoch 16, train Loss: 1.011  Avg Training Accuracy: {90 %} Avg Validation Accuracy: 60 % Epoch Time: 3.5980348587036133 ms\n",
      "Epoch 17:[0/16], Current Loss: 1.0326855182647705, Current Training Accuracy: 86.71875, Time: 0.1419990062713623 ms\n",
      "Epoch 17:[5/16], Current Loss: 0.9913221001625061, Current Training Accuracy: 93.22916666666667, Time: 0.14099884033203125 ms\n",
      "Epoch 17:[10/16], Current Loss: 0.9975259304046631, Current Training Accuracy: 94.10511363636364, Time: 0.1419992446899414 ms\n",
      "Epoch 17:[15/16], Current Loss: 0.9710379838943481, Current Training Accuracy: 94.3359375, Time: 0.14200305938720703 ms\n",
      "Epoch 17, train Loss: 0.987  Avg Training Accuracy: {93 %} Avg Validation Accuracy: 61 % Epoch Time: 3.600008010864258 ms\n",
      "Epoch 18:[0/16], Current Loss: 0.961789071559906, Current Training Accuracy: 96.09375, Time: 0.14299964904785156 ms\n",
      "Epoch 18:[5/16], Current Loss: 0.9615253210067749, Current Training Accuracy: 95.703125, Time: 0.14099931716918945 ms\n",
      "Epoch 18:[10/16], Current Loss: 0.9746422171592712, Current Training Accuracy: 96.3778409090909, Time: 0.14200139045715332 ms\n",
      "Epoch 18:[15/16], Current Loss: 0.9659157395362854, Current Training Accuracy: 96.240234375, Time: 0.14299869537353516 ms\n",
      "Epoch 18, train Loss: 0.962  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 61 % Epoch Time: 3.6059863567352295 ms\n",
      "Epoch 19:[0/16], Current Loss: 0.9420461654663086, Current Training Accuracy: 96.875, Time: 0.14400029182434082 ms\n",
      "Epoch 19:[5/16], Current Loss: 0.9344662427902222, Current Training Accuracy: 97.265625, Time: 0.14100098609924316 ms\n",
      "Epoch 19:[10/16], Current Loss: 0.9409412741661072, Current Training Accuracy: 97.01704545454545, Time: 0.1419975757598877 ms\n",
      "Epoch 19:[15/16], Current Loss: 0.9412335157394409, Current Training Accuracy: 96.875, Time: 0.14499855041503906 ms\n",
      "Epoch 19, train Loss: 0.945  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6150014400482178 ms\n",
      "Epoch 20:[0/16], Current Loss: 0.940593957901001, Current Training Accuracy: 96.875, Time: 0.14400029182434082 ms\n",
      "Epoch 20:[5/16], Current Loss: 0.933586597442627, Current Training Accuracy: 97.65625, Time: 0.14300251007080078 ms\n",
      "Epoch 20:[10/16], Current Loss: 0.9315316677093506, Current Training Accuracy: 97.3721590909091, Time: 0.14101433753967285 ms\n",
      "Epoch 20:[15/16], Current Loss: 0.9193790555000305, Current Training Accuracy: 97.509765625, Time: 0.14100193977355957 ms\n",
      "Epoch 20, train Loss: 0.935  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6210832595825195 ms\n",
      "Epoch 21:[0/16], Current Loss: 0.9392707943916321, Current Training Accuracy: 96.875, Time: 0.14211678504943848 ms\n",
      "Epoch 21:[5/16], Current Loss: 0.9613441228866577, Current Training Accuracy: 97.39583333333333, Time: 0.14499855041503906 ms\n",
      "Epoch 21:[10/16], Current Loss: 0.9177850484848022, Current Training Accuracy: 97.51420454545455, Time: 0.1411290168762207 ms\n",
      "Epoch 21:[15/16], Current Loss: 0.9156513214111328, Current Training Accuracy: 97.65625, Time: 0.1430220603942871 ms\n",
      "Epoch 21, train Loss: 0.931  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.6254165172576904 ms\n",
      "Epoch 22:[0/16], Current Loss: 0.9153966903686523, Current Training Accuracy: 99.21875, Time: 0.1430199146270752 ms\n",
      "Epoch 22:[5/16], Current Loss: 0.9312778115272522, Current Training Accuracy: 97.91666666666667, Time: 0.14099907875061035 ms\n",
      "Epoch 22:[10/16], Current Loss: 0.9363493919372559, Current Training Accuracy: 97.51420454545455, Time: 0.1431128978729248 ms\n",
      "Epoch 22:[15/16], Current Loss: 0.9227738380432129, Current Training Accuracy: 97.75390625, Time: 0.1419987678527832 ms\n",
      "Epoch 22, train Loss: 0.929  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.6050918102264404 ms\n",
      "Epoch 23:[0/16], Current Loss: 0.9299414157867432, Current Training Accuracy: 97.65625, Time: 0.1430037021636963 ms\n",
      "Epoch 23:[5/16], Current Loss: 0.9370846152305603, Current Training Accuracy: 97.91666666666667, Time: 0.14200448989868164 ms\n",
      "Epoch 23:[10/16], Current Loss: 0.9332689642906189, Current Training Accuracy: 97.72727272727273, Time: 0.14310073852539062 ms\n",
      "Epoch 23:[15/16], Current Loss: 0.939042866230011, Current Training Accuracy: 97.75390625, Time: 0.14101672172546387 ms\n",
      "Epoch 23, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.5978903770446777 ms\n",
      "Epoch 24:[0/16], Current Loss: 0.9223170876502991, Current Training Accuracy: 98.4375, Time: 0.14201760292053223 ms\n",
      "Epoch 24:[5/16], Current Loss: 0.9426199197769165, Current Training Accuracy: 97.13541666666667, Time: 0.14200448989868164 ms\n",
      "Epoch 24:[10/16], Current Loss: 0.9140753149986267, Current Training Accuracy: 97.65625, Time: 0.14209485054016113 ms\n",
      "Epoch 24:[15/16], Current Loss: 0.9219648241996765, Current Training Accuracy: 97.8515625, Time: 0.14310002326965332 ms\n",
      "Epoch 24, train Loss: 0.927  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.624999761581421 ms\n",
      "Epoch 25:[0/16], Current Loss: 0.929574191570282, Current Training Accuracy: 97.65625, Time: 0.1430211067199707 ms\n",
      "Epoch 25:[5/16], Current Loss: 0.9134600758552551, Current Training Accuracy: 97.65625, Time: 0.1419990062713623 ms\n",
      "Epoch 25:[10/16], Current Loss: 0.9285938143730164, Current Training Accuracy: 97.72727272727273, Time: 0.14300155639648438 ms\n",
      "Epoch 25:[15/16], Current Loss: 0.9287216067314148, Current Training Accuracy: 97.94921875, Time: 0.1419992446899414 ms\n",
      "Epoch 25, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6011219024658203 ms\n",
      "Epoch 26:[0/16], Current Loss: 0.9427018761634827, Current Training Accuracy: 96.09375, Time: 0.1421191692352295 ms\n",
      "Epoch 26:[5/16], Current Loss: 0.9132341742515564, Current Training Accuracy: 98.17708333333333, Time: 0.1419997215270996 ms\n",
      "Epoch 26:[10/16], Current Loss: 0.9366002678871155, Current Training Accuracy: 97.58522727272727, Time: 0.14200091361999512 ms\n",
      "Epoch 26:[15/16], Current Loss: 0.9132007360458374, Current Training Accuracy: 97.900390625, Time: 0.14099788665771484 ms\n",
      "Epoch 26, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.5986313819885254 ms\n",
      "Epoch 27:[0/16], Current Loss: 0.9287890791893005, Current Training Accuracy: 97.65625, Time: 0.14299845695495605 ms\n",
      "Epoch 27:[5/16], Current Loss: 0.913311779499054, Current Training Accuracy: 98.046875, Time: 0.14200043678283691 ms\n",
      "Epoch 27:[10/16], Current Loss: 0.9208537340164185, Current Training Accuracy: 97.86931818181819, Time: 0.14101815223693848 ms\n",
      "Epoch 27:[15/16], Current Loss: 0.9201785326004028, Current Training Accuracy: 97.900390625, Time: 0.14299988746643066 ms\n",
      "Epoch 27, train Loss: 0.926  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.598997116088867 ms\n",
      "Epoch 28:[0/16], Current Loss: 0.9205490946769714, Current Training Accuracy: 98.4375, Time: 0.1419999599456787 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:[5/16], Current Loss: 0.9440993070602417, Current Training Accuracy: 97.65625, Time: 0.14300107955932617 ms\n",
      "Epoch 28:[10/16], Current Loss: 0.9357461333274841, Current Training Accuracy: 98.1534090909091, Time: 0.14200067520141602 ms\n",
      "Epoch 28:[15/16], Current Loss: 0.9426228404045105, Current Training Accuracy: 97.900390625, Time: 0.14198088645935059 ms\n",
      "Epoch 28, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.622002601623535 ms\n",
      "Epoch 29:[0/16], Current Loss: 0.9207281470298767, Current Training Accuracy: 98.4375, Time: 0.1439981460571289 ms\n",
      "Epoch 29:[5/16], Current Loss: 0.9134534597396851, Current Training Accuracy: 97.91666666666667, Time: 0.1419985294342041 ms\n",
      "Epoch 29:[10/16], Current Loss: 0.921489417552948, Current Training Accuracy: 97.79829545454545, Time: 0.14200043678283691 ms\n",
      "Epoch 29:[15/16], Current Loss: 0.9134783744812012, Current Training Accuracy: 97.94921875, Time: 0.1419999599456787 ms\n",
      "Epoch 29, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.618997812271118 ms\n",
      "Epoch 30:[0/16], Current Loss: 0.920623779296875, Current Training Accuracy: 98.4375, Time: 0.14300060272216797 ms\n",
      "Epoch 30:[5/16], Current Loss: 0.9278090596199036, Current Training Accuracy: 97.52604166666667, Time: 0.14099812507629395 ms\n",
      "Epoch 30:[10/16], Current Loss: 0.9200277924537659, Current Training Accuracy: 98.08238636363636, Time: 0.14400053024291992 ms\n",
      "Epoch 30:[15/16], Current Loss: 0.9211332201957703, Current Training Accuracy: 97.94921875, Time: 0.14299917221069336 ms\n",
      "Epoch 30, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6230626106262207 ms\n",
      "Epoch 31:[0/16], Current Loss: 0.9432709217071533, Current Training Accuracy: 96.09375, Time: 0.1430039405822754 ms\n",
      "Epoch 31:[5/16], Current Loss: 0.9354872703552246, Current Training Accuracy: 97.78645833333333, Time: 0.14200091361999512 ms\n",
      "Epoch 31:[10/16], Current Loss: 0.9132047295570374, Current Training Accuracy: 98.08238636363636, Time: 0.14400029182434082 ms\n",
      "Epoch 31:[15/16], Current Loss: 0.936312198638916, Current Training Accuracy: 97.94921875, Time: 0.14400005340576172 ms\n",
      "Epoch 31, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6330015659332275 ms\n",
      "Epoch 32:[0/16], Current Loss: 0.9206604361534119, Current Training Accuracy: 98.4375, Time: 0.1420001983642578 ms\n",
      "Epoch 32:[5/16], Current Loss: 0.9434455633163452, Current Training Accuracy: 98.046875, Time: 0.14400219917297363 ms\n",
      "Epoch 32:[10/16], Current Loss: 0.912934422492981, Current Training Accuracy: 98.08238636363636, Time: 0.14499998092651367 ms\n",
      "Epoch 32:[15/16], Current Loss: 0.9204956293106079, Current Training Accuracy: 97.998046875, Time: 0.14400219917297363 ms\n",
      "Epoch 32, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.6440768241882324 ms\n",
      "Epoch 33:[0/16], Current Loss: 0.92784583568573, Current Training Accuracy: 97.65625, Time: 0.14299941062927246 ms\n",
      "Epoch 33:[5/16], Current Loss: 0.9278957843780518, Current Training Accuracy: 98.17708333333333, Time: 0.14499926567077637 ms\n",
      "Epoch 33:[10/16], Current Loss: 0.9432357549667358, Current Training Accuracy: 98.29545454545455, Time: 0.14400005340576172 ms\n",
      "Epoch 33:[15/16], Current Loss: 0.9209015965461731, Current Training Accuracy: 97.94921875, Time: 0.14300251007080078 ms\n",
      "Epoch 33, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6639983654022217 ms\n",
      "Epoch 34:[0/16], Current Loss: 0.9509406685829163, Current Training Accuracy: 95.3125, Time: 0.1419992446899414 ms\n",
      "Epoch 34:[5/16], Current Loss: 0.9201396703720093, Current Training Accuracy: 98.046875, Time: 0.14101791381835938 ms\n",
      "Epoch 34:[10/16], Current Loss: 0.9356799721717834, Current Training Accuracy: 97.9403409090909, Time: 0.1439979076385498 ms\n",
      "Epoch 34:[15/16], Current Loss: 0.9356759190559387, Current Training Accuracy: 97.94921875, Time: 0.14300084114074707 ms\n",
      "Epoch 34, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6160037517547607 ms\n",
      "Epoch 35:[0/16], Current Loss: 0.9280545711517334, Current Training Accuracy: 97.65625, Time: 0.14300298690795898 ms\n",
      "Epoch 35:[5/16], Current Loss: 0.9202596545219421, Current Training Accuracy: 97.39583333333333, Time: 0.14300107955932617 ms\n",
      "Epoch 35:[10/16], Current Loss: 0.905174195766449, Current Training Accuracy: 98.08238636363636, Time: 0.1441175937652588 ms\n",
      "Epoch 35:[15/16], Current Loss: 0.9354633092880249, Current Training Accuracy: 97.94921875, Time: 0.14499831199645996 ms\n",
      "Epoch 35, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.627032995223999 ms\n",
      "Epoch 36:[0/16], Current Loss: 0.9359037280082703, Current Training Accuracy: 96.875, Time: 0.1439981460571289 ms\n",
      "Epoch 36:[5/16], Current Loss: 0.9275422096252441, Current Training Accuracy: 98.046875, Time: 0.14300155639648438 ms\n",
      "Epoch 36:[10/16], Current Loss: 0.9351032972335815, Current Training Accuracy: 98.08238636363636, Time: 0.1420145034790039 ms\n",
      "Epoch 36:[15/16], Current Loss: 0.9429273009300232, Current Training Accuracy: 97.94921875, Time: 0.14201784133911133 ms\n",
      "Epoch 36, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6178932189941406 ms\n",
      "Epoch 37:[0/16], Current Loss: 0.9365326762199402, Current Training Accuracy: 96.875, Time: 0.14301848411560059 ms\n",
      "Epoch 37:[5/16], Current Loss: 0.935836672782898, Current Training Accuracy: 97.78645833333333, Time: 0.14300274848937988 ms\n",
      "Epoch 37:[10/16], Current Loss: 0.9127209186553955, Current Training Accuracy: 98.08238636363636, Time: 0.14500093460083008 ms\n",
      "Epoch 37:[15/16], Current Loss: 0.9271945357322693, Current Training Accuracy: 97.94921875, Time: 0.14300107955932617 ms\n",
      "Epoch 37, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6453583240509033 ms\n",
      "Epoch 38:[0/16], Current Loss: 0.9124376177787781, Current Training Accuracy: 99.21875, Time: 0.1430034637451172 ms\n",
      "Epoch 38:[5/16], Current Loss: 0.9353561997413635, Current Training Accuracy: 98.046875, Time: 0.14300060272216797 ms\n",
      "Epoch 38:[10/16], Current Loss: 0.9296845197677612, Current Training Accuracy: 97.58522727272727, Time: 0.14299893379211426 ms\n",
      "Epoch 38:[15/16], Current Loss: 0.9278327226638794, Current Training Accuracy: 98.046875, Time: 0.1430191993713379 ms\n",
      "Epoch 38, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.62200927734375 ms\n",
      "Epoch 39:[0/16], Current Loss: 0.9286212921142578, Current Training Accuracy: 97.65625, Time: 0.14300084114074707 ms\n",
      "Epoch 39:[5/16], Current Loss: 0.9206766486167908, Current Training Accuracy: 98.046875, Time: 0.14299988746643066 ms\n",
      "Epoch 39:[10/16], Current Loss: 0.9207926988601685, Current Training Accuracy: 97.79829545454545, Time: 0.14300179481506348 ms\n",
      "Epoch 39:[15/16], Current Loss: 0.9052432775497437, Current Training Accuracy: 98.046875, Time: 0.14400076866149902 ms\n",
      "Epoch 39, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.631080389022827 ms\n",
      "Epoch 40:[0/16], Current Loss: 0.9129667282104492, Current Training Accuracy: 99.21875, Time: 0.14400029182434082 ms\n",
      "Epoch 40:[5/16], Current Loss: 0.9129389524459839, Current Training Accuracy: 98.17708333333333, Time: 0.1419985294342041 ms\n",
      "Epoch 40:[10/16], Current Loss: 0.9129685759544373, Current Training Accuracy: 98.01136363636364, Time: 0.14503908157348633 ms\n",
      "Epoch 40:[15/16], Current Loss: 0.9208107590675354, Current Training Accuracy: 97.998046875, Time: 0.14309477806091309 ms\n",
      "Epoch 40, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.633244514465332 ms\n",
      "Epoch 41:[0/16], Current Loss: 0.9364282488822937, Current Training Accuracy: 96.875, Time: 0.14305830001831055 ms\n",
      "Epoch 41:[5/16], Current Loss: 0.935380220413208, Current Training Accuracy: 98.046875, Time: 0.14110255241394043 ms\n",
      "Epoch 41:[10/16], Current Loss: 0.9130145311355591, Current Training Accuracy: 98.29545454545455, Time: 0.14500021934509277 ms\n",
      "Epoch 41:[15/16], Current Loss: 0.9279782176017761, Current Training Accuracy: 97.998046875, Time: 0.14609551429748535 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.69891357421875 ms\n",
      "Epoch 42:[0/16], Current Loss: 0.9124166965484619, Current Training Accuracy: 99.21875, Time: 0.14599871635437012 ms\n",
      "Epoch 42:[5/16], Current Loss: 0.9204149842262268, Current Training Accuracy: 98.4375, Time: 0.14300084114074707 ms\n",
      "Epoch 42:[10/16], Current Loss: 0.9355324506759644, Current Training Accuracy: 97.86931818181819, Time: 0.14208269119262695 ms\n",
      "Epoch 42:[15/16], Current Loss: 0.9197185039520264, Current Training Accuracy: 97.998046875, Time: 0.14206981658935547 ms\n",
      "Epoch 42, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.688995838165283 ms\n",
      "Epoch 43:[0/16], Current Loss: 0.9279659986495972, Current Training Accuracy: 97.65625, Time: 0.14307260513305664 ms\n",
      "Epoch 43:[5/16], Current Loss: 0.9126693606376648, Current Training Accuracy: 97.78645833333333, Time: 0.14408326148986816 ms\n",
      "Epoch 43:[10/16], Current Loss: 0.9208123683929443, Current Training Accuracy: 97.9403409090909, Time: 0.1421058177947998 ms\n",
      "Epoch 43:[15/16], Current Loss: 0.9283745884895325, Current Training Accuracy: 98.095703125, Time: 0.14311003684997559 ms\n",
      "Epoch 43, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6500210762023926 ms\n",
      "Epoch 44:[0/16], Current Loss: 0.9379763007164001, Current Training Accuracy: 96.875, Time: 0.14203429222106934 ms\n",
      "Epoch 44:[5/16], Current Loss: 0.9061878323554993, Current Training Accuracy: 98.046875, Time: 0.14210224151611328 ms\n",
      "Epoch 44:[10/16], Current Loss: 0.9365927577018738, Current Training Accuracy: 98.1534090909091, Time: 0.1430678367614746 ms\n",
      "Epoch 44:[15/16], Current Loss: 0.9597030878067017, Current Training Accuracy: 98.095703125, Time: 0.14110755920410156 ms\n",
      "Epoch 44, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.6500403881073 ms\n",
      "Epoch 45:[0/16], Current Loss: 0.9054109454154968, Current Training Accuracy: 100.0, Time: 0.14207959175109863 ms\n",
      "Epoch 45:[5/16], Current Loss: 0.9208002090454102, Current Training Accuracy: 98.95833333333333, Time: 0.1430966854095459 ms\n",
      "Epoch 45:[10/16], Current Loss: 0.9358557462692261, Current Training Accuracy: 98.4375, Time: 0.1420879364013672 ms\n",
      "Epoch 45:[15/16], Current Loss: 0.9357700943946838, Current Training Accuracy: 98.14453125, Time: 0.14298319816589355 ms\n",
      "Epoch 45, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.651442289352417 ms\n",
      "Epoch 46:[0/16], Current Loss: 0.9130507111549377, Current Training Accuracy: 99.21875, Time: 0.14200496673583984 ms\n",
      "Epoch 46:[5/16], Current Loss: 0.9204146862030029, Current Training Accuracy: 98.4375, Time: 0.1420001983642578 ms\n",
      "Epoch 46:[10/16], Current Loss: 0.9208047389984131, Current Training Accuracy: 98.22443181818181, Time: 0.14299917221069336 ms\n",
      "Epoch 46:[15/16], Current Loss: 0.9204193353652954, Current Training Accuracy: 98.095703125, Time: 0.14299798011779785 ms\n",
      "Epoch 46, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.660997152328491 ms\n",
      "Epoch 47:[0/16], Current Loss: 0.9278544783592224, Current Training Accuracy: 97.65625, Time: 0.14400124549865723 ms\n",
      "Epoch 47:[5/16], Current Loss: 0.9279958605766296, Current Training Accuracy: 98.17708333333333, Time: 0.14299941062927246 ms\n",
      "Epoch 47:[10/16], Current Loss: 0.9129875898361206, Current Training Accuracy: 98.36647727272727, Time: 0.14300274848937988 ms\n",
      "Epoch 47:[15/16], Current Loss: 0.9208649396896362, Current Training Accuracy: 98.14453125, Time: 0.14300107955932617 ms\n",
      "Epoch 47, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6320011615753174 ms\n",
      "Epoch 48:[0/16], Current Loss: 0.9201798439025879, Current Training Accuracy: 98.4375, Time: 0.14200067520141602 ms\n",
      "Epoch 48:[5/16], Current Loss: 0.9205533266067505, Current Training Accuracy: 97.91666666666667, Time: 0.14407086372375488 ms\n",
      "Epoch 48:[10/16], Current Loss: 0.9051872491836548, Current Training Accuracy: 98.29545454545455, Time: 0.14300084114074707 ms\n",
      "Epoch 48:[15/16], Current Loss: 0.9271354675292969, Current Training Accuracy: 98.14453125, Time: 0.1419990062713623 ms\n",
      "Epoch 48, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6366214752197266 ms\n",
      "Epoch 49:[0/16], Current Loss: 0.9285420179367065, Current Training Accuracy: 97.65625, Time: 0.14499974250793457 ms\n",
      "Epoch 49:[5/16], Current Loss: 0.936282217502594, Current Training Accuracy: 97.39583333333333, Time: 0.14299893379211426 ms\n",
      "Epoch 49:[10/16], Current Loss: 0.9208073616027832, Current Training Accuracy: 97.79829545454545, Time: 0.14299917221069336 ms\n",
      "Epoch 49:[15/16], Current Loss: 0.9280351996421814, Current Training Accuracy: 98.14453125, Time: 0.14400076866149902 ms\n",
      "Epoch 49, train Loss: 0.923  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6373775005340576 ms\n",
      "Epoch 50:[0/16], Current Loss: 0.9280542731285095, Current Training Accuracy: 97.65625, Time: 0.14299964904785156 ms\n",
      "Epoch 50:[5/16], Current Loss: 0.9206634163856506, Current Training Accuracy: 98.17708333333333, Time: 0.1439962387084961 ms\n",
      "Epoch 50:[10/16], Current Loss: 0.9206854104995728, Current Training Accuracy: 98.01136363636364, Time: 0.14400124549865723 ms\n",
      "Epoch 50:[15/16], Current Loss: 0.9202894568443298, Current Training Accuracy: 98.095703125, Time: 0.14500117301940918 ms\n",
      "Epoch 50, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.656001091003418 ms\n",
      "Epoch 51:[0/16], Current Loss: 0.9362646341323853, Current Training Accuracy: 96.875, Time: 0.1439990997314453 ms\n",
      "Epoch 51:[5/16], Current Loss: 0.9128748178482056, Current Training Accuracy: 97.91666666666667, Time: 0.1439988613128662 ms\n",
      "Epoch 51:[10/16], Current Loss: 0.9278602600097656, Current Training Accuracy: 98.36647727272727, Time: 0.14399957656860352 ms\n",
      "Epoch 51:[15/16], Current Loss: 0.9356759190559387, Current Training Accuracy: 98.095703125, Time: 0.14299917221069336 ms\n",
      "Epoch 51, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.646998167037964 ms\n",
      "Epoch 52:[0/16], Current Loss: 0.9128522872924805, Current Training Accuracy: 99.21875, Time: 0.14300251007080078 ms\n",
      "Epoch 52:[5/16], Current Loss: 0.9206476211547852, Current Training Accuracy: 98.17708333333333, Time: 0.14300942420959473 ms\n",
      "Epoch 52:[10/16], Current Loss: 0.9201662540435791, Current Training Accuracy: 98.22443181818181, Time: 0.14400148391723633 ms\n",
      "Epoch 52:[15/16], Current Loss: 0.9128872752189636, Current Training Accuracy: 98.095703125, Time: 0.14250755310058594 ms\n",
      "Epoch 52, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.616312265396118 ms\n",
      "Epoch 53:[0/16], Current Loss: 0.9202494025230408, Current Training Accuracy: 98.4375, Time: 0.14699721336364746 ms\n",
      "Epoch 53:[5/16], Current Loss: 0.9356426000595093, Current Training Accuracy: 97.52604166666667, Time: 0.14300131797790527 ms\n",
      "Epoch 53:[10/16], Current Loss: 0.9206703305244446, Current Training Accuracy: 98.01136363636364, Time: 0.1439976692199707 ms\n",
      "Epoch 53:[15/16], Current Loss: 0.9050396084785461, Current Training Accuracy: 98.095703125, Time: 0.14300107955932617 ms\n",
      "Epoch 53, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6369969844818115 ms\n",
      "Epoch 54:[0/16], Current Loss: 0.9201409816741943, Current Training Accuracy: 98.4375, Time: 0.14399933815002441 ms\n",
      "Epoch 54:[5/16], Current Loss: 0.9128496050834656, Current Training Accuracy: 98.4375, Time: 0.14300155639648438 ms\n",
      "Epoch 54:[10/16], Current Loss: 0.9200556874275208, Current Training Accuracy: 98.29545454545455, Time: 0.1450026035308838 ms\n",
      "Epoch 54:[15/16], Current Loss: 0.9129019975662231, Current Training Accuracy: 98.095703125, Time: 0.1419990062713623 ms\n",
      "Epoch 54, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.646000623703003 ms\n",
      "Epoch 55:[0/16], Current Loss: 0.9286352396011353, Current Training Accuracy: 97.65625, Time: 0.14400100708007812 ms\n",
      "Epoch 55:[5/16], Current Loss: 0.9202755689620972, Current Training Accuracy: 97.65625, Time: 0.14400196075439453 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55:[10/16], Current Loss: 0.9123507738113403, Current Training Accuracy: 98.1534090909091, Time: 0.14500141143798828 ms\n",
      "Epoch 55:[15/16], Current Loss: 0.9051450490951538, Current Training Accuracy: 98.2421875, Time: 0.14500069618225098 ms\n",
      "Epoch 55, train Loss: 0.923  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 3.695997953414917 ms\n",
      "Epoch 56:[0/16], Current Loss: 0.9284480810165405, Current Training Accuracy: 97.65625, Time: 0.14400124549865723 ms\n",
      "Epoch 56:[5/16], Current Loss: 0.912238597869873, Current Training Accuracy: 98.69791666666667, Time: 0.14299774169921875 ms\n",
      "Epoch 56:[10/16], Current Loss: 0.9424394369125366, Current Training Accuracy: 98.57954545454545, Time: 0.1419999599456787 ms\n",
      "Epoch 56:[15/16], Current Loss: 0.9121952652931213, Current Training Accuracy: 98.2421875, Time: 0.14299988746643066 ms\n",
      "Epoch 56, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.651055097579956 ms\n",
      "Epoch 57:[0/16], Current Loss: 0.9274441003799438, Current Training Accuracy: 97.65625, Time: 0.1419997215270996 ms\n",
      "Epoch 57:[5/16], Current Loss: 0.9199961423873901, Current Training Accuracy: 98.046875, Time: 0.14201784133911133 ms\n",
      "Epoch 57:[10/16], Current Loss: 0.928501307964325, Current Training Accuracy: 98.22443181818181, Time: 0.143998384475708 ms\n",
      "Epoch 57:[15/16], Current Loss: 0.9128617644309998, Current Training Accuracy: 98.291015625, Time: 0.14412260055541992 ms\n",
      "Epoch 57, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.626821994781494 ms\n",
      "Epoch 58:[0/16], Current Loss: 0.92778480052948, Current Training Accuracy: 97.65625, Time: 0.14201617240905762 ms\n",
      "Epoch 58:[5/16], Current Loss: 0.9206491708755493, Current Training Accuracy: 98.828125, Time: 0.14200091361999512 ms\n",
      "Epoch 58:[10/16], Current Loss: 0.9432480931282043, Current Training Accuracy: 98.29545454545455, Time: 0.14600133895874023 ms\n",
      "Epoch 58:[15/16], Current Loss: 0.9350317120552063, Current Training Accuracy: 98.291015625, Time: 0.14199566841125488 ms\n",
      "Epoch 58, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6454672813415527 ms\n",
      "Epoch 59:[0/16], Current Loss: 0.9123167395591736, Current Training Accuracy: 99.21875, Time: 0.14299917221069336 ms\n",
      "Epoch 59:[5/16], Current Loss: 0.9050148129463196, Current Training Accuracy: 98.69791666666667, Time: 0.14300227165222168 ms\n",
      "Epoch 59:[10/16], Current Loss: 0.912253201007843, Current Training Accuracy: 98.36647727272727, Time: 0.14497804641723633 ms\n",
      "Epoch 59:[15/16], Current Loss: 0.9431361556053162, Current Training Accuracy: 98.291015625, Time: 0.1420152187347412 ms\n",
      "Epoch 59, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6889824867248535 ms\n",
      "Epoch 60:[0/16], Current Loss: 0.9278198480606079, Current Training Accuracy: 97.65625, Time: 0.1419994831085205 ms\n",
      "Epoch 60:[5/16], Current Loss: 0.9206219911575317, Current Training Accuracy: 98.56770833333333, Time: 0.14399981498718262 ms\n",
      "Epoch 60:[10/16], Current Loss: 0.9127938151359558, Current Training Accuracy: 98.57954545454545, Time: 0.14500188827514648 ms\n",
      "Epoch 60:[15/16], Current Loss: 0.9283953905105591, Current Training Accuracy: 98.33984375, Time: 0.14500093460083008 ms\n",
      "Epoch 60, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6450541019439697 ms\n",
      "Epoch 61:[0/16], Current Loss: 0.9205920100212097, Current Training Accuracy: 98.4375, Time: 0.14299821853637695 ms\n",
      "Epoch 61:[5/16], Current Loss: 0.934909999370575, Current Training Accuracy: 97.91666666666667, Time: 0.14499902725219727 ms\n",
      "Epoch 61:[10/16], Current Loss: 0.9355065822601318, Current Training Accuracy: 98.01136363636364, Time: 0.14200139045715332 ms\n",
      "Epoch 61:[15/16], Current Loss: 0.9049752950668335, Current Training Accuracy: 98.291015625, Time: 0.14599943161010742 ms\n",
      "Epoch 61, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6259963512420654 ms\n",
      "Epoch 62:[0/16], Current Loss: 0.9206308722496033, Current Training Accuracy: 98.4375, Time: 0.14602041244506836 ms\n",
      "Epoch 62:[5/16], Current Loss: 0.9049757719039917, Current Training Accuracy: 98.30729166666667, Time: 0.14599943161010742 ms\n",
      "Epoch 62:[10/16], Current Loss: 0.9283921718597412, Current Training Accuracy: 98.1534090909091, Time: 0.143998384475708 ms\n",
      "Epoch 62:[15/16], Current Loss: 0.935601532459259, Current Training Accuracy: 98.291015625, Time: 0.14300131797790527 ms\n",
      "Epoch 62, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.640005350112915 ms\n",
      "Epoch 63:[0/16], Current Loss: 0.9049732089042664, Current Training Accuracy: 100.0, Time: 0.1439986228942871 ms\n",
      "Epoch 63:[5/16], Current Loss: 0.9515170454978943, Current Training Accuracy: 98.17708333333333, Time: 0.14499711990356445 ms\n",
      "Epoch 63:[10/16], Current Loss: 0.9049672484397888, Current Training Accuracy: 98.1534090909091, Time: 0.14300298690795898 ms\n",
      "Epoch 63:[15/16], Current Loss: 0.9127865433692932, Current Training Accuracy: 98.291015625, Time: 0.14300155639648438 ms\n",
      "Epoch 63, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.644996404647827 ms\n",
      "Epoch 64:[0/16], Current Loss: 0.9206012487411499, Current Training Accuracy: 98.4375, Time: 0.14500188827514648 ms\n",
      "Epoch 64:[5/16], Current Loss: 0.9127792119979858, Current Training Accuracy: 98.17708333333333, Time: 0.14300107955932617 ms\n",
      "Epoch 64:[10/16], Current Loss: 0.9127916693687439, Current Training Accuracy: 98.29545454545455, Time: 0.14399981498718262 ms\n",
      "Epoch 64:[15/16], Current Loss: 0.9199270009994507, Current Training Accuracy: 98.291015625, Time: 0.14299893379211426 ms\n",
      "Epoch 64, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.643003463745117 ms\n",
      "Epoch 65:[0/16], Current Loss: 0.9127552509307861, Current Training Accuracy: 99.21875, Time: 0.1439986228942871 ms\n",
      "Epoch 65:[5/16], Current Loss: 0.9198729991912842, Current Training Accuracy: 98.17708333333333, Time: 0.14699959754943848 ms\n",
      "Epoch 65:[10/16], Current Loss: 0.9283889532089233, Current Training Accuracy: 98.29545454545455, Time: 0.14400005340576172 ms\n",
      "Epoch 65:[15/16], Current Loss: 0.9283943176269531, Current Training Accuracy: 98.291015625, Time: 0.14399957656860352 ms\n",
      "Epoch 65, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6469948291778564 ms\n",
      "Epoch 66:[0/16], Current Loss: 0.9127591252326965, Current Training Accuracy: 99.21875, Time: 0.14300203323364258 ms\n",
      "Epoch 66:[5/16], Current Loss: 0.9049621224403381, Current Training Accuracy: 98.828125, Time: 0.14500117301940918 ms\n",
      "Epoch 66:[10/16], Current Loss: 0.9127591252326965, Current Training Accuracy: 98.4375, Time: 0.1450028419494629 ms\n",
      "Epoch 66:[15/16], Current Loss: 0.9049515128135681, Current Training Accuracy: 98.291015625, Time: 0.14699888229370117 ms\n",
      "Epoch 66, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.64200496673584 ms\n",
      "Epoch 67:[0/16], Current Loss: 0.9192609786987305, Current Training Accuracy: 98.4375, Time: 0.14399981498718262 ms\n",
      "Epoch 67:[5/16], Current Loss: 0.9426351189613342, Current Training Accuracy: 97.65625, Time: 0.14500045776367188 ms\n",
      "Epoch 67:[10/16], Current Loss: 0.9205666184425354, Current Training Accuracy: 97.9403409090909, Time: 0.1419992446899414 ms\n",
      "Epoch 67:[15/16], Current Loss: 0.9121314287185669, Current Training Accuracy: 98.291015625, Time: 0.1449897289276123 ms\n",
      "Epoch 67, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6209962368011475 ms\n",
      "Epoch 68:[0/16], Current Loss: 0.9120481014251709, Current Training Accuracy: 99.21875, Time: 0.14399409294128418 ms\n",
      "Epoch 68:[5/16], Current Loss: 0.9127597808837891, Current Training Accuracy: 98.69791666666667, Time: 0.14699506759643555 ms\n",
      "Epoch 68:[10/16], Current Loss: 0.9205816984176636, Current Training Accuracy: 98.29545454545455, Time: 0.1459980010986328 ms\n",
      "Epoch 68:[15/16], Current Loss: 0.9283772706985474, Current Training Accuracy: 98.291015625, Time: 0.14401745796203613 ms\n",
      "Epoch 68, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.671001672744751 ms\n",
      "Epoch 69:[0/16], Current Loss: 0.9127541184425354, Current Training Accuracy: 99.21875, Time: 0.14500045776367188 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69:[5/16], Current Loss: 0.9498888850212097, Current Training Accuracy: 98.046875, Time: 0.14500045776367188 ms\n",
      "Epoch 69:[10/16], Current Loss: 0.9354571104049683, Current Training Accuracy: 98.4375, Time: 0.14400053024291992 ms\n",
      "Epoch 69:[15/16], Current Loss: 0.9276843667030334, Current Training Accuracy: 98.291015625, Time: 0.14299988746643066 ms\n",
      "Epoch 69, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.642998695373535 ms\n",
      "Epoch 70:[0/16], Current Loss: 0.9269699454307556, Current Training Accuracy: 97.65625, Time: 0.14299798011779785 ms\n",
      "Epoch 70:[5/16], Current Loss: 0.9191737174987793, Current Training Accuracy: 98.17708333333333, Time: 0.14700007438659668 ms\n",
      "Epoch 70:[10/16], Current Loss: 0.9348072409629822, Current Training Accuracy: 98.22443181818181, Time: 0.14599895477294922 ms\n",
      "Epoch 70:[15/16], Current Loss: 0.9120527505874634, Current Training Accuracy: 98.291015625, Time: 0.14299893379211426 ms\n",
      "Epoch 70, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6549999713897705 ms\n",
      "Epoch 71:[0/16], Current Loss: 0.9354705214500427, Current Training Accuracy: 96.875, Time: 0.14299964904785156 ms\n",
      "Epoch 71:[5/16], Current Loss: 0.9199081063270569, Current Training Accuracy: 98.17708333333333, Time: 0.14300084114074707 ms\n",
      "Epoch 71:[10/16], Current Loss: 0.912222683429718, Current Training Accuracy: 98.22443181818181, Time: 0.14300084114074707 ms\n",
      "Epoch 71:[15/16], Current Loss: 0.9263098835945129, Current Training Accuracy: 98.291015625, Time: 0.14300036430358887 ms\n",
      "Epoch 71, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6459994316101074 ms\n",
      "Epoch 72:[0/16], Current Loss: 0.904931902885437, Current Training Accuracy: 100.0, Time: 0.14299988746643066 ms\n",
      "Epoch 72:[5/16], Current Loss: 0.9198477268218994, Current Training Accuracy: 98.17708333333333, Time: 0.14299821853637695 ms\n",
      "Epoch 72:[10/16], Current Loss: 0.9127562046051025, Current Training Accuracy: 98.01136363636364, Time: 0.14499998092651367 ms\n",
      "Epoch 72:[15/16], Current Loss: 0.9127376079559326, Current Training Accuracy: 98.33984375, Time: 0.14500117301940918 ms\n",
      "Epoch 72, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6650004386901855 ms\n",
      "Epoch 73:[0/16], Current Loss: 0.9199223518371582, Current Training Accuracy: 98.4375, Time: 0.14699935913085938 ms\n",
      "Epoch 73:[5/16], Current Loss: 0.9205517768859863, Current Training Accuracy: 98.69791666666667, Time: 0.14600038528442383 ms\n",
      "Epoch 73:[10/16], Current Loss: 0.9357682466506958, Current Training Accuracy: 98.08238636363636, Time: 0.14499950408935547 ms\n",
      "Epoch 73:[15/16], Current Loss: 0.9198496341705322, Current Training Accuracy: 98.291015625, Time: 0.14499855041503906 ms\n",
      "Epoch 73, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.665999174118042 ms\n",
      "Epoch 74:[0/16], Current Loss: 0.935470461845398, Current Training Accuracy: 96.875, Time: 0.14500212669372559 ms\n",
      "Epoch 74:[5/16], Current Loss: 0.9127557277679443, Current Training Accuracy: 98.56770833333333, Time: 0.14499926567077637 ms\n",
      "Epoch 74:[10/16], Current Loss: 0.9127520322799683, Current Training Accuracy: 98.36647727272727, Time: 0.14500164985656738 ms\n",
      "Epoch 74:[15/16], Current Loss: 0.9277204871177673, Current Training Accuracy: 98.33984375, Time: 0.1439976692199707 ms\n",
      "Epoch 74, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.682001829147339 ms\n",
      "Epoch 75:[0/16], Current Loss: 0.9198408126831055, Current Training Accuracy: 98.4375, Time: 0.1439979076385498 ms\n",
      "Epoch 75:[5/16], Current Loss: 0.919844925403595, Current Training Accuracy: 98.30729166666667, Time: 0.14099812507629395 ms\n",
      "Epoch 75:[10/16], Current Loss: 0.9355131387710571, Current Training Accuracy: 97.86931818181819, Time: 0.14400053024291992 ms\n",
      "Epoch 75:[15/16], Current Loss: 0.9127411842346191, Current Training Accuracy: 98.291015625, Time: 0.14499783515930176 ms\n",
      "Epoch 75, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.647998571395874 ms\n",
      "Epoch 76:[0/16], Current Loss: 0.9205026626586914, Current Training Accuracy: 98.4375, Time: 0.14400029182434082 ms\n",
      "Epoch 76:[5/16], Current Loss: 0.9127229452133179, Current Training Accuracy: 98.828125, Time: 0.14899873733520508 ms\n",
      "Epoch 76:[10/16], Current Loss: 0.9120219945907593, Current Training Accuracy: 98.57954545454545, Time: 0.14632058143615723 ms\n",
      "Epoch 76:[15/16], Current Loss: 0.9585956335067749, Current Training Accuracy: 98.291015625, Time: 0.14401626586914062 ms\n",
      "Epoch 76, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.652085542678833 ms\n",
      "Epoch 77:[0/16], Current Loss: 0.927652895450592, Current Training Accuracy: 97.65625, Time: 0.143996000289917 ms\n",
      "Epoch 77:[5/16], Current Loss: 0.9574434161186218, Current Training Accuracy: 97.265625, Time: 0.147111177444458 ms\n",
      "Epoch 77:[10/16], Current Loss: 0.9205635190010071, Current Training Accuracy: 97.79829545454545, Time: 0.14400029182434082 ms\n",
      "Epoch 77:[15/16], Current Loss: 0.9277315735816956, Current Training Accuracy: 98.291015625, Time: 0.1439990997314453 ms\n",
      "Epoch 77, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6982247829437256 ms\n",
      "Epoch 78:[0/16], Current Loss: 0.9127404093742371, Current Training Accuracy: 99.21875, Time: 0.14500164985656738 ms\n",
      "Epoch 78:[5/16], Current Loss: 0.9127145409584045, Current Training Accuracy: 99.08854166666667, Time: 0.1460120677947998 ms\n",
      "Epoch 78:[10/16], Current Loss: 0.9276430010795593, Current Training Accuracy: 98.4375, Time: 0.14699935913085938 ms\n",
      "Epoch 78:[15/16], Current Loss: 0.9358451962471008, Current Training Accuracy: 98.291015625, Time: 0.14499878883361816 ms\n",
      "Epoch 78, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.681670904159546 ms\n",
      "Epoch 79:[0/16], Current Loss: 0.9192755222320557, Current Training Accuracy: 98.4375, Time: 0.14500093460083008 ms\n",
      "Epoch 79:[5/16], Current Loss: 0.9361938238143921, Current Training Accuracy: 98.046875, Time: 0.14399981498718262 ms\n",
      "Epoch 79:[10/16], Current Loss: 0.9127374887466431, Current Training Accuracy: 98.29545454545455, Time: 0.14500188827514648 ms\n",
      "Epoch 79:[15/16], Current Loss: 0.9276624917984009, Current Training Accuracy: 98.291015625, Time: 0.14500141143798828 ms\n",
      "Epoch 79, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6689999103546143 ms\n",
      "Epoch 80:[0/16], Current Loss: 0.9276889562606812, Current Training Accuracy: 97.65625, Time: 0.14500141143798828 ms\n",
      "Epoch 80:[5/16], Current Loss: 0.9127301573753357, Current Training Accuracy: 97.52604166666667, Time: 0.14499902725219727 ms\n",
      "Epoch 80:[10/16], Current Loss: 0.9359177947044373, Current Training Accuracy: 97.79829545454545, Time: 0.14500045776367188 ms\n",
      "Epoch 80:[15/16], Current Loss: 0.9049320220947266, Current Training Accuracy: 98.291015625, Time: 0.1439988613128662 ms\n",
      "Epoch 80, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6550018787384033 ms\n",
      "Epoch 81:[0/16], Current Loss: 0.912117063999176, Current Training Accuracy: 99.21875, Time: 0.14499831199645996 ms\n",
      "Epoch 81:[5/16], Current Loss: 0.9205437302589417, Current Training Accuracy: 98.95833333333333, Time: 0.14499711990356445 ms\n",
      "Epoch 81:[10/16], Current Loss: 0.9276754856109619, Current Training Accuracy: 98.4375, Time: 0.14700102806091309 ms\n",
      "Epoch 81:[15/16], Current Loss: 0.9429689645767212, Current Training Accuracy: 98.291015625, Time: 0.14400029182434082 ms\n",
      "Epoch 81, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.7009994983673096 ms\n",
      "Epoch 82:[0/16], Current Loss: 0.9127303957939148, Current Training Accuracy: 99.21875, Time: 0.1470012664794922 ms\n",
      "Epoch 82:[5/16], Current Loss: 0.928391695022583, Current Training Accuracy: 98.828125, Time: 0.14399933815002441 ms\n",
      "Epoch 82:[10/16], Current Loss: 0.9198400378227234, Current Training Accuracy: 98.36647727272727, Time: 0.14599895477294922 ms\n",
      "Epoch 82:[15/16], Current Loss: 0.9355841875076294, Current Training Accuracy: 98.291015625, Time: 0.14600133895874023 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 3.653001070022583 ms\n",
      "Epoch 83:[0/16], Current Loss: 0.9204661250114441, Current Training Accuracy: 98.4375, Time: 0.14599919319152832 ms\n",
      "Epoch 83:[5/16], Current Loss: 0.9205416440963745, Current Training Accuracy: 98.046875, Time: 0.14600133895874023 ms\n",
      "Epoch 83:[10/16], Current Loss: 0.9277005195617676, Current Training Accuracy: 98.4375, Time: 0.145003080368042 ms\n",
      "Epoch 83:[15/16], Current Loss: 0.9283743500709534, Current Training Accuracy: 98.291015625, Time: 0.14313864707946777 ms\n",
      "Epoch 83, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6670045852661133 ms\n",
      "Epoch 84:[0/16], Current Loss: 0.9276990294456482, Current Training Accuracy: 97.65625, Time: 0.14507389068603516 ms\n",
      "Epoch 84:[5/16], Current Loss: 0.9199031591415405, Current Training Accuracy: 98.56770833333333, Time: 0.14510536193847656 ms\n",
      "Epoch 84:[10/16], Current Loss: 0.9127353429794312, Current Training Accuracy: 98.65056818181819, Time: 0.1470203399658203 ms\n",
      "Epoch 84:[15/16], Current Loss: 0.9282682538032532, Current Training Accuracy: 98.291015625, Time: 0.14508891105651855 ms\n",
      "Epoch 84, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.6729652881622314 ms\n",
      "Epoch 85:[0/16], Current Loss: 0.936147153377533, Current Training Accuracy: 96.875, Time: 0.14609837532043457 ms\n",
      "Epoch 85:[5/16], Current Loss: 0.9277272820472717, Current Training Accuracy: 98.30729166666667, Time: 0.1461043357849121 ms\n",
      "Epoch 85:[10/16], Current Loss: 0.9124369621276855, Current Training Accuracy: 98.36647727272727, Time: 0.14611530303955078 ms\n",
      "Epoch 85:[15/16], Current Loss: 0.9350080490112305, Current Training Accuracy: 98.291015625, Time: 0.14403271675109863 ms\n",
      "Epoch 85, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6920053958892822 ms\n",
      "Epoch 86:[0/16], Current Loss: 0.9049121737480164, Current Training Accuracy: 100.0, Time: 0.14609169960021973 ms\n",
      "Epoch 86:[5/16], Current Loss: 0.9270346164703369, Current Training Accuracy: 98.4375, Time: 0.14408659934997559 ms\n",
      "Epoch 86:[10/16], Current Loss: 0.9205301403999329, Current Training Accuracy: 98.1534090909091, Time: 0.1471107006072998 ms\n",
      "Epoch 86:[15/16], Current Loss: 0.9205451011657715, Current Training Accuracy: 98.33984375, Time: 0.14408278465270996 ms\n",
      "Epoch 86, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.659027338027954 ms\n",
      "Epoch 87:[0/16], Current Loss: 0.9576430320739746, Current Training Accuracy: 94.53125, Time: 0.14407706260681152 ms\n",
      "Epoch 87:[5/16], Current Loss: 0.919834315776825, Current Training Accuracy: 97.78645833333333, Time: 0.14410877227783203 ms\n",
      "Epoch 87:[10/16], Current Loss: 0.9282395839691162, Current Training Accuracy: 98.1534090909091, Time: 0.14509201049804688 ms\n",
      "Epoch 87:[15/16], Current Loss: 0.9198397994041443, Current Training Accuracy: 98.291015625, Time: 0.14501428604125977 ms\n",
      "Epoch 87, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 3.6458849906921387 ms\n",
      "Epoch 88:[0/16], Current Loss: 0.9198320508003235, Current Training Accuracy: 98.4375, Time: 0.14310574531555176 ms\n",
      "Epoch 88:[5/16], Current Loss: 0.9203059077262878, Current Training Accuracy: 98.56770833333333, Time: 0.14710044860839844 ms\n",
      "Epoch 88:[10/16], Current Loss: 0.9127187728881836, Current Training Accuracy: 98.65056818181819, Time: 0.14609622955322266 ms\n",
      "Epoch 88:[15/16], Current Loss: 0.9205382466316223, Current Training Accuracy: 98.291015625, Time: 0.14400219917297363 ms\n",
      "Epoch 88, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.672154188156128 ms\n",
      "Epoch 89:[0/16], Current Loss: 0.920531153678894, Current Training Accuracy: 98.4375, Time: 0.1459980010986328 ms\n",
      "Epoch 89:[5/16], Current Loss: 0.9127230048179626, Current Training Accuracy: 98.69791666666667, Time: 0.14600300788879395 ms\n",
      "Epoch 89:[10/16], Current Loss: 0.9121214747428894, Current Training Accuracy: 98.57954545454545, Time: 0.14499974250793457 ms\n",
      "Epoch 89:[15/16], Current Loss: 0.9199095964431763, Current Training Accuracy: 98.291015625, Time: 0.14500117301940918 ms\n",
      "Epoch 89, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 3.682013988494873 ms\n",
      "Epoch 90:[0/16], Current Loss: 0.927708625793457, Current Training Accuracy: 97.65625, Time: 0.14399981498718262 ms\n",
      "Epoch 90:[5/16], Current Loss: 0.9269586205482483, Current Training Accuracy: 98.046875, Time: 0.14899826049804688 ms\n",
      "Epoch 90:[10/16], Current Loss: 0.912006139755249, Current Training Accuracy: 98.22443181818181, Time: 0.14499878883361816 ms\n",
      "Epoch 90:[15/16], Current Loss: 0.9276595115661621, Current Training Accuracy: 98.291015625, Time: 0.14599871635437012 ms\n",
      "Epoch 90, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.7219998836517334 ms\n",
      "Epoch 91:[0/16], Current Loss: 0.9049044847488403, Current Training Accuracy: 100.0, Time: 0.143998384475708 ms\n",
      "Epoch 91:[5/16], Current Loss: 0.9127199053764343, Current Training Accuracy: 98.56770833333333, Time: 0.14600062370300293 ms\n",
      "Epoch 91:[10/16], Current Loss: 0.9049006700515747, Current Training Accuracy: 98.36647727272727, Time: 0.14299869537353516 ms\n",
      "Epoch 91:[15/16], Current Loss: 0.9191344976425171, Current Training Accuracy: 98.33984375, Time: 0.14300107955932617 ms\n",
      "Epoch 91, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.674997329711914 ms\n",
      "Epoch 92:[0/16], Current Loss: 0.9283331632614136, Current Training Accuracy: 97.65625, Time: 0.14500021934509277 ms\n",
      "Epoch 92:[5/16], Current Loss: 0.9276214241981506, Current Training Accuracy: 98.30729166666667, Time: 0.14500141143798828 ms\n",
      "Epoch 92:[10/16], Current Loss: 0.9198260307312012, Current Training Accuracy: 98.22443181818181, Time: 0.1439988613128662 ms\n",
      "Epoch 92:[15/16], Current Loss: 0.9198281168937683, Current Training Accuracy: 98.291015625, Time: 0.1452028751373291 ms\n",
      "Epoch 92, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 3.6850664615631104 ms\n",
      "Epoch 93:[0/16], Current Loss: 0.9277060031890869, Current Training Accuracy: 97.65625, Time: 0.14400124549865723 ms\n",
      "Epoch 93:[5/16], Current Loss: 0.9049100875854492, Current Training Accuracy: 97.52604166666667, Time: 0.14200305938720703 ms\n",
      "Epoch 93:[10/16], Current Loss: 0.9200171232223511, Current Training Accuracy: 98.29545454545455, Time: 0.14302349090576172 ms\n",
      "Epoch 93:[15/16], Current Loss: 0.9191100597381592, Current Training Accuracy: 98.291015625, Time: 0.14600086212158203 ms\n",
      "Epoch 93, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6520423889160156 ms\n",
      "Epoch 94:[0/16], Current Loss: 0.9205197691917419, Current Training Accuracy: 98.4375, Time: 0.1459972858428955 ms\n",
      "Epoch 94:[5/16], Current Loss: 0.9277068972587585, Current Training Accuracy: 98.56770833333333, Time: 0.1439988613128662 ms\n",
      "Epoch 94:[10/16], Current Loss: 0.9276174306869507, Current Training Accuracy: 98.29545454545455, Time: 0.14599967002868652 ms\n",
      "Epoch 94:[15/16], Current Loss: 0.9425393342971802, Current Training Accuracy: 98.291015625, Time: 0.1640000343322754 ms\n",
      "Epoch 94, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.7110445499420166 ms\n",
      "Epoch 95:[0/16], Current Loss: 0.9127141237258911, Current Training Accuracy: 99.21875, Time: 0.14399981498718262 ms\n",
      "Epoch 95:[5/16], Current Loss: 0.9354525208473206, Current Training Accuracy: 98.95833333333333, Time: 0.14599943161010742 ms\n",
      "Epoch 95:[10/16], Current Loss: 0.927955687046051, Current Training Accuracy: 98.7215909090909, Time: 0.14499831199645996 ms\n",
      "Epoch 95:[15/16], Current Loss: 0.9437709450721741, Current Training Accuracy: 98.291015625, Time: 0.1440119743347168 ms\n",
      "Epoch 95, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.641205310821533 ms\n",
      "Epoch 96:[0/16], Current Loss: 0.9049049019813538, Current Training Accuracy: 100.0, Time: 0.14500069618225098 ms\n",
      "Epoch 96:[5/16], Current Loss: 0.927619993686676, Current Training Accuracy: 98.56770833333333, Time: 0.14699912071228027 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96:[10/16], Current Loss: 0.9194205403327942, Current Training Accuracy: 98.7215909090909, Time: 0.14300060272216797 ms\n",
      "Epoch 96:[15/16], Current Loss: 0.9432458281517029, Current Training Accuracy: 98.33984375, Time: 0.14500117301940918 ms\n",
      "Epoch 96, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.674483299255371 ms\n",
      "Epoch 97:[0/16], Current Loss: 0.9198166131973267, Current Training Accuracy: 98.4375, Time: 0.1439988613128662 ms\n",
      "Epoch 97:[5/16], Current Loss: 0.9048895239830017, Current Training Accuracy: 98.30729166666667, Time: 0.1459972858428955 ms\n",
      "Epoch 97:[10/16], Current Loss: 0.9205167889595032, Current Training Accuracy: 98.57954545454545, Time: 0.1459975242614746 ms\n",
      "Epoch 97:[15/16], Current Loss: 0.9432511925697327, Current Training Accuracy: 98.291015625, Time: 0.14591169357299805 ms\n",
      "Epoch 97, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6710317134857178 ms\n",
      "Epoch 98:[0/16], Current Loss: 0.9198259711265564, Current Training Accuracy: 98.4375, Time: 0.14402461051940918 ms\n",
      "Epoch 98:[5/16], Current Loss: 0.9276655316352844, Current Training Accuracy: 98.30729166666667, Time: 0.14500093460083008 ms\n",
      "Epoch 98:[10/16], Current Loss: 0.9198526740074158, Current Training Accuracy: 98.29545454545455, Time: 0.14500117301940918 ms\n",
      "Epoch 98:[15/16], Current Loss: 0.9127101302146912, Current Training Accuracy: 98.33984375, Time: 0.1490192413330078 ms\n",
      "Epoch 98, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6926774978637695 ms\n",
      "Epoch 99:[0/16], Current Loss: 0.9120098352432251, Current Training Accuracy: 99.21875, Time: 0.14499926567077637 ms\n",
      "Epoch 99:[5/16], Current Loss: 0.935510516166687, Current Training Accuracy: 97.65625, Time: 0.14701581001281738 ms\n",
      "Epoch 99:[10/16], Current Loss: 0.9198119640350342, Current Training Accuracy: 98.22443181818181, Time: 0.14500045776367188 ms\n",
      "Epoch 99:[15/16], Current Loss: 0.919256865978241, Current Training Accuracy: 98.291015625, Time: 0.14299869537353516 ms\n",
      "Epoch 99, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6613903045654297 ms\n",
      "Epoch 100:[0/16], Current Loss: 0.9127146601676941, Current Training Accuracy: 99.21875, Time: 0.14400029182434082 ms\n",
      "Epoch 100:[5/16], Current Loss: 0.9198055267333984, Current Training Accuracy: 97.78645833333333, Time: 0.14700007438659668 ms\n",
      "Epoch 100:[10/16], Current Loss: 0.9127010107040405, Current Training Accuracy: 98.1534090909091, Time: 0.14500117301940918 ms\n",
      "Epoch 100:[15/16], Current Loss: 0.9205141067504883, Current Training Accuracy: 98.291015625, Time: 0.14402103424072266 ms\n",
      "Epoch 100, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.65297794342041 ms\n",
      "Epoch 101:[0/16], Current Loss: 0.9048959612846375, Current Training Accuracy: 100.0, Time: 0.14511561393737793 ms\n",
      "Epoch 101:[5/16], Current Loss: 0.9048815965652466, Current Training Accuracy: 99.34895833333333, Time: 0.14411020278930664 ms\n",
      "Epoch 101:[10/16], Current Loss: 0.9432743787765503, Current Training Accuracy: 98.86363636363636, Time: 0.1450028419494629 ms\n",
      "Epoch 101:[15/16], Current Loss: 0.9508237242698669, Current Training Accuracy: 98.33984375, Time: 0.14601778984069824 ms\n",
      "Epoch 101, train Loss: 0.921  Avg Training Accuracy: {99 %} Avg Validation Accuracy: 67 % Epoch Time: 3.661041021347046 ms\n",
      "Epoch 102:[0/16], Current Loss: 0.9283244013786316, Current Training Accuracy: 97.65625, Time: 0.14799904823303223 ms\n",
      "Epoch 102:[5/16], Current Loss: 0.9351810216903687, Current Training Accuracy: 98.046875, Time: 0.14499878883361816 ms\n",
      "Epoch 102:[10/16], Current Loss: 0.920515239238739, Current Training Accuracy: 98.1534090909091, Time: 0.14600276947021484 ms\n",
      "Epoch 102:[15/16], Current Loss: 0.9282880425453186, Current Training Accuracy: 98.291015625, Time: 0.14600014686584473 ms\n",
      "Epoch 102, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.671999216079712 ms\n",
      "Epoch 103:[0/16], Current Loss: 0.9126946926116943, Current Training Accuracy: 99.21875, Time: 0.14600062370300293 ms\n",
      "Epoch 103:[5/16], Current Loss: 0.9205065369606018, Current Training Accuracy: 98.56770833333333, Time: 0.14900517463684082 ms\n",
      "Epoch 103:[10/16], Current Loss: 0.9354478120803833, Current Training Accuracy: 98.4375, Time: 0.14801573753356934 ms\n",
      "Epoch 103:[15/16], Current Loss: 0.9205238819122314, Current Training Accuracy: 98.291015625, Time: 0.14800071716308594 ms\n",
      "Epoch 103, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.735002040863037 ms\n",
      "Epoch 104:[0/16], Current Loss: 0.9205343723297119, Current Training Accuracy: 98.4375, Time: 0.14599895477294922 ms\n",
      "Epoch 104:[5/16], Current Loss: 0.9432615041732788, Current Training Accuracy: 97.78645833333333, Time: 0.14300036430358887 ms\n",
      "Epoch 104:[10/16], Current Loss: 0.9048920273780823, Current Training Accuracy: 98.01136363636364, Time: 0.14800071716308594 ms\n",
      "Epoch 104:[15/16], Current Loss: 0.9205139875411987, Current Training Accuracy: 98.291015625, Time: 0.14300012588500977 ms\n",
      "Epoch 104, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.667999267578125 ms\n",
      "Epoch 105:[0/16], Current Loss: 0.9276244640350342, Current Training Accuracy: 97.65625, Time: 0.14611291885375977 ms\n",
      "Epoch 105:[5/16], Current Loss: 0.9127063155174255, Current Training Accuracy: 98.17708333333333, Time: 0.14501619338989258 ms\n",
      "Epoch 105:[10/16], Current Loss: 0.9122219085693359, Current Training Accuracy: 98.08238636363636, Time: 0.1461009979248047 ms\n",
      "Epoch 105:[15/16], Current Loss: 0.9127007126808167, Current Training Accuracy: 98.33984375, Time: 0.14499998092651367 ms\n",
      "Epoch 105, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 3.6605937480926514 ms\n",
      "Epoch 106:[0/16], Current Loss: 0.9205102920532227, Current Training Accuracy: 98.4375, Time: 0.14301609992980957 ms\n",
      "Epoch 106:[5/16], Current Loss: 0.9191439151763916, Current Training Accuracy: 98.30729166666667, Time: 0.14600253105163574 ms\n",
      "Epoch 106:[10/16], Current Loss: 0.9361399412155151, Current Training Accuracy: 98.08238636363636, Time: 0.14307332038879395 ms\n",
      "Epoch 106:[15/16], Current Loss: 0.904887318611145, Current Training Accuracy: 98.291015625, Time: 0.14799976348876953 ms\n",
      "Epoch 106, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 3.6710903644561768 ms\n",
      "Epoch 107:[0/16], Current Loss: 0.9198097586631775, Current Training Accuracy: 98.4375, Time: 0.14599871635437012 ms\n",
      "Epoch 107:[5/16], Current Loss: 0.9198312759399414, Current Training Accuracy: 97.78645833333333, Time: 0.14499878883361816 ms\n",
      "Epoch 107:[10/16], Current Loss: 0.9126914739608765, Current Training Accuracy: 98.08238636363636, Time: 0.14600539207458496 ms\n",
      "Epoch 107:[15/16], Current Loss: 0.9277071356773376, Current Training Accuracy: 98.33984375, Time: 0.14600062370300293 ms\n",
      "Epoch 107, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.7030463218688965 ms\n",
      "Epoch 108:[0/16], Current Loss: 0.9276426434516907, Current Training Accuracy: 97.65625, Time: 0.1470036506652832 ms\n",
      "Epoch 108:[5/16], Current Loss: 0.9276139736175537, Current Training Accuracy: 98.30729166666667, Time: 0.14499950408935547 ms\n",
      "Epoch 108:[10/16], Current Loss: 0.9120597243309021, Current Training Accuracy: 98.29545454545455, Time: 0.14700031280517578 ms\n",
      "Epoch 108:[15/16], Current Loss: 0.9354556202888489, Current Training Accuracy: 98.291015625, Time: 0.14899659156799316 ms\n",
      "Epoch 108, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6829993724823 ms\n",
      "Epoch 109:[0/16], Current Loss: 0.9204974174499512, Current Training Accuracy: 98.4375, Time: 0.14999914169311523 ms\n",
      "Epoch 109:[5/16], Current Loss: 0.9354361891746521, Current Training Accuracy: 97.78645833333333, Time: 0.14601683616638184 ms\n",
      "Epoch 109:[10/16], Current Loss: 0.9276148676872253, Current Training Accuracy: 97.9403409090909, Time: 0.147017240524292 ms\n",
      "Epoch 109:[15/16], Current Loss: 0.9205112457275391, Current Training Accuracy: 98.291015625, Time: 0.14201831817626953 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6828248500823975 ms\n",
      "Epoch 110:[0/16], Current Loss: 0.9205060601234436, Current Training Accuracy: 98.4375, Time: 0.14409875869750977 ms\n",
      "Epoch 110:[5/16], Current Loss: 0.9119855165481567, Current Training Accuracy: 98.17708333333333, Time: 0.1450965404510498 ms\n",
      "Epoch 110:[10/16], Current Loss: 0.912697970867157, Current Training Accuracy: 98.4375, Time: 0.146101713180542 ms\n",
      "Epoch 110:[15/16], Current Loss: 0.935418963432312, Current Training Accuracy: 98.291015625, Time: 0.14503979682922363 ms\n",
      "Epoch 110, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.667999505996704 ms\n",
      "Epoch 111:[0/16], Current Loss: 0.9347856044769287, Current Training Accuracy: 96.875, Time: 0.1441054344177246 ms\n",
      "Epoch 111:[5/16], Current Loss: 0.9048745632171631, Current Training Accuracy: 98.30729166666667, Time: 0.14910173416137695 ms\n",
      "Epoch 111:[10/16], Current Loss: 0.9126859307289124, Current Training Accuracy: 98.4375, Time: 0.14609694480895996 ms\n",
      "Epoch 111:[15/16], Current Loss: 0.912692666053772, Current Training Accuracy: 98.291015625, Time: 0.14804553985595703 ms\n",
      "Epoch 111, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.727703332901001 ms\n",
      "Epoch 112:[0/16], Current Loss: 0.9197977185249329, Current Training Accuracy: 98.4375, Time: 0.14804744720458984 ms\n",
      "Epoch 112:[5/16], Current Loss: 0.9283183813095093, Current Training Accuracy: 98.046875, Time: 0.14409828186035156 ms\n",
      "Epoch 112:[10/16], Current Loss: 0.9361284971237183, Current Training Accuracy: 98.1534090909091, Time: 0.1500999927520752 ms\n",
      "Epoch 112:[15/16], Current Loss: 0.9126818776130676, Current Training Accuracy: 98.291015625, Time: 0.1451122760772705 ms\n",
      "Epoch 112, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6930735111236572 ms\n",
      "Epoch 113:[0/16], Current Loss: 0.9347004294395447, Current Training Accuracy: 96.875, Time: 0.14511394500732422 ms\n",
      "Epoch 113:[5/16], Current Loss: 0.9361275434494019, Current Training Accuracy: 97.265625, Time: 0.1450364589691162 ms\n",
      "Epoch 113:[10/16], Current Loss: 0.9048784375190735, Current Training Accuracy: 97.79829545454545, Time: 0.14600300788879395 ms\n",
      "Epoch 113:[15/16], Current Loss: 0.912685751914978, Current Training Accuracy: 98.33984375, Time: 0.1470954418182373 ms\n",
      "Epoch 113, train Loss: 0.921  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.679996967315674 ms\n",
      "Epoch 114:[0/16], Current Loss: 0.9354081153869629, Current Training Accuracy: 96.875, Time: 0.14811229705810547 ms\n",
      "Epoch 114:[5/16], Current Loss: 0.9119796752929688, Current Training Accuracy: 98.56770833333333, Time: 0.14616680145263672 ms\n",
      "Epoch 114:[10/16], Current Loss: 0.9361295104026794, Current Training Accuracy: 98.36647727272727, Time: 0.14508962631225586 ms\n",
      "Epoch 114:[15/16], Current Loss: 0.9347007274627686, Current Training Accuracy: 98.291015625, Time: 0.14905166625976562 ms\n",
      "Epoch 114, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.721101760864258 ms\n",
      "Epoch 115:[0/16], Current Loss: 0.9204825162887573, Current Training Accuracy: 98.4375, Time: 0.14600324630737305 ms\n",
      "Epoch 115:[5/16], Current Loss: 0.9048727750778198, Current Training Accuracy: 98.046875, Time: 0.1430039405822754 ms\n",
      "Epoch 115:[10/16], Current Loss: 0.9048728346824646, Current Training Accuracy: 98.1534090909091, Time: 0.1461012363433838 ms\n",
      "Epoch 115:[15/16], Current Loss: 0.9048722982406616, Current Training Accuracy: 98.291015625, Time: 0.14612984657287598 ms\n",
      "Epoch 115, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6829094886779785 ms\n",
      "Epoch 116:[0/16], Current Loss: 0.9205005168914795, Current Training Accuracy: 98.4375, Time: 0.14403939247131348 ms\n",
      "Epoch 116:[5/16], Current Loss: 0.9191460013389587, Current Training Accuracy: 98.828125, Time: 0.16104769706726074 ms\n",
      "Epoch 116:[10/16], Current Loss: 0.9283051490783691, Current Training Accuracy: 98.36647727272727, Time: 0.14609408378601074 ms\n",
      "Epoch 116:[15/16], Current Loss: 0.9438940286636353, Current Training Accuracy: 98.291015625, Time: 0.1461336612701416 ms\n",
      "Epoch 116, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.7270660400390625 ms\n",
      "Epoch 117:[0/16], Current Loss: 0.9048731327056885, Current Training Accuracy: 100.0, Time: 0.15310430526733398 ms\n",
      "Epoch 117:[5/16], Current Loss: 0.9283121824264526, Current Training Accuracy: 98.4375, Time: 0.14609575271606445 ms\n",
      "Epoch 117:[10/16], Current Loss: 0.9126874804496765, Current Training Accuracy: 98.22443181818181, Time: 0.14709758758544922 ms\n",
      "Epoch 117:[15/16], Current Loss: 0.9126867651939392, Current Training Accuracy: 98.291015625, Time: 0.14612174034118652 ms\n",
      "Epoch 117, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.7120001316070557 ms\n",
      "Epoch 118:[0/16], Current Loss: 0.9126858711242676, Current Training Accuracy: 99.21875, Time: 0.14509248733520508 ms\n",
      "Epoch 118:[5/16], Current Loss: 0.9119850993156433, Current Training Accuracy: 98.17708333333333, Time: 0.14510631561279297 ms\n",
      "Epoch 118:[10/16], Current Loss: 0.9119781255722046, Current Training Accuracy: 98.57954545454545, Time: 0.1540968418121338 ms\n",
      "Epoch 118:[15/16], Current Loss: 0.9197908639907837, Current Training Accuracy: 98.33984375, Time: 0.14411258697509766 ms\n",
      "Epoch 118, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.7319676876068115 ms\n",
      "Epoch 119:[0/16], Current Loss: 0.9048728942871094, Current Training Accuracy: 100.0, Time: 0.14610791206359863 ms\n",
      "Epoch 119:[5/16], Current Loss: 0.935413658618927, Current Training Accuracy: 98.046875, Time: 0.14499902725219727 ms\n",
      "Epoch 119:[10/16], Current Loss: 0.9432358741760254, Current Training Accuracy: 98.1534090909091, Time: 0.14600110054016113 ms\n",
      "Epoch 119:[15/16], Current Loss: 0.9276306629180908, Current Training Accuracy: 98.291015625, Time: 0.14500045776367188 ms\n",
      "Epoch 119, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.6780080795288086 ms\n",
      "Epoch 120:[0/16], Current Loss: 0.9204902648925781, Current Training Accuracy: 98.4375, Time: 0.14599895477294922 ms\n",
      "Epoch 120:[5/16], Current Loss: 0.9126874208450317, Current Training Accuracy: 98.69791666666667, Time: 0.14699888229370117 ms\n",
      "Epoch 120:[10/16], Current Loss: 0.9354354739189148, Current Training Accuracy: 98.1534090909091, Time: 0.14501309394836426 ms\n",
      "Epoch 120:[15/16], Current Loss: 0.9126852750778198, Current Training Accuracy: 98.291015625, Time: 0.14699912071228027 ms\n",
      "Epoch 120, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.712615966796875 ms\n",
      "Epoch 121:[0/16], Current Loss: 0.9204975962638855, Current Training Accuracy: 98.4375, Time: 0.14709734916687012 ms\n",
      "Epoch 121:[5/16], Current Loss: 0.9503397941589355, Current Training Accuracy: 97.91666666666667, Time: 0.14500069618225098 ms\n",
      "Epoch 121:[10/16], Current Loss: 0.9048693180084229, Current Training Accuracy: 98.29545454545455, Time: 0.14600181579589844 ms\n",
      "Epoch 121:[15/16], Current Loss: 0.9276050329208374, Current Training Accuracy: 98.291015625, Time: 0.14502239227294922 ms\n",
      "Epoch 121, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.717047691345215 ms\n",
      "Epoch 122:[0/16], Current Loss: 0.9283095598220825, Current Training Accuracy: 97.65625, Time: 0.14404654502868652 ms\n",
      "Epoch 122:[5/16], Current Loss: 0.9204949140548706, Current Training Accuracy: 98.17708333333333, Time: 0.1450190544128418 ms\n",
      "Epoch 122:[10/16], Current Loss: 0.9126842021942139, Current Training Accuracy: 98.1534090909091, Time: 0.14500021934509277 ms\n",
      "Epoch 122:[15/16], Current Loss: 0.9119850993156433, Current Training Accuracy: 98.291015625, Time: 0.1441023349761963 ms\n",
      "Epoch 122, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.7011146545410156 ms\n",
      "Epoch 123:[0/16], Current Loss: 0.9197848439216614, Current Training Accuracy: 98.4375, Time: 0.14510202407836914 ms\n",
      "Epoch 123:[5/16], Current Loss: 0.9048691391944885, Current Training Accuracy: 98.4375, Time: 0.14612340927124023 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123:[10/16], Current Loss: 0.9347076416015625, Current Training Accuracy: 98.29545454545455, Time: 0.14512848854064941 ms\n",
      "Epoch 123:[15/16], Current Loss: 0.9126870632171631, Current Training Accuracy: 98.291015625, Time: 0.14310121536254883 ms\n",
      "Epoch 123, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.65671968460083 ms\n",
      "Epoch 124:[0/16], Current Loss: 0.9283020496368408, Current Training Accuracy: 97.65625, Time: 0.14500641822814941 ms\n",
      "Epoch 124:[5/16], Current Loss: 0.9048750996589661, Current Training Accuracy: 98.56770833333333, Time: 0.1470019817352295 ms\n",
      "Epoch 124:[10/16], Current Loss: 0.9425357580184937, Current Training Accuracy: 98.08238636363636, Time: 0.1460423469543457 ms\n",
      "Epoch 124:[15/16], Current Loss: 0.9119869470596313, Current Training Accuracy: 98.291015625, Time: 0.14800500869750977 ms\n",
      "Epoch 124, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.737443447113037 ms\n",
      "Epoch 125:[0/16], Current Loss: 0.9504208564758301, Current Training Accuracy: 95.3125, Time: 0.14800143241882324 ms\n",
      "Epoch 125:[5/16], Current Loss: 0.9204778075218201, Current Training Accuracy: 98.046875, Time: 0.14610052108764648 ms\n",
      "Epoch 125:[10/16], Current Loss: 0.9198492765426636, Current Training Accuracy: 98.29545454545455, Time: 0.14513826370239258 ms\n",
      "Epoch 125:[15/16], Current Loss: 0.9126922488212585, Current Training Accuracy: 98.291015625, Time: 0.14709925651550293 ms\n",
      "Epoch 125, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 3.794868230819702 ms\n",
      "Epoch 126:[0/16], Current Loss: 0.9122171998023987, Current Training Accuracy: 99.21875, Time: 0.14709734916687012 ms\n",
      "Epoch 126:[5/16], Current Loss: 0.9198418855667114, Current Training Accuracy: 98.56770833333333, Time: 0.1441023349761963 ms\n",
      "Epoch 126:[10/16], Current Loss: 0.9204930663108826, Current Training Accuracy: 98.08238636363636, Time: 0.14713120460510254 ms\n",
      "Epoch 126:[15/16], Current Loss: 0.9120252728462219, Current Training Accuracy: 98.291015625, Time: 0.14510297775268555 ms\n",
      "Epoch 126, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 3.6740591526031494 ms\n",
      "Epoch 127:[0/16], Current Loss: 0.9126781821250916, Current Training Accuracy: 99.21875, Time: 0.14612269401550293 ms\n",
      "Epoch 127:[5/16], Current Loss: 0.9126871824264526, Current Training Accuracy: 98.828125, Time: 0.14609217643737793 ms\n",
      "Epoch 127:[10/16], Current Loss: 0.9283108115196228, Current Training Accuracy: 98.57954545454545, Time: 0.1470048427581787 ms\n",
      "Epoch 127:[15/16], Current Loss: 0.9340682625770569, Current Training Accuracy: 98.291015625, Time: 0.14510416984558105 ms\n",
      "Epoch 127, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 3.669999837875366 ms\n",
      "Epoch 128:[0/16], Current Loss: 0.9275952577590942, Current Training Accuracy: 97.65625, Time: 0.14409446716308594 ms\n",
      "Epoch 128:[5/16], Current Loss: 0.9048705697059631, Current Training Accuracy: 97.91666666666667, Time: 0.14708924293518066 ms\n",
      "Epoch 128:[10/16], Current Loss: 0.9347307085990906, Current Training Accuracy: 98.22443181818181, Time: 0.14610791206359863 ms\n",
      "Epoch 128:[15/16], Current Loss: 0.9276022911071777, Current Training Accuracy: 98.291015625, Time: 0.14510202407836914 ms\n",
      "Epoch 128, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 3.668036460876465 ms\n"
     ]
    }
   ],
   "source": [
    "loss_list, counter =[], []\n",
    "count = 0\n",
    "running_loss=0\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0)\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "train_epoch, train_loss = [], []\n",
    "train_acc, val_acc = [], []\n",
    "avg_epoch, avg_train_loss, avg_val_acc = [], [], []\n",
    "epoch_time=[]\n",
    "\n",
    "model.train()\n",
    "for epoch in range(128): \n",
    "    running_loss = 0\n",
    "    total_train = 0\n",
    "    correct_train = 0\n",
    "    total_accuracy = 0\n",
    "    total_val_accuracy = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0   \n",
    "    start1 = time.time()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        start = time.time()\n",
    "        t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
    "        t_image=t_image.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(t_image) # forward\n",
    "        ###########################################################################\n",
    "        outputs=outputs.cuda()\n",
    "        mask=mask.cuda()\n",
    "        loss = criterion(outputs, mask.long()) # calculate the loss\n",
    "        loss.backward() # back propagation\n",
    "        optimizer.step() # update gradients\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += mask.nelement()\n",
    "        correct_train += predicted.eq(mask.data).sum().item()\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        total_accuracy += train_accuracy\n",
    "        if i % 5 == 0:\n",
    "            end = time.time()\n",
    "            print('Epoch {}:[{}/{}], Current Loss: {}, Current Training Accuracy: {}, Time: {} ms'.format(epoch+1, i, len(train_loader), loss.item(), train_accuracy, end - start))      \n",
    "            train_acc.append(train_accuracy)\n",
    "            train_loss.append(loss.item())\n",
    "            train_epoch.append(str(epoch+1) + '/' + str(i))\n",
    "\n",
    "            for j, data1 in enumerate(val_loader, 0):\n",
    "                t_image1, mask1 = data1[0],data1[1].long()\n",
    "                outputs1 = model(t_image1)\n",
    "                mask1_temp=torch.max(mask1.data,1)\n",
    "                mask1_temp1=mask1_temp[1].cuda()\n",
    "                _, predicted1 = torch.max(outputs1.data, 1)\n",
    "                total_val += mask1.nelement()\n",
    "                correct_val += predicted1.eq(mask1_temp1).sum().item()\n",
    "                val_accuracy= 100 * correct_val / total_val\n",
    "                total_val_accuracy += val_accuracy\n",
    "            val_acc.append(val_accuracy)\n",
    "    end1 = time.time()\n",
    "    print('Epoch {}, train Loss: {:.3f} '.format(epoch+1, running_loss/len(train_loader)), \"Avg Training Accuracy: {%d %%}\" % (total_accuracy/len(train_loader)), \"Avg Validation Accuracy: %d %%\" % (total_val_accuracy/len(val_loader)), \"Epoch Time: {} ms\".format(end1 - start1))\n",
    "    epoch_time.append(end1-start1)\n",
    "    avg_epoch.append(epoch+1)\n",
    "    avg_train_loss.append(running_loss/len(train_loader))\n",
    "    avg_val_acc.append(total_val_accuracy/len(val_loader))\n",
    "    #print(avg_epoch)\n",
    "    #print(avg_train_loss)\n",
    "    #print(avg_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c6573e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of detecting news bias: 83.8542%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred_correct_num=[]\n",
    "pred_total_num=[]\n",
    "pred_result_list=[]\n",
    "pred_prob_list = []\n",
    "label_prob_list=[]\n",
    "label_list=[]\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
    "    mask=mask.cuda()\n",
    "    output_test=model(t_image)\n",
    "    pred_prob_list.append(output_test)\n",
    "    label_prob_list.append(data[1])\n",
    "    label_list.append(mask)\n",
    "    output=torch.max(output_test,1)[1].long()\n",
    "    pred_result_list.append(output)\n",
    "    pred_correct_num.append(output.eq(mask).sum().item())\n",
    "    pred_total_num.append(output_test.shape[0])\n",
    "acc_test=sum(pred_correct_num)/sum(pred_total_num)\n",
    "print(\"The accuracy of detecting news bias: {}\".format(('%.4f%%'%(acc_test*100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9002b7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for i in range(len(pred_result_list)):\n",
    "    if len(pred_result_list) == 1:\n",
    "        pred_result = pred_result_list[0]\n",
    "        label = label_list[0]\n",
    "    if len(pred_result_list) == 2:\n",
    "        pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
    "        label = torch.cat((label_list[0], label_list[1]), -1)\n",
    "    if len(pred_result_list) > 2:\n",
    "        pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
    "        label = torch.cat((label_list[0], label_list[1]), -1)\n",
    "    for j in range(len(pred_result_list)-2):\n",
    "        pred_result = torch.cat((pred_result, pred_result_list[j+2]), -1)\n",
    "        label = torch.cat((label, label_list[j+2]), -1)\n",
    "label = label.cpu()\n",
    "pred_result = pred_result.cpu()\n",
    "C=confusion_matrix(label,pred_result)\n",
    "df=pd.DataFrame(C,index=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"],columns=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"])\n",
    "p1=sns.heatmap(df,annot=True,cmap=\"hot_r\")\n",
    "s1 = p1.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b20615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Value: 0.0667\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred_prob_list)):\n",
    "    if len(pred_prob_list) == 1:\n",
    "        pred_prob = pred_prob_list[0]\n",
    "        label_prob = label_prob_list[0]\n",
    "    if len(pred_prob_list) == 2:\n",
    "        pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
    "        label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
    "    if len(pred_prob_list) > 2:\n",
    "        pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
    "        label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
    "    for j in range(len(pred_prob_list)-2):\n",
    "        pred_prob = torch.cat((pred_prob, pred_prob_list[j+2]), -1)\n",
    "        label_prob = torch.cat((label_prob, label_prob_list[j+2]), -1)\n",
    "label_prob = label_prob.cpu()\n",
    "pred_prob = pred_prob.cpu()\n",
    "criterion=nn.L1Loss(reduction=\"mean\")\n",
    "loss=criterion(pred_prob, label_prob)\n",
    "print(\"MAE Value: {}\".format(\"%.4f\" % loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbe43770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-F1 Score: 0.8000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(pred_result,label,average=\"macro\")\n",
    "print(\"Macro-F1 Score: {}\".format(\"%.4f\" % f1_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
