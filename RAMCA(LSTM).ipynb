{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rj9f4qfMgp4M"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "import torch.utils.data as Data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from math import log"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')\n",
        "#改变当前工作目录到谷歌云盘的路径\n",
        "path=\"/content/drive/My Drive/Colab Notebooks/Bias Detection/\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxi7X3Dgh2mq",
        "outputId": "d30baa22-b42f-4e11-8362-a85837bf13f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['X_valid_glove_title.npy',\n",
              " 'y_test_glove.npy',\n",
              " 'y_train_glove.npy',\n",
              " 'y_valid_glove.npy',\n",
              " 'X_test_glove_headline.npy',\n",
              " 'X_test_glove_title.npy',\n",
              " 'X_valid_glove_headline.npy',\n",
              " 'X_train_glove_headline.npy',\n",
              " 'X_train_glove_title.npy',\n",
              " 'Single Region Size.ipynb',\n",
              " 'Multiple Region Size.ipynb',\n",
              " '#Feature Map.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_process1=np.load(\"X_train_glove_title.npy\")\n",
        "X_test_process1=np.load(\"X_test_glove_title.npy\")\n",
        "X_valid_process1=np.load(\"X_valid_glove_title.npy\")\n",
        "y_train_process=np.load(\"y_train_glove.npy\")\n",
        "y_test_process=np.load(\"y_test_glove.npy\")\n",
        "y_valid_process=np.load(\"y_valid_glove.npy\")"
      ],
      "metadata": {
        "id": "z-DkyNUah3XO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = Data.DataLoader(\n",
        "    dataset=Data.TensorDataset(torch.Tensor(X_train_process1),torch.LongTensor(y_train_process)),      \n",
        "    batch_size=128,      \n",
        "    shuffle=True,               \n",
        "    num_workers=2, \n",
        "    drop_last=True\n",
        ")\n",
        "test_loader = Data.DataLoader(\n",
        "    dataset=Data.TensorDataset(torch.Tensor(X_test_process1),torch.LongTensor(y_test_process)),      \n",
        "    batch_size=128,      \n",
        "    shuffle=True,               \n",
        "    num_workers=2,  \n",
        "    drop_last=True\n",
        ")\n",
        "val_loader = Data.DataLoader(\n",
        "    dataset=Data.TensorDataset(torch.Tensor(X_valid_process1),torch.LongTensor(y_valid_process)),      \n",
        "    batch_size=128,      \n",
        "    shuffle=True,               \n",
        "    num_workers=2,\n",
        "    drop_last=True\n",
        ")"
      ],
      "metadata": {
        "id": "Pn9D2_uIilim"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ECA(x,gamma=2,b=1):\n",
        "    N,C,H,W=x.size()\n",
        "    t=int(abs((log(C,2)+b)/gamma))\n",
        "    k=t if t%2 else t+1\n",
        "    \n",
        "    avg_pool=nn.AdaptiveAvgPool2d(1).cuda()\n",
        "    conv=nn.Conv1d(1,1,kernel_size=k,padding=int(k/2),bias=False).cuda()\n",
        "    sigmoid=nn.Sigmoid().cuda()\n",
        "    \n",
        "    y=avg_pool(x)\n",
        "    y=conv(y.squeeze(-1).transpose(-1,-2))\n",
        "    y=y.transpose(-1,-2).unsqueeze(-1)\n",
        "    y=sigmoid(y)\n",
        "    return y"
      ],
      "metadata": {
        "id": "z0UM-9t6jGCn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextRCNN(nn.Module):\n",
        "    def __init__(self,vocab_size,embedding_dim,hidden_size,num_labels=5):\n",
        "        super(TextRCNN,self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=hidden_size,\n",
        "                            batch_first=True,bidirectional=True)\n",
        "        self.dropout = nn.Dropout(.3)\n",
        "        self.linear1 = nn.Linear(embedding_dim+2*hidden_size, 128)\n",
        "        self.linear2 = nn.Linear(600, 128)\n",
        "        self.linear3 = nn.Linear(128, num_labels)\n",
        "        self.conv1 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=6)#通过out_channel改变文中的feature map，且out_channel∈[10,50,100,200,400,600,800,1000]\n",
        "        self.conv2 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=7)\n",
        "        self.conv3 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=8)\n",
        "        self.conv4 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=9)\n",
        "        self.w_omiga = torch.randn(128,hidden_size*2,1,requires_grad=True).cuda()\n",
        "\n",
        "    def forward(self, x):#x: [batch,L]\n",
        "        x_embed = x.cuda()\n",
        "        last_hidden_state,(c,h) = self.lstm(x_embed) #last_hidden_state: [batch,L,hidden_size * num_bidirectional]\n",
        "        H = torch.nn.Tanh()(last_hidden_state)\n",
        "        weights=torch.nn.Softmax(dim=-1)(torch.bmm(H,self.w_omiga).squeeze(-1)).unsqueeze(dim=-1).repeat(1,1,2*12)  # LSTM+ATTN-Weight\n",
        "        last_hidden_state=torch.mul(last_hidden_state,weights)\n",
        "        out = torch.cat((last_hidden_state[:,:,:12],x_embed,last_hidden_state[:,:,12:]),2)#out: [batch,L,embedding_size + hidden_size * num_bidirectional]  \n",
        "        out = F.tanh(self.linear1(out))\n",
        "        out = out.permute(dims=[0,2,1]) #out: [batch,embedding_size + hidden_size * num_bidirectional,L]\n",
        "        out_1 = self.conv1(out)\n",
        "        out_1 = nn.ReLU()(out_1)\n",
        "        out_1 = nn.MaxPool1d(kernel_size=495)(out_1)\n",
        "        out_2 = self.conv1(out)\n",
        "        out_2 = nn.ReLU()(out_2)\n",
        "        out_2 = nn.MaxPool1d(kernel_size=494)(out_2)\n",
        "        out_3 = self.conv1(out)\n",
        "        out_3 = nn.ReLU()(out_3)\n",
        "        out_3 = nn.MaxPool1d(kernel_size=493)(out_3)\n",
        "        out_4 = self.conv1(out)\n",
        "        out_4 = nn.ReLU()(out_4)\n",
        "        out_4 = nn.MaxPool1d(kernel_size=492)(out_4)\n",
        "        out_1 = out_1.unsqueeze(1).cuda()\n",
        "        out_2 = out_2.unsqueeze(1).cuda()\n",
        "        out_3 = out_3.unsqueeze(1).cuda()\n",
        "        out_4 = out_4.unsqueeze(1).cuda()\n",
        "        out = torch.cat([out_1, out_2, out_3, out_4],dim=1).cuda()\n",
        "        channel_weights = F.softmax(ECA(out).squeeze().squeeze(),dim=1).unsqueeze(-1).unsqueeze(-1).expand_as(out)\n",
        "        out = torch.mul(channel_weights,out)\n",
        "        out = torch.sum(out, dim = 1)\n",
        "        out = self.linear2(out.squeeze()) #out: [batch,num_labels]\n",
        "        out = self.linear3(F.tanh(out))\n",
        "        out = F.softmax(out,dim=1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "1IctmSGnjA14"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextRCNN(5302,200,12).cuda()"
      ],
      "metadata": {
        "id": "u7234TzGqQIH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list, counter =[], []\n",
        "count = 0\n",
        "running_loss=0\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0)\n",
        "total_train = 0\n",
        "correct_train = 0\n",
        "train_epoch, train_loss = [], []\n",
        "train_acc, val_acc = [], []\n",
        "avg_epoch, avg_train_loss, avg_val_acc = [], [], []\n",
        "epoch_time=[]\n",
        "\n",
        "model.train()\n",
        "for epoch in range(128): \n",
        "    running_loss = 0\n",
        "    total_train = 0\n",
        "    correct_train = 0\n",
        "    total_accuracy = 0\n",
        "    total_val_accuracy = 0\n",
        "    correct_val = 0\n",
        "    total_val = 0   \n",
        "    start1 = time.time()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        start = time.time()\n",
        "        t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
        "        t_image=t_image.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(t_image) # forward\n",
        "        ###########################################################################\n",
        "        outputs=outputs.cuda()\n",
        "        mask=mask.cuda()\n",
        "        loss = criterion(outputs, mask.long()) # calculate the loss\n",
        "        loss.backward() # back propagation\n",
        "        optimizer.step() # update gradients\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += mask.nelement()\n",
        "        correct_train += predicted.eq(mask.data).sum().item()\n",
        "        train_accuracy = 100 * correct_train / total_train\n",
        "        total_accuracy += train_accuracy\n",
        "        if i % 5 == 0:\n",
        "            end = time.time()\n",
        "            print('Epoch {}:[{}/{}], Current Loss: {}, Current Training Accuracy: {}, Time: {} ms'.format(epoch+1, i, len(train_loader), loss.item(), train_accuracy, end - start))      \n",
        "            train_acc.append(train_accuracy)\n",
        "            train_loss.append(loss.item())\n",
        "            train_epoch.append(str(epoch+1) + '/' + str(i))\n",
        "\n",
        "            for j, data1 in enumerate(val_loader, 0):\n",
        "                t_image1, mask1 = data1[0],data1[1].long()\n",
        "                outputs1 = model(t_image1)\n",
        "                mask1_temp=torch.max(mask1.data,1)\n",
        "                mask1_temp1=mask1_temp[1].cuda()\n",
        "                _, predicted1 = torch.max(outputs1.data, 1)\n",
        "                total_val += mask1.nelement()\n",
        "                correct_val += predicted1.eq(mask1_temp1).sum().item()\n",
        "                val_accuracy= 100 * correct_val / total_val\n",
        "                total_val_accuracy += val_accuracy\n",
        "            val_acc.append(val_accuracy)\n",
        "    end1 = time.time()\n",
        "    print('Epoch {}, train Loss: {:.3f} '.format(epoch+1, running_loss/len(train_loader)), \"Avg Training Accuracy: {%d %%}\" % (total_accuracy/len(train_loader)), \"Avg Validation Accuracy: %d %%\" % (total_val_accuracy/len(val_loader)), \"Epoch Time: {} ms\".format(end1 - start1))\n",
        "    epoch_time.append(end1-start1)\n",
        "    avg_epoch.append(epoch+1)\n",
        "    avg_train_loss.append(running_loss/len(train_loader))\n",
        "    avg_val_acc.append(total_val_accuracy/len(val_loader))\n",
        "    #print(avg_epoch)\n",
        "    #print(avg_train_loss)\n",
        "    #print(avg_val_acc)"
      ],
      "metadata": {
        "id": "kEFMuViRqSsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "109604a3-149d-4ea7-f95b-0106d960c79e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:[0/16], Current Loss: 1.3423771858215332, Current Training Accuracy: 56.25, Time: 0.36989402770996094 ms\n",
            "Epoch 1:[5/16], Current Loss: 1.3462998867034912, Current Training Accuracy: 55.338541666666664, Time: 0.24431467056274414 ms\n",
            "Epoch 1:[10/16], Current Loss: 1.3472285270690918, Current Training Accuracy: 56.25, Time: 0.2511124610900879 ms\n",
            "Epoch 1:[15/16], Current Loss: 1.3201390504837036, Current Training Accuracy: 55.95703125, Time: 0.24169230461120605 ms\n",
            "Epoch 1, train Loss: 1.340  Avg Training Accuracy: {55 %} Avg Validation Accuracy: 41 % Epoch Time: 6.54850435256958 ms\n",
            "Epoch 2:[0/16], Current Loss: 1.2906593084335327, Current Training Accuracy: 64.0625, Time: 0.26872920989990234 ms\n",
            "Epoch 2:[5/16], Current Loss: 1.2689772844314575, Current Training Accuracy: 65.36458333333333, Time: 0.2472672462463379 ms\n",
            "Epoch 2:[10/16], Current Loss: 1.206536054611206, Current Training Accuracy: 65.98011363636364, Time: 0.24727797508239746 ms\n",
            "Epoch 2:[15/16], Current Loss: 1.2296117544174194, Current Training Accuracy: 66.845703125, Time: 0.2526888847351074 ms\n",
            "Epoch 2, train Loss: 1.246  Avg Training Accuracy: {65 %} Avg Validation Accuracy: 51 % Epoch Time: 6.495352029800415 ms\n",
            "Epoch 3:[0/16], Current Loss: 1.2149994373321533, Current Training Accuracy: 67.96875, Time: 0.2525019645690918 ms\n",
            "Epoch 3:[5/16], Current Loss: 1.2203545570373535, Current Training Accuracy: 72.91666666666667, Time: 0.24844765663146973 ms\n",
            "Epoch 3:[10/16], Current Loss: 1.145104169845581, Current Training Accuracy: 73.65056818181819, Time: 0.24689841270446777 ms\n",
            "Epoch 3:[15/16], Current Loss: 1.1995278596878052, Current Training Accuracy: 72.412109375, Time: 0.24646615982055664 ms\n",
            "Epoch 3, train Loss: 1.188  Avg Training Accuracy: {72 %} Avg Validation Accuracy: 53 % Epoch Time: 6.491452932357788 ms\n",
            "Epoch 4:[0/16], Current Loss: 1.2036211490631104, Current Training Accuracy: 68.75, Time: 0.27103686332702637 ms\n",
            "Epoch 4:[5/16], Current Loss: 1.1786129474639893, Current Training Accuracy: 74.47916666666667, Time: 0.25728726387023926 ms\n",
            "Epoch 4:[10/16], Current Loss: 1.1664650440216064, Current Training Accuracy: 75.07102272727273, Time: 0.2512960433959961 ms\n",
            "Epoch 4:[15/16], Current Loss: 1.1320881843566895, Current Training Accuracy: 75.390625, Time: 0.25083303451538086 ms\n",
            "Epoch 4, train Loss: 1.157  Avg Training Accuracy: {74 %} Avg Validation Accuracy: 53 % Epoch Time: 6.539142847061157 ms\n",
            "Epoch 5:[0/16], Current Loss: 1.1339088678359985, Current Training Accuracy: 78.125, Time: 0.2671191692352295 ms\n",
            "Epoch 5:[5/16], Current Loss: 1.103100299835205, Current Training Accuracy: 76.69270833333333, Time: 0.25243592262268066 ms\n",
            "Epoch 5:[10/16], Current Loss: 1.1744725704193115, Current Training Accuracy: 76.70454545454545, Time: 0.25047969818115234 ms\n",
            "Epoch 5:[15/16], Current Loss: 1.0742931365966797, Current Training Accuracy: 77.34375, Time: 0.2476027011871338 ms\n",
            "Epoch 5, train Loss: 1.131  Avg Training Accuracy: {76 %} Avg Validation Accuracy: 54 % Epoch Time: 6.5352466106414795 ms\n",
            "Epoch 6:[0/16], Current Loss: 1.0635935068130493, Current Training Accuracy: 85.15625, Time: 0.272075891494751 ms\n",
            "Epoch 6:[5/16], Current Loss: 1.1070805788040161, Current Training Accuracy: 79.42708333333333, Time: 0.24991750717163086 ms\n",
            "Epoch 6:[10/16], Current Loss: 1.1606355905532837, Current Training Accuracy: 78.6221590909091, Time: 0.25284266471862793 ms\n",
            "Epoch 6:[15/16], Current Loss: 1.0817960500717163, Current Training Accuracy: 79.931640625, Time: 0.2482147216796875 ms\n",
            "Epoch 6, train Loss: 1.107  Avg Training Accuracy: {79 %} Avg Validation Accuracy: 55 % Epoch Time: 6.598519325256348 ms\n",
            "Epoch 7:[0/16], Current Loss: 1.0714993476867676, Current Training Accuracy: 85.9375, Time: 0.2714674472808838 ms\n",
            "Epoch 7:[5/16], Current Loss: 1.0497337579727173, Current Training Accuracy: 85.546875, Time: 0.25123000144958496 ms\n",
            "Epoch 7:[10/16], Current Loss: 1.0506932735443115, Current Training Accuracy: 86.15056818181819, Time: 0.25433921813964844 ms\n",
            "Epoch 7:[15/16], Current Loss: 1.0478155612945557, Current Training Accuracy: 85.205078125, Time: 0.24879145622253418 ms\n",
            "Epoch 7, train Loss: 1.056  Avg Training Accuracy: {85 %} Avg Validation Accuracy: 59 % Epoch Time: 6.568816900253296 ms\n",
            "Epoch 8:[0/16], Current Loss: 1.0111579895019531, Current Training Accuracy: 89.84375, Time: 0.28043699264526367 ms\n",
            "Epoch 8:[5/16], Current Loss: 0.9983559250831604, Current Training Accuracy: 89.32291666666667, Time: 0.25014209747314453 ms\n",
            "Epoch 8:[10/16], Current Loss: 1.02338707447052, Current Training Accuracy: 89.77272727272727, Time: 0.25232434272766113 ms\n",
            "Epoch 8:[15/16], Current Loss: 1.0380440950393677, Current Training Accuracy: 90.478515625, Time: 0.2519862651824951 ms\n",
            "Epoch 8, train Loss: 1.017  Avg Training Accuracy: {89 %} Avg Validation Accuracy: 60 % Epoch Time: 6.605726718902588 ms\n",
            "Epoch 9:[0/16], Current Loss: 0.9630929231643677, Current Training Accuracy: 96.09375, Time: 0.27442479133605957 ms\n",
            "Epoch 9:[5/16], Current Loss: 0.9913472533226013, Current Training Accuracy: 94.27083333333333, Time: 0.251708984375 ms\n",
            "Epoch 9:[10/16], Current Loss: 0.9903343915939331, Current Training Accuracy: 93.75, Time: 0.2529764175415039 ms\n",
            "Epoch 9:[15/16], Current Loss: 0.988616943359375, Current Training Accuracy: 92.96875, Time: 0.24782943725585938 ms\n",
            "Epoch 9, train Loss: 0.988  Avg Training Accuracy: {94 %} Avg Validation Accuracy: 61 % Epoch Time: 6.61164927482605 ms\n",
            "Epoch 10:[0/16], Current Loss: 0.9546347856521606, Current Training Accuracy: 96.09375, Time: 0.2770044803619385 ms\n",
            "Epoch 10:[5/16], Current Loss: 0.9629557728767395, Current Training Accuracy: 94.27083333333333, Time: 0.2542698383331299 ms\n",
            "Epoch 10:[10/16], Current Loss: 0.9678575396537781, Current Training Accuracy: 94.8153409090909, Time: 0.26622557640075684 ms\n",
            "Epoch 10:[15/16], Current Loss: 0.9576472043991089, Current Training Accuracy: 94.921875, Time: 0.2512078285217285 ms\n",
            "Epoch 10, train Loss: 0.968  Avg Training Accuracy: {94 %} Avg Validation Accuracy: 59 % Epoch Time: 6.646442890167236 ms\n",
            "Epoch 11:[0/16], Current Loss: 0.9747969508171082, Current Training Accuracy: 93.75, Time: 0.27680230140686035 ms\n",
            "Epoch 11:[5/16], Current Loss: 0.9690883755683899, Current Training Accuracy: 95.703125, Time: 0.2511615753173828 ms\n",
            "Epoch 11:[10/16], Current Loss: 0.9604412317276001, Current Training Accuracy: 96.02272727272727, Time: 0.26361727714538574 ms\n",
            "Epoch 11:[15/16], Current Loss: 0.9514513611793518, Current Training Accuracy: 96.09375, Time: 0.24959969520568848 ms\n",
            "Epoch 11, train Loss: 0.951  Avg Training Accuracy: {95 %} Avg Validation Accuracy: 60 % Epoch Time: 6.642654657363892 ms\n",
            "Epoch 12:[0/16], Current Loss: 0.9278557896614075, Current Training Accuracy: 98.4375, Time: 0.27235865592956543 ms\n",
            "Epoch 12:[5/16], Current Loss: 0.9197860360145569, Current Training Accuracy: 96.484375, Time: 0.256636381149292 ms\n",
            "Epoch 12:[10/16], Current Loss: 0.9456864595413208, Current Training Accuracy: 96.80397727272727, Time: 0.2506563663482666 ms\n",
            "Epoch 12:[15/16], Current Loss: 0.9454911351203918, Current Training Accuracy: 96.58203125, Time: 0.24936413764953613 ms\n",
            "Epoch 12, train Loss: 0.944  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 62 % Epoch Time: 6.636194944381714 ms\n",
            "Epoch 13:[0/16], Current Loss: 1.0118167400360107, Current Training Accuracy: 89.0625, Time: 0.2735419273376465 ms\n",
            "Epoch 13:[5/16], Current Loss: 0.9384692311286926, Current Training Accuracy: 96.61458333333333, Time: 0.25929951667785645 ms\n",
            "Epoch 13:[10/16], Current Loss: 0.9468485713005066, Current Training Accuracy: 96.94602272727273, Time: 0.2518587112426758 ms\n",
            "Epoch 13:[15/16], Current Loss: 0.9243482351303101, Current Training Accuracy: 97.36328125, Time: 0.24796199798583984 ms\n",
            "Epoch 13, train Loss: 0.935  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 63 % Epoch Time: 6.6042540073394775 ms\n",
            "Epoch 14:[0/16], Current Loss: 0.929396390914917, Current Training Accuracy: 97.65625, Time: 0.27406859397888184 ms\n",
            "Epoch 14:[5/16], Current Loss: 0.9465264081954956, Current Training Accuracy: 97.91666666666667, Time: 0.24889230728149414 ms\n",
            "Epoch 14:[10/16], Current Loss: 0.9391168355941772, Current Training Accuracy: 97.58522727272727, Time: 0.2548987865447998 ms\n",
            "Epoch 14:[15/16], Current Loss: 0.9218522906303406, Current Training Accuracy: 97.65625, Time: 0.24881958961486816 ms\n",
            "Epoch 14, train Loss: 0.930  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 62 % Epoch Time: 6.5605762004852295 ms\n",
            "Epoch 15:[0/16], Current Loss: 0.9297231435775757, Current Training Accuracy: 97.65625, Time: 0.2741422653198242 ms\n",
            "Epoch 15:[5/16], Current Loss: 0.922053337097168, Current Training Accuracy: 97.78645833333333, Time: 0.25299882888793945 ms\n",
            "Epoch 15:[10/16], Current Loss: 0.914330780506134, Current Training Accuracy: 97.79829545454545, Time: 0.24791264533996582 ms\n",
            "Epoch 15:[15/16], Current Loss: 0.9141328930854797, Current Training Accuracy: 97.8515625, Time: 0.24883008003234863 ms\n",
            "Epoch 15, train Loss: 0.928  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 6.5987229347229 ms\n",
            "Epoch 16:[0/16], Current Loss: 0.922172486782074, Current Training Accuracy: 98.4375, Time: 0.2698240280151367 ms\n",
            "Epoch 16:[5/16], Current Loss: 0.9286483526229858, Current Training Accuracy: 98.046875, Time: 0.24993205070495605 ms\n",
            "Epoch 16:[10/16], Current Loss: 0.9140262603759766, Current Training Accuracy: 98.1534090909091, Time: 0.2511606216430664 ms\n",
            "Epoch 16:[15/16], Current Loss: 0.9289495348930359, Current Training Accuracy: 97.94921875, Time: 0.24731135368347168 ms\n",
            "Epoch 16, train Loss: 0.926  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 6.604254722595215 ms\n",
            "Epoch 17:[0/16], Current Loss: 0.9134780168533325, Current Training Accuracy: 99.21875, Time: 0.27803802490234375 ms\n",
            "Epoch 17:[5/16], Current Loss: 0.9136603474617004, Current Training Accuracy: 98.56770833333333, Time: 0.25580739974975586 ms\n",
            "Epoch 17:[10/16], Current Loss: 0.9283117055892944, Current Training Accuracy: 98.29545454545455, Time: 0.25032782554626465 ms\n",
            "Epoch 17:[15/16], Current Loss: 0.9286622405052185, Current Training Accuracy: 98.046875, Time: 0.24756717681884766 ms\n",
            "Epoch 17, train Loss: 0.925  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 6.589812994003296 ms\n",
            "Epoch 18:[0/16], Current Loss: 0.9217945337295532, Current Training Accuracy: 98.4375, Time: 0.2799808979034424 ms\n",
            "Epoch 18:[5/16], Current Loss: 0.9204664826393127, Current Training Accuracy: 97.78645833333333, Time: 0.2489621639251709 ms\n",
            "Epoch 18:[10/16], Current Loss: 0.9186227321624756, Current Training Accuracy: 97.86931818181819, Time: 0.2529292106628418 ms\n",
            "Epoch 18:[15/16], Current Loss: 0.9136041402816772, Current Training Accuracy: 98.046875, Time: 0.2471473217010498 ms\n",
            "Epoch 18, train Loss: 0.925  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 63 % Epoch Time: 6.5796003341674805 ms\n",
            "Epoch 19:[0/16], Current Loss: 0.9363881945610046, Current Training Accuracy: 96.875, Time: 0.27258777618408203 ms\n",
            "Epoch 19:[5/16], Current Loss: 0.9353616237640381, Current Training Accuracy: 98.046875, Time: 0.258772611618042 ms\n",
            "Epoch 19:[10/16], Current Loss: 0.9133682250976562, Current Training Accuracy: 98.08238636363636, Time: 0.25581789016723633 ms\n",
            "Epoch 19:[15/16], Current Loss: 0.9207289814949036, Current Training Accuracy: 98.095703125, Time: 0.24753904342651367 ms\n",
            "Epoch 19, train Loss: 0.924  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 6.601739406585693 ms\n",
            "Epoch 20:[0/16], Current Loss: 0.9210024476051331, Current Training Accuracy: 98.4375, Time: 0.274428129196167 ms\n",
            "Epoch 20:[5/16], Current Loss: 0.936610221862793, Current Training Accuracy: 98.17708333333333, Time: 0.25129103660583496 ms\n",
            "Epoch 20:[10/16], Current Loss: 0.9280707836151123, Current Training Accuracy: 98.29545454545455, Time: 0.25061535835266113 ms\n",
            "Epoch 20:[15/16], Current Loss: 0.9058434367179871, Current Training Accuracy: 98.193359375, Time: 0.2498762607574463 ms\n",
            "Epoch 20, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.575584888458252 ms\n",
            "Epoch 21:[0/16], Current Loss: 0.9205361008644104, Current Training Accuracy: 98.4375, Time: 0.28013181686401367 ms\n",
            "Epoch 21:[5/16], Current Loss: 0.9288489818572998, Current Training Accuracy: 98.046875, Time: 0.26259636878967285 ms\n",
            "Epoch 21:[10/16], Current Loss: 0.9282568097114563, Current Training Accuracy: 98.29545454545455, Time: 0.256819486618042 ms\n",
            "Epoch 21:[15/16], Current Loss: 0.9287054538726807, Current Training Accuracy: 98.2421875, Time: 0.25098586082458496 ms\n",
            "Epoch 21, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.630556106567383 ms\n",
            "Epoch 22:[0/16], Current Loss: 0.913070023059845, Current Training Accuracy: 99.21875, Time: 0.2828807830810547 ms\n",
            "Epoch 22:[5/16], Current Loss: 0.9363762140274048, Current Training Accuracy: 98.69791666666667, Time: 0.25315427780151367 ms\n",
            "Epoch 22:[10/16], Current Loss: 0.9280674457550049, Current Training Accuracy: 98.7215909090909, Time: 0.2519676685333252 ms\n",
            "Epoch 22:[15/16], Current Loss: 0.9517085552215576, Current Training Accuracy: 98.291015625, Time: 0.25028276443481445 ms\n",
            "Epoch 22, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.646147012710571 ms\n",
            "Epoch 23:[0/16], Current Loss: 0.9201891422271729, Current Training Accuracy: 98.4375, Time: 0.2748546600341797 ms\n",
            "Epoch 23:[5/16], Current Loss: 0.9196367263793945, Current Training Accuracy: 98.69791666666667, Time: 0.2506096363067627 ms\n",
            "Epoch 23:[10/16], Current Loss: 0.92085862159729, Current Training Accuracy: 98.4375, Time: 0.25209522247314453 ms\n",
            "Epoch 23:[15/16], Current Loss: 0.9209235310554504, Current Training Accuracy: 98.2421875, Time: 0.24965429306030273 ms\n",
            "Epoch 23, train Loss: 0.923  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.592757701873779 ms\n",
            "Epoch 24:[0/16], Current Loss: 0.9131450653076172, Current Training Accuracy: 99.21875, Time: 0.27581024169921875 ms\n",
            "Epoch 24:[5/16], Current Loss: 0.9431140422821045, Current Training Accuracy: 97.52604166666667, Time: 0.25428295135498047 ms\n",
            "Epoch 24:[10/16], Current Loss: 0.9365211725234985, Current Training Accuracy: 98.01136363636364, Time: 0.25091123580932617 ms\n",
            "Epoch 24:[15/16], Current Loss: 0.9203171133995056, Current Training Accuracy: 98.291015625, Time: 0.24957537651062012 ms\n",
            "Epoch 24, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 6.63204026222229 ms\n",
            "Epoch 25:[0/16], Current Loss: 0.9297163486480713, Current Training Accuracy: 97.65625, Time: 0.2753620147705078 ms\n",
            "Epoch 25:[5/16], Current Loss: 0.9050988554954529, Current Training Accuracy: 98.30729166666667, Time: 0.25269150733947754 ms\n",
            "Epoch 25:[10/16], Current Loss: 0.928081750869751, Current Training Accuracy: 98.1534090909091, Time: 0.25917863845825195 ms\n",
            "Epoch 25:[15/16], Current Loss: 0.9130591154098511, Current Training Accuracy: 98.291015625, Time: 0.2496650218963623 ms\n",
            "Epoch 25, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 6.591614007949829 ms\n",
            "Epoch 26:[0/16], Current Loss: 0.9125088453292847, Current Training Accuracy: 99.21875, Time: 0.2810854911804199 ms\n",
            "Epoch 26:[5/16], Current Loss: 0.9051660895347595, Current Training Accuracy: 98.95833333333333, Time: 0.25615715980529785 ms\n",
            "Epoch 26:[10/16], Current Loss: 0.9363909959793091, Current Training Accuracy: 98.36647727272727, Time: 0.24967551231384277 ms\n",
            "Epoch 26:[15/16], Current Loss: 0.9052109718322754, Current Training Accuracy: 98.33984375, Time: 0.25069618225097656 ms\n",
            "Epoch 26, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 6.6109864711761475 ms\n",
            "Epoch 27:[0/16], Current Loss: 0.9204189777374268, Current Training Accuracy: 98.4375, Time: 0.2788853645324707 ms\n",
            "Epoch 27:[5/16], Current Loss: 0.92800372838974, Current Training Accuracy: 98.17708333333333, Time: 0.251676082611084 ms\n",
            "Epoch 27:[10/16], Current Loss: 0.9123591184616089, Current Training Accuracy: 98.29545454545455, Time: 0.25488853454589844 ms\n",
            "Epoch 27:[15/16], Current Loss: 0.912496030330658, Current Training Accuracy: 98.291015625, Time: 0.2482926845550537 ms\n",
            "Epoch 27, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.601644277572632 ms\n",
            "Epoch 28:[0/16], Current Loss: 0.9280760884284973, Current Training Accuracy: 97.65625, Time: 0.2792785167694092 ms\n",
            "Epoch 28:[5/16], Current Loss: 0.9204013347625732, Current Training Accuracy: 97.78645833333333, Time: 0.24999403953552246 ms\n",
            "Epoch 28:[10/16], Current Loss: 0.9281416535377502, Current Training Accuracy: 98.1534090909091, Time: 0.25297069549560547 ms\n",
            "Epoch 28:[15/16], Current Loss: 0.9207284450531006, Current Training Accuracy: 98.291015625, Time: 0.24936962127685547 ms\n",
            "Epoch 28, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 6.601474046707153 ms\n",
            "Epoch 29:[0/16], Current Loss: 0.9353179335594177, Current Training Accuracy: 96.875, Time: 0.2708752155303955 ms\n",
            "Epoch 29:[5/16], Current Loss: 0.9434992671012878, Current Training Accuracy: 97.91666666666667, Time: 0.2509915828704834 ms\n",
            "Epoch 29:[10/16], Current Loss: 0.9280994534492493, Current Training Accuracy: 98.36647727272727, Time: 0.2501792907714844 ms\n",
            "Epoch 29:[15/16], Current Loss: 0.9358823895454407, Current Training Accuracy: 98.388671875, Time: 0.2538187503814697 ms\n",
            "Epoch 29, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.6135523319244385 ms\n",
            "Epoch 30:[0/16], Current Loss: 0.9129254817962646, Current Training Accuracy: 99.21875, Time: 0.26982688903808594 ms\n",
            "Epoch 30:[5/16], Current Loss: 0.9363429546356201, Current Training Accuracy: 98.828125, Time: 0.2547750473022461 ms\n",
            "Epoch 30:[10/16], Current Loss: 0.9201529622077942, Current Training Accuracy: 98.50852272727273, Time: 0.252105712890625 ms\n",
            "Epoch 30:[15/16], Current Loss: 0.9202770590782166, Current Training Accuracy: 98.291015625, Time: 0.24697661399841309 ms\n",
            "Epoch 30, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.620553493499756 ms\n",
            "Epoch 31:[0/16], Current Loss: 0.9513304829597473, Current Training Accuracy: 95.3125, Time: 0.2731199264526367 ms\n",
            "Epoch 31:[5/16], Current Loss: 0.9050400853157043, Current Training Accuracy: 98.046875, Time: 0.2529282569885254 ms\n",
            "Epoch 31:[10/16], Current Loss: 0.9206642508506775, Current Training Accuracy: 98.22443181818181, Time: 0.2603437900543213 ms\n",
            "Epoch 31:[15/16], Current Loss: 0.9206681251525879, Current Training Accuracy: 98.291015625, Time: 0.24701261520385742 ms\n",
            "Epoch 31, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 6.610037565231323 ms\n",
            "Epoch 32:[0/16], Current Loss: 0.9200457334518433, Current Training Accuracy: 98.4375, Time: 0.2775242328643799 ms\n",
            "Epoch 32:[5/16], Current Loss: 0.9200615286827087, Current Training Accuracy: 98.17708333333333, Time: 0.2519798278808594 ms\n",
            "Epoch 32:[10/16], Current Loss: 0.9128623604774475, Current Training Accuracy: 98.36647727272727, Time: 0.2505910396575928 ms\n",
            "Epoch 32:[15/16], Current Loss: 0.920687198638916, Current Training Accuracy: 98.291015625, Time: 0.24709510803222656 ms\n",
            "Epoch 32, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.606378793716431 ms\n",
            "Epoch 33:[0/16], Current Loss: 0.9506073594093323, Current Training Accuracy: 95.3125, Time: 0.27092552185058594 ms\n",
            "Epoch 33:[5/16], Current Loss: 0.9050542712211609, Current Training Accuracy: 98.046875, Time: 0.25112056732177734 ms\n",
            "Epoch 33:[10/16], Current Loss: 0.9049968719482422, Current Training Accuracy: 98.50852272727273, Time: 0.2536778450012207 ms\n",
            "Epoch 33:[15/16], Current Loss: 0.9356839656829834, Current Training Accuracy: 98.33984375, Time: 0.24969911575317383 ms\n",
            "Epoch 33, train Loss: 0.921  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 6.607154607772827 ms\n",
            "Epoch 34:[0/16], Current Loss: 0.9128578901290894, Current Training Accuracy: 99.21875, Time: 0.2775266170501709 ms\n",
            "Epoch 34:[5/16], Current Loss: 0.9355989694595337, Current Training Accuracy: 98.30729166666667, Time: 0.2540607452392578 ms\n",
            "Epoch 34:[10/16], Current Loss: 0.920628011226654, Current Training Accuracy: 98.57954545454545, Time: 0.2505528926849365 ms\n",
            "Epoch 34:[15/16], Current Loss: 0.9357713460922241, Current Training Accuracy: 98.291015625, Time: 0.253448486328125 ms\n",
            "Epoch 34, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.578963994979858 ms\n",
            "Epoch 35:[0/16], Current Loss: 0.9284150004386902, Current Training Accuracy: 97.65625, Time: 0.27289342880249023 ms\n",
            "Epoch 35:[5/16], Current Loss: 0.9200174808502197, Current Training Accuracy: 98.4375, Time: 0.2496778964996338 ms\n",
            "Epoch 35:[10/16], Current Loss: 0.9204921722412109, Current Training Accuracy: 98.22443181818181, Time: 0.2519083023071289 ms\n",
            "Epoch 35:[15/16], Current Loss: 0.9284383058547974, Current Training Accuracy: 98.291015625, Time: 0.2528836727142334 ms\n",
            "Epoch 35, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.623062610626221 ms\n",
            "Epoch 36:[0/16], Current Loss: 0.9434301257133484, Current Training Accuracy: 96.09375, Time: 0.27514052391052246 ms\n",
            "Epoch 36:[5/16], Current Loss: 0.9199872016906738, Current Training Accuracy: 97.78645833333333, Time: 0.24942374229431152 ms\n",
            "Epoch 36:[10/16], Current Loss: 0.927770733833313, Current Training Accuracy: 98.01136363636364, Time: 0.2612273693084717 ms\n",
            "Epoch 36:[15/16], Current Loss: 0.9123128056526184, Current Training Accuracy: 98.291015625, Time: 0.25113344192504883 ms\n",
            "Epoch 36, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 6.645899534225464 ms\n",
            "Epoch 37:[0/16], Current Loss: 0.9355745911598206, Current Training Accuracy: 96.875, Time: 0.28511929512023926 ms\n",
            "Epoch 37:[5/16], Current Loss: 0.9362308979034424, Current Training Accuracy: 97.78645833333333, Time: 0.25330138206481934 ms\n",
            "Epoch 37:[10/16], Current Loss: 0.9206904768943787, Current Training Accuracy: 98.36647727272727, Time: 0.2625706195831299 ms\n",
            "Epoch 37:[15/16], Current Loss: 0.9202292561531067, Current Training Accuracy: 98.33984375, Time: 0.2464594841003418 ms\n",
            "Epoch 37, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.644723415374756 ms\n",
            "Epoch 38:[0/16], Current Loss: 0.927874743938446, Current Training Accuracy: 97.65625, Time: 0.2717869281768799 ms\n",
            "Epoch 38:[5/16], Current Loss: 0.9204798936843872, Current Training Accuracy: 98.56770833333333, Time: 0.2495441436767578 ms\n",
            "Epoch 38:[10/16], Current Loss: 0.935185432434082, Current Training Accuracy: 98.29545454545455, Time: 0.2515287399291992 ms\n",
            "Epoch 38:[15/16], Current Loss: 0.9206234216690063, Current Training Accuracy: 98.291015625, Time: 0.24772214889526367 ms\n",
            "Epoch 38, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 63 % Epoch Time: 6.593091726303101 ms\n",
            "Epoch 39:[0/16], Current Loss: 0.9284366965293884, Current Training Accuracy: 97.65625, Time: 0.2728874683380127 ms\n",
            "Epoch 39:[5/16], Current Loss: 0.9200202822685242, Current Training Accuracy: 98.56770833333333, Time: 0.25275588035583496 ms\n",
            "Epoch 39:[10/16], Current Loss: 0.9199585318565369, Current Training Accuracy: 98.36647727272727, Time: 0.25366973876953125 ms\n",
            "Epoch 39:[15/16], Current Loss: 0.9441103339195251, Current Training Accuracy: 98.291015625, Time: 0.25075507164001465 ms\n",
            "Epoch 39, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.6248228549957275 ms\n",
            "Epoch 40:[0/16], Current Loss: 0.9362214803695679, Current Training Accuracy: 96.875, Time: 0.2762420177459717 ms\n",
            "Epoch 40:[5/16], Current Loss: 0.9128062725067139, Current Training Accuracy: 97.91666666666667, Time: 0.2524833679199219 ms\n",
            "Epoch 40:[10/16], Current Loss: 0.9049541354179382, Current Training Accuracy: 98.22443181818181, Time: 0.25310850143432617 ms\n",
            "Epoch 40:[15/16], Current Loss: 0.9122911691665649, Current Training Accuracy: 98.291015625, Time: 0.249558687210083 ms\n",
            "Epoch 40, train Loss: 0.922  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 6.617429256439209 ms\n",
            "Epoch 41:[0/16], Current Loss: 0.9126887917518616, Current Training Accuracy: 99.21875, Time: 0.28127288818359375 ms\n",
            "Epoch 41:[5/16], Current Loss: 0.928073525428772, Current Training Accuracy: 97.39583333333333, Time: 0.2535881996154785 ms\n",
            "Epoch 41:[10/16], Current Loss: 0.928415060043335, Current Training Accuracy: 98.22443181818181, Time: 0.2509632110595703 ms\n",
            "Epoch 41:[15/16], Current Loss: 0.935701310634613, Current Training Accuracy: 98.291015625, Time: 0.24937033653259277 ms\n",
            "Epoch 41, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.6003334522247314 ms\n",
            "Epoch 42:[0/16], Current Loss: 0.9362008571624756, Current Training Accuracy: 96.875, Time: 0.27649617195129395 ms\n",
            "Epoch 42:[5/16], Current Loss: 0.928386390209198, Current Training Accuracy: 98.17708333333333, Time: 0.25752830505371094 ms\n",
            "Epoch 42:[10/16], Current Loss: 0.9283887147903442, Current Training Accuracy: 98.29545454545455, Time: 0.2548377513885498 ms\n",
            "Epoch 42:[15/16], Current Loss: 0.9283958077430725, Current Training Accuracy: 98.33984375, Time: 0.24965786933898926 ms\n",
            "Epoch 42, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.65655779838562 ms\n",
            "Epoch 43:[0/16], Current Loss: 0.9283842444419861, Current Training Accuracy: 97.65625, Time: 0.27599000930786133 ms\n",
            "Epoch 43:[5/16], Current Loss: 0.9199904203414917, Current Training Accuracy: 98.30729166666667, Time: 0.25117039680480957 ms\n",
            "Epoch 43:[10/16], Current Loss: 0.9127908945083618, Current Training Accuracy: 98.36647727272727, Time: 0.2626957893371582 ms\n",
            "Epoch 43:[15/16], Current Loss: 0.9283432364463806, Current Training Accuracy: 98.291015625, Time: 0.2500171661376953 ms\n",
            "Epoch 43, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.601923227310181 ms\n",
            "Epoch 44:[0/16], Current Loss: 0.928405225276947, Current Training Accuracy: 97.65625, Time: 0.2730400562286377 ms\n",
            "Epoch 44:[5/16], Current Loss: 0.9361916184425354, Current Training Accuracy: 98.30729166666667, Time: 0.24874401092529297 ms\n",
            "Epoch 44:[10/16], Current Loss: 0.92058265209198, Current Training Accuracy: 98.50852272727273, Time: 0.2521235942840576 ms\n",
            "Epoch 44:[15/16], Current Loss: 0.9205946326255798, Current Training Accuracy: 98.291015625, Time: 0.24957966804504395 ms\n",
            "Epoch 44, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.569597959518433 ms\n",
            "Epoch 45:[0/16], Current Loss: 0.9200883507728577, Current Training Accuracy: 98.4375, Time: 0.2720158100128174 ms\n",
            "Epoch 45:[5/16], Current Loss: 0.9362287521362305, Current Training Accuracy: 97.78645833333333, Time: 0.2524704933166504 ms\n",
            "Epoch 45:[10/16], Current Loss: 0.9127737879753113, Current Training Accuracy: 98.08238636363636, Time: 0.2521169185638428 ms\n",
            "Epoch 45:[15/16], Current Loss: 0.9127780795097351, Current Training Accuracy: 98.291015625, Time: 0.25359010696411133 ms\n",
            "Epoch 45, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.627036809921265 ms\n",
            "Epoch 46:[0/16], Current Loss: 0.9199694991111755, Current Training Accuracy: 98.4375, Time: 0.2667427062988281 ms\n",
            "Epoch 46:[5/16], Current Loss: 0.9049587249755859, Current Training Accuracy: 98.30729166666667, Time: 0.25203633308410645 ms\n",
            "Epoch 46:[10/16], Current Loss: 0.9049463868141174, Current Training Accuracy: 98.22443181818181, Time: 0.24848079681396484 ms\n",
            "Epoch 46:[15/16], Current Loss: 0.9205800294876099, Current Training Accuracy: 98.33984375, Time: 0.25008654594421387 ms\n",
            "Epoch 46, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.567519187927246 ms\n",
            "Epoch 47:[0/16], Current Loss: 0.9355736970901489, Current Training Accuracy: 96.875, Time: 0.2773737907409668 ms\n",
            "Epoch 47:[5/16], Current Loss: 0.9127482771873474, Current Training Accuracy: 98.56770833333333, Time: 0.2529721260070801 ms\n",
            "Epoch 47:[10/16], Current Loss: 0.9049410223960876, Current Training Accuracy: 98.57954545454545, Time: 0.25232601165771484 ms\n",
            "Epoch 47:[15/16], Current Loss: 0.9205754399299622, Current Training Accuracy: 98.291015625, Time: 0.24760937690734863 ms\n",
            "Epoch 47, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.596121311187744 ms\n",
            "Epoch 48:[0/16], Current Loss: 0.9198972582817078, Current Training Accuracy: 98.4375, Time: 0.2712595462799072 ms\n",
            "Epoch 48:[5/16], Current Loss: 0.9205738306045532, Current Training Accuracy: 99.08854166666667, Time: 0.2513880729675293 ms\n",
            "Epoch 48:[10/16], Current Loss: 0.943469226360321, Current Training Accuracy: 98.65056818181819, Time: 0.25108814239501953 ms\n",
            "Epoch 48:[15/16], Current Loss: 0.9205572605133057, Current Training Accuracy: 98.291015625, Time: 0.2465507984161377 ms\n",
            "Epoch 48, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.617020130157471 ms\n",
            "Epoch 49:[0/16], Current Loss: 0.9205520749092102, Current Training Accuracy: 98.4375, Time: 0.27005815505981445 ms\n",
            "Epoch 49:[5/16], Current Loss: 0.920564591884613, Current Training Accuracy: 98.56770833333333, Time: 0.2509274482727051 ms\n",
            "Epoch 49:[10/16], Current Loss: 0.9362062215805054, Current Training Accuracy: 98.08238636363636, Time: 0.2525019645690918 ms\n",
            "Epoch 49:[15/16], Current Loss: 0.9127617478370667, Current Training Accuracy: 98.291015625, Time: 0.250596284866333 ms\n",
            "Epoch 49, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.578348636627197 ms\n",
            "Epoch 50:[0/16], Current Loss: 0.9201867580413818, Current Training Accuracy: 98.4375, Time: 0.28562283515930176 ms\n",
            "Epoch 50:[5/16], Current Loss: 0.9127694964408875, Current Training Accuracy: 98.17708333333333, Time: 0.25533080101013184 ms\n",
            "Epoch 50:[10/16], Current Loss: 0.9201078414916992, Current Training Accuracy: 98.4375, Time: 0.2531759738922119 ms\n",
            "Epoch 50:[15/16], Current Loss: 0.9495455622673035, Current Training Accuracy: 98.291015625, Time: 0.24941086769104004 ms\n",
            "Epoch 50, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.6141040325164795 ms\n",
            "Epoch 51:[0/16], Current Loss: 0.9127693176269531, Current Training Accuracy: 99.21875, Time: 0.26105833053588867 ms\n",
            "Epoch 51:[5/16], Current Loss: 0.9273419976234436, Current Training Accuracy: 98.17708333333333, Time: 0.25393176078796387 ms\n",
            "Epoch 51:[10/16], Current Loss: 0.9205322265625, Current Training Accuracy: 98.01136363636364, Time: 0.25893497467041016 ms\n",
            "Epoch 51:[15/16], Current Loss: 0.9283764362335205, Current Training Accuracy: 98.291015625, Time: 0.2491295337677002 ms\n",
            "Epoch 51, train Loss: 0.922  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.569469928741455 ms\n",
            "Epoch 52:[0/16], Current Loss: 0.9205654263496399, Current Training Accuracy: 98.4375, Time: 0.2762284278869629 ms\n",
            "Epoch 52:[5/16], Current Loss: 0.9121799468994141, Current Training Accuracy: 98.046875, Time: 0.2500467300415039 ms\n",
            "Epoch 52:[10/16], Current Loss: 0.9136684536933899, Current Training Accuracy: 98.29545454545455, Time: 0.25157713890075684 ms\n",
            "Epoch 52:[15/16], Current Loss: 0.9206103682518005, Current Training Accuracy: 98.33984375, Time: 0.24912357330322266 ms\n",
            "Epoch 52, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.564533948898315 ms\n",
            "Epoch 53:[0/16], Current Loss: 0.9351667165756226, Current Training Accuracy: 96.875, Time: 0.27498507499694824 ms\n",
            "Epoch 53:[5/16], Current Loss: 0.905074954032898, Current Training Accuracy: 98.30729166666667, Time: 0.25107455253601074 ms\n",
            "Epoch 53:[10/16], Current Loss: 0.943448543548584, Current Training Accuracy: 98.22443181818181, Time: 0.25170302391052246 ms\n",
            "Epoch 53:[15/16], Current Loss: 0.9199199676513672, Current Training Accuracy: 98.33984375, Time: 0.2494058609008789 ms\n",
            "Epoch 53, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.553865432739258 ms\n",
            "Epoch 54:[0/16], Current Loss: 0.9199435114860535, Current Training Accuracy: 98.4375, Time: 0.27117109298706055 ms\n",
            "Epoch 54:[5/16], Current Loss: 0.9201908707618713, Current Training Accuracy: 98.56770833333333, Time: 0.2508974075317383 ms\n",
            "Epoch 54:[10/16], Current Loss: 0.9355034828186035, Current Training Accuracy: 98.57954545454545, Time: 0.25199341773986816 ms\n",
            "Epoch 54:[15/16], Current Loss: 0.9205695390701294, Current Training Accuracy: 98.33984375, Time: 0.24914813041687012 ms\n",
            "Epoch 54, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.561557054519653 ms\n",
            "Epoch 55:[0/16], Current Loss: 0.904929518699646, Current Training Accuracy: 100.0, Time: 0.27397632598876953 ms\n",
            "Epoch 55:[5/16], Current Loss: 0.9205530285835266, Current Training Accuracy: 98.30729166666667, Time: 0.2548534870147705 ms\n",
            "Epoch 55:[10/16], Current Loss: 0.9352574348449707, Current Training Accuracy: 98.1534090909091, Time: 0.25122618675231934 ms\n",
            "Epoch 55:[15/16], Current Loss: 0.912749171257019, Current Training Accuracy: 98.33984375, Time: 0.2463841438293457 ms\n",
            "Epoch 55, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.575976133346558 ms\n",
            "Epoch 56:[0/16], Current Loss: 0.9205676913261414, Current Training Accuracy: 98.4375, Time: 0.2655904293060303 ms\n",
            "Epoch 56:[5/16], Current Loss: 0.9128126502037048, Current Training Accuracy: 98.30729166666667, Time: 0.2514760494232178 ms\n",
            "Epoch 56:[10/16], Current Loss: 0.935126006603241, Current Training Accuracy: 98.22443181818181, Time: 0.24980473518371582 ms\n",
            "Epoch 56:[15/16], Current Loss: 0.9205609560012817, Current Training Accuracy: 98.33984375, Time: 0.24918746948242188 ms\n",
            "Epoch 56, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.5569422245025635 ms\n",
            "Epoch 57:[0/16], Current Loss: 0.9361943006515503, Current Training Accuracy: 96.875, Time: 0.27333641052246094 ms\n",
            "Epoch 57:[5/16], Current Loss: 0.9205706119537354, Current Training Accuracy: 98.17708333333333, Time: 0.25150537490844727 ms\n",
            "Epoch 57:[10/16], Current Loss: 0.912769615650177, Current Training Accuracy: 98.36647727272727, Time: 0.24970006942749023 ms\n",
            "Epoch 57:[15/16], Current Loss: 0.9127557873725891, Current Training Accuracy: 98.33984375, Time: 0.24897050857543945 ms\n",
            "Epoch 57, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.5910444259643555 ms\n",
            "Epoch 58:[0/16], Current Loss: 0.9433442950248718, Current Training Accuracy: 96.09375, Time: 0.27375102043151855 ms\n",
            "Epoch 58:[5/16], Current Loss: 0.9194179177284241, Current Training Accuracy: 98.17708333333333, Time: 0.250927209854126 ms\n",
            "Epoch 58:[10/16], Current Loss: 0.9283689856529236, Current Training Accuracy: 98.4375, Time: 0.26125454902648926 ms\n",
            "Epoch 58:[15/16], Current Loss: 0.9283802509307861, Current Training Accuracy: 98.33984375, Time: 0.2513163089752197 ms\n",
            "Epoch 58, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.632240533828735 ms\n",
            "Epoch 59:[0/16], Current Loss: 0.9205676913261414, Current Training Accuracy: 98.4375, Time: 0.27434325218200684 ms\n",
            "Epoch 59:[5/16], Current Loss: 0.9275729656219482, Current Training Accuracy: 97.91666666666667, Time: 0.2503821849822998 ms\n",
            "Epoch 59:[10/16], Current Loss: 0.9127448797225952, Current Training Accuracy: 98.29545454545455, Time: 0.2547752857208252 ms\n",
            "Epoch 59:[15/16], Current Loss: 0.935545802116394, Current Training Accuracy: 98.33984375, Time: 0.2491908073425293 ms\n",
            "Epoch 59, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.614450454711914 ms\n",
            "Epoch 60:[0/16], Current Loss: 0.9271576404571533, Current Training Accuracy: 97.65625, Time: 0.273273229598999 ms\n",
            "Epoch 60:[5/16], Current Loss: 0.9199984073638916, Current Training Accuracy: 97.78645833333333, Time: 0.25109291076660156 ms\n",
            "Epoch 60:[10/16], Current Loss: 0.912743091583252, Current Training Accuracy: 98.22443181818181, Time: 0.25136470794677734 ms\n",
            "Epoch 60:[15/16], Current Loss: 0.9205377101898193, Current Training Accuracy: 98.33984375, Time: 0.24901652336120605 ms\n",
            "Epoch 60, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.621623992919922 ms\n",
            "Epoch 61:[0/16], Current Loss: 0.9127140641212463, Current Training Accuracy: 99.21875, Time: 0.27626895904541016 ms\n",
            "Epoch 61:[5/16], Current Loss: 0.9199060201644897, Current Training Accuracy: 97.65625, Time: 0.25295138359069824 ms\n",
            "Epoch 61:[10/16], Current Loss: 0.9120558500289917, Current Training Accuracy: 98.29545454545455, Time: 0.24955391883850098 ms\n",
            "Epoch 61:[15/16], Current Loss: 0.920766294002533, Current Training Accuracy: 98.33984375, Time: 0.2487931251525879 ms\n",
            "Epoch 61, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.611912488937378 ms\n",
            "Epoch 62:[0/16], Current Loss: 0.9279235601425171, Current Training Accuracy: 97.65625, Time: 0.27256274223327637 ms\n",
            "Epoch 62:[5/16], Current Loss: 0.919879674911499, Current Training Accuracy: 98.046875, Time: 0.25246357917785645 ms\n",
            "Epoch 62:[10/16], Current Loss: 0.9200085997581482, Current Training Accuracy: 98.1534090909091, Time: 0.2507972717285156 ms\n",
            "Epoch 62:[15/16], Current Loss: 0.9127803444862366, Current Training Accuracy: 98.388671875, Time: 0.2502005100250244 ms\n",
            "Epoch 62, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.609259605407715 ms\n",
            "Epoch 63:[0/16], Current Loss: 0.9283842444419861, Current Training Accuracy: 97.65625, Time: 0.27373337745666504 ms\n",
            "Epoch 63:[5/16], Current Loss: 0.9347193837165833, Current Training Accuracy: 98.17708333333333, Time: 0.25449037551879883 ms\n",
            "Epoch 63:[10/16], Current Loss: 0.9200190305709839, Current Training Accuracy: 98.36647727272727, Time: 0.2517848014831543 ms\n",
            "Epoch 63:[15/16], Current Loss: 0.9183329343795776, Current Training Accuracy: 98.388671875, Time: 0.24802803993225098 ms\n",
            "Epoch 63, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.607866048812866 ms\n",
            "Epoch 64:[0/16], Current Loss: 0.920179545879364, Current Training Accuracy: 98.4375, Time: 0.2729837894439697 ms\n",
            "Epoch 64:[5/16], Current Loss: 0.9283684492111206, Current Training Accuracy: 98.828125, Time: 0.25855112075805664 ms\n",
            "Epoch 64:[10/16], Current Loss: 0.9264487028121948, Current Training Accuracy: 98.65056818181819, Time: 0.24918746948242188 ms\n",
            "Epoch 64:[15/16], Current Loss: 0.9353234171867371, Current Training Accuracy: 98.486328125, Time: 0.24806499481201172 ms\n",
            "Epoch 64, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.611713647842407 ms\n",
            "Epoch 65:[0/16], Current Loss: 0.9282398223876953, Current Training Accuracy: 97.65625, Time: 0.2725799083709717 ms\n",
            "Epoch 65:[5/16], Current Loss: 0.920391857624054, Current Training Accuracy: 98.046875, Time: 0.25122714042663574 ms\n",
            "Epoch 65:[10/16], Current Loss: 0.9207435250282288, Current Training Accuracy: 98.36647727272727, Time: 0.25575757026672363 ms\n",
            "Epoch 65:[15/16], Current Loss: 0.9211681485176086, Current Training Accuracy: 98.4375, Time: 0.24759769439697266 ms\n",
            "Epoch 65, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.6375133991241455 ms\n",
            "Epoch 66:[0/16], Current Loss: 0.9052352905273438, Current Training Accuracy: 100.0, Time: 0.2811005115509033 ms\n",
            "Epoch 66:[5/16], Current Loss: 0.9206188321113586, Current Training Accuracy: 98.4375, Time: 0.2621638774871826 ms\n",
            "Epoch 66:[10/16], Current Loss: 0.9590097069740295, Current Training Accuracy: 98.29545454545455, Time: 0.25128698348999023 ms\n",
            "Epoch 66:[15/16], Current Loss: 0.9125708937644958, Current Training Accuracy: 98.486328125, Time: 0.24866557121276855 ms\n",
            "Epoch 66, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.616269826889038 ms\n",
            "Epoch 67:[0/16], Current Loss: 0.9205694198608398, Current Training Accuracy: 98.4375, Time: 0.27406883239746094 ms\n",
            "Epoch 67:[5/16], Current Loss: 0.9363284111022949, Current Training Accuracy: 98.30729166666667, Time: 0.25121045112609863 ms\n",
            "Epoch 67:[10/16], Current Loss: 0.9205834269523621, Current Training Accuracy: 98.57954545454545, Time: 0.25017666816711426 ms\n",
            "Epoch 67:[15/16], Current Loss: 0.9110953211784363, Current Training Accuracy: 98.53515625, Time: 0.24817419052124023 ms\n",
            "Epoch 67, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.599675893783569 ms\n",
            "Epoch 68:[0/16], Current Loss: 0.9276562929153442, Current Training Accuracy: 97.65625, Time: 0.2814292907714844 ms\n",
            "Epoch 68:[5/16], Current Loss: 0.9051947593688965, Current Training Accuracy: 98.56770833333333, Time: 0.25029754638671875 ms\n",
            "Epoch 68:[10/16], Current Loss: 0.9049380421638489, Current Training Accuracy: 98.79261363636364, Time: 0.2537071704864502 ms\n",
            "Epoch 68:[15/16], Current Loss: 0.9356265664100647, Current Training Accuracy: 98.583984375, Time: 0.24904870986938477 ms\n",
            "Epoch 68, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.614885330200195 ms\n",
            "Epoch 69:[0/16], Current Loss: 0.9203377366065979, Current Training Accuracy: 98.4375, Time: 0.2731039524078369 ms\n",
            "Epoch 69:[5/16], Current Loss: 0.9127222299575806, Current Training Accuracy: 98.56770833333333, Time: 0.25746774673461914 ms\n",
            "Epoch 69:[10/16], Current Loss: 0.9515355825424194, Current Training Accuracy: 98.36647727272727, Time: 0.24945759773254395 ms\n",
            "Epoch 69:[15/16], Current Loss: 0.9205556511878967, Current Training Accuracy: 98.6328125, Time: 0.2480461597442627 ms\n",
            "Epoch 69, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.622303009033203 ms\n",
            "Epoch 70:[0/16], Current Loss: 0.9278239011764526, Current Training Accuracy: 97.65625, Time: 0.2742805480957031 ms\n",
            "Epoch 70:[5/16], Current Loss: 0.9127640724182129, Current Training Accuracy: 98.69791666666667, Time: 0.24865961074829102 ms\n",
            "Epoch 70:[10/16], Current Loss: 0.9127861857414246, Current Training Accuracy: 98.65056818181819, Time: 0.2539849281311035 ms\n",
            "Epoch 70:[15/16], Current Loss: 0.9127115607261658, Current Training Accuracy: 98.681640625, Time: 0.24792098999023438 ms\n",
            "Epoch 70, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.591752052307129 ms\n",
            "Epoch 71:[0/16], Current Loss: 0.9205306172370911, Current Training Accuracy: 98.4375, Time: 0.2747228145599365 ms\n",
            "Epoch 71:[5/16], Current Loss: 0.9127181768417358, Current Training Accuracy: 98.17708333333333, Time: 0.25056886672973633 ms\n",
            "Epoch 71:[10/16], Current Loss: 0.9205197095870972, Current Training Accuracy: 98.57954545454545, Time: 0.24865031242370605 ms\n",
            "Epoch 71:[15/16], Current Loss: 0.9205635786056519, Current Training Accuracy: 98.583984375, Time: 0.24858498573303223 ms\n",
            "Epoch 71, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.592206954956055 ms\n",
            "Epoch 72:[0/16], Current Loss: 0.9359443783760071, Current Training Accuracy: 96.875, Time: 0.27416062355041504 ms\n",
            "Epoch 72:[5/16], Current Loss: 0.9205960035324097, Current Training Accuracy: 97.91666666666667, Time: 0.2513751983642578 ms\n",
            "Epoch 72:[10/16], Current Loss: 0.9049068093299866, Current Training Accuracy: 98.4375, Time: 0.26144981384277344 ms\n",
            "Epoch 72:[15/16], Current Loss: 0.9127108454704285, Current Training Accuracy: 98.583984375, Time: 0.24936747550964355 ms\n",
            "Epoch 72, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.648680925369263 ms\n",
            "Epoch 73:[0/16], Current Loss: 0.912701427936554, Current Training Accuracy: 99.21875, Time: 0.25522518157958984 ms\n",
            "Epoch 73:[5/16], Current Loss: 0.9283273816108704, Current Training Accuracy: 98.17708333333333, Time: 0.25069522857666016 ms\n",
            "Epoch 73:[10/16], Current Loss: 0.935422420501709, Current Training Accuracy: 98.36647727272727, Time: 0.2531249523162842 ms\n",
            "Epoch 73:[15/16], Current Loss: 0.9049307703971863, Current Training Accuracy: 98.583984375, Time: 0.25078368186950684 ms\n",
            "Epoch 73, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.595306158065796 ms\n",
            "Epoch 74:[0/16], Current Loss: 0.9049107432365417, Current Training Accuracy: 100.0, Time: 0.2722318172454834 ms\n",
            "Epoch 74:[5/16], Current Loss: 0.9279096126556396, Current Training Accuracy: 98.4375, Time: 0.2505612373352051 ms\n",
            "Epoch 74:[10/16], Current Loss: 0.9198858737945557, Current Training Accuracy: 98.65056818181819, Time: 0.2523934841156006 ms\n",
            "Epoch 74:[15/16], Current Loss: 0.9205244183540344, Current Training Accuracy: 98.583984375, Time: 0.24893879890441895 ms\n",
            "Epoch 74, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.616708993911743 ms\n",
            "Epoch 75:[0/16], Current Loss: 0.9350957870483398, Current Training Accuracy: 96.875, Time: 0.2781796455383301 ms\n",
            "Epoch 75:[5/16], Current Loss: 0.9277543425559998, Current Training Accuracy: 98.69791666666667, Time: 0.25144124031066895 ms\n",
            "Epoch 75:[10/16], Current Loss: 0.9127063751220703, Current Training Accuracy: 98.7215909090909, Time: 0.25071144104003906 ms\n",
            "Epoch 75:[15/16], Current Loss: 0.912689745426178, Current Training Accuracy: 98.6328125, Time: 0.2484292984008789 ms\n",
            "Epoch 75, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.599738836288452 ms\n",
            "Epoch 76:[0/16], Current Loss: 0.9278659820556641, Current Training Accuracy: 97.65625, Time: 0.27159667015075684 ms\n",
            "Epoch 76:[5/16], Current Loss: 0.9205169677734375, Current Training Accuracy: 98.56770833333333, Time: 0.2546861171722412 ms\n",
            "Epoch 76:[10/16], Current Loss: 0.9048745632171631, Current Training Accuracy: 98.57954545454545, Time: 0.25176119804382324 ms\n",
            "Epoch 76:[15/16], Current Loss: 0.9048863649368286, Current Training Accuracy: 98.583984375, Time: 0.24859237670898438 ms\n",
            "Epoch 76, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.634261608123779 ms\n",
            "Epoch 77:[0/16], Current Loss: 0.9199203848838806, Current Training Accuracy: 98.4375, Time: 0.2767212390899658 ms\n",
            "Epoch 77:[5/16], Current Loss: 0.9205132126808167, Current Training Accuracy: 98.56770833333333, Time: 0.2542760372161865 ms\n",
            "Epoch 77:[10/16], Current Loss: 0.9048793315887451, Current Training Accuracy: 98.36647727272727, Time: 0.25379109382629395 ms\n",
            "Epoch 77:[15/16], Current Loss: 0.9120113253593445, Current Training Accuracy: 98.583984375, Time: 0.24951672554016113 ms\n",
            "Epoch 77, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.642088174819946 ms\n",
            "Epoch 78:[0/16], Current Loss: 0.9048876166343689, Current Training Accuracy: 100.0, Time: 0.2752342224121094 ms\n",
            "Epoch 78:[5/16], Current Loss: 0.919244110584259, Current Training Accuracy: 98.4375, Time: 0.25078773498535156 ms\n",
            "Epoch 78:[10/16], Current Loss: 0.9127010703086853, Current Training Accuracy: 98.4375, Time: 0.25380945205688477 ms\n",
            "Epoch 78:[15/16], Current Loss: 0.9127156138420105, Current Training Accuracy: 98.583984375, Time: 0.24854612350463867 ms\n",
            "Epoch 78, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.616074085235596 ms\n",
            "Epoch 79:[0/16], Current Loss: 0.9126986265182495, Current Training Accuracy: 99.21875, Time: 0.284512996673584 ms\n",
            "Epoch 79:[5/16], Current Loss: 0.9276983141899109, Current Training Accuracy: 98.4375, Time: 0.2573068141937256 ms\n",
            "Epoch 79:[10/16], Current Loss: 0.9199084043502808, Current Training Accuracy: 98.50852272727273, Time: 0.2533681392669678 ms\n",
            "Epoch 79:[15/16], Current Loss: 0.9205049872398376, Current Training Accuracy: 98.583984375, Time: 0.24820423126220703 ms\n",
            "Epoch 79, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.620136022567749 ms\n",
            "Epoch 80:[0/16], Current Loss: 0.9127072095870972, Current Training Accuracy: 99.21875, Time: 0.27437877655029297 ms\n",
            "Epoch 80:[5/16], Current Loss: 0.9124069809913635, Current Training Accuracy: 98.95833333333333, Time: 0.25298261642456055 ms\n",
            "Epoch 80:[10/16], Current Loss: 0.9127017855644226, Current Training Accuracy: 98.9346590909091, Time: 0.2630422115325928 ms\n",
            "Epoch 80:[15/16], Current Loss: 0.9205141067504883, Current Training Accuracy: 98.583984375, Time: 0.24934840202331543 ms\n",
            "Epoch 80, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.634354114532471 ms\n",
            "Epoch 81:[0/16], Current Loss: 0.9205067157745361, Current Training Accuracy: 98.4375, Time: 0.27600574493408203 ms\n",
            "Epoch 81:[5/16], Current Loss: 0.9205302596092224, Current Training Accuracy: 98.4375, Time: 0.24947404861450195 ms\n",
            "Epoch 81:[10/16], Current Loss: 0.9205055832862854, Current Training Accuracy: 98.29545454545455, Time: 0.25357675552368164 ms\n",
            "Epoch 81:[15/16], Current Loss: 0.9126962423324585, Current Training Accuracy: 98.583984375, Time: 0.24918150901794434 ms\n",
            "Epoch 81, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.60854434967041 ms\n",
            "Epoch 82:[0/16], Current Loss: 0.9126877784729004, Current Training Accuracy: 99.21875, Time: 0.27700233459472656 ms\n",
            "Epoch 82:[5/16], Current Loss: 0.9205085039138794, Current Training Accuracy: 98.69791666666667, Time: 0.25470900535583496 ms\n",
            "Epoch 82:[10/16], Current Loss: 0.9502298831939697, Current Training Accuracy: 98.4375, Time: 0.25707173347473145 ms\n",
            "Epoch 82:[15/16], Current Loss: 0.9120712876319885, Current Training Accuracy: 98.583984375, Time: 0.2465653419494629 ms\n",
            "Epoch 82, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.597922086715698 ms\n",
            "Epoch 83:[0/16], Current Loss: 0.9126920700073242, Current Training Accuracy: 99.21875, Time: 0.2855994701385498 ms\n",
            "Epoch 83:[5/16], Current Loss: 0.9048726558685303, Current Training Accuracy: 98.95833333333333, Time: 0.24975919723510742 ms\n",
            "Epoch 83:[10/16], Current Loss: 0.912690281867981, Current Training Accuracy: 98.79261363636364, Time: 0.24930214881896973 ms\n",
            "Epoch 83:[15/16], Current Loss: 0.9361340403556824, Current Training Accuracy: 98.583984375, Time: 0.24931573867797852 ms\n",
            "Epoch 83, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.612611532211304 ms\n",
            "Epoch 84:[0/16], Current Loss: 0.9205046892166138, Current Training Accuracy: 98.4375, Time: 0.27690649032592773 ms\n",
            "Epoch 84:[5/16], Current Loss: 0.9432433247566223, Current Training Accuracy: 98.4375, Time: 0.2537400722503662 ms\n",
            "Epoch 84:[10/16], Current Loss: 0.9126904010772705, Current Training Accuracy: 98.65056818181819, Time: 0.2545170783996582 ms\n",
            "Epoch 84:[15/16], Current Loss: 0.9350882172584534, Current Training Accuracy: 98.583984375, Time: 0.24957537651062012 ms\n",
            "Epoch 84, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.592730283737183 ms\n",
            "Epoch 85:[0/16], Current Loss: 0.9198079109191895, Current Training Accuracy: 98.4375, Time: 0.27808666229248047 ms\n",
            "Epoch 85:[5/16], Current Loss: 0.9277389645576477, Current Training Accuracy: 98.17708333333333, Time: 0.2492842674255371 ms\n",
            "Epoch 85:[10/16], Current Loss: 0.9127049446105957, Current Training Accuracy: 98.36647727272727, Time: 0.2502744197845459 ms\n",
            "Epoch 85:[15/16], Current Loss: 0.9121673107147217, Current Training Accuracy: 98.583984375, Time: 0.24917006492614746 ms\n",
            "Epoch 85, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.648961544036865 ms\n",
            "Epoch 86:[0/16], Current Loss: 0.912691593170166, Current Training Accuracy: 99.21875, Time: 0.2753901481628418 ms\n",
            "Epoch 86:[5/16], Current Loss: 0.919842541217804, Current Training Accuracy: 98.4375, Time: 0.2533073425292969 ms\n",
            "Epoch 86:[10/16], Current Loss: 0.920504093170166, Current Training Accuracy: 98.65056818181819, Time: 0.2506539821624756 ms\n",
            "Epoch 86:[15/16], Current Loss: 0.9205037355422974, Current Training Accuracy: 98.583984375, Time: 0.24735760688781738 ms\n",
            "Epoch 86, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.626292943954468 ms\n",
            "Epoch 87:[0/16], Current Loss: 0.9355774521827698, Current Training Accuracy: 96.875, Time: 0.276137113571167 ms\n",
            "Epoch 87:[5/16], Current Loss: 0.9126890301704407, Current Training Accuracy: 98.17708333333333, Time: 0.2506413459777832 ms\n",
            "Epoch 87:[10/16], Current Loss: 0.9276955723762512, Current Training Accuracy: 98.50852272727273, Time: 0.2516613006591797 ms\n",
            "Epoch 87:[15/16], Current Loss: 0.9126890897750854, Current Training Accuracy: 98.583984375, Time: 0.2534046173095703 ms\n",
            "Epoch 87, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.656037330627441 ms\n",
            "Epoch 88:[0/16], Current Loss: 0.9126859307289124, Current Training Accuracy: 99.21875, Time: 0.27615952491760254 ms\n",
            "Epoch 88:[5/16], Current Loss: 0.9126835465431213, Current Training Accuracy: 98.828125, Time: 0.25191354751586914 ms\n",
            "Epoch 88:[10/16], Current Loss: 0.9204986095428467, Current Training Accuracy: 98.4375, Time: 0.24813055992126465 ms\n",
            "Epoch 88:[15/16], Current Loss: 0.9205049276351929, Current Training Accuracy: 98.583984375, Time: 0.24828767776489258 ms\n",
            "Epoch 88, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.596955299377441 ms\n",
            "Epoch 89:[0/16], Current Loss: 0.9126814007759094, Current Training Accuracy: 99.21875, Time: 0.26867151260375977 ms\n",
            "Epoch 89:[5/16], Current Loss: 0.9122117161750793, Current Training Accuracy: 98.69791666666667, Time: 0.2523164749145508 ms\n",
            "Epoch 89:[10/16], Current Loss: 0.9120425581932068, Current Training Accuracy: 98.57954545454545, Time: 0.2506368160247803 ms\n",
            "Epoch 89:[15/16], Current Loss: 0.9126657247543335, Current Training Accuracy: 98.583984375, Time: 0.24756741523742676 ms\n",
            "Epoch 89, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.630402326583862 ms\n",
            "Epoch 90:[0/16], Current Loss: 0.9347929954528809, Current Training Accuracy: 96.875, Time: 0.27312326431274414 ms\n",
            "Epoch 90:[5/16], Current Loss: 0.9204976558685303, Current Training Accuracy: 98.046875, Time: 0.2497084140777588 ms\n",
            "Epoch 90:[10/16], Current Loss: 0.9126998782157898, Current Training Accuracy: 98.4375, Time: 0.25852513313293457 ms\n",
            "Epoch 90:[15/16], Current Loss: 0.9048871397972107, Current Training Accuracy: 98.583984375, Time: 0.24941062927246094 ms\n",
            "Epoch 90, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.618068218231201 ms\n",
            "Epoch 91:[0/16], Current Loss: 0.9198869466781616, Current Training Accuracy: 98.4375, Time: 0.2571711540222168 ms\n",
            "Epoch 91:[5/16], Current Loss: 0.9205148220062256, Current Training Accuracy: 98.828125, Time: 0.2578256130218506 ms\n",
            "Epoch 91:[10/16], Current Loss: 0.9355117082595825, Current Training Accuracy: 98.79261363636364, Time: 0.25379490852355957 ms\n",
            "Epoch 91:[15/16], Current Loss: 0.9282811880111694, Current Training Accuracy: 98.583984375, Time: 0.2485816478729248 ms\n",
            "Epoch 91, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.597137451171875 ms\n",
            "Epoch 92:[0/16], Current Loss: 0.9048693180084229, Current Training Accuracy: 100.0, Time: 0.27813100814819336 ms\n",
            "Epoch 92:[5/16], Current Loss: 0.9126834869384766, Current Training Accuracy: 99.08854166666667, Time: 0.250866174697876 ms\n",
            "Epoch 92:[10/16], Current Loss: 0.9278463125228882, Current Training Accuracy: 99.00568181818181, Time: 0.25583529472351074 ms\n",
            "Epoch 92:[15/16], Current Loss: 0.9434146881103516, Current Training Accuracy: 98.583984375, Time: 0.24995875358581543 ms\n",
            "Epoch 92, train Loss: 0.919  Avg Training Accuracy: {99 %} Avg Validation Accuracy: 65 % Epoch Time: 6.644955635070801 ms\n",
            "Epoch 93:[0/16], Current Loss: 0.9354451894760132, Current Training Accuracy: 96.875, Time: 0.27583765983581543 ms\n",
            "Epoch 93:[5/16], Current Loss: 0.9120501279830933, Current Training Accuracy: 98.828125, Time: 0.25075387954711914 ms\n",
            "Epoch 93:[10/16], Current Loss: 0.9198904037475586, Current Training Accuracy: 98.65056818181819, Time: 0.2623610496520996 ms\n",
            "Epoch 93:[15/16], Current Loss: 0.9361224174499512, Current Training Accuracy: 98.583984375, Time: 0.24766278266906738 ms\n",
            "Epoch 93, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.647304534912109 ms\n",
            "Epoch 94:[0/16], Current Loss: 0.9355952143669128, Current Training Accuracy: 96.875, Time: 0.26702165603637695 ms\n",
            "Epoch 94:[5/16], Current Loss: 0.912726104259491, Current Training Accuracy: 98.30729166666667, Time: 0.2511708736419678 ms\n",
            "Epoch 94:[10/16], Current Loss: 0.9205576777458191, Current Training Accuracy: 98.36647727272727, Time: 0.2542729377746582 ms\n",
            "Epoch 94:[15/16], Current Loss: 0.9284588694572449, Current Training Accuracy: 98.388671875, Time: 0.2494966983795166 ms\n",
            "Epoch 94, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.601860284805298 ms\n",
            "Epoch 95:[0/16], Current Loss: 0.9266025424003601, Current Training Accuracy: 98.4375, Time: 0.2747528553009033 ms\n",
            "Epoch 95:[5/16], Current Loss: 1.0089328289031982, Current Training Accuracy: 95.83333333333333, Time: 0.25040674209594727 ms\n",
            "Epoch 95:[10/16], Current Loss: 1.1050798892974854, Current Training Accuracy: 92.61363636363636, Time: 0.2542262077331543 ms\n",
            "Epoch 95:[15/16], Current Loss: 1.0003682374954224, Current Training Accuracy: 92.1875, Time: 0.25020337104797363 ms\n",
            "Epoch 95, train Loss: 0.988  Avg Training Accuracy: {95 %} Avg Validation Accuracy: 63 % Epoch Time: 6.593271017074585 ms\n",
            "Epoch 96:[0/16], Current Loss: 1.0047340393066406, Current Training Accuracy: 90.625, Time: 0.2817502021789551 ms\n",
            "Epoch 96:[5/16], Current Loss: 1.0144261121749878, Current Training Accuracy: 90.10416666666667, Time: 0.25399279594421387 ms\n",
            "Epoch 96:[10/16], Current Loss: 0.9910023808479309, Current Training Accuracy: 89.3465909090909, Time: 0.2523503303527832 ms\n",
            "Epoch 96:[15/16], Current Loss: 1.0287315845489502, Current Training Accuracy: 89.74609375, Time: 0.24904680252075195 ms\n",
            "Epoch 96, train Loss: 1.009  Avg Training Accuracy: {89 %} Avg Validation Accuracy: 59 % Epoch Time: 6.632254362106323 ms\n",
            "Epoch 97:[0/16], Current Loss: 1.1077396869659424, Current Training Accuracy: 78.90625, Time: 0.2717149257659912 ms\n",
            "Epoch 97:[5/16], Current Loss: 0.9890367984771729, Current Training Accuracy: 89.19270833333333, Time: 0.2515745162963867 ms\n",
            "Epoch 97:[10/16], Current Loss: 0.9805383086204529, Current Training Accuracy: 90.3409090909091, Time: 0.26633763313293457 ms\n",
            "Epoch 97:[15/16], Current Loss: 1.0080878734588623, Current Training Accuracy: 90.625, Time: 0.2487473487854004 ms\n",
            "Epoch 97, train Loss: 0.994  Avg Training Accuracy: {88 %} Avg Validation Accuracy: 60 % Epoch Time: 6.617544174194336 ms\n",
            "Epoch 98:[0/16], Current Loss: 0.9196922779083252, Current Training Accuracy: 99.21875, Time: 0.27588915824890137 ms\n",
            "Epoch 98:[5/16], Current Loss: 0.9359105825424194, Current Training Accuracy: 95.703125, Time: 0.2538642883300781 ms\n",
            "Epoch 98:[10/16], Current Loss: 0.9709937572479248, Current Training Accuracy: 94.88636363636364, Time: 0.26686620712280273 ms\n",
            "Epoch 98:[15/16], Current Loss: 0.936802327632904, Current Training Accuracy: 94.7265625, Time: 0.24766206741333008 ms\n",
            "Epoch 98, train Loss: 0.960  Avg Training Accuracy: {95 %} Avg Validation Accuracy: 64 % Epoch Time: 6.636897087097168 ms\n",
            "Epoch 99:[0/16], Current Loss: 0.9388313889503479, Current Training Accuracy: 96.09375, Time: 0.27415990829467773 ms\n",
            "Epoch 99:[5/16], Current Loss: 0.9203301072120667, Current Training Accuracy: 96.484375, Time: 0.25133585929870605 ms\n",
            "Epoch 99:[10/16], Current Loss: 0.9496358036994934, Current Training Accuracy: 96.5909090909091, Time: 0.2523181438446045 ms\n",
            "Epoch 99:[15/16], Current Loss: 0.9376102685928345, Current Training Accuracy: 96.533203125, Time: 0.249861478805542 ms\n",
            "Epoch 99, train Loss: 0.941  Avg Training Accuracy: {96 %} Avg Validation Accuracy: 63 % Epoch Time: 6.589956045150757 ms\n",
            "Epoch 100:[0/16], Current Loss: 0.9161510467529297, Current Training Accuracy: 99.21875, Time: 0.2826714515686035 ms\n",
            "Epoch 100:[5/16], Current Loss: 0.920714259147644, Current Training Accuracy: 98.56770833333333, Time: 0.24842619895935059 ms\n",
            "Epoch 100:[10/16], Current Loss: 0.9216597080230713, Current Training Accuracy: 97.86931818181819, Time: 0.24848151206970215 ms\n",
            "Epoch 100:[15/16], Current Loss: 0.9263885021209717, Current Training Accuracy: 97.94921875, Time: 0.2500028610229492 ms\n",
            "Epoch 100, train Loss: 0.928  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.613769769668579 ms\n",
            "Epoch 101:[0/16], Current Loss: 0.921052098274231, Current Training Accuracy: 98.4375, Time: 0.27997446060180664 ms\n",
            "Epoch 101:[5/16], Current Loss: 0.9359498023986816, Current Training Accuracy: 98.56770833333333, Time: 0.255237340927124 ms\n",
            "Epoch 101:[10/16], Current Loss: 0.9288469552993774, Current Training Accuracy: 98.36647727272727, Time: 0.25409913063049316 ms\n",
            "Epoch 101:[15/16], Current Loss: 0.9421059489250183, Current Training Accuracy: 98.193359375, Time: 0.24782276153564453 ms\n",
            "Epoch 101, train Loss: 0.924  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.6686036586761475 ms\n",
            "Epoch 102:[0/16], Current Loss: 0.9436063766479492, Current Training Accuracy: 96.09375, Time: 0.2652888298034668 ms\n",
            "Epoch 102:[5/16], Current Loss: 0.930366039276123, Current Training Accuracy: 97.78645833333333, Time: 0.25294995307922363 ms\n",
            "Epoch 102:[10/16], Current Loss: 0.9201834201812744, Current Training Accuracy: 98.1534090909091, Time: 0.24963855743408203 ms\n",
            "Epoch 102:[15/16], Current Loss: 0.9127400517463684, Current Training Accuracy: 98.2421875, Time: 0.24907898902893066 ms\n",
            "Epoch 102, train Loss: 0.923  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 6.6401214599609375 ms\n",
            "Epoch 103:[0/16], Current Loss: 0.9048877954483032, Current Training Accuracy: 100.0, Time: 0.26784753799438477 ms\n",
            "Epoch 103:[5/16], Current Loss: 0.920372724533081, Current Training Accuracy: 98.828125, Time: 0.2510864734649658 ms\n",
            "Epoch 103:[10/16], Current Loss: 0.9280559420585632, Current Training Accuracy: 98.4375, Time: 0.2504870891571045 ms\n",
            "Epoch 103:[15/16], Current Loss: 0.9206353425979614, Current Training Accuracy: 98.4375, Time: 0.24918222427368164 ms\n",
            "Epoch 103, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.582995414733887 ms\n",
            "Epoch 104:[0/16], Current Loss: 0.9279200434684753, Current Training Accuracy: 97.65625, Time: 0.27524852752685547 ms\n",
            "Epoch 104:[5/16], Current Loss: 0.9283358454704285, Current Training Accuracy: 97.39583333333333, Time: 0.24958443641662598 ms\n",
            "Epoch 104:[10/16], Current Loss: 0.9206462502479553, Current Training Accuracy: 97.9403409090909, Time: 0.2560915946960449 ms\n",
            "Epoch 104:[15/16], Current Loss: 0.9049044251441956, Current Training Accuracy: 98.486328125, Time: 0.24702715873718262 ms\n",
            "Epoch 104, train Loss: 0.920  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 66 % Epoch Time: 6.590951919555664 ms\n",
            "Epoch 105:[0/16], Current Loss: 0.9126530289649963, Current Training Accuracy: 99.21875, Time: 0.27422666549682617 ms\n",
            "Epoch 105:[5/16], Current Loss: 0.9048678278923035, Current Training Accuracy: 99.21875, Time: 0.24752521514892578 ms\n",
            "Epoch 105:[10/16], Current Loss: 0.9204846024513245, Current Training Accuracy: 98.57954545454545, Time: 0.2539381980895996 ms\n",
            "Epoch 105:[15/16], Current Loss: 0.9048682451248169, Current Training Accuracy: 98.486328125, Time: 0.24747657775878906 ms\n",
            "Epoch 105, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.610896110534668 ms\n",
            "Epoch 106:[0/16], Current Loss: 0.9048547148704529, Current Training Accuracy: 100.0, Time: 0.2816309928894043 ms\n",
            "Epoch 106:[5/16], Current Loss: 0.9205185770988464, Current Training Accuracy: 99.08854166666667, Time: 0.25025439262390137 ms\n",
            "Epoch 106:[10/16], Current Loss: 0.9281525611877441, Current Training Accuracy: 98.4375, Time: 0.257265567779541 ms\n",
            "Epoch 106:[15/16], Current Loss: 0.9204891920089722, Current Training Accuracy: 98.53515625, Time: 0.24723124504089355 ms\n",
            "Epoch 106, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.66822075843811 ms\n",
            "Epoch 107:[0/16], Current Loss: 0.9204763174057007, Current Training Accuracy: 98.4375, Time: 0.2789018154144287 ms\n",
            "Epoch 107:[5/16], Current Loss: 0.9126735925674438, Current Training Accuracy: 98.56770833333333, Time: 0.2527124881744385 ms\n",
            "Epoch 107:[10/16], Current Loss: 0.9283032417297363, Current Training Accuracy: 98.57954545454545, Time: 0.2535436153411865 ms\n",
            "Epoch 107:[15/16], Current Loss: 0.9283098578453064, Current Training Accuracy: 98.486328125, Time: 0.24648141860961914 ms\n",
            "Epoch 107, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.631545782089233 ms\n",
            "Epoch 108:[0/16], Current Loss: 0.9439250826835632, Current Training Accuracy: 96.09375, Time: 0.27757859230041504 ms\n",
            "Epoch 108:[5/16], Current Loss: 0.920487642288208, Current Training Accuracy: 98.4375, Time: 0.2507741451263428 ms\n",
            "Epoch 108:[10/16], Current Loss: 0.9126802086830139, Current Training Accuracy: 98.29545454545455, Time: 0.25141096115112305 ms\n",
            "Epoch 108:[15/16], Current Loss: 0.9201139211654663, Current Training Accuracy: 98.486328125, Time: 0.2500646114349365 ms\n",
            "Epoch 108, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.645545244216919 ms\n",
            "Epoch 109:[0/16], Current Loss: 0.9126766920089722, Current Training Accuracy: 99.21875, Time: 0.2787516117095947 ms\n",
            "Epoch 109:[5/16], Current Loss: 0.9126784801483154, Current Training Accuracy: 98.046875, Time: 0.25040721893310547 ms\n",
            "Epoch 109:[10/16], Current Loss: 0.9048541784286499, Current Training Accuracy: 98.50852272727273, Time: 0.2517569065093994 ms\n",
            "Epoch 109:[15/16], Current Loss: 0.9276943802833557, Current Training Accuracy: 98.486328125, Time: 0.24725794792175293 ms\n",
            "Epoch 109, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.6156675815582275 ms\n",
            "Epoch 110:[0/16], Current Loss: 0.9126718640327454, Current Training Accuracy: 99.21875, Time: 0.2771420478820801 ms\n",
            "Epoch 110:[5/16], Current Loss: 0.9354656338691711, Current Training Accuracy: 98.95833333333333, Time: 0.2534003257751465 ms\n",
            "Epoch 110:[10/16], Current Loss: 0.9121319055557251, Current Training Accuracy: 98.50852272727273, Time: 0.2550477981567383 ms\n",
            "Epoch 110:[15/16], Current Loss: 0.9126645922660828, Current Training Accuracy: 98.486328125, Time: 0.24723410606384277 ms\n",
            "Epoch 110, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.6201112270355225 ms\n",
            "Epoch 111:[0/16], Current Loss: 0.9204815626144409, Current Training Accuracy: 98.4375, Time: 0.27600932121276855 ms\n",
            "Epoch 111:[5/16], Current Loss: 0.9276541471481323, Current Training Accuracy: 97.91666666666667, Time: 0.24973130226135254 ms\n",
            "Epoch 111:[10/16], Current Loss: 0.9126766920089722, Current Training Accuracy: 98.36647727272727, Time: 0.25731825828552246 ms\n",
            "Epoch 111:[15/16], Current Loss: 0.927647054195404, Current Training Accuracy: 98.486328125, Time: 0.24974536895751953 ms\n",
            "Epoch 111, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.640609979629517 ms\n",
            "Epoch 112:[0/16], Current Loss: 0.9126752018928528, Current Training Accuracy: 99.21875, Time: 0.2748138904571533 ms\n",
            "Epoch 112:[5/16], Current Loss: 0.9281924962997437, Current Training Accuracy: 98.56770833333333, Time: 0.25307345390319824 ms\n",
            "Epoch 112:[10/16], Current Loss: 0.9119972586631775, Current Training Accuracy: 98.50852272727273, Time: 0.25653576850891113 ms\n",
            "Epoch 112:[15/16], Current Loss: 0.9126659035682678, Current Training Accuracy: 98.53515625, Time: 0.24794483184814453 ms\n",
            "Epoch 112, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 69 % Epoch Time: 6.61768913269043 ms\n",
            "Epoch 113:[0/16], Current Loss: 0.9126694798469543, Current Training Accuracy: 99.21875, Time: 0.26911425590515137 ms\n",
            "Epoch 113:[5/16], Current Loss: 0.9048553109169006, Current Training Accuracy: 98.69791666666667, Time: 0.2598850727081299 ms\n",
            "Epoch 113:[10/16], Current Loss: 0.9204831123352051, Current Training Accuracy: 98.65056818181819, Time: 0.2489638328552246 ms\n",
            "Epoch 113:[15/16], Current Loss: 0.9276012778282166, Current Training Accuracy: 98.53515625, Time: 0.24722933769226074 ms\n",
            "Epoch 113, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.6212158203125 ms\n",
            "Epoch 114:[0/16], Current Loss: 0.9126654863357544, Current Training Accuracy: 99.21875, Time: 0.2760584354400635 ms\n",
            "Epoch 114:[5/16], Current Loss: 0.9121291637420654, Current Training Accuracy: 98.30729166666667, Time: 0.2543802261352539 ms\n",
            "Epoch 114:[10/16], Current Loss: 0.9048542380332947, Current Training Accuracy: 98.7215909090909, Time: 0.25405406951904297 ms\n",
            "Epoch 114:[15/16], Current Loss: 0.9274774789810181, Current Training Accuracy: 98.53515625, Time: 0.24959635734558105 ms\n",
            "Epoch 114, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.613316535949707 ms\n",
            "Epoch 115:[0/16], Current Loss: 0.9282974600791931, Current Training Accuracy: 97.65625, Time: 0.2718336582183838 ms\n",
            "Epoch 115:[5/16], Current Loss: 0.9204752445220947, Current Training Accuracy: 98.95833333333333, Time: 0.25487709045410156 ms\n",
            "Epoch 115:[10/16], Current Loss: 0.9126694798469543, Current Training Accuracy: 98.65056818181819, Time: 0.2488691806793213 ms\n",
            "Epoch 115:[15/16], Current Loss: 0.9126602411270142, Current Training Accuracy: 98.53515625, Time: 0.25004076957702637 ms\n",
            "Epoch 115, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.6190361976623535 ms\n",
            "Epoch 116:[0/16], Current Loss: 0.9282816052436829, Current Training Accuracy: 97.65625, Time: 0.27578091621398926 ms\n",
            "Epoch 116:[5/16], Current Loss: 0.9204850196838379, Current Training Accuracy: 98.30729166666667, Time: 0.25142526626586914 ms\n",
            "Epoch 116:[10/16], Current Loss: 0.9282883405685425, Current Training Accuracy: 98.4375, Time: 0.24932646751403809 ms\n",
            "Epoch 116:[15/16], Current Loss: 0.9204758405685425, Current Training Accuracy: 98.53515625, Time: 0.2477712631225586 ms\n",
            "Epoch 116, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 69 % Epoch Time: 6.590052127838135 ms\n",
            "Epoch 117:[0/16], Current Loss: 0.9349453449249268, Current Training Accuracy: 96.875, Time: 0.2781214714050293 ms\n",
            "Epoch 117:[5/16], Current Loss: 0.9204797744750977, Current Training Accuracy: 97.91666666666667, Time: 0.2508859634399414 ms\n",
            "Epoch 117:[10/16], Current Loss: 0.9275842308998108, Current Training Accuracy: 98.22443181818181, Time: 0.2482917308807373 ms\n",
            "Epoch 117:[15/16], Current Loss: 0.9119709730148315, Current Training Accuracy: 98.53515625, Time: 0.24781084060668945 ms\n",
            "Epoch 117, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.62816047668457 ms\n",
            "Epoch 118:[0/16], Current Loss: 0.9275294542312622, Current Training Accuracy: 97.65625, Time: 0.27307629585266113 ms\n",
            "Epoch 118:[5/16], Current Loss: 0.9204776287078857, Current Training Accuracy: 98.828125, Time: 0.25212860107421875 ms\n",
            "Epoch 118:[10/16], Current Loss: 0.9268868565559387, Current Training Accuracy: 98.79261363636364, Time: 0.2573723793029785 ms\n",
            "Epoch 118:[15/16], Current Loss: 0.935698390007019, Current Training Accuracy: 98.53515625, Time: 0.24857473373413086 ms\n",
            "Epoch 118, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.632103204727173 ms\n",
            "Epoch 119:[0/16], Current Loss: 0.927647590637207, Current Training Accuracy: 97.65625, Time: 0.2785487174987793 ms\n",
            "Epoch 119:[5/16], Current Loss: 0.920478105545044, Current Training Accuracy: 98.17708333333333, Time: 0.25322747230529785 ms\n",
            "Epoch 119:[10/16], Current Loss: 0.9204790592193604, Current Training Accuracy: 98.50852272727273, Time: 0.25474071502685547 ms\n",
            "Epoch 119:[15/16], Current Loss: 0.9204856753349304, Current Training Accuracy: 98.53515625, Time: 0.24624085426330566 ms\n",
            "Epoch 119, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.635342359542847 ms\n",
            "Epoch 120:[0/16], Current Loss: 0.9126767516136169, Current Training Accuracy: 99.21875, Time: 0.26904988288879395 ms\n",
            "Epoch 120:[5/16], Current Loss: 0.9120686054229736, Current Training Accuracy: 98.56770833333333, Time: 0.2495729923248291 ms\n",
            "Epoch 120:[10/16], Current Loss: 0.9119755029678345, Current Training Accuracy: 98.65056818181819, Time: 0.25277042388916016 ms\n",
            "Epoch 120:[15/16], Current Loss: 0.9204824566841125, Current Training Accuracy: 98.53515625, Time: 0.2477555274963379 ms\n",
            "Epoch 120, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.579167604446411 ms\n",
            "Epoch 121:[0/16], Current Loss: 0.9199793934822083, Current Training Accuracy: 98.4375, Time: 0.2730727195739746 ms\n",
            "Epoch 121:[5/16], Current Loss: 0.9126655459403992, Current Training Accuracy: 98.69791666666667, Time: 0.25252866744995117 ms\n",
            "Epoch 121:[10/16], Current Loss: 0.9119619131088257, Current Training Accuracy: 98.57954545454545, Time: 0.25112295150756836 ms\n",
            "Epoch 121:[15/16], Current Loss: 0.9203732013702393, Current Training Accuracy: 98.53515625, Time: 0.24829769134521484 ms\n",
            "Epoch 121, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.624995470046997 ms\n",
            "Epoch 122:[0/16], Current Loss: 0.9126647114753723, Current Training Accuracy: 99.21875, Time: 0.2761855125427246 ms\n",
            "Epoch 122:[5/16], Current Loss: 0.9353851079940796, Current Training Accuracy: 98.828125, Time: 0.2563326358795166 ms\n",
            "Epoch 122:[10/16], Current Loss: 0.9204879403114319, Current Training Accuracy: 98.57954545454545, Time: 0.2535715103149414 ms\n",
            "Epoch 122:[15/16], Current Loss: 0.9126783013343811, Current Training Accuracy: 98.53515625, Time: 0.24753189086914062 ms\n",
            "Epoch 122, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.631274223327637 ms\n",
            "Epoch 123:[0/16], Current Loss: 0.9204388856887817, Current Training Accuracy: 98.4375, Time: 0.2743508815765381 ms\n",
            "Epoch 123:[5/16], Current Loss: 0.9049949049949646, Current Training Accuracy: 98.4375, Time: 0.2531464099884033 ms\n",
            "Epoch 123:[10/16], Current Loss: 0.9275927543640137, Current Training Accuracy: 98.57954545454545, Time: 0.2500770092010498 ms\n",
            "Epoch 123:[15/16], Current Loss: 0.9126858711242676, Current Training Accuracy: 98.53515625, Time: 0.2495126724243164 ms\n",
            "Epoch 123, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.618101119995117 ms\n",
            "Epoch 124:[0/16], Current Loss: 0.912745475769043, Current Training Accuracy: 99.21875, Time: 0.2687110900878906 ms\n",
            "Epoch 124:[5/16], Current Loss: 0.9211965203285217, Current Training Accuracy: 98.69791666666667, Time: 0.2593109607696533 ms\n",
            "Epoch 124:[10/16], Current Loss: 0.928320050239563, Current Training Accuracy: 98.22443181818181, Time: 0.2520322799682617 ms\n",
            "Epoch 124:[15/16], Current Loss: 0.9119739532470703, Current Training Accuracy: 98.583984375, Time: 0.24854350090026855 ms\n",
            "Epoch 124, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.619654655456543 ms\n",
            "Epoch 125:[0/16], Current Loss: 0.9204820394515991, Current Training Accuracy: 98.4375, Time: 0.27618956565856934 ms\n",
            "Epoch 125:[5/16], Current Loss: 0.9282957315444946, Current Training Accuracy: 98.4375, Time: 0.2508983612060547 ms\n",
            "Epoch 125:[10/16], Current Loss: 0.9126699566841125, Current Training Accuracy: 98.50852272727273, Time: 0.25174689292907715 ms\n",
            "Epoch 125:[15/16], Current Loss: 0.9204566478729248, Current Training Accuracy: 98.583984375, Time: 0.24750041961669922 ms\n",
            "Epoch 125, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.580366849899292 ms\n",
            "Epoch 126:[0/16], Current Loss: 0.9432072043418884, Current Training Accuracy: 96.09375, Time: 0.2737691402435303 ms\n",
            "Epoch 126:[5/16], Current Loss: 0.9197869896888733, Current Training Accuracy: 98.17708333333333, Time: 0.2511870861053467 ms\n",
            "Epoch 126:[10/16], Current Loss: 0.9048653244972229, Current Training Accuracy: 98.50852272727273, Time: 0.2512552738189697 ms\n",
            "Epoch 126:[15/16], Current Loss: 0.9360795617103577, Current Training Accuracy: 98.583984375, Time: 0.25031518936157227 ms\n",
            "Epoch 126, train Loss: 0.919  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.622558832168579 ms\n",
            "Epoch 127:[0/16], Current Loss: 0.9204591512680054, Current Training Accuracy: 98.4375, Time: 0.277271032333374 ms\n",
            "Epoch 127:[5/16], Current Loss: 0.9585955142974854, Current Training Accuracy: 98.17708333333333, Time: 0.25229954719543457 ms\n",
            "Epoch 127:[10/16], Current Loss: 0.9048553109169006, Current Training Accuracy: 98.50852272727273, Time: 0.24765229225158691 ms\n",
            "Epoch 127:[15/16], Current Loss: 0.9126704931259155, Current Training Accuracy: 98.6328125, Time: 0.24789667129516602 ms\n",
            "Epoch 127, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.596162796020508 ms\n",
            "Epoch 128:[0/16], Current Loss: 0.9048717021942139, Current Training Accuracy: 100.0, Time: 0.2693288326263428 ms\n",
            "Epoch 128:[5/16], Current Loss: 0.9126856327056885, Current Training Accuracy: 98.69791666666667, Time: 0.25850963592529297 ms\n",
            "Epoch 128:[10/16], Current Loss: 0.9197747707366943, Current Training Accuracy: 98.57954545454545, Time: 0.2514214515686035 ms\n",
            "Epoch 128:[15/16], Current Loss: 0.9276648759841919, Current Training Accuracy: 98.6328125, Time: 0.2513713836669922 ms\n",
            "Epoch 128, train Loss: 0.918  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.6136298179626465 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "pred_correct_num=[]\n",
        "pred_total_num=[]\n",
        "pred_result_list=[]\n",
        "pred_prob_list = []\n",
        "label_prob_list=[]\n",
        "label_list=[]\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "    t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
        "    mask=mask.cuda()\n",
        "    output_test=model(t_image)\n",
        "    pred_prob_list.append(output_test)\n",
        "    label_prob_list.append(data[1])\n",
        "    label_list.append(mask)\n",
        "    output=torch.max(output_test,1)[1].long()\n",
        "    pred_result_list.append(output)\n",
        "    pred_correct_num.append(output.eq(mask).sum().item())\n",
        "    pred_total_num.append(output_test.shape[0])\n",
        "acc_test=sum(pred_correct_num)/sum(pred_total_num)\n",
        "print(\"The accuracy of detecting news bias: {}\".format(('%.4f%%'%(acc_test*100))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDlJZUxK1XKA",
        "outputId": "2f655be4-821f-486b-9aa3-be299293fd0d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of detecting news bias: 84.6354%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "for i in range(len(pred_result_list)):\n",
        "  if len(pred_result_list) == 1:\n",
        "    pred_result = pred_result_list[0]\n",
        "    label = label_list[0]\n",
        "  if len(pred_result_list) == 2:\n",
        "    pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
        "    label = torch.cat((label_list[0], label_list[1]), -1)\n",
        "  if len(pred_result_list) > 2:\n",
        "    pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
        "    label = torch.cat((label_list[0], label_list[1]), -1)\n",
        "    for j in range(len(pred_result_list)-2):\n",
        "      pred_result = torch.cat((pred_result, pred_result_list[j+2]), -1)\n",
        "      label = torch.cat((label, label_list[j+2]), -1)\n",
        "label = label.cpu()\n",
        "pred_result = pred_result.cpu()\n",
        "C=confusion_matrix(label,pred_result)\n",
        "df=pd.DataFrame(C,index=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"],columns=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"])\n",
        "p1=sns.heatmap(df,annot=True,cmap=\"hot_r\")\n",
        "s1 = p1.get_figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "AAsS7hFK1iyG",
        "outputId": "d4f35069-4132-42ee-c3c0-cbc9502fe51f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(pred_prob_list)):\n",
        "  if len(pred_prob_list) == 1:\n",
        "    pred_prob = pred_prob_list[0]\n",
        "    label_prob = label_prob_list[0]\n",
        "  if len(pred_prob_list) == 2:\n",
        "    pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
        "    label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
        "  if len(pred_prob_list) > 2:\n",
        "    pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
        "    label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
        "    for j in range(len(pred_prob_list)-2):\n",
        "      pred_prob = torch.cat((pred_prob, pred_prob_list[j+2]), -1)\n",
        "      label_prob = torch.cat((label_prob, label_prob_list[j+2]), -1)\n",
        "label_prob = label_prob.cpu()\n",
        "pred_prob = pred_prob.cpu()\n",
        "criterion=nn.L1Loss(reduction=\"mean\")\n",
        "loss=criterion(pred_prob, label_prob)\n",
        "print(\"MAE Value: {}\".format(\"%.4f\" % loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyZi5AtB1oDV",
        "outputId": "f74b398b-14a0-4ab9-8bac-a424335aba1a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE Value: 0.0636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score = f1_score(pred_result,label,average=\"macro\")\n",
        "print(\"Macro-F1 Score: {}\".format(\"%.4f\" % f1_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJP8QNey1umr",
        "outputId": "7a7c6de4-9935-4e50-dbb5-0beeea61dc3d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-F1 Score: 0.8074\n"
          ]
        }
      ]
    }
  ]
}