{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PYm-bdo_70fp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "import torch.utils.data as Data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from math import log"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')\n",
        "#改变当前工作目录到谷歌云盘的路径\n",
        "path=\"/content/drive/My Drive/Colab Notebooks/Bias Detection/\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5JFWgC1753u",
        "outputId": "3780470c-b372-4833-a072-6b19badefe12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['X_valid_glove_title.npy',\n",
              " 'y_test_glove.npy',\n",
              " 'y_train_glove.npy',\n",
              " 'y_valid_glove.npy',\n",
              " 'X_test_glove_headline.npy',\n",
              " 'X_test_glove_title.npy',\n",
              " 'X_valid_glove_headline.npy',\n",
              " 'X_train_glove_headline.npy',\n",
              " 'X_train_glove_title.npy',\n",
              " 'Single Region Size.ipynb',\n",
              " 'Multiple Region Size.ipynb',\n",
              " '#Feature Map.ipynb',\n",
              " 'RAMCA(LSTM).ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_process1=np.load(\"X_train_glove_title.npy\")\n",
        "X_test_process1=np.load(\"X_test_glove_title.npy\")\n",
        "X_valid_process1=np.load(\"X_valid_glove_title.npy\")\n",
        "y_train_process=np.load(\"y_train_glove.npy\")\n",
        "y_test_process=np.load(\"y_test_glove.npy\")\n",
        "y_valid_process=np.load(\"y_valid_glove.npy\")"
      ],
      "metadata": {
        "id": "Cv5HbSeu8EGT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = Data.DataLoader(\n",
        "    dataset=Data.TensorDataset(torch.Tensor(X_train_process1),torch.LongTensor(y_train_process)),      \n",
        "    batch_size=128,      \n",
        "    shuffle=True,               \n",
        "    num_workers=2, \n",
        "    drop_last=True\n",
        ")\n",
        "test_loader = Data.DataLoader(\n",
        "    dataset=Data.TensorDataset(torch.Tensor(X_test_process1),torch.LongTensor(y_test_process)),      \n",
        "    batch_size=128,      \n",
        "    shuffle=True,               \n",
        "    num_workers=2,  \n",
        "    drop_last=True\n",
        ")\n",
        "val_loader = Data.DataLoader(\n",
        "    dataset=Data.TensorDataset(torch.Tensor(X_valid_process1),torch.LongTensor(y_valid_process)),      \n",
        "    batch_size=128,      \n",
        "    shuffle=True,               \n",
        "    num_workers=2,\n",
        "    drop_last=True\n",
        ")"
      ],
      "metadata": {
        "id": "zmYdgZgF8HhV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ECA(x,gamma=2,b=1):\n",
        "    N,C,H,W=x.size()\n",
        "    t=int(abs((log(C,2)+b)/gamma))\n",
        "    k=t if t%2 else t+1\n",
        "    \n",
        "    avg_pool=nn.AdaptiveAvgPool2d(1).cuda()\n",
        "    conv=nn.Conv1d(1,1,kernel_size=k,padding=int(k/2),bias=False).cuda()\n",
        "    sigmoid=nn.Sigmoid().cuda()\n",
        "    \n",
        "    y=avg_pool(x)\n",
        "    y=conv(y.squeeze(-1).transpose(-1,-2))\n",
        "    y=y.transpose(-1,-2).unsqueeze(-1)\n",
        "    y=sigmoid(y)\n",
        "    return y"
      ],
      "metadata": {
        "id": "7TebM8ng8PXK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextRCNN(nn.Module):\n",
        "    def __init__(self,vocab_size,embedding_dim,hidden_size,num_labels=5):\n",
        "        super(TextRCNN,self).__init__()\n",
        "        self.lstm = nn.GRU(input_size=embedding_dim,hidden_size=hidden_size,\n",
        "                            batch_first=True,bidirectional=True)\n",
        "        self.dropout = nn.Dropout(.3)\n",
        "        self.linear1 = nn.Linear(embedding_dim+2*hidden_size, 128)\n",
        "        self.linear2 = nn.Linear(600, 128)\n",
        "        self.linear3 = nn.Linear(128, num_labels)\n",
        "        self.conv1 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=6)#通过out_channel改变文中的feature map，且out_channel∈[10,50,100,200,400,600,800,1000]\n",
        "        self.conv2 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=7)\n",
        "        self.conv3 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=8)\n",
        "        self.conv4 = nn.Conv1d(in_channels=128,out_channels=600,kernel_size=9)\n",
        "        self.w_omiga = torch.randn(128,hidden_size*2,1,requires_grad=True).cuda()\n",
        "\n",
        "    def forward(self, x):#x: [batch,L]\n",
        "        x_embed = x.cuda()\n",
        "        last_hidden_state,(c,h) = self.lstm(x_embed) #last_hidden_state: [batch,L,hidden_size * num_bidirectional]\n",
        "        H = torch.nn.Tanh()(last_hidden_state)\n",
        "        weights=torch.nn.Softmax(dim=-1)(torch.bmm(H,self.w_omiga).squeeze(-1)).unsqueeze(dim=-1).repeat(1,1,2*12)  # LSTM+ATTN-Weight\n",
        "        last_hidden_state=torch.mul(last_hidden_state,weights)\n",
        "        out = torch.cat((last_hidden_state[:,:,:12],x_embed,last_hidden_state[:,:,12:]),2)#out: [batch,L,embedding_size + hidden_size * num_bidirectional]  \n",
        "        out = F.tanh(self.linear1(out))\n",
        "        out = out.permute(dims=[0,2,1]) #out: [batch,embedding_size + hidden_size * num_bidirectional,L]\n",
        "        out_1 = self.conv1(out)\n",
        "        out_1 = nn.ReLU()(out_1)\n",
        "        out_1 = nn.MaxPool1d(kernel_size=495)(out_1)\n",
        "        out_2 = self.conv1(out)\n",
        "        out_2 = nn.ReLU()(out_2)\n",
        "        out_2 = nn.MaxPool1d(kernel_size=494)(out_2)\n",
        "        out_3 = self.conv1(out)\n",
        "        out_3 = nn.ReLU()(out_3)\n",
        "        out_3 = nn.MaxPool1d(kernel_size=493)(out_3)\n",
        "        out_4 = self.conv1(out)\n",
        "        out_4 = nn.ReLU()(out_4)\n",
        "        out_4 = nn.MaxPool1d(kernel_size=492)(out_4)\n",
        "        out_1 = out_1.unsqueeze(1).cuda()\n",
        "        out_2 = out_2.unsqueeze(1).cuda()\n",
        "        out_3 = out_3.unsqueeze(1).cuda()\n",
        "        out_4 = out_4.unsqueeze(1).cuda()\n",
        "        out = torch.cat([out_1, out_2, out_3, out_4],dim=1).cuda()\n",
        "        channel_weights = F.softmax(ECA(out).squeeze().squeeze(),dim=1).unsqueeze(-1).unsqueeze(-1).expand_as(out)\n",
        "        out = torch.mul(channel_weights,out)\n",
        "        out = torch.sum(out, dim = 1)\n",
        "        out = self.linear2(out.squeeze()) #out: [batch,num_labels]\n",
        "        out = self.linear3(F.tanh(out))\n",
        "        out = F.softmax(out,dim=1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "R6Rs1agS8Sgj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextRCNN(5302,200,12).cuda()"
      ],
      "metadata": {
        "id": "JABn7Sh88iQ8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list, counter =[], []\n",
        "count = 0\n",
        "running_loss=0\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0)\n",
        "total_train = 0\n",
        "correct_train = 0\n",
        "train_epoch, train_loss = [], []\n",
        "train_acc, val_acc = [], []\n",
        "avg_epoch, avg_train_loss, avg_val_acc = [], [], []\n",
        "epoch_time=[]\n",
        "\n",
        "model.train()\n",
        "for epoch in range(128): \n",
        "    running_loss = 0\n",
        "    total_train = 0\n",
        "    correct_train = 0\n",
        "    total_accuracy = 0\n",
        "    total_val_accuracy = 0\n",
        "    correct_val = 0\n",
        "    total_val = 0   \n",
        "    start1 = time.time()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        start = time.time()\n",
        "        t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
        "        t_image=t_image.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(t_image) # forward\n",
        "        ###########################################################################\n",
        "        outputs=outputs.cuda()\n",
        "        mask=mask.cuda()\n",
        "        loss = criterion(outputs, mask.long()) # calculate the loss\n",
        "        loss.backward() # back propagation\n",
        "        optimizer.step() # update gradients\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += mask.nelement()\n",
        "        correct_train += predicted.eq(mask.data).sum().item()\n",
        "        train_accuracy = 100 * correct_train / total_train\n",
        "        total_accuracy += train_accuracy\n",
        "        if i % 5 == 0:\n",
        "            end = time.time()\n",
        "            print('Epoch {}:[{}/{}], Current Loss: {}, Current Training Accuracy: {}, Time: {} ms'.format(epoch+1, i, len(train_loader), loss.item(), train_accuracy, end - start))      \n",
        "            train_acc.append(train_accuracy)\n",
        "            train_loss.append(loss.item())\n",
        "            train_epoch.append(str(epoch+1) + '/' + str(i))\n",
        "\n",
        "            for j, data1 in enumerate(val_loader, 0):\n",
        "                t_image1, mask1 = data1[0],data1[1].long()\n",
        "                outputs1 = model(t_image1)\n",
        "                mask1_temp=torch.max(mask1.data,1)\n",
        "                mask1_temp1=mask1_temp[1].cuda()\n",
        "                _, predicted1 = torch.max(outputs1.data, 1)\n",
        "                total_val += mask1.nelement()\n",
        "                correct_val += predicted1.eq(mask1_temp1).sum().item()\n",
        "                val_accuracy= 100 * correct_val / total_val\n",
        "                total_val_accuracy += val_accuracy\n",
        "            val_acc.append(val_accuracy)\n",
        "    end1 = time.time()\n",
        "    print('Epoch {}, train Loss: {:.3f} '.format(epoch+1, running_loss/len(train_loader)), \"Avg Training Accuracy: {%d %%}\" % (total_accuracy/len(train_loader)), \"Avg Validation Accuracy: %d %%\" % (total_val_accuracy/len(val_loader)), \"Epoch Time: {} ms\".format(end1 - start1))\n",
        "    epoch_time.append(end1-start1)\n",
        "    avg_epoch.append(epoch+1)\n",
        "    avg_train_loss.append(running_loss/len(train_loader))\n",
        "    avg_val_acc.append(total_val_accuracy/len(val_loader))\n",
        "    #print(avg_epoch)\n",
        "    #print(avg_train_loss)\n",
        "    #print(avg_val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-0xmVlv85Q8",
        "outputId": "bc5ad4a0-aa94-479e-f186-7cc85b1c7d30"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:[0/16], Current Loss: 0.9126489162445068, Current Training Accuracy: 99.21875, Time: 0.3782951831817627 ms\n",
            "Epoch 1:[5/16], Current Loss: 0.9284018874168396, Current Training Accuracy: 97.91666666666667, Time: 0.25363779067993164 ms\n",
            "Epoch 1:[10/16], Current Loss: 0.9202914237976074, Current Training Accuracy: 97.9403409090909, Time: 0.2539792060852051 ms\n",
            "Epoch 1:[15/16], Current Loss: 0.9360966086387634, Current Training Accuracy: 97.75390625, Time: 0.2527344226837158 ms\n",
            "Epoch 1, train Loss: 0.929  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 61 % Epoch Time: 6.955443382263184 ms\n",
            "Epoch 2:[0/16], Current Loss: 0.9282810688018799, Current Training Accuracy: 97.65625, Time: 0.29210972785949707 ms\n",
            "Epoch 2:[5/16], Current Loss: 0.9280793070793152, Current Training Accuracy: 97.91666666666667, Time: 0.2547733783721924 ms\n",
            "Epoch 2:[10/16], Current Loss: 0.9389345645904541, Current Training Accuracy: 98.01136363636364, Time: 0.2572793960571289 ms\n",
            "Epoch 2:[15/16], Current Loss: 0.9219703674316406, Current Training Accuracy: 98.193359375, Time: 0.25282931327819824 ms\n",
            "Epoch 2, train Loss: 0.923  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 65 % Epoch Time: 7.354206562042236 ms\n",
            "Epoch 3:[0/16], Current Loss: 0.9274003505706787, Current Training Accuracy: 97.65625, Time: 0.27727317810058594 ms\n",
            "Epoch 3:[5/16], Current Loss: 0.9283007383346558, Current Training Accuracy: 98.69791666666667, Time: 0.3008284568786621 ms\n",
            "Epoch 3:[10/16], Current Loss: 0.936144232749939, Current Training Accuracy: 98.29545454545455, Time: 0.26099658012390137 ms\n",
            "Epoch 3:[15/16], Current Loss: 0.9351669549942017, Current Training Accuracy: 98.388671875, Time: 0.28299689292907715 ms\n",
            "Epoch 3, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 8.361730098724365 ms\n",
            "Epoch 4:[0/16], Current Loss: 0.927727460861206, Current Training Accuracy: 97.65625, Time: 0.2741103172302246 ms\n",
            "Epoch 4:[5/16], Current Loss: 0.9353248476982117, Current Training Accuracy: 98.17708333333333, Time: 0.26215171813964844 ms\n",
            "Epoch 4:[10/16], Current Loss: 0.9050017595291138, Current Training Accuracy: 98.22443181818181, Time: 0.25928306579589844 ms\n",
            "Epoch 4:[15/16], Current Loss: 0.9126746654510498, Current Training Accuracy: 98.33984375, Time: 0.25803208351135254 ms\n",
            "Epoch 4, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 7.491239547729492 ms\n",
            "Epoch 5:[0/16], Current Loss: 0.9126843810081482, Current Training Accuracy: 99.21875, Time: 0.2647361755371094 ms\n",
            "Epoch 5:[5/16], Current Loss: 0.9121295213699341, Current Training Accuracy: 98.95833333333333, Time: 0.2670295238494873 ms\n",
            "Epoch 5:[10/16], Current Loss: 0.9203353524208069, Current Training Accuracy: 98.57954545454545, Time: 0.2580604553222656 ms\n",
            "Epoch 5:[15/16], Current Loss: 0.9276940822601318, Current Training Accuracy: 98.33984375, Time: 0.25533008575439453 ms\n",
            "Epoch 5, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.926641225814819 ms\n",
            "Epoch 6:[0/16], Current Loss: 0.9198716878890991, Current Training Accuracy: 98.4375, Time: 0.27753496170043945 ms\n",
            "Epoch 6:[5/16], Current Loss: 0.9048462510108948, Current Training Accuracy: 98.30729166666667, Time: 0.26078200340270996 ms\n",
            "Epoch 6:[10/16], Current Loss: 0.9198358058929443, Current Training Accuracy: 98.29545454545455, Time: 0.2538633346557617 ms\n",
            "Epoch 6:[15/16], Current Loss: 0.9199072122573853, Current Training Accuracy: 98.33984375, Time: 0.2527148723602295 ms\n",
            "Epoch 6, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.912067413330078 ms\n",
            "Epoch 7:[0/16], Current Loss: 0.9277079701423645, Current Training Accuracy: 97.65625, Time: 0.27962470054626465 ms\n",
            "Epoch 7:[5/16], Current Loss: 0.920463502407074, Current Training Accuracy: 97.91666666666667, Time: 0.26236987113952637 ms\n",
            "Epoch 7:[10/16], Current Loss: 0.9355222582817078, Current Training Accuracy: 98.1534090909091, Time: 0.2563488483428955 ms\n",
            "Epoch 7:[15/16], Current Loss: 0.9048416614532471, Current Training Accuracy: 98.33984375, Time: 0.25143885612487793 ms\n",
            "Epoch 7, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.887552738189697 ms\n",
            "Epoch 8:[0/16], Current Loss: 0.9126536846160889, Current Training Accuracy: 99.21875, Time: 0.2695319652557373 ms\n",
            "Epoch 8:[5/16], Current Loss: 0.9439018368721008, Current Training Accuracy: 98.046875, Time: 0.2642831802368164 ms\n",
            "Epoch 8:[10/16], Current Loss: 0.9274600744247437, Current Training Accuracy: 98.1534090909091, Time: 0.25368785858154297 ms\n",
            "Epoch 8:[15/16], Current Loss: 0.9048397541046143, Current Training Accuracy: 98.388671875, Time: 0.2523994445800781 ms\n",
            "Epoch 8, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.858303546905518 ms\n",
            "Epoch 9:[0/16], Current Loss: 0.9198232889175415, Current Training Accuracy: 98.4375, Time: 0.27420997619628906 ms\n",
            "Epoch 9:[5/16], Current Loss: 0.9120668172836304, Current Training Accuracy: 98.17708333333333, Time: 0.25722241401672363 ms\n",
            "Epoch 9:[10/16], Current Loss: 0.9204673767089844, Current Training Accuracy: 98.50852272727273, Time: 0.253894567489624 ms\n",
            "Epoch 9:[15/16], Current Loss: 0.9204652905464172, Current Training Accuracy: 98.388671875, Time: 0.2531728744506836 ms\n",
            "Epoch 9, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.825025796890259 ms\n",
            "Epoch 10:[0/16], Current Loss: 0.9360874891281128, Current Training Accuracy: 96.875, Time: 0.2733736038208008 ms\n",
            "Epoch 10:[5/16], Current Loss: 0.9276637434959412, Current Training Accuracy: 98.30729166666667, Time: 0.25313282012939453 ms\n",
            "Epoch 10:[10/16], Current Loss: 0.9126564860343933, Current Training Accuracy: 98.36647727272727, Time: 0.2528374195098877 ms\n",
            "Epoch 10:[15/16], Current Loss: 0.920462429523468, Current Training Accuracy: 98.388671875, Time: 0.2515888214111328 ms\n",
            "Epoch 10, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.809477090835571 ms\n",
            "Epoch 11:[0/16], Current Loss: 0.9354458451271057, Current Training Accuracy: 96.875, Time: 0.28830742835998535 ms\n",
            "Epoch 11:[5/16], Current Loss: 0.9048400521278381, Current Training Accuracy: 97.91666666666667, Time: 0.2536020278930664 ms\n",
            "Epoch 11:[10/16], Current Loss: 0.9432558417320251, Current Training Accuracy: 97.79829545454545, Time: 0.25407862663269043 ms\n",
            "Epoch 11:[15/16], Current Loss: 0.9048376679420471, Current Training Accuracy: 98.33984375, Time: 0.24709486961364746 ms\n",
            "Epoch 11, train Loss: 0.921  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 68 % Epoch Time: 6.8318235874176025 ms\n",
            "Epoch 12:[0/16], Current Loss: 0.9126495122909546, Current Training Accuracy: 99.21875, Time: 0.2841165065765381 ms\n",
            "Epoch 12:[5/16], Current Loss: 0.9660857319831848, Current Training Accuracy: 97.91666666666667, Time: 0.25748109817504883 ms\n",
            "Epoch 12:[10/16], Current Loss: 0.9198194742202759, Current Training Accuracy: 98.1534090909091, Time: 0.25325989723205566 ms\n",
            "Epoch 12:[15/16], Current Loss: 0.9126539826393127, Current Training Accuracy: 98.33984375, Time: 0.24805116653442383 ms\n",
            "Epoch 12, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.804075717926025 ms\n",
            "Epoch 13:[0/16], Current Loss: 0.9120064377784729, Current Training Accuracy: 99.21875, Time: 0.2705235481262207 ms\n",
            "Epoch 13:[5/16], Current Loss: 0.91200852394104, Current Training Accuracy: 98.56770833333333, Time: 0.25356078147888184 ms\n",
            "Epoch 13:[10/16], Current Loss: 0.9354427456855774, Current Training Accuracy: 98.36647727272727, Time: 0.2528235912322998 ms\n",
            "Epoch 13:[15/16], Current Loss: 0.9204633831977844, Current Training Accuracy: 98.33984375, Time: 0.2525463104248047 ms\n",
            "Epoch 13, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.862073659896851 ms\n",
            "Epoch 14:[0/16], Current Loss: 0.943279504776001, Current Training Accuracy: 96.09375, Time: 0.27375316619873047 ms\n",
            "Epoch 14:[5/16], Current Loss: 0.9198208451271057, Current Training Accuracy: 98.30729166666667, Time: 0.2532835006713867 ms\n",
            "Epoch 14:[10/16], Current Loss: 0.9198185205459595, Current Training Accuracy: 98.50852272727273, Time: 0.25690770149230957 ms\n",
            "Epoch 14:[15/16], Current Loss: 0.9048380851745605, Current Training Accuracy: 98.388671875, Time: 0.2490832805633545 ms\n",
            "Epoch 14, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.8413026332855225 ms\n",
            "Epoch 15:[0/16], Current Loss: 0.9126532673835754, Current Training Accuracy: 99.21875, Time: 0.2764418125152588 ms\n",
            "Epoch 15:[5/16], Current Loss: 0.9354490637779236, Current Training Accuracy: 98.046875, Time: 0.25482702255249023 ms\n",
            "Epoch 15:[10/16], Current Loss: 0.9204633235931396, Current Training Accuracy: 98.22443181818181, Time: 0.2538115978240967 ms\n",
            "Epoch 15:[15/16], Current Loss: 0.9276407361030579, Current Training Accuracy: 98.33984375, Time: 0.2518730163574219 ms\n",
            "Epoch 15, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.842724323272705 ms\n",
            "Epoch 16:[0/16], Current Loss: 0.9204632043838501, Current Training Accuracy: 98.4375, Time: 0.27617931365966797 ms\n",
            "Epoch 16:[5/16], Current Loss: 0.9048373699188232, Current Training Accuracy: 98.4375, Time: 0.25691771507263184 ms\n",
            "Epoch 16:[10/16], Current Loss: 0.9276270866394043, Current Training Accuracy: 98.22443181818181, Time: 0.2585718631744385 ms\n",
            "Epoch 16:[15/16], Current Loss: 0.9126539826393127, Current Training Accuracy: 98.33984375, Time: 0.2526981830596924 ms\n",
            "Epoch 16, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.888539791107178 ms\n",
            "Epoch 17:[0/16], Current Loss: 0.926980197429657, Current Training Accuracy: 97.65625, Time: 0.2839949131011963 ms\n",
            "Epoch 17:[5/16], Current Loss: 0.9126498103141785, Current Training Accuracy: 98.30729166666667, Time: 0.2597808837890625 ms\n",
            "Epoch 17:[10/16], Current Loss: 0.927631676197052, Current Training Accuracy: 98.29545454545455, Time: 0.25485873222351074 ms\n",
            "Epoch 17:[15/16], Current Loss: 0.9126507043838501, Current Training Accuracy: 98.33984375, Time: 0.2525901794433594 ms\n",
            "Epoch 17, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.904178142547607 ms\n",
            "Epoch 18:[0/16], Current Loss: 0.9354449510574341, Current Training Accuracy: 96.875, Time: 0.27973175048828125 ms\n",
            "Epoch 18:[5/16], Current Loss: 0.9276297688484192, Current Training Accuracy: 97.65625, Time: 0.25335693359375 ms\n",
            "Epoch 18:[10/16], Current Loss: 0.9198177456855774, Current Training Accuracy: 98.29545454545455, Time: 0.26203441619873047 ms\n",
            "Epoch 18:[15/16], Current Loss: 0.9048377275466919, Current Training Accuracy: 98.388671875, Time: 0.25295233726501465 ms\n",
            "Epoch 18, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 7.578983545303345 ms\n",
            "Epoch 19:[0/16], Current Loss: 0.9126501083374023, Current Training Accuracy: 99.21875, Time: 0.27467823028564453 ms\n",
            "Epoch 19:[5/16], Current Loss: 0.9282761812210083, Current Training Accuracy: 97.91666666666667, Time: 0.2541165351867676 ms\n",
            "Epoch 19:[10/16], Current Loss: 0.9120036363601685, Current Training Accuracy: 98.36647727272727, Time: 0.2563657760620117 ms\n",
            "Epoch 19:[15/16], Current Loss: 0.9126492738723755, Current Training Accuracy: 98.33984375, Time: 0.25074219703674316 ms\n",
            "Epoch 19, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.401778221130371 ms\n",
            "Epoch 20:[0/16], Current Loss: 0.926986813545227, Current Training Accuracy: 97.65625, Time: 0.27730727195739746 ms\n",
            "Epoch 20:[5/16], Current Loss: 0.9198171496391296, Current Training Accuracy: 98.17708333333333, Time: 0.2533435821533203 ms\n",
            "Epoch 20:[10/16], Current Loss: 0.9204620122909546, Current Training Accuracy: 98.57954545454545, Time: 0.2550203800201416 ms\n",
            "Epoch 20:[15/16], Current Loss: 0.9276332259178162, Current Training Accuracy: 98.33984375, Time: 0.2512083053588867 ms\n",
            "Epoch 20, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 7.743617534637451 ms\n",
            "Epoch 21:[0/16], Current Loss: 0.9276326894760132, Current Training Accuracy: 97.65625, Time: 0.27091455459594727 ms\n",
            "Epoch 21:[5/16], Current Loss: 0.9048393964767456, Current Training Accuracy: 98.17708333333333, Time: 0.25606489181518555 ms\n",
            "Epoch 21:[10/16], Current Loss: 0.9198184609413147, Current Training Accuracy: 98.08238636363636, Time: 0.25495457649230957 ms\n",
            "Epoch 21:[15/16], Current Loss: 0.9126501679420471, Current Training Accuracy: 98.33984375, Time: 0.25075626373291016 ms\n",
            "Epoch 21, train Loss: 0.921  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 7.270732641220093 ms\n",
            "Epoch 22:[0/16], Current Loss: 0.9204616546630859, Current Training Accuracy: 98.4375, Time: 0.27610158920288086 ms\n",
            "Epoch 22:[5/16], Current Loss: 0.9126503467559814, Current Training Accuracy: 98.4375, Time: 0.2524888515472412 ms\n",
            "Epoch 22:[10/16], Current Loss: 0.9198186993598938, Current Training Accuracy: 98.29545454545455, Time: 0.25432562828063965 ms\n",
            "Epoch 22:[15/16], Current Loss: 0.9198179244995117, Current Training Accuracy: 98.33984375, Time: 0.2524111270904541 ms\n",
            "Epoch 22, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.893552303314209 ms\n",
            "Epoch 23:[0/16], Current Loss: 0.904836118221283, Current Training Accuracy: 100.0, Time: 0.2865908145904541 ms\n",
            "Epoch 23:[5/16], Current Loss: 0.9191678166389465, Current Training Accuracy: 98.828125, Time: 0.2543153762817383 ms\n",
            "Epoch 23:[10/16], Current Loss: 0.9282743334770203, Current Training Accuracy: 98.22443181818181, Time: 0.2559363842010498 ms\n",
            "Epoch 23:[15/16], Current Loss: 0.9198196530342102, Current Training Accuracy: 98.33984375, Time: 0.25162267684936523 ms\n",
            "Epoch 23, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.898664951324463 ms\n",
            "Epoch 24:[0/16], Current Loss: 0.9347975254058838, Current Training Accuracy: 96.875, Time: 0.27237915992736816 ms\n",
            "Epoch 24:[5/16], Current Loss: 0.9276317954063416, Current Training Accuracy: 98.4375, Time: 0.2567102909088135 ms\n",
            "Epoch 24:[10/16], Current Loss: 0.9048374891281128, Current Training Accuracy: 98.65056818181819, Time: 0.25536060333251953 ms\n",
            "Epoch 24:[15/16], Current Loss: 0.9204636812210083, Current Training Accuracy: 98.33984375, Time: 0.2514631748199463 ms\n",
            "Epoch 24, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.896191358566284 ms\n",
            "Epoch 25:[0/16], Current Loss: 0.9191738963127136, Current Training Accuracy: 98.4375, Time: 0.28218960762023926 ms\n",
            "Epoch 25:[5/16], Current Loss: 0.9191746115684509, Current Training Accuracy: 97.91666666666667, Time: 0.25871992111206055 ms\n",
            "Epoch 25:[10/16], Current Loss: 0.920462429523468, Current Training Accuracy: 98.08238636363636, Time: 0.2523784637451172 ms\n",
            "Epoch 25:[15/16], Current Loss: 0.9126499891281128, Current Training Accuracy: 98.388671875, Time: 0.2535362243652344 ms\n",
            "Epoch 25, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.8658692836761475 ms\n",
            "Epoch 26:[0/16], Current Loss: 0.9276295304298401, Current Training Accuracy: 97.65625, Time: 0.2769608497619629 ms\n",
            "Epoch 26:[5/16], Current Loss: 0.9282743334770203, Current Training Accuracy: 98.17708333333333, Time: 0.2539830207824707 ms\n",
            "Epoch 26:[10/16], Current Loss: 0.9204620122909546, Current Training Accuracy: 98.4375, Time: 0.2542304992675781 ms\n",
            "Epoch 26:[15/16], Current Loss: 0.942605197429657, Current Training Accuracy: 98.33984375, Time: 0.2510991096496582 ms\n",
            "Epoch 26, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.849145412445068 ms\n",
            "Epoch 27:[0/16], Current Loss: 0.9198174476623535, Current Training Accuracy: 98.4375, Time: 0.27538275718688965 ms\n",
            "Epoch 27:[5/16], Current Loss: 0.9276323914527893, Current Training Accuracy: 98.30729166666667, Time: 0.26442956924438477 ms\n",
            "Epoch 27:[10/16], Current Loss: 0.9354434013366699, Current Training Accuracy: 98.29545454545455, Time: 0.25366806983947754 ms\n",
            "Epoch 27:[15/16], Current Loss: 0.9198179244995117, Current Training Accuracy: 98.33984375, Time: 0.25498509407043457 ms\n",
            "Epoch 27, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.859622240066528 ms\n",
            "Epoch 28:[0/16], Current Loss: 0.9198222160339355, Current Training Accuracy: 98.4375, Time: 0.27423858642578125 ms\n",
            "Epoch 28:[5/16], Current Loss: 0.9347999095916748, Current Training Accuracy: 98.30729166666667, Time: 0.2550816535949707 ms\n",
            "Epoch 28:[10/16], Current Loss: 0.9204608798027039, Current Training Accuracy: 98.29545454545455, Time: 0.25676584243774414 ms\n",
            "Epoch 28:[15/16], Current Loss: 0.9204627871513367, Current Training Accuracy: 98.33984375, Time: 0.25102663040161133 ms\n",
            "Epoch 28, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.846141576766968 ms\n",
            "Epoch 29:[0/16], Current Loss: 0.9354414343833923, Current Training Accuracy: 96.875, Time: 0.27758169174194336 ms\n",
            "Epoch 29:[5/16], Current Loss: 0.9126481413841248, Current Training Accuracy: 98.56770833333333, Time: 0.2559669017791748 ms\n",
            "Epoch 29:[10/16], Current Loss: 0.9048359990119934, Current Training Accuracy: 98.65056818181819, Time: 0.2534208297729492 ms\n",
            "Epoch 29:[15/16], Current Loss: 0.9354761242866516, Current Training Accuracy: 98.388671875, Time: 0.25205373764038086 ms\n",
            "Epoch 29, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.847669363021851 ms\n",
            "Epoch 30:[0/16], Current Loss: 0.9198147654533386, Current Training Accuracy: 98.4375, Time: 0.27306103706359863 ms\n",
            "Epoch 30:[5/16], Current Loss: 0.9204617738723755, Current Training Accuracy: 98.30729166666667, Time: 0.256331205368042 ms\n",
            "Epoch 30:[10/16], Current Loss: 0.9426164627075195, Current Training Accuracy: 98.1534090909091, Time: 0.2601816654205322 ms\n",
            "Epoch 30:[15/16], Current Loss: 0.9126497507095337, Current Training Accuracy: 98.33984375, Time: 0.2509322166442871 ms\n",
            "Epoch 30, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.875884532928467 ms\n",
            "Epoch 31:[0/16], Current Loss: 0.9048370718955994, Current Training Accuracy: 100.0, Time: 0.2788980007171631 ms\n",
            "Epoch 31:[5/16], Current Loss: 0.912648618221283, Current Training Accuracy: 98.4375, Time: 0.25473713874816895 ms\n",
            "Epoch 31:[10/16], Current Loss: 0.9341957569122314, Current Training Accuracy: 98.29545454545455, Time: 0.256103515625 ms\n",
            "Epoch 31:[15/16], Current Loss: 0.9126496911048889, Current Training Accuracy: 98.33984375, Time: 0.24971294403076172 ms\n",
            "Epoch 31, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.847044229507446 ms\n",
            "Epoch 32:[0/16], Current Loss: 0.9119960069656372, Current Training Accuracy: 99.21875, Time: 0.2771732807159424 ms\n",
            "Epoch 32:[5/16], Current Loss: 0.9126497507095337, Current Training Accuracy: 98.17708333333333, Time: 0.25513243675231934 ms\n",
            "Epoch 32:[10/16], Current Loss: 0.9198179841041565, Current Training Accuracy: 98.22443181818181, Time: 0.2551381587982178 ms\n",
            "Epoch 32:[15/16], Current Loss: 0.9048370122909546, Current Training Accuracy: 98.33984375, Time: 0.25169873237609863 ms\n",
            "Epoch 32, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.861964225769043 ms\n",
            "Epoch 33:[0/16], Current Loss: 0.9204628467559814, Current Training Accuracy: 98.4375, Time: 0.2760307788848877 ms\n",
            "Epoch 33:[5/16], Current Loss: 0.9204615354537964, Current Training Accuracy: 98.30729166666667, Time: 0.25637245178222656 ms\n",
            "Epoch 33:[10/16], Current Loss: 0.9126489162445068, Current Training Accuracy: 98.22443181818181, Time: 0.25492119789123535 ms\n",
            "Epoch 33:[15/16], Current Loss: 0.9126483798027039, Current Training Accuracy: 98.33984375, Time: 0.2507765293121338 ms\n",
            "Epoch 33, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.87339448928833 ms\n",
            "Epoch 34:[0/16], Current Loss: 0.9276303052902222, Current Training Accuracy: 97.65625, Time: 0.2823672294616699 ms\n",
            "Epoch 34:[5/16], Current Loss: 0.9204619526863098, Current Training Accuracy: 97.52604166666667, Time: 0.25505638122558594 ms\n",
            "Epoch 34:[10/16], Current Loss: 0.9204611778259277, Current Training Accuracy: 98.08238636363636, Time: 0.25166893005371094 ms\n",
            "Epoch 34:[15/16], Current Loss: 0.9126486778259277, Current Training Accuracy: 98.33984375, Time: 0.25529980659484863 ms\n",
            "Epoch 34, train Loss: 0.921  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 6.872720956802368 ms\n",
            "Epoch 35:[0/16], Current Loss: 0.9048363566398621, Current Training Accuracy: 100.0, Time: 0.2790255546569824 ms\n",
            "Epoch 35:[5/16], Current Loss: 0.9198234677314758, Current Training Accuracy: 98.56770833333333, Time: 0.2539973258972168 ms\n",
            "Epoch 35:[10/16], Current Loss: 0.9120063781738281, Current Training Accuracy: 98.29545454545455, Time: 0.2571284770965576 ms\n",
            "Epoch 35:[15/16], Current Loss: 0.9198173880577087, Current Training Accuracy: 98.33984375, Time: 0.2543342113494873 ms\n",
            "Epoch 35, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.893373489379883 ms\n",
            "Epoch 36:[0/16], Current Loss: 0.9276299476623535, Current Training Accuracy: 97.65625, Time: 0.27566051483154297 ms\n",
            "Epoch 36:[5/16], Current Loss: 0.9360849261283875, Current Training Accuracy: 98.17708333333333, Time: 0.2530956268310547 ms\n",
            "Epoch 36:[10/16], Current Loss: 0.9126484990119934, Current Training Accuracy: 98.29545454545455, Time: 0.2536153793334961 ms\n",
            "Epoch 36:[15/16], Current Loss: 0.9198169112205505, Current Training Accuracy: 98.33984375, Time: 0.2505056858062744 ms\n",
            "Epoch 36, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.869305372238159 ms\n",
            "Epoch 37:[0/16], Current Loss: 0.9354425072669983, Current Training Accuracy: 96.875, Time: 0.27643465995788574 ms\n",
            "Epoch 37:[5/16], Current Loss: 0.926971435546875, Current Training Accuracy: 98.30729166666667, Time: 0.2620086669921875 ms\n",
            "Epoch 37:[10/16], Current Loss: 0.928273618221283, Current Training Accuracy: 98.01136363636364, Time: 0.25537610054016113 ms\n",
            "Epoch 37:[15/16], Current Loss: 0.9126483798027039, Current Training Accuracy: 98.33984375, Time: 0.25136375427246094 ms\n",
            "Epoch 37, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.909759044647217 ms\n",
            "Epoch 38:[0/16], Current Loss: 0.9354429841041565, Current Training Accuracy: 96.875, Time: 0.2763032913208008 ms\n",
            "Epoch 38:[5/16], Current Loss: 0.9198176860809326, Current Training Accuracy: 98.69791666666667, Time: 0.2527585029602051 ms\n",
            "Epoch 38:[10/16], Current Loss: 0.9204616546630859, Current Training Accuracy: 98.7215909090909, Time: 0.25234556198120117 ms\n",
            "Epoch 38:[15/16], Current Loss: 0.9342249631881714, Current Training Accuracy: 98.33984375, Time: 0.24990200996398926 ms\n",
            "Epoch 38, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.898043870925903 ms\n",
            "Epoch 39:[0/16], Current Loss: 0.9126498699188232, Current Training Accuracy: 99.21875, Time: 0.2821621894836426 ms\n",
            "Epoch 39:[5/16], Current Loss: 0.9282742142677307, Current Training Accuracy: 98.95833333333333, Time: 0.25536417961120605 ms\n",
            "Epoch 39:[10/16], Current Loss: 0.9276314377784729, Current Training Accuracy: 98.4375, Time: 0.25585174560546875 ms\n",
            "Epoch 39:[15/16], Current Loss: 0.9341588616371155, Current Training Accuracy: 98.33984375, Time: 0.24944496154785156 ms\n",
            "Epoch 39, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.867862701416016 ms\n",
            "Epoch 40:[0/16], Current Loss: 0.9504258036613464, Current Training Accuracy: 95.3125, Time: 0.27674365043640137 ms\n",
            "Epoch 40:[5/16], Current Loss: 0.9282735586166382, Current Training Accuracy: 97.91666666666667, Time: 0.2550985813140869 ms\n",
            "Epoch 40:[10/16], Current Loss: 0.9126486778259277, Current Training Accuracy: 98.4375, Time: 0.2552025318145752 ms\n",
            "Epoch 40:[15/16], Current Loss: 0.9426121115684509, Current Training Accuracy: 98.388671875, Time: 0.24924850463867188 ms\n",
            "Epoch 40, train Loss: 0.921  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 6.871356248855591 ms\n",
            "Epoch 41:[0/16], Current Loss: 0.9276303052902222, Current Training Accuracy: 97.65625, Time: 0.2759542465209961 ms\n",
            "Epoch 41:[5/16], Current Loss: 0.9120063185691833, Current Training Accuracy: 97.91666666666667, Time: 0.2547292709350586 ms\n",
            "Epoch 41:[10/16], Current Loss: 0.9048365950584412, Current Training Accuracy: 98.36647727272727, Time: 0.25194406509399414 ms\n",
            "Epoch 41:[15/16], Current Loss: 0.9276081919670105, Current Training Accuracy: 98.33984375, Time: 0.2502710819244385 ms\n",
            "Epoch 41, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.883225202560425 ms\n",
            "Epoch 42:[0/16], Current Loss: 0.9048359990119934, Current Training Accuracy: 100.0, Time: 0.27433037757873535 ms\n",
            "Epoch 42:[5/16], Current Loss: 0.9048355221748352, Current Training Accuracy: 98.828125, Time: 0.2561202049255371 ms\n",
            "Epoch 42:[10/16], Current Loss: 0.9282732009887695, Current Training Accuracy: 98.50852272727273, Time: 0.25327277183532715 ms\n",
            "Epoch 42:[15/16], Current Loss: 0.9204605221748352, Current Training Accuracy: 98.33984375, Time: 0.25328946113586426 ms\n",
            "Epoch 42, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.897549867630005 ms\n",
            "Epoch 43:[0/16], Current Loss: 0.93544602394104, Current Training Accuracy: 96.875, Time: 0.26198840141296387 ms\n",
            "Epoch 43:[5/16], Current Loss: 0.9191736578941345, Current Training Accuracy: 98.046875, Time: 0.25997185707092285 ms\n",
            "Epoch 43:[10/16], Current Loss: 0.9048363566398621, Current Training Accuracy: 98.29545454545455, Time: 0.2555365562438965 ms\n",
            "Epoch 43:[15/16], Current Loss: 0.9347978234291077, Current Training Accuracy: 98.388671875, Time: 0.2558121681213379 ms\n",
            "Epoch 43, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.853865623474121 ms\n",
            "Epoch 44:[0/16], Current Loss: 0.9048353433609009, Current Training Accuracy: 100.0, Time: 0.2848348617553711 ms\n",
            "Epoch 44:[5/16], Current Loss: 0.9126485586166382, Current Training Accuracy: 99.21875, Time: 0.25455617904663086 ms\n",
            "Epoch 44:[10/16], Current Loss: 0.9126478433609009, Current Training Accuracy: 98.7215909090909, Time: 0.25183939933776855 ms\n",
            "Epoch 44:[15/16], Current Loss: 0.912648618221283, Current Training Accuracy: 98.33984375, Time: 0.25118494033813477 ms\n",
            "Epoch 44, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.866711139678955 ms\n",
            "Epoch 45:[0/16], Current Loss: 0.9282732605934143, Current Training Accuracy: 97.65625, Time: 0.2765803337097168 ms\n",
            "Epoch 45:[5/16], Current Loss: 0.9119669795036316, Current Training Accuracy: 98.30729166666667, Time: 0.25368809700012207 ms\n",
            "Epoch 45:[10/16], Current Loss: 0.9276328682899475, Current Training Accuracy: 98.4375, Time: 0.25484609603881836 ms\n",
            "Epoch 45:[15/16], Current Loss: 0.9360860586166382, Current Training Accuracy: 98.33984375, Time: 0.24966740608215332 ms\n",
            "Epoch 45, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.8765034675598145 ms\n",
            "Epoch 46:[0/16], Current Loss: 0.9126498699188232, Current Training Accuracy: 99.21875, Time: 0.27551817893981934 ms\n",
            "Epoch 46:[5/16], Current Loss: 0.9276349544525146, Current Training Accuracy: 98.4375, Time: 0.2618238925933838 ms\n",
            "Epoch 46:[10/16], Current Loss: 0.9204620122909546, Current Training Accuracy: 98.1534090909091, Time: 0.2559196949005127 ms\n",
            "Epoch 46:[15/16], Current Loss: 0.9349302053451538, Current Training Accuracy: 98.33984375, Time: 0.2504904270172119 ms\n",
            "Epoch 46, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.866384983062744 ms\n",
            "Epoch 47:[0/16], Current Loss: 0.9277390837669373, Current Training Accuracy: 97.65625, Time: 0.27905821800231934 ms\n",
            "Epoch 47:[5/16], Current Loss: 0.9198200702667236, Current Training Accuracy: 98.30729166666667, Time: 0.2545931339263916 ms\n",
            "Epoch 47:[10/16], Current Loss: 0.9282668828964233, Current Training Accuracy: 98.50852272727273, Time: 0.2533586025238037 ms\n",
            "Epoch 47:[15/16], Current Loss: 0.9126478433609009, Current Training Accuracy: 98.33984375, Time: 0.2541193962097168 ms\n",
            "Epoch 47, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.904221773147583 ms\n",
            "Epoch 48:[0/16], Current Loss: 0.9126486778259277, Current Training Accuracy: 99.21875, Time: 0.27646470069885254 ms\n",
            "Epoch 48:[5/16], Current Loss: 0.9204614162445068, Current Training Accuracy: 97.91666666666667, Time: 0.25372791290283203 ms\n",
            "Epoch 48:[10/16], Current Loss: 0.9048383831977844, Current Training Accuracy: 98.22443181818181, Time: 0.2545013427734375 ms\n",
            "Epoch 48:[15/16], Current Loss: 0.9126492738723755, Current Training Accuracy: 98.33984375, Time: 0.2508258819580078 ms\n",
            "Epoch 48, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.881157398223877 ms\n",
            "Epoch 49:[0/16], Current Loss: 0.9204617142677307, Current Training Accuracy: 98.4375, Time: 0.2832367420196533 ms\n",
            "Epoch 49:[5/16], Current Loss: 0.9120058417320251, Current Training Accuracy: 98.69791666666667, Time: 0.25688862800598145 ms\n",
            "Epoch 49:[10/16], Current Loss: 0.9204640984535217, Current Training Accuracy: 98.36647727272727, Time: 0.2539653778076172 ms\n",
            "Epoch 49:[15/16], Current Loss: 0.9204679131507874, Current Training Accuracy: 98.33984375, Time: 0.257343053817749 ms\n",
            "Epoch 49, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.885071516036987 ms\n",
            "Epoch 50:[0/16], Current Loss: 0.9276351928710938, Current Training Accuracy: 97.65625, Time: 0.28023600578308105 ms\n",
            "Epoch 50:[5/16], Current Loss: 0.9510722756385803, Current Training Accuracy: 97.265625, Time: 0.2579219341278076 ms\n",
            "Epoch 50:[10/16], Current Loss: 0.9126616716384888, Current Training Accuracy: 98.1534090909091, Time: 0.27245187759399414 ms\n",
            "Epoch 50:[15/16], Current Loss: 0.9278287291526794, Current Training Accuracy: 98.388671875, Time: 0.2512476444244385 ms\n",
            "Epoch 50, train Loss: 0.921  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 64 % Epoch Time: 6.889866828918457 ms\n",
            "Epoch 51:[0/16], Current Loss: 0.9127899408340454, Current Training Accuracy: 99.21875, Time: 0.277738094329834 ms\n",
            "Epoch 51:[5/16], Current Loss: 0.9428719878196716, Current Training Accuracy: 98.17708333333333, Time: 0.2565157413482666 ms\n",
            "Epoch 51:[10/16], Current Loss: 0.9282887578010559, Current Training Accuracy: 98.36647727272727, Time: 0.25589847564697266 ms\n",
            "Epoch 51:[15/16], Current Loss: 0.9282795786857605, Current Training Accuracy: 98.388671875, Time: 0.25482988357543945 ms\n",
            "Epoch 51, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 64 % Epoch Time: 6.8588547706604 ms\n",
            "Epoch 52:[0/16], Current Loss: 0.9204692244529724, Current Training Accuracy: 98.4375, Time: 0.27079272270202637 ms\n",
            "Epoch 52:[5/16], Current Loss: 0.920464813709259, Current Training Accuracy: 98.69791666666667, Time: 0.2537682056427002 ms\n",
            "Epoch 52:[10/16], Current Loss: 0.9282832145690918, Current Training Accuracy: 98.4375, Time: 0.2539198398590088 ms\n",
            "Epoch 52:[15/16], Current Loss: 0.9277061820030212, Current Training Accuracy: 98.4375, Time: 0.2528846263885498 ms\n",
            "Epoch 52, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.88270378112793 ms\n",
            "Epoch 53:[0/16], Current Loss: 0.9126520752906799, Current Training Accuracy: 99.21875, Time: 0.2776913642883301 ms\n",
            "Epoch 53:[5/16], Current Loss: 0.9120038747787476, Current Training Accuracy: 98.828125, Time: 0.25463175773620605 ms\n",
            "Epoch 53:[10/16], Current Loss: 0.912042498588562, Current Training Accuracy: 98.36647727272727, Time: 0.2554483413696289 ms\n",
            "Epoch 53:[15/16], Current Loss: 0.9282793998718262, Current Training Accuracy: 98.388671875, Time: 0.2504880428314209 ms\n",
            "Epoch 53, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.863858222961426 ms\n",
            "Epoch 54:[0/16], Current Loss: 0.9276384115219116, Current Training Accuracy: 97.65625, Time: 0.2947578430175781 ms\n",
            "Epoch 54:[5/16], Current Loss: 0.9126518368721008, Current Training Accuracy: 98.30729166666667, Time: 0.2570624351501465 ms\n",
            "Epoch 54:[10/16], Current Loss: 0.9122331142425537, Current Training Accuracy: 98.4375, Time: 0.2539503574371338 ms\n",
            "Epoch 54:[15/16], Current Loss: 0.9204687476158142, Current Training Accuracy: 98.388671875, Time: 0.25477099418640137 ms\n",
            "Epoch 54, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.905553817749023 ms\n",
            "Epoch 55:[0/16], Current Loss: 0.928276777267456, Current Training Accuracy: 97.65625, Time: 0.2721214294433594 ms\n",
            "Epoch 55:[5/16], Current Loss: 0.9126580953598022, Current Training Accuracy: 98.17708333333333, Time: 0.25663232803344727 ms\n",
            "Epoch 55:[10/16], Current Loss: 0.9204654097557068, Current Training Accuracy: 98.4375, Time: 0.2566852569580078 ms\n",
            "Epoch 55:[15/16], Current Loss: 0.9199557900428772, Current Training Accuracy: 98.388671875, Time: 0.2527141571044922 ms\n",
            "Epoch 55, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.869229078292847 ms\n",
            "Epoch 56:[0/16], Current Loss: 0.9198226928710938, Current Training Accuracy: 98.4375, Time: 0.27613282203674316 ms\n",
            "Epoch 56:[5/16], Current Loss: 0.9282783269882202, Current Training Accuracy: 98.30729166666667, Time: 0.255373477935791 ms\n",
            "Epoch 56:[10/16], Current Loss: 0.9204692244529724, Current Training Accuracy: 98.50852272727273, Time: 0.262819766998291 ms\n",
            "Epoch 56:[15/16], Current Loss: 0.9201181530952454, Current Training Accuracy: 98.388671875, Time: 0.2507007122039795 ms\n",
            "Epoch 56, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.8706090450286865 ms\n",
            "Epoch 57:[0/16], Current Loss: 0.9354678392410278, Current Training Accuracy: 96.875, Time: 0.27868032455444336 ms\n",
            "Epoch 57:[5/16], Current Loss: 0.9126531481742859, Current Training Accuracy: 98.30729166666667, Time: 0.2559328079223633 ms\n",
            "Epoch 57:[10/16], Current Loss: 0.9126523733139038, Current Training Accuracy: 98.08238636363636, Time: 0.25536227226257324 ms\n",
            "Epoch 57:[15/16], Current Loss: 0.928279459476471, Current Training Accuracy: 98.388671875, Time: 0.25517988204956055 ms\n",
            "Epoch 57, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.862744569778442 ms\n",
            "Epoch 58:[0/16], Current Loss: 0.9120168089866638, Current Training Accuracy: 99.21875, Time: 0.2766377925872803 ms\n",
            "Epoch 58:[5/16], Current Loss: 0.9282811880111694, Current Training Accuracy: 98.95833333333333, Time: 0.2596564292907715 ms\n",
            "Epoch 58:[10/16], Current Loss: 0.9276558756828308, Current Training Accuracy: 98.57954545454545, Time: 0.2652139663696289 ms\n",
            "Epoch 58:[15/16], Current Loss: 0.9360880851745605, Current Training Accuracy: 98.388671875, Time: 0.25324487686157227 ms\n",
            "Epoch 58, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.9139509201049805 ms\n",
            "Epoch 59:[0/16], Current Loss: 0.9197560548782349, Current Training Accuracy: 98.4375, Time: 0.27610349655151367 ms\n",
            "Epoch 59:[5/16], Current Loss: 0.9048416018486023, Current Training Accuracy: 98.69791666666667, Time: 0.25687217712402344 ms\n",
            "Epoch 59:[10/16], Current Loss: 0.9126546382904053, Current Training Accuracy: 98.57954545454545, Time: 0.2629401683807373 ms\n",
            "Epoch 59:[15/16], Current Loss: 0.9353827834129333, Current Training Accuracy: 98.388671875, Time: 0.2505190372467041 ms\n",
            "Epoch 59, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.882951259613037 ms\n",
            "Epoch 60:[0/16], Current Loss: 0.9126520752906799, Current Training Accuracy: 99.21875, Time: 0.27791690826416016 ms\n",
            "Epoch 60:[5/16], Current Loss: 0.9275711178779602, Current Training Accuracy: 98.17708333333333, Time: 0.25595617294311523 ms\n",
            "Epoch 60:[10/16], Current Loss: 0.9048401117324829, Current Training Accuracy: 98.1534090909091, Time: 0.26559996604919434 ms\n",
            "Epoch 60:[15/16], Current Loss: 0.9126520752906799, Current Training Accuracy: 98.388671875, Time: 0.25124359130859375 ms\n",
            "Epoch 60, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.839123964309692 ms\n",
            "Epoch 61:[0/16], Current Loss: 0.912652313709259, Current Training Accuracy: 99.21875, Time: 0.27974677085876465 ms\n",
            "Epoch 61:[5/16], Current Loss: 0.9262703061103821, Current Training Accuracy: 98.95833333333333, Time: 0.25562191009521484 ms\n",
            "Epoch 61:[10/16], Current Loss: 0.9354501962661743, Current Training Accuracy: 98.86363636363636, Time: 0.2532944679260254 ms\n",
            "Epoch 61:[15/16], Current Loss: 0.9360853433609009, Current Training Accuracy: 98.4375, Time: 0.25266551971435547 ms\n",
            "Epoch 61, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.8808770179748535 ms\n",
            "Epoch 62:[0/16], Current Loss: 0.9204642176628113, Current Training Accuracy: 98.4375, Time: 0.275226354598999 ms\n",
            "Epoch 62:[5/16], Current Loss: 0.9282766580581665, Current Training Accuracy: 98.30729166666667, Time: 0.255521297454834 ms\n",
            "Epoch 62:[10/16], Current Loss: 0.934790313243866, Current Training Accuracy: 98.29545454545455, Time: 0.2540721893310547 ms\n",
            "Epoch 62:[15/16], Current Loss: 0.9197517037391663, Current Training Accuracy: 98.388671875, Time: 0.25392985343933105 ms\n",
            "Epoch 62, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.8707945346832275 ms\n",
            "Epoch 63:[0/16], Current Loss: 0.9269728660583496, Current Training Accuracy: 97.65625, Time: 0.27883362770080566 ms\n",
            "Epoch 63:[5/16], Current Loss: 0.9425604939460754, Current Training Accuracy: 98.046875, Time: 0.2605135440826416 ms\n",
            "Epoch 63:[10/16], Current Loss: 0.9276271462440491, Current Training Accuracy: 98.1534090909091, Time: 0.2566530704498291 ms\n",
            "Epoch 63:[15/16], Current Loss: 0.9119451642036438, Current Training Accuracy: 98.388671875, Time: 0.25228190422058105 ms\n",
            "Epoch 63, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.8681910037994385 ms\n",
            "Epoch 64:[0/16], Current Loss: 0.9204637408256531, Current Training Accuracy: 98.4375, Time: 0.27854466438293457 ms\n",
            "Epoch 64:[5/16], Current Loss: 0.9126537442207336, Current Training Accuracy: 98.30729166666667, Time: 0.2568049430847168 ms\n",
            "Epoch 64:[10/16], Current Loss: 0.92763352394104, Current Training Accuracy: 98.22443181818181, Time: 0.2550678253173828 ms\n",
            "Epoch 64:[15/16], Current Loss: 0.9204641580581665, Current Training Accuracy: 98.388671875, Time: 0.2537868022918701 ms\n",
            "Epoch 64, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.8626062870025635 ms\n",
            "Epoch 65:[0/16], Current Loss: 0.9282522201538086, Current Training Accuracy: 97.65625, Time: 0.28103137016296387 ms\n",
            "Epoch 65:[5/16], Current Loss: 0.9354531764984131, Current Training Accuracy: 98.17708333333333, Time: 0.2534446716308594 ms\n",
            "Epoch 65:[10/16], Current Loss: 0.949720561504364, Current Training Accuracy: 98.1534090909091, Time: 0.25556087493896484 ms\n",
            "Epoch 65:[15/16], Current Loss: 0.9048380255699158, Current Training Accuracy: 98.388671875, Time: 0.2496659755706787 ms\n",
            "Epoch 65, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.883807420730591 ms\n",
            "Epoch 66:[0/16], Current Loss: 0.9048376679420471, Current Training Accuracy: 100.0, Time: 0.2787010669708252 ms\n",
            "Epoch 66:[5/16], Current Loss: 0.9353824853897095, Current Training Accuracy: 98.17708333333333, Time: 0.264538049697876 ms\n",
            "Epoch 66:[10/16], Current Loss: 0.9204643964767456, Current Training Accuracy: 98.01136363636364, Time: 0.25307416915893555 ms\n",
            "Epoch 66:[15/16], Current Loss: 0.9126538038253784, Current Training Accuracy: 98.388671875, Time: 0.25130605697631836 ms\n",
            "Epoch 66, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.8884968757629395 ms\n",
            "Epoch 67:[0/16], Current Loss: 0.9348196387290955, Current Training Accuracy: 96.875, Time: 0.2754075527191162 ms\n",
            "Epoch 67:[5/16], Current Loss: 0.9048426151275635, Current Training Accuracy: 98.4375, Time: 0.262392520904541 ms\n",
            "Epoch 67:[10/16], Current Loss: 0.9282764196395874, Current Training Accuracy: 98.50852272727273, Time: 0.2580287456512451 ms\n",
            "Epoch 67:[15/16], Current Loss: 0.9197578430175781, Current Training Accuracy: 98.388671875, Time: 0.2512166500091553 ms\n",
            "Epoch 67, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.864621639251709 ms\n",
            "Epoch 68:[0/16], Current Loss: 0.9204660654067993, Current Training Accuracy: 98.4375, Time: 0.27611804008483887 ms\n",
            "Epoch 68:[5/16], Current Loss: 0.9048405885696411, Current Training Accuracy: 98.828125, Time: 0.25341129302978516 ms\n",
            "Epoch 68:[10/16], Current Loss: 0.9354459643363953, Current Training Accuracy: 98.50852272727273, Time: 0.25722789764404297 ms\n",
            "Epoch 68:[15/16], Current Loss: 0.9120155572891235, Current Training Accuracy: 98.388671875, Time: 0.25124025344848633 ms\n",
            "Epoch 68, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.8791961669921875 ms\n",
            "Epoch 69:[0/16], Current Loss: 0.9120194911956787, Current Training Accuracy: 99.21875, Time: 0.2798185348510742 ms\n",
            "Epoch 69:[5/16], Current Loss: 0.9275850653648376, Current Training Accuracy: 98.69791666666667, Time: 0.2529418468475342 ms\n",
            "Epoch 69:[10/16], Current Loss: 0.9204665422439575, Current Training Accuracy: 98.86363636363636, Time: 0.25785374641418457 ms\n",
            "Epoch 69:[15/16], Current Loss: 0.9048425555229187, Current Training Accuracy: 98.388671875, Time: 0.25212883949279785 ms\n",
            "Epoch 69, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.864906549453735 ms\n",
            "Epoch 70:[0/16], Current Loss: 0.9126572012901306, Current Training Accuracy: 99.21875, Time: 0.2719850540161133 ms\n",
            "Epoch 70:[5/16], Current Loss: 0.9126490950584412, Current Training Accuracy: 98.828125, Time: 0.25506591796875 ms\n",
            "Epoch 70:[10/16], Current Loss: 0.9282775521278381, Current Training Accuracy: 98.4375, Time: 0.2542266845703125 ms\n",
            "Epoch 70:[15/16], Current Loss: 0.9204648733139038, Current Training Accuracy: 98.388671875, Time: 0.25168919563293457 ms\n",
            "Epoch 70, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.9089250564575195 ms\n",
            "Epoch 71:[0/16], Current Loss: 0.9439026117324829, Current Training Accuracy: 96.09375, Time: 0.266615629196167 ms\n",
            "Epoch 71:[5/16], Current Loss: 0.9204660058021545, Current Training Accuracy: 97.65625, Time: 0.25829076766967773 ms\n",
            "Epoch 71:[10/16], Current Loss: 0.9048402905464172, Current Training Accuracy: 98.08238636363636, Time: 0.25754261016845703 ms\n",
            "Epoch 71:[15/16], Current Loss: 0.9204696416854858, Current Training Accuracy: 98.388671875, Time: 0.24998116493225098 ms\n",
            "Epoch 71, train Loss: 0.921  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 6.871068239212036 ms\n",
            "Epoch 72:[0/16], Current Loss: 0.9204683303833008, Current Training Accuracy: 98.4375, Time: 0.27633023262023926 ms\n",
            "Epoch 72:[5/16], Current Loss: 0.9195674061775208, Current Training Accuracy: 98.828125, Time: 0.2567427158355713 ms\n",
            "Epoch 72:[10/16], Current Loss: 0.9275909662246704, Current Training Accuracy: 98.4375, Time: 0.25492334365844727 ms\n",
            "Epoch 72:[15/16], Current Loss: 0.9355568289756775, Current Training Accuracy: 98.388671875, Time: 0.2501544952392578 ms\n",
            "Epoch 72, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.848875999450684 ms\n",
            "Epoch 73:[0/16], Current Loss: 0.9048411250114441, Current Training Accuracy: 100.0, Time: 0.27373695373535156 ms\n",
            "Epoch 73:[5/16], Current Loss: 0.9204647541046143, Current Training Accuracy: 98.95833333333333, Time: 0.2542088031768799 ms\n",
            "Epoch 73:[10/16], Current Loss: 0.9353857040405273, Current Training Accuracy: 98.57954545454545, Time: 0.25632715225219727 ms\n",
            "Epoch 73:[15/16], Current Loss: 0.9120191335678101, Current Training Accuracy: 98.388671875, Time: 0.25140833854675293 ms\n",
            "Epoch 73, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.868817090988159 ms\n",
            "Epoch 74:[0/16], Current Loss: 0.9048416614532471, Current Training Accuracy: 100.0, Time: 0.27857065200805664 ms\n",
            "Epoch 74:[5/16], Current Loss: 0.9126502275466919, Current Training Accuracy: 98.17708333333333, Time: 0.25379371643066406 ms\n",
            "Epoch 74:[10/16], Current Loss: 0.9197584390640259, Current Training Accuracy: 98.4375, Time: 0.2573733329772949 ms\n",
            "Epoch 74:[15/16], Current Loss: 0.9198241829872131, Current Training Accuracy: 98.388671875, Time: 0.25342798233032227 ms\n",
            "Epoch 74, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.923558235168457 ms\n",
            "Epoch 75:[0/16], Current Loss: 0.904839277267456, Current Training Accuracy: 100.0, Time: 0.2743380069732666 ms\n",
            "Epoch 75:[5/16], Current Loss: 0.9204667806625366, Current Training Accuracy: 98.69791666666667, Time: 0.26476597785949707 ms\n",
            "Epoch 75:[10/16], Current Loss: 0.9126547574996948, Current Training Accuracy: 98.50852272727273, Time: 0.2548635005950928 ms\n",
            "Epoch 75:[15/16], Current Loss: 0.9503068327903748, Current Training Accuracy: 98.388671875, Time: 0.2494966983795166 ms\n",
            "Epoch 75, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.940108060836792 ms\n",
            "Epoch 76:[0/16], Current Loss: 0.9197916388511658, Current Training Accuracy: 98.4375, Time: 0.280841588973999 ms\n",
            "Epoch 76:[5/16], Current Loss: 0.9120088815689087, Current Training Accuracy: 97.78645833333333, Time: 0.2535974979400635 ms\n",
            "Epoch 76:[10/16], Current Loss: 0.9048394560813904, Current Training Accuracy: 98.1534090909091, Time: 0.25485730171203613 ms\n",
            "Epoch 76:[15/16], Current Loss: 0.9126503467559814, Current Training Accuracy: 98.388671875, Time: 0.25191640853881836 ms\n",
            "Epoch 76, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.928078889846802 ms\n",
            "Epoch 77:[0/16], Current Loss: 0.912651002407074, Current Training Accuracy: 99.21875, Time: 0.27501535415649414 ms\n",
            "Epoch 77:[5/16], Current Loss: 0.9204638004302979, Current Training Accuracy: 98.30729166666667, Time: 0.26415157318115234 ms\n",
            "Epoch 77:[10/16], Current Loss: 0.927639365196228, Current Training Accuracy: 98.4375, Time: 0.25363636016845703 ms\n",
            "Epoch 77:[15/16], Current Loss: 0.9126518368721008, Current Training Accuracy: 98.388671875, Time: 0.2521853446960449 ms\n",
            "Epoch 77, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.8885908126831055 ms\n",
            "Epoch 78:[0/16], Current Loss: 0.9126512408256531, Current Training Accuracy: 99.21875, Time: 0.278353214263916 ms\n",
            "Epoch 78:[5/16], Current Loss: 0.9354059100151062, Current Training Accuracy: 98.17708333333333, Time: 0.25469207763671875 ms\n",
            "Epoch 78:[10/16], Current Loss: 0.9126502871513367, Current Training Accuracy: 98.57954545454545, Time: 0.25545835494995117 ms\n",
            "Epoch 78:[15/16], Current Loss: 0.9126508831977844, Current Training Accuracy: 98.388671875, Time: 0.2522003650665283 ms\n",
            "Epoch 78, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.884418487548828 ms\n",
            "Epoch 79:[0/16], Current Loss: 0.9120085835456848, Current Training Accuracy: 99.21875, Time: 0.2783470153808594 ms\n",
            "Epoch 79:[5/16], Current Loss: 0.9204626083374023, Current Training Accuracy: 97.52604166666667, Time: 0.25435543060302734 ms\n",
            "Epoch 79:[10/16], Current Loss: 0.9282754063606262, Current Training Accuracy: 98.01136363636364, Time: 0.25574398040771484 ms\n",
            "Epoch 79:[15/16], Current Loss: 0.9126504063606262, Current Training Accuracy: 98.388671875, Time: 0.24886202812194824 ms\n",
            "Epoch 79, train Loss: 0.921  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 68 % Epoch Time: 6.926069259643555 ms\n",
            "Epoch 80:[0/16], Current Loss: 0.9126500487327576, Current Training Accuracy: 99.21875, Time: 0.28336215019226074 ms\n",
            "Epoch 80:[5/16], Current Loss: 0.9204641580581665, Current Training Accuracy: 98.4375, Time: 0.25383877754211426 ms\n",
            "Epoch 80:[10/16], Current Loss: 0.9048377871513367, Current Training Accuracy: 98.4375, Time: 0.2549777030944824 ms\n",
            "Epoch 80:[15/16], Current Loss: 0.9282761216163635, Current Training Accuracy: 98.388671875, Time: 0.25186634063720703 ms\n",
            "Epoch 80, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.8861329555511475 ms\n",
            "Epoch 81:[0/16], Current Loss: 0.9198236465454102, Current Training Accuracy: 98.4375, Time: 0.2816007137298584 ms\n",
            "Epoch 81:[5/16], Current Loss: 0.9282745718955994, Current Training Accuracy: 98.046875, Time: 0.254558801651001 ms\n",
            "Epoch 81:[10/16], Current Loss: 0.9204623103141785, Current Training Accuracy: 98.1534090909091, Time: 0.2554304599761963 ms\n",
            "Epoch 81:[15/16], Current Loss: 0.9197546243667603, Current Training Accuracy: 98.388671875, Time: 0.25041794776916504 ms\n",
            "Epoch 81, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.892829418182373 ms\n",
            "Epoch 82:[0/16], Current Loss: 0.9197543859481812, Current Training Accuracy: 98.4375, Time: 0.2744929790496826 ms\n",
            "Epoch 82:[5/16], Current Loss: 0.9348145723342896, Current Training Accuracy: 97.91666666666667, Time: 0.25688910484313965 ms\n",
            "Epoch 82:[10/16], Current Loss: 0.919762909412384, Current Training Accuracy: 98.22443181818181, Time: 0.2522270679473877 ms\n",
            "Epoch 82:[15/16], Current Loss: 0.9126496911048889, Current Training Accuracy: 98.388671875, Time: 0.2513437271118164 ms\n",
            "Epoch 82, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.898219347000122 ms\n",
            "Epoch 83:[0/16], Current Loss: 0.9048377275466919, Current Training Accuracy: 100.0, Time: 0.2715749740600586 ms\n",
            "Epoch 83:[5/16], Current Loss: 0.928274929523468, Current Training Accuracy: 98.30729166666667, Time: 0.2561337947845459 ms\n",
            "Epoch 83:[10/16], Current Loss: 0.9126495718955994, Current Training Accuracy: 98.1534090909091, Time: 0.2572653293609619 ms\n",
            "Epoch 83:[15/16], Current Loss: 0.9126503467559814, Current Training Accuracy: 98.388671875, Time: 0.2518916130065918 ms\n",
            "Epoch 83, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.895221471786499 ms\n",
            "Epoch 84:[0/16], Current Loss: 0.9438997507095337, Current Training Accuracy: 96.09375, Time: 0.2862675189971924 ms\n",
            "Epoch 84:[5/16], Current Loss: 0.9048373699188232, Current Training Accuracy: 98.30729166666667, Time: 0.2532041072845459 ms\n",
            "Epoch 84:[10/16], Current Loss: 0.904836893081665, Current Training Accuracy: 98.29545454545455, Time: 0.25779199600219727 ms\n",
            "Epoch 84:[15/16], Current Loss: 0.9126489162445068, Current Training Accuracy: 98.388671875, Time: 0.25095701217651367 ms\n",
            "Epoch 84, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.930174827575684 ms\n",
            "Epoch 85:[0/16], Current Loss: 0.9282732009887695, Current Training Accuracy: 97.65625, Time: 0.2747609615325928 ms\n",
            "Epoch 85:[5/16], Current Loss: 0.9360869526863098, Current Training Accuracy: 97.91666666666667, Time: 0.2566540241241455 ms\n",
            "Epoch 85:[10/16], Current Loss: 0.9126500487327576, Current Training Accuracy: 98.36647727272727, Time: 0.25209999084472656 ms\n",
            "Epoch 85:[15/16], Current Loss: 0.9282740950584412, Current Training Accuracy: 98.388671875, Time: 0.25340700149536133 ms\n",
            "Epoch 85, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.881400108337402 ms\n",
            "Epoch 86:[0/16], Current Loss: 0.9048367142677307, Current Training Accuracy: 100.0, Time: 0.26433706283569336 ms\n",
            "Epoch 86:[5/16], Current Loss: 0.943190336227417, Current Training Accuracy: 98.046875, Time: 0.2545461654663086 ms\n",
            "Epoch 86:[10/16], Current Loss: 0.911942720413208, Current Training Accuracy: 98.08238636363636, Time: 0.25786495208740234 ms\n",
            "Epoch 86:[15/16], Current Loss: 0.9126492738723755, Current Training Accuracy: 98.388671875, Time: 0.249985933303833 ms\n",
            "Epoch 86, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.905591726303101 ms\n",
            "Epoch 87:[0/16], Current Loss: 0.9204604029655457, Current Training Accuracy: 98.4375, Time: 0.28237080574035645 ms\n",
            "Epoch 87:[5/16], Current Loss: 0.9276314377784729, Current Training Accuracy: 98.69791666666667, Time: 0.25754714012145996 ms\n",
            "Epoch 87:[10/16], Current Loss: 0.9126490354537964, Current Training Accuracy: 98.65056818181819, Time: 0.2525012493133545 ms\n",
            "Epoch 87:[15/16], Current Loss: 0.9204608798027039, Current Training Accuracy: 98.4375, Time: 0.2541368007659912 ms\n",
            "Epoch 87, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 65 % Epoch Time: 6.88512396812439 ms\n",
            "Epoch 88:[0/16], Current Loss: 0.9048361778259277, Current Training Accuracy: 100.0, Time: 0.27513813972473145 ms\n",
            "Epoch 88:[5/16], Current Loss: 0.9204613566398621, Current Training Accuracy: 98.69791666666667, Time: 0.25548410415649414 ms\n",
            "Epoch 88:[10/16], Current Loss: 0.9119403958320618, Current Training Accuracy: 98.36647727272727, Time: 0.25431084632873535 ms\n",
            "Epoch 88:[15/16], Current Loss: 0.9269871115684509, Current Training Accuracy: 98.388671875, Time: 0.25018906593322754 ms\n",
            "Epoch 88, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.893439292907715 ms\n",
            "Epoch 89:[0/16], Current Loss: 0.9282738566398621, Current Training Accuracy: 97.65625, Time: 0.274921178817749 ms\n",
            "Epoch 89:[5/16], Current Loss: 0.9120052456855774, Current Training Accuracy: 98.56770833333333, Time: 0.26619863510131836 ms\n",
            "Epoch 89:[10/16], Current Loss: 0.9269222021102905, Current Training Accuracy: 98.22443181818181, Time: 0.2531626224517822 ms\n",
            "Epoch 89:[15/16], Current Loss: 0.91264808177948, Current Training Accuracy: 98.388671875, Time: 0.25149011611938477 ms\n",
            "Epoch 89, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.858381509780884 ms\n",
            "Epoch 90:[0/16], Current Loss: 0.9360859990119934, Current Training Accuracy: 96.875, Time: 0.2781360149383545 ms\n",
            "Epoch 90:[5/16], Current Loss: 0.9204609394073486, Current Training Accuracy: 98.17708333333333, Time: 0.2587440013885498 ms\n",
            "Epoch 90:[10/16], Current Loss: 0.9119405746459961, Current Training Accuracy: 98.22443181818181, Time: 0.25679755210876465 ms\n",
            "Epoch 90:[15/16], Current Loss: 0.9275650978088379, Current Training Accuracy: 98.388671875, Time: 0.2509036064147949 ms\n",
            "Epoch 90, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.87121057510376 ms\n",
            "Epoch 91:[0/16], Current Loss: 0.9262140393257141, Current Training Accuracy: 97.65625, Time: 0.2797269821166992 ms\n",
            "Epoch 91:[5/16], Current Loss: 0.9275662899017334, Current Training Accuracy: 98.4375, Time: 0.2542276382446289 ms\n",
            "Epoch 91:[10/16], Current Loss: 0.9353779554367065, Current Training Accuracy: 98.08238636363636, Time: 0.2534801959991455 ms\n",
            "Epoch 91:[15/16], Current Loss: 0.9354522228240967, Current Training Accuracy: 98.388671875, Time: 0.2507622241973877 ms\n",
            "Epoch 91, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.904742479324341 ms\n",
            "Epoch 92:[0/16], Current Loss: 0.9197522401809692, Current Training Accuracy: 98.4375, Time: 0.285616397857666 ms\n",
            "Epoch 92:[5/16], Current Loss: 0.911941409111023, Current Training Accuracy: 98.69791666666667, Time: 0.26273250579833984 ms\n",
            "Epoch 92:[10/16], Current Loss: 0.9204606413841248, Current Training Accuracy: 98.1534090909091, Time: 0.25606560707092285 ms\n",
            "Epoch 92:[15/16], Current Loss: 0.9048365950584412, Current Training Accuracy: 98.388671875, Time: 0.2524378299713135 ms\n",
            "Epoch 92, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.914705514907837 ms\n",
            "Epoch 93:[0/16], Current Loss: 0.9282729029655457, Current Training Accuracy: 97.65625, Time: 0.282289981842041 ms\n",
            "Epoch 93:[5/16], Current Loss: 0.9204604625701904, Current Training Accuracy: 98.17708333333333, Time: 0.25576210021972656 ms\n",
            "Epoch 93:[10/16], Current Loss: 0.9048354029655457, Current Training Accuracy: 98.36647727272727, Time: 0.2540590763092041 ms\n",
            "Epoch 93:[15/16], Current Loss: 0.9276295900344849, Current Training Accuracy: 98.388671875, Time: 0.25046563148498535 ms\n",
            "Epoch 93, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.929253101348877 ms\n",
            "Epoch 94:[0/16], Current Loss: 0.9198163747787476, Current Training Accuracy: 98.4375, Time: 0.2783966064453125 ms\n",
            "Epoch 94:[5/16], Current Loss: 0.9204609394073486, Current Training Accuracy: 98.046875, Time: 0.25809574127197266 ms\n",
            "Epoch 94:[10/16], Current Loss: 0.9268577694892883, Current Training Accuracy: 98.36647727272727, Time: 0.2534058094024658 ms\n",
            "Epoch 94:[15/16], Current Loss: 0.9275649189949036, Current Training Accuracy: 98.388671875, Time: 0.2530090808868408 ms\n",
            "Epoch 94, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.898642301559448 ms\n",
            "Epoch 95:[0/16], Current Loss: 0.9276292324066162, Current Training Accuracy: 97.65625, Time: 0.27895402908325195 ms\n",
            "Epoch 95:[5/16], Current Loss: 0.919816792011261, Current Training Accuracy: 98.046875, Time: 0.2574746608734131 ms\n",
            "Epoch 95:[10/16], Current Loss: 0.9204601049423218, Current Training Accuracy: 98.36647727272727, Time: 0.2555844783782959 ms\n",
            "Epoch 95:[15/16], Current Loss: 0.92046058177948, Current Training Accuracy: 98.4375, Time: 0.2501511573791504 ms\n",
            "Epoch 95, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.893458604812622 ms\n",
            "Epoch 96:[0/16], Current Loss: 0.9269228577613831, Current Training Accuracy: 97.65625, Time: 0.27335357666015625 ms\n",
            "Epoch 96:[5/16], Current Loss: 0.9204611778259277, Current Training Accuracy: 98.17708333333333, Time: 0.25575733184814453 ms\n",
            "Epoch 96:[10/16], Current Loss: 0.9198167324066162, Current Training Accuracy: 98.36647727272727, Time: 0.2546207904815674 ms\n",
            "Epoch 96:[15/16], Current Loss: 0.9126476049423218, Current Training Accuracy: 98.4375, Time: 0.2519805431365967 ms\n",
            "Epoch 96, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.913940191268921 ms\n",
            "Epoch 97:[0/16], Current Loss: 0.9048355221748352, Current Training Accuracy: 100.0, Time: 0.2753453254699707 ms\n",
            "Epoch 97:[5/16], Current Loss: 0.9197525382041931, Current Training Accuracy: 98.828125, Time: 0.26165127754211426 ms\n",
            "Epoch 97:[10/16], Current Loss: 0.9347352981567383, Current Training Accuracy: 98.57954545454545, Time: 0.25597047805786133 ms\n",
            "Epoch 97:[15/16], Current Loss: 0.9282728433609009, Current Training Accuracy: 98.388671875, Time: 0.252521276473999 ms\n",
            "Epoch 97, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.877945423126221 ms\n",
            "Epoch 98:[0/16], Current Loss: 0.91975337266922, Current Training Accuracy: 98.4375, Time: 0.28159475326538086 ms\n",
            "Epoch 98:[5/16], Current Loss: 0.9126479029655457, Current Training Accuracy: 98.4375, Time: 0.2560422420501709 ms\n",
            "Epoch 98:[10/16], Current Loss: 0.9198966026306152, Current Training Accuracy: 98.4375, Time: 0.2556459903717041 ms\n",
            "Epoch 98:[15/16], Current Loss: 0.9282733201980591, Current Training Accuracy: 98.4375, Time: 0.2544562816619873 ms\n",
            "Epoch 98, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.918619632720947 ms\n",
            "Epoch 99:[0/16], Current Loss: 0.9199145436286926, Current Training Accuracy: 98.4375, Time: 0.2770507335662842 ms\n",
            "Epoch 99:[5/16], Current Loss: 0.9191144108772278, Current Training Accuracy: 98.30729166666667, Time: 0.2674696445465088 ms\n",
            "Epoch 99:[10/16], Current Loss: 0.9126476049423218, Current Training Accuracy: 98.4375, Time: 0.2554047107696533 ms\n",
            "Epoch 99:[15/16], Current Loss: 0.9360852241516113, Current Training Accuracy: 98.388671875, Time: 0.2507753372192383 ms\n",
            "Epoch 99, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.902547836303711 ms\n",
            "Epoch 100:[0/16], Current Loss: 0.9432547092437744, Current Training Accuracy: 96.09375, Time: 0.27707886695861816 ms\n",
            "Epoch 100:[5/16], Current Loss: 0.9198166131973267, Current Training Accuracy: 98.4375, Time: 0.2553861141204834 ms\n",
            "Epoch 100:[10/16], Current Loss: 0.9204603433609009, Current Training Accuracy: 98.29545454545455, Time: 0.2548501491546631 ms\n",
            "Epoch 100:[15/16], Current Loss: 0.9198188185691833, Current Training Accuracy: 98.4375, Time: 0.2530806064605713 ms\n",
            "Epoch 100, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.888274431228638 ms\n",
            "Epoch 101:[0/16], Current Loss: 0.9360858201980591, Current Training Accuracy: 96.875, Time: 0.2733733654022217 ms\n",
            "Epoch 101:[5/16], Current Loss: 0.9275692105293274, Current Training Accuracy: 98.17708333333333, Time: 0.2539205551147461 ms\n",
            "Epoch 101:[10/16], Current Loss: 0.9425510764122009, Current Training Accuracy: 98.1534090909091, Time: 0.25498270988464355 ms\n",
            "Epoch 101:[15/16], Current Loss: 0.9119411706924438, Current Training Accuracy: 98.388671875, Time: 0.25174736976623535 ms\n",
            "Epoch 101, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.857972145080566 ms\n",
            "Epoch 102:[0/16], Current Loss: 0.9048351049423218, Current Training Accuracy: 100.0, Time: 0.278980016708374 ms\n",
            "Epoch 102:[5/16], Current Loss: 0.9349551200866699, Current Training Accuracy: 98.046875, Time: 0.2605922222137451 ms\n",
            "Epoch 102:[10/16], Current Loss: 0.9275673627853394, Current Training Accuracy: 98.22443181818181, Time: 0.25617241859436035 ms\n",
            "Epoch 102:[15/16], Current Loss: 0.9126480221748352, Current Training Accuracy: 98.4375, Time: 0.2530512809753418 ms\n",
            "Epoch 102, train Loss: 0.920  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.911695957183838 ms\n",
            "Epoch 103:[0/16], Current Loss: 0.9358314871788025, Current Training Accuracy: 96.875, Time: 0.27837634086608887 ms\n",
            "Epoch 103:[5/16], Current Loss: 0.9268617630004883, Current Training Accuracy: 98.30729166666667, Time: 0.26505541801452637 ms\n",
            "Epoch 103:[10/16], Current Loss: 0.9119420051574707, Current Training Accuracy: 98.1534090909091, Time: 0.25690507888793945 ms\n",
            "Epoch 103:[15/16], Current Loss: 0.9204602837562561, Current Training Accuracy: 98.388671875, Time: 0.25130796432495117 ms\n",
            "Epoch 103, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.942961692810059 ms\n",
            "Epoch 104:[0/16], Current Loss: 0.9126476645469666, Current Training Accuracy: 99.21875, Time: 0.2866816520690918 ms\n",
            "Epoch 104:[5/16], Current Loss: 0.9048354625701904, Current Training Accuracy: 98.69791666666667, Time: 0.25544142723083496 ms\n",
            "Epoch 104:[10/16], Current Loss: 0.927568256855011, Current Training Accuracy: 98.4375, Time: 0.2565295696258545 ms\n",
            "Epoch 104:[15/16], Current Loss: 0.9360857605934143, Current Training Accuracy: 98.388671875, Time: 0.25136351585388184 ms\n",
            "Epoch 104, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.916669130325317 ms\n",
            "Epoch 105:[0/16], Current Loss: 0.9121343493461609, Current Training Accuracy: 99.21875, Time: 0.2755284309387207 ms\n",
            "Epoch 105:[5/16], Current Loss: 0.9197736978530884, Current Training Accuracy: 98.30729166666667, Time: 0.2594165802001953 ms\n",
            "Epoch 105:[10/16], Current Loss: 0.9354439973831177, Current Training Accuracy: 98.22443181818181, Time: 0.2529289722442627 ms\n",
            "Epoch 105:[15/16], Current Loss: 0.9275648593902588, Current Training Accuracy: 98.388671875, Time: 0.252246618270874 ms\n",
            "Epoch 105, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.962329149246216 ms\n",
            "Epoch 106:[0/16], Current Loss: 0.9048365354537964, Current Training Accuracy: 100.0, Time: 0.2789785861968994 ms\n",
            "Epoch 106:[5/16], Current Loss: 0.9197535514831543, Current Training Accuracy: 97.65625, Time: 0.2636840343475342 ms\n",
            "Epoch 106:[10/16], Current Loss: 0.9048358201980591, Current Training Accuracy: 98.36647727272727, Time: 0.2576780319213867 ms\n",
            "Epoch 106:[15/16], Current Loss: 0.9048361778259277, Current Training Accuracy: 98.388671875, Time: 0.2503643035888672 ms\n",
            "Epoch 106, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.906404733657837 ms\n",
            "Epoch 107:[0/16], Current Loss: 0.9048370718955994, Current Training Accuracy: 100.0, Time: 0.275317907333374 ms\n",
            "Epoch 107:[5/16], Current Loss: 0.926935613155365, Current Training Accuracy: 98.56770833333333, Time: 0.2574350833892822 ms\n",
            "Epoch 107:[10/16], Current Loss: 0.934670627117157, Current Training Accuracy: 98.22443181818181, Time: 0.2543187141418457 ms\n",
            "Epoch 107:[15/16], Current Loss: 0.9282732009887695, Current Training Accuracy: 98.388671875, Time: 0.2553706169128418 ms\n",
            "Epoch 107, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.894545793533325 ms\n",
            "Epoch 108:[0/16], Current Loss: 0.9204620122909546, Current Training Accuracy: 98.4375, Time: 0.27643299102783203 ms\n",
            "Epoch 108:[5/16], Current Loss: 0.9275700449943542, Current Training Accuracy: 98.30729166666667, Time: 0.2557718753814697 ms\n",
            "Epoch 108:[10/16], Current Loss: 0.9126487970352173, Current Training Accuracy: 98.36647727272727, Time: 0.25632476806640625 ms\n",
            "Epoch 108:[15/16], Current Loss: 0.9119439721107483, Current Training Accuracy: 98.388671875, Time: 0.2508077621459961 ms\n",
            "Epoch 108, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.90473747253418 ms\n",
            "Epoch 109:[0/16], Current Loss: 0.9197567701339722, Current Training Accuracy: 98.4375, Time: 0.2701528072357178 ms\n",
            "Epoch 109:[5/16], Current Loss: 0.9198320508003235, Current Training Accuracy: 97.91666666666667, Time: 0.25715065002441406 ms\n",
            "Epoch 109:[10/16], Current Loss: 0.9282729625701904, Current Training Accuracy: 98.29545454545455, Time: 0.2565581798553467 ms\n",
            "Epoch 109:[15/16], Current Loss: 0.9048362374305725, Current Training Accuracy: 98.388671875, Time: 0.25103211402893066 ms\n",
            "Epoch 109, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.904684543609619 ms\n",
            "Epoch 110:[0/16], Current Loss: 0.9282742142677307, Current Training Accuracy: 97.65625, Time: 0.2763979434967041 ms\n",
            "Epoch 110:[5/16], Current Loss: 0.9347399473190308, Current Training Accuracy: 97.78645833333333, Time: 0.25424647331237793 ms\n",
            "Epoch 110:[10/16], Current Loss: 0.9048353433609009, Current Training Accuracy: 98.1534090909091, Time: 0.2555503845214844 ms\n",
            "Epoch 110:[15/16], Current Loss: 0.9119424819946289, Current Training Accuracy: 98.388671875, Time: 0.25143980979919434 ms\n",
            "Epoch 110, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.939496040344238 ms\n",
            "Epoch 111:[0/16], Current Loss: 0.9126478433609009, Current Training Accuracy: 99.21875, Time: 0.2735142707824707 ms\n",
            "Epoch 111:[5/16], Current Loss: 0.91264808177948, Current Training Accuracy: 98.4375, Time: 0.2545359134674072 ms\n",
            "Epoch 111:[10/16], Current Loss: 0.9277370572090149, Current Training Accuracy: 98.4375, Time: 0.25192809104919434 ms\n",
            "Epoch 111:[15/16], Current Loss: 0.9204614758491516, Current Training Accuracy: 98.388671875, Time: 0.24947190284729004 ms\n",
            "Epoch 111, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.916022300720215 ms\n",
            "Epoch 112:[0/16], Current Loss: 0.9198698401451111, Current Training Accuracy: 98.4375, Time: 0.27841901779174805 ms\n",
            "Epoch 112:[5/16], Current Loss: 0.9275761246681213, Current Training Accuracy: 97.91666666666667, Time: 0.2543141841888428 ms\n",
            "Epoch 112:[10/16], Current Loss: 0.9126490950584412, Current Training Accuracy: 98.36647727272727, Time: 0.25745654106140137 ms\n",
            "Epoch 112:[15/16], Current Loss: 0.9126492142677307, Current Training Accuracy: 98.388671875, Time: 0.24918174743652344 ms\n",
            "Epoch 112, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.861742734909058 ms\n",
            "Epoch 113:[0/16], Current Loss: 0.9119412899017334, Current Training Accuracy: 99.21875, Time: 0.27620434761047363 ms\n",
            "Epoch 113:[5/16], Current Loss: 0.9048355221748352, Current Training Accuracy: 98.69791666666667, Time: 0.26658058166503906 ms\n",
            "Epoch 113:[10/16], Current Loss: 0.9282732009887695, Current Training Accuracy: 98.4375, Time: 0.2535400390625 ms\n",
            "Epoch 113:[15/16], Current Loss: 0.9347503781318665, Current Training Accuracy: 98.388671875, Time: 0.2513716220855713 ms\n",
            "Epoch 113, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.895765066146851 ms\n",
            "Epoch 114:[0/16], Current Loss: 0.9190559983253479, Current Training Accuracy: 98.4375, Time: 0.2788424491882324 ms\n",
            "Epoch 114:[5/16], Current Loss: 0.9275674819946289, Current Training Accuracy: 98.56770833333333, Time: 0.25602173805236816 ms\n",
            "Epoch 114:[10/16], Current Loss: 0.9198219180107117, Current Training Accuracy: 98.50852272727273, Time: 0.25365209579467773 ms\n",
            "Epoch 114:[15/16], Current Loss: 0.9275656342506409, Current Training Accuracy: 98.388671875, Time: 0.2514345645904541 ms\n",
            "Epoch 114, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.920896291732788 ms\n",
            "Epoch 115:[0/16], Current Loss: 0.9197721481323242, Current Training Accuracy: 98.4375, Time: 0.2720625400543213 ms\n",
            "Epoch 115:[5/16], Current Loss: 0.9204612970352173, Current Training Accuracy: 98.56770833333333, Time: 0.26388978958129883 ms\n",
            "Epoch 115:[10/16], Current Loss: 0.9276335835456848, Current Training Accuracy: 98.50852272727273, Time: 0.2562596797943115 ms\n",
            "Epoch 115:[15/16], Current Loss: 0.9197549819946289, Current Training Accuracy: 98.388671875, Time: 0.2517240047454834 ms\n",
            "Epoch 115, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.8790953159332275 ms\n",
            "Epoch 116:[0/16], Current Loss: 0.927565336227417, Current Training Accuracy: 97.65625, Time: 0.2744028568267822 ms\n",
            "Epoch 116:[5/16], Current Loss: 0.9126481413841248, Current Training Accuracy: 98.30729166666667, Time: 0.25710105895996094 ms\n",
            "Epoch 116:[10/16], Current Loss: 0.9048359990119934, Current Training Accuracy: 98.65056818181819, Time: 0.254835844039917 ms\n",
            "Epoch 116:[15/16], Current Loss: 0.92046058177948, Current Training Accuracy: 98.388671875, Time: 0.2507028579711914 ms\n",
            "Epoch 116, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.863134384155273 ms\n",
            "Epoch 117:[0/16], Current Loss: 0.9126483798027039, Current Training Accuracy: 99.21875, Time: 0.2767934799194336 ms\n",
            "Epoch 117:[5/16], Current Loss: 0.9190444946289062, Current Training Accuracy: 98.30729166666667, Time: 0.2555830478668213 ms\n",
            "Epoch 117:[10/16], Current Loss: 0.9354416131973267, Current Training Accuracy: 98.22443181818181, Time: 0.253978967666626 ms\n",
            "Epoch 117:[15/16], Current Loss: 0.9198168516159058, Current Training Accuracy: 98.388671875, Time: 0.25007081031799316 ms\n",
            "Epoch 117, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 66 % Epoch Time: 6.85436224937439 ms\n",
            "Epoch 118:[0/16], Current Loss: 0.9197520613670349, Current Training Accuracy: 98.4375, Time: 0.2750217914581299 ms\n",
            "Epoch 118:[5/16], Current Loss: 0.9197519421577454, Current Training Accuracy: 98.4375, Time: 0.2529299259185791 ms\n",
            "Epoch 118:[10/16], Current Loss: 0.9360851049423218, Current Training Accuracy: 98.22443181818181, Time: 0.25638508796691895 ms\n",
            "Epoch 118:[15/16], Current Loss: 0.9048348069190979, Current Training Accuracy: 98.388671875, Time: 0.2545936107635498 ms\n",
            "Epoch 118, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.878900527954102 ms\n",
            "Epoch 119:[0/16], Current Loss: 0.9198170304298401, Current Training Accuracy: 98.4375, Time: 0.27805590629577637 ms\n",
            "Epoch 119:[5/16], Current Loss: 0.9204601645469666, Current Training Accuracy: 98.30729166666667, Time: 0.2650327682495117 ms\n",
            "Epoch 119:[10/16], Current Loss: 0.9282726645469666, Current Training Accuracy: 98.36647727272727, Time: 0.25615715980529785 ms\n",
            "Epoch 119:[15/16], Current Loss: 0.9048349857330322, Current Training Accuracy: 98.388671875, Time: 0.25088000297546387 ms\n",
            "Epoch 119, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.920047044754028 ms\n",
            "Epoch 120:[0/16], Current Loss: 0.9048351645469666, Current Training Accuracy: 100.0, Time: 0.28257036209106445 ms\n",
            "Epoch 120:[5/16], Current Loss: 0.9126486778259277, Current Training Accuracy: 98.828125, Time: 0.2546570301055908 ms\n",
            "Epoch 120:[10/16], Current Loss: 0.9204604029655457, Current Training Accuracy: 98.29545454545455, Time: 0.2554481029510498 ms\n",
            "Epoch 120:[15/16], Current Loss: 0.9126477837562561, Current Training Accuracy: 98.388671875, Time: 0.2532801628112793 ms\n",
            "Epoch 120, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.911752223968506 ms\n",
            "Epoch 121:[0/16], Current Loss: 0.9204602837562561, Current Training Accuracy: 98.4375, Time: 0.27587223052978516 ms\n",
            "Epoch 121:[5/16], Current Loss: 0.9275652170181274, Current Training Accuracy: 98.56770833333333, Time: 0.2529325485229492 ms\n",
            "Epoch 121:[10/16], Current Loss: 0.9204601049423218, Current Training Accuracy: 98.36647727272727, Time: 0.2534360885620117 ms\n",
            "Epoch 121:[15/16], Current Loss: 0.9275646805763245, Current Training Accuracy: 98.388671875, Time: 0.251629114151001 ms\n",
            "Epoch 121, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.904731512069702 ms\n",
            "Epoch 122:[0/16], Current Loss: 0.9204596877098083, Current Training Accuracy: 98.4375, Time: 0.28040027618408203 ms\n",
            "Epoch 122:[5/16], Current Loss: 0.9126478433609009, Current Training Accuracy: 98.69791666666667, Time: 0.2542095184326172 ms\n",
            "Epoch 122:[10/16], Current Loss: 0.9353776574134827, Current Training Accuracy: 98.36647727272727, Time: 0.25631022453308105 ms\n",
            "Epoch 122:[15/16], Current Loss: 0.9126470685005188, Current Training Accuracy: 98.388671875, Time: 0.2518024444580078 ms\n",
            "Epoch 122, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.9148736000061035 ms\n",
            "Epoch 123:[0/16], Current Loss: 0.912647008895874, Current Training Accuracy: 99.21875, Time: 0.28400158882141113 ms\n",
            "Epoch 123:[5/16], Current Loss: 0.9120035767555237, Current Training Accuracy: 98.69791666666667, Time: 0.25670528411865234 ms\n",
            "Epoch 123:[10/16], Current Loss: 0.9204598665237427, Current Training Accuracy: 98.57954545454545, Time: 0.25226283073425293 ms\n",
            "Epoch 123:[15/16], Current Loss: 0.943189799785614, Current Training Accuracy: 98.388671875, Time: 0.2526893615722656 ms\n",
            "Epoch 123, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.901670217514038 ms\n",
            "Epoch 124:[0/16], Current Loss: 0.9197530150413513, Current Training Accuracy: 98.4375, Time: 0.2951996326446533 ms\n",
            "Epoch 124:[5/16], Current Loss: 0.9120040535926819, Current Training Accuracy: 98.30729166666667, Time: 0.25787997245788574 ms\n",
            "Epoch 124:[10/16], Current Loss: 0.9048352241516113, Current Training Accuracy: 98.22443181818181, Time: 0.2521240711212158 ms\n",
            "Epoch 124:[15/16], Current Loss: 0.9119413495063782, Current Training Accuracy: 98.388671875, Time: 0.25115084648132324 ms\n",
            "Epoch 124, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.912172555923462 ms\n",
            "Epoch 125:[0/16], Current Loss: 0.9204602837562561, Current Training Accuracy: 98.4375, Time: 0.2750582695007324 ms\n",
            "Epoch 125:[5/16], Current Loss: 0.912647008895874, Current Training Accuracy: 98.69791666666667, Time: 0.2677040100097656 ms\n",
            "Epoch 125:[10/16], Current Loss: 0.9126474857330322, Current Training Accuracy: 98.36647727272727, Time: 0.25328683853149414 ms\n",
            "Epoch 125:[15/16], Current Loss: 0.9269205927848816, Current Training Accuracy: 98.388671875, Time: 0.25267624855041504 ms\n",
            "Epoch 125, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.873031854629517 ms\n",
            "Epoch 126:[0/16], Current Loss: 0.9197521209716797, Current Training Accuracy: 98.4375, Time: 0.2790501117706299 ms\n",
            "Epoch 126:[5/16], Current Loss: 0.9126470685005188, Current Training Accuracy: 97.65625, Time: 0.26446986198425293 ms\n",
            "Epoch 126:[10/16], Current Loss: 0.9198160171508789, Current Training Accuracy: 98.08238636363636, Time: 0.2549738883972168 ms\n",
            "Epoch 126:[15/16], Current Loss: 0.9119399189949036, Current Training Accuracy: 98.388671875, Time: 0.24962663650512695 ms\n",
            "Epoch 126, train Loss: 0.921  Avg Training Accuracy: {97 %} Avg Validation Accuracy: 67 % Epoch Time: 6.9339683055877686 ms\n",
            "Epoch 127:[0/16], Current Loss: 0.9204596281051636, Current Training Accuracy: 98.4375, Time: 0.2790799140930176 ms\n",
            "Epoch 127:[5/16], Current Loss: 0.9204607605934143, Current Training Accuracy: 98.4375, Time: 0.2526397705078125 ms\n",
            "Epoch 127:[10/16], Current Loss: 0.9048351645469666, Current Training Accuracy: 98.50852272727273, Time: 0.2685534954071045 ms\n",
            "Epoch 127:[15/16], Current Loss: 0.9353792071342468, Current Training Accuracy: 98.388671875, Time: 0.25278449058532715 ms\n",
            "Epoch 127, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 67 % Epoch Time: 6.896780014038086 ms\n",
            "Epoch 128:[0/16], Current Loss: 0.9204597473144531, Current Training Accuracy: 98.4375, Time: 0.2807295322418213 ms\n",
            "Epoch 128:[5/16], Current Loss: 0.9197561740875244, Current Training Accuracy: 98.046875, Time: 0.2555551528930664 ms\n",
            "Epoch 128:[10/16], Current Loss: 0.9120035171508789, Current Training Accuracy: 98.57954545454545, Time: 0.2562417984008789 ms\n",
            "Epoch 128:[15/16], Current Loss: 0.9282723665237427, Current Training Accuracy: 98.388671875, Time: 0.2507917881011963 ms\n",
            "Epoch 128, train Loss: 0.921  Avg Training Accuracy: {98 %} Avg Validation Accuracy: 68 % Epoch Time: 6.909473419189453 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "pred_correct_num=[]\n",
        "pred_total_num=[]\n",
        "pred_result_list=[]\n",
        "pred_prob_list = []\n",
        "label_prob_list=[]\n",
        "label_list=[]\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "    t_image, mask = data[0],torch.max(data[1],1)[1].long()\n",
        "    mask=mask.cuda()\n",
        "    output_test=model(t_image)\n",
        "    pred_prob_list.append(output_test)\n",
        "    label_prob_list.append(data[1])\n",
        "    label_list.append(mask)\n",
        "    output=torch.max(output_test,1)[1].long()\n",
        "    pred_result_list.append(output)\n",
        "    pred_correct_num.append(output.eq(mask).sum().item())\n",
        "    pred_total_num.append(output_test.shape[0])\n",
        "acc_test=sum(pred_correct_num)/sum(pred_total_num)\n",
        "print(\"The accuracy of detecting news bias: {}\".format(('%.4f%%'%(acc_test*100))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E32ZtsCAi6g",
        "outputId": "daa2fe6d-9bbb-4fd9-81d6-777408922faf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of detecting news bias: 84.1146%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "for i in range(len(pred_result_list)):\n",
        "  if len(pred_result_list) == 1:\n",
        "    pred_result = pred_result_list[0]\n",
        "    label = label_list[0]\n",
        "  if len(pred_result_list) == 2:\n",
        "    pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
        "    label = torch.cat((label_list[0], label_list[1]), -1)\n",
        "  if len(pred_result_list) > 2:\n",
        "    pred_result = torch.cat((pred_result_list[0], pred_result_list[1]), -1)\n",
        "    label = torch.cat((label_list[0], label_list[1]), -1)\n",
        "    for j in range(len(pred_result_list)-2):\n",
        "      pred_result = torch.cat((pred_result, pred_result_list[j+2]), -1)\n",
        "      label = torch.cat((label, label_list[j+2]), -1)\n",
        "label = label.cpu()\n",
        "pred_result = pred_result.cpu()\n",
        "C=confusion_matrix(label,pred_result)\n",
        "df=pd.DataFrame(C,index=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"],columns=[\"Left\",\"Lean Left\",\"Center\",\"Lean Right\",\"Right\"])\n",
        "p1=sns.heatmap(df,annot=True,cmap=\"hot_r\")\n",
        "s1 = p1.get_figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4SmFYyPqFjS9",
        "outputId": "6ef213c3-95fc-4cd0-c40d-0a93e2358513"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(pred_prob_list)):\n",
        "  if len(pred_prob_list) == 1:\n",
        "    pred_prob = pred_prob_list[0]\n",
        "    label_prob = label_prob_list[0]\n",
        "  if len(pred_prob_list) == 2:\n",
        "    pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
        "    label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
        "  if len(pred_prob_list) > 2:\n",
        "    pred_prob = torch.cat((pred_prob_list[0], pred_prob_list[1]), -1)\n",
        "    label_prob = torch.cat((label_prob_list[0], label_prob_list[1]), -1)\n",
        "    for j in range(len(pred_prob_list)-2):\n",
        "      pred_prob = torch.cat((pred_prob, pred_prob_list[j+2]), -1)\n",
        "      label_prob = torch.cat((label_prob, label_prob_list[j+2]), -1)\n",
        "label_prob = label_prob.cpu()\n",
        "pred_prob = pred_prob.cpu()\n",
        "criterion=nn.L1Loss(reduction=\"mean\")\n",
        "loss=criterion(pred_prob, label_prob)\n",
        "print(\"MAE Value: {}\".format(\"%.4f\" % loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al47wIBYFnBK",
        "outputId": "984e5343-86ba-42e5-bd6d-a174de0c484c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE Value: 0.0662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score = f1_score(pred_result,label,average=\"macro\")\n",
        "print(\"Macro-F1 Score: {}\".format(\"%.4f\" % f1_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIBz5QFnFqGq",
        "outputId": "3fc32575-5df6-4c5d-8ef8-57bdf4a78e70"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-F1 Score: 0.8014\n"
          ]
        }
      ]
    }
  ]
}